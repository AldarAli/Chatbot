Detecting UAVs Using Acoustic Camera 
 
 
Jurica Ivošević, Tomislav Radišić, Mario Muštra 
Faculty of Transport and Traffic Sciences 
University of Zagreb 
HR-10000 Zagreb, Croatia 
Email: jivosevic@fpz.hr, tradisic@fpz.hr, mmustra@fpz.hr  
Ivan Bublić, Ivan Tudor, Darije Varžić 
Testing Laboratory 
The Institute for Advancement of Safety 
HR-31000 Osijek, Croatia  
Email: ivan.bublic@zus.hr, ivan.tudor@zus.hr, 
darije.varzic@zus.hr 
 
 
Abstract— Over the past decade, a huge increase in production 
and operation of Unmanned Aerial Vehicles (UAVs) has been 
present on a global scale. To maintain the required level of 
safety and to accommodate the expanding traffic, the 
governments worldwide have implemented regulations to 
operations of UAVs. Nonetheless, in recent years there have 
been numerous safety and security incidents with UAVs, which 
prompted an increase in research of surveillance and 
interdiction methods tailored for UAVs. Detection of UAVs 
using acoustic camera, which is the primary topic of this paper, 
is possible due to UAV’s propeller noise which is predominant 
noise source, at least in multicopter UAVs. We performed a 
detectability test of a commonly used custom made UAV type – 
multirotor with 6 motors. We concluded that small multirotor 
UAVs can be detected with acoustic camera, a human 
interpreter is necessary for detection due to the background 
noise, maximum detection range can be greater than with 
visual detection, and UAV detectability depends on UAV noise 
spectrum, its ratio to background noise, the dynamic range of 
acoustic camera, and its frequency resolution. 
Keywords-UAV; acoustic camera; surveillance; detection. 
I. 
 INTRODUCTION 
Over the past decade, a huge increase in production and 
operation of UAVs has been present on a global scale. 
According to Federal Aviation Administration (FAA) 
Aerospace Forecast for fiscal years 2017-2037, there are 
currently over 1.1 million registered UAVs in the United 
States (US). By the year 2021, in the US alone, the number 
of registered UAVs is expected to reach 6 million units. Of 
these, three quarters will be hobbyist UAVs and model 
aircraft in the 0.25 kg – 25 kg category [1].  
To maintain the required level of safety and to 
accommodate the expanding traffic, the governments 
worldwide have implemented regulations to operations of 
UAVs. In 2012, US government regulated operation of 
UAVs by publishing Public Law 112-95 - FAA 
Modernization and Reform Act of 2012 [2]. Operation of 
UAVs in Europe has been regulated by the act of European 
Comission in 2008 with Regulation (EC) No 216/2008 for 
UAVs heavier than 150 kilograms, and with national 
regulations for UAVs lighter than 150 kg [3]. In 2017, 
however, a new regulation was proposed with the purpose 
of regulating all categories of UAVs in European Union 
(EU) and it is expected to be adopted during the 2018 [4]. 
Notwithstanding the attempts at regulating the UAV 
operations, the increase in number of operations alone has 
increased the probability of incidents. In [5], UAV sighting 
reports published by FAA dating from December 17, 2013 
to September 12, 2015 were analyzed. FAA reports were 
organized in two categories: Sightings, which included 
incidents where a pilot or an air traffic controller spotted an 
UAV flying within or near the flight paths of manned 
aircraft though not posing an immediate threat or collision, 
and Close Encounters, where a manned aircraft came close 
enough to an UAV that it met the FAA's definition of a 
“near mid-air collision” or close enough that there was a 
possible danger [5]. They have analyzed 921 incident 
reports and deduced that 35.5 % of recorded incidents were 
Close Encounters and that over 90 % of all incidents 
occurred above allowed maximum altitude [5]. 
For safety and security reasons, it is necessary to 
develop methods for detection and monitoring of UAV 
operations in predetermined areas. Conventional methods of 
UAV detection are using radars, visual detection, and 
thermal or acoustic sensors. Radar detection of UAVs based 
on differentiating Doppler signatures of various UAVs was 
successfully performed and described in [6] and [7]. 
However, there are obvious difficulties in using this method 
in urban areas. Visual detection method by analyzing 
images from cameras with image processing algorithms was 
proven somewhat successful, with shortcomings typical of 
visual identification systems, namely false positives in case 
of other flying objects (e.g., birds) [8].  
Another method of UAV detection is thermal imaging, 
which can be used for ground-based detection or for 
airborne collision avoidance during night-time operations. 
To prove that UAV detection using thermal imaging can be 
used as a viable detection system, thermal images obtained 
via FLIR Lepton micro thermal camera mounted on a 
Raspberry Pi processing unit were analyzed [9]. UAVs used 
for testing were DJI Phantom 4, Parrot AR.drone 2, and one 
custom made hexacopter.  
56
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-638-5
SIGNAL 2018 : The Third International Conference on Advances in Signal, Image and Video Processing

Beside conventional methods of detection, possibility of 
detecting UAVs controlled via wireless devices (such as 
Parrot AR Drone) was successfully tested [10]. Authors 
have successfully detected and gained control of targeted 
drone as third party users. One shortcoming of this detection 
method is requirement for a wireless receiver installed on 
UAV. 
Detection using acoustic sensors relies on sound 
emission of different units. Authors in [11] state that UAV 
detection with acoustic array, unlike radar detection and 
visual detection methods, does not depend on the size of 
observed object for detection, but rather on the sound of the 
engine. For their method, however, a requirement is a 
comprehensive database of UAV sounds. 
Detection of UAVs using acoustic camera, which is the 
primary topic of this paper, is possible due to their propeller 
noise, the predominant noise source, at least in multicopter 
UAVs. Propeller noise is composed of tonal and broadband 
components. Tonal component contains basic frequency and 
harmonics. The basic frequency f1 or Blade Pass Frequency 
(BPF) is the product of propeller rotation speed and number 
of propeller blades [12]: 
 
BPF = NR NB 60-1,                                 (1) 
 
where is: 
BPF - basic frequency of tonal propeller component, 
NR - propeller rotation speed (rotations per minute), 
NB - number of propeller blades. 
Besides the base frequency harmonic components also 
appear [12]: 
 
fN = f1 N,                                       (2) 
 
where is: 
fN - frequency of the n-th harmonic, 
f1 - basic tonal frequency, 
N - number of particular harmonic. 
Besides propeller noise, UAV's noise consists of 
airframe and structure borne noise. Airframe noise is the 
result of air flow (wind around airframe). It is of the 
broadband flow mixing type, except where a resonant cavity 
is formed. Its main characteristic is a great dependence on 
UAV's speed. In multirotors, this type of noise is quite low. 
Structure borne noise results from airframe vibrations. 
Various vibration modes excite structural modes. Acoustic 
space again has its acoustic modes that are excited by 
structural modes. This noise is quite complex and in UAV 
operations it does not have a great importance. 
The primary scope of this paper is detection possibility of 
UAVs using acoustic camera. In Section 2 of the paper, we 
describe the methods and apparatus used for the test. In 
Section 3, we show and interpret results of the test, and in the 
Section 4, we draw conclusions and suggest ideas for the 
future work. 
II. 
METHOD AND APPARATUS 
A. Test track 
In order to test the ability of acoustic camera to detect 
small airborne UAV, we flew custom built UAV over a 170 
m long test track (Figure 1). The goal was to determine at 
what distance the UAV could be detected without trying to 
identify it. UAV was flown at the approximately 15 m – 45 
m above ground level and at a steady velocity of around 2 
m/s. The test was performed on a relatively cold winter day 
(4 °C) with little to no wind. The terrain of the polygon was 
grassy, without significant noise sources and without any 
sound sources with predominant tonal components. The test 
was performed in the early afternoon. Equivalent A-
weighted residual (background) noise was 42.5 dB with 41.3 
dB exceeded for 99 % of the measured time. 
 
 
B. Acoustic sensor 
For this test, the acoustic camera produced by The 
Faculty of Mechanical Engineering from Ljubljana, called 
SoundEye, has been used. SoundEye consists of a 
microphone array and an optical camera in the center. It can 
work in two different configurations, basic (Figure 2, left), 
with 30 microphones equally distributed on the circular disc 
carrier, and extended, with 54 microphones – 3 flat 
extensions with 8 microphones each attached to the basic 
circular carrier at the angle of 120° to each other (Figure 2, 
right). The camera has fixed Field-of-View (FOV) angles, 
horizontal FOV of 58° and vertical FOV of 44° (these are 
angles at which the scene is covered by both optical and 
acoustic camera). Detailed camera specifications can be 
found in Table 1. 
The working principle of an acoustic camera is based on 
the microphone array’s properties to form a highly 
directional beam. The signals from the microphones are 
acquired simultaneously or with known relative time delays 
to be able to use the phase difference between the signals. As 
the sound propagates in the air at a finite known speed, a 
sound source is perceived by the microphones at different 
time instants and at different sound intensities that depend on 
both the sound source location and the microphone location. 
 
 
2m 
170m 
44° 
 
Figure 1. Test track 
57
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-638-5
SIGNAL 2018 : The Third International Conference on Advances in Signal, Image and Video Processing

TABLE I. SOUNDEYE ACOUSTIC CAMERA SPECIFICATIONS 
 
Specification 
Description 
Function  
Imaging device used to locate 
and characterize sound sources 
Producer  
Faculty of mechanical 
engineering, Ljubljana, Slovenia 
Configuration  
Basic and extended 
Number of microphones 
30 (basic), 54 (extended) 
Microphone frequency range 
20 Hz – 20 kHz 
Mapping frequency range 
800 Hz – 12.5 kHz (basic),  
100 Hz – 12.5 kHz (extended) 
Sampling frequency of AD 
converter 
48 kHz 
Sampling resolution 
16 bit/sample 
Algorithm 
Cross Spectral Matrix 
Beamforming 
Analysing spectrum 
1/1 octave, 1/3 octave, FFT 
Optical/acoustic covering angle 
± 58° horizontal, ± 44° vertical 
Optical camera frame rate 
30 fps 
Operating distance 
>5 m 
Mains supply 
USB 
Disc diameter 
0.4 m 
Extension length 
1 m 
Weight 
10 kg 
One of the methods to obtain an acoustic image from the 
measurement 
of 
the 
microphone 
array 
is 
to 
use 
beamforming. By delaying each microphone signal relatively 
to each other and adding them together, the signals coming 
from a specific direction are amplified while signals coming 
from other directions are canceled. The power of this 
resulting signal is then calculated and reported on a power 
map at a pixel corresponding to the specific direction. The 
process is iterated for each direction where the power needs 
to be computed. The algorithm to obtain acoustic picture 
used by SoundEye acoustic camera is Cross Spectral Matrix 
Beamforming. 
The 
working 
principle 
is 
presented 
graphically in Figure 3. 
 
The dynamic range of acoustic image (the ratio of the 
largest to the smallest intensity of sound that can be 
presented, measured in decibels) depends on the frequency 
of the sound source. For the frequencies above the 1000 Hz, 
dynamic range is 24 dB, while for the lowest frequencies is 
smaller – at the frequency of 100 Hz it is about 2 dB. This 
understanding is crucial for interpretation of acoustic images. 
Figure 4 - Figure 6 present examples to better understand 
the interpretation of acoustic images. Directivity function of 
acoustic camera for a certain angle depending on the 
frequency is presented in Figure 4. For this theoretical 
example extended configuration of camera was used and the 
source that emits white noise (random signal having equal 
intensity at different frequencies, giving it a constant power 
Figure 3. Two configurations of acoustic camera 
Signal Delay 
Δ1 
Signal Delay 
Δ2 
Signal Delay 
Δ3 
Signal Delay 
Δ4 
Signal Delay 
Δ5 
Signal Delay 
Δ6 
Sound Pressure 
Sound Pressure Sound Pressure 
Sound Pressure Sound Pressure 
Sound Pressure 
Sound Pressure 
Sound Pressure 
Sound Pressure 
Time 
Time 
Time 
Time 
Time 
Time 
Time 
Time 
Time 
Sum of Signals 
Sum of Signals 
Figure 2. Working principle of the acoustic camera 
58
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-638-5
SIGNAL 2018 : The Third International Conference on Advances in Signal, Image and Video Processing

spectral density) is situated right in the middle of the 
camera’s FOV at the distance of 100 m (far field). Figure 4 
shows the ability to distinguish the emitted sound levels of a 
single source at a selected frequency. The range of angles on 
the vertical axis is chosen to correspond to the horizontal 
FOV of acoustic camera and is equal to 58°. The angle of 
90° is situated at the middle of the axis. Based on the 
calculation, the camera would show the acoustic image of 
the same size at a given frequency as presented in Figure 4. 
For example, at the frequency of 1000 Hz the red area 
(highest level) will be slightly larger than the red area at a 
frequency of 10000 Hz, although the noise emission at both 
frequencies is the same. The ratio between dark red and dark 
blue color is 24 dB. At the frequency range between 1000 Hz 
and 12500 Hz, the dynamic range of the acoustic image is 24 
dB. This does not apply to a frequency range below 1000 Hz.  
 
 
Figure 5 shows directivity function of acoustic camera in 
the frequency range 100 Hz - 1000 Hz with acoustic image 
dynamic range of 5 dB.  
 
As can be seen, dynamic range is much narrower than 
that in Figure 4, especially at frequencies lower than 200 Hz 
(for the same sound emission at all frequencies). If the 
source would emit a sound at 100 Hz (source location right 
in the middle of the camera’s FOV and at the distance of 100 
m) and if the camera would have image dynamics (scale on 
the right side of the characteristics) 5 dB, the algorithm 
would calculate the acoustic image, which would be shown 
in red over the entire picture. 
If the dynamic range would be reduced to 0.5 dB, the 
algorithm would calculate the acoustic image with 
characteristics as shown in Figure 6. A large red circle would 
be displayed in more than half of the image.  
 
The results of the calculation of the acoustic image by an 
acoustic camera algorithm at frequencies lower than 1000 Hz 
and especially lower than 500 Hz should be considered only 
conditionally, both in terms of the range of noise level and in 
terms of the exact position of the noise source. At these 
frequencies, the dynamic range of acoustic images, some of 
which are presented in the results at the next paragraph, is set 
to lower values - from 0.1 dB to 2 dB. 
C. UAV 
A custom built hexacopter was used in this test. The 
specifications are available in Table 2.  
 
TABLE II. SPECIFICATIONS OF THE HEXACOPTER USED IN 
TESTING  
Parameter 
Description 
Size (w/o propellers) 
75 × 75 × 37 cm 
Weight 
4420 g 
Number of motors 
6 
Motor power 
480 W 
Motor type 
Outrunner 
Battery 
LiPo, 6S, 5000 mAh 
Propeller type 
2-blade 
Propeller size 
12” 
 
Figure 6. Directivity function of acoustic camera in the frequency range 
100 Hz - 1000 Hz with acoustic image dynamic range of 0.5 dB 
Figure 5. Directivity function of acoustic camera in the frequency range 
100 Hz - 1000 Hz with acoustic image dynamic range of 5 dB 
Figure 4. Directivity function of acoustic camera in the frequency range 
1000 Hz - 12000 Hz with acoustic image dynamic range of 24 dB  
59
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-638-5
SIGNAL 2018 : The Third International Conference on Advances in Signal, Image and Video Processing

The most important parameter which determines UAVs 
acoustic footprint is propeller rotation speed. This UAV has 
6 motors and their rotation speed varies within certain limits 
to achieve a satisfactory control and stability of the UAV. 
This rotation speed range is unknown so we did 1/3 octave 
band premeasurements of its noise to define a frequency 
band where basic frequency of tonal propeller component 
and its harmonics are situated. 
 
III. 
RESULTS AND DISCUSSION 
First, we did 1/3 octave band measurements of UAV’s 
noise to define a predominant frequency bands. The noise 
was measured by means of Nor140 Sound Analyzer with an 
extensive set of functions available in its expanded version. 
UAV’s noise was recorded in time period of 5 s at the 
distance of 20 m at stabilized UAV flight mode. The noise 
levels were calculated and the characteristics are presented in 
Figure 7. 
 
  
Residual noise is presented in blue color and the UAV’s 
noise in green color. It is obvious that the UAV has 
broadband noise with basic frequency of tonal propeller 
component in 1/3 octave bands of central frequency of 125 
Hz or 160 Hz. The difference of UAVs noise and 
background noise is at least 20 dB for the frequency range 
100 Hz – 20 kHz.  
Next four figures present the most interesting results of 
UAV visibility measurements using acoustic camera. All 
figures consist of four parts. At the top left side is situated a 
black and white photograph with the indicated position of the 
UAV. At the top right side is the overall spectrogram with 
the indicated part of the spectrogram (frequency components 
which originate from the UAV) used for calculation of 
specific acoustic image.  
At the bottom left side is the acoustic image calculated 
from overall spectrogram and at the bottom right side is the 
acoustic image calculated from indicated part of the 
spectrogram. Measurement results at the distance of the 20 m 
are presented in Figure 8. 
 
 
UAV is visually clearly visible. It stands out as the 
dominant noise source within the overall sound image. The 
overall spectrogram highly expresses frequency components 
that come from the UAV. By using the selected part of the 
spectrogram, after signal processing, it is possible to 
determine the location of the UAV very well.    
 
 
Results of the measurements at the distance of 60 m are 
presented in Figure 9. UAV is discernible visually. It stands 
out as the dominant noise source within the overall sound 
image. The spectrogram shows frequency components that 
come from the UAV. By using the selected part of the 
spectrogram, after signal processing, it is possible to 
determine the location of the UAV.  
Measurement results at the distance of the 100 m are 
presented in Figure 10. The UAV is visually noticeable. 
Within the overall sound image it does not stands out. In the 
spectrogram, the frequency components that come from the 
UAV are poorly visualized. By using the selected part of the 
spectrogram, after signal processing, it is possible to 
determine the location of the UAV.  
 
Figure 9. Measurement results at the distance of 60 m 
Figure 8. Measurement results at the distance of 20 m 
Figure 7. One-third octave band measurement results of UAVs noise 
60
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-638-5
SIGNAL 2018 : The Third International Conference on Advances in Signal, Image and Video Processing

 
Measurement results at the distance of the 170 m are 
presented at Figure 11. 
  
The UAV is visually hardly noticeable. Within the 
overall acoustic image, it does not stand out. In the 
spectrogram, the frequency components that originate from 
the UAV are poorly visualized. By using the selected part of 
the spectrogram, after signal processing, it is possible to 
determine the location of the UAV with uncertainty. This is 
the detection limit based on the existing background noise. 
IV. 
CONCLUSIONS 
We have performed a detectability test of commonly 
used custom-made type UAVs. Our goal was to determine 
whether an acoustic sensor could be used to detect multirotor 
UAVs for the purpose of air traffic surveillance or collision 
avoidance. To achieve this, we have flown a custom-built 
UAV over a test track and recorded its movement with the 
SoundEye acoustic camera. 
We concluded that: 
• Small multirotor UAVs can be detected with acoustic 
camera in some conditions; 
• Basic four parameters on which detectability depends 
on are: UAV noise spectrum, its ratio to background 
noise, the dynamic range of acoustic camera, and its 
frequency resolution; 
• Due to background noise, human interpreter is 
necessary in the detection process; 
• Maximum range of detection can be greater than visual 
detection; 
• Due to necessity of human interpreter and time for 
processing, it is questionable whether the acoustic 
camera can be used for air traffic surveillance purposes. 
In the future work, we will test detectability of UAVs 
against noisier background conditions. A more rigorous test 
of detectability will be performed with UAVs appearing 
from unknown directions. Finally, we will test methods for 
reducing the noise signature of an UAV. 
REFERENCES 
 
[1] Federal Aviation Administration, “FAA Aerospace Forecast - 
Fiscal Years 2017-2037”, United States Department of 
Transportation, Washington, 2017. 
[2] United States, “Public Law 112 - 95 - FAA Modernization 
and Reform Act of 2012”, U.S. Goverment Publishing Office, 
Washington, 2012. 
[3] European Comission, “Regulation (EC) No 216/2008”, 
Official Journal of the European Union, Brussels, 2008.  
[4] European Aviation Safety Agency, “Notice of Proposed 
Amendment 2017-05 (A), Introduction of a regulatory 
framework for the operation of drones, Unmanned aircraft 
system operations in the open and specific category”, EASA, 
2017. 
[5] D. Gettinger and M.A. Holland, “Drone Sightings and Close 
Encounters: An Analysis”, Center for the Study of the Drone 
at Bard College, New York. 2015. 
[6] F. Hoffmann, M. Ritchie, F. Fioranelli, A. Charlish, and H. 
Griffiths, “Micro-Doppler Based Detection and Tracking of 
UAVs with Multistatic Radar”, in IEEE Radar Conference, 
Philadelphia. 2016, pp. 1-6 
[7] A. Moses, M. J. Rutherford, and K. P. Valvanis, “Radar-
Based Detection and Identification for Miniature Air 
Vehicles”, in 2011 IEEE Multi-Conference on Systems and 
Control, Denver, 2011, pp. 933-940 
[8] T. Zsedrovits et al., “Collision avoidance for UAV using 
visual detection”, in 2011 IEEE International Symposium of 
Circuits and Systems, Rio de Janeiro, 2011, pp. 2173-2176 
[9] P. Andraši, T. Radišić, M. Muštra, and J. Ivošević, “Night-
time Detection of UAVs using Thermal Infrared Camera”, 
InAIR Conference 2017. Prague, 2017, pp. 183-190 
[10] M. Peacock and M. N. Johnstone, “Towards detection and 
control of civilian unmanned aerial vehicles”, in 14th 
Australian Information Warfare Conference, Perth, 2013, pp. 
9-15 
[11] E. E. Case, A. M. Zelnio, and B.D. Rigling, “Low-Cost 
Acoustic Array for Small UAV Detection and Tracking”, in 
Aerospace and Electronics Conference, Dayton, 2008, pp. 
110-113 
[12] D. Miljković, J. Ivošević, and T. Bucak, “Two vs. three blade 
propeller - cockpit noise comparison”, International Congress 
Alps Adria Acoustics Association 2012 Proceedings, Zadar, 
Croatia, 2012, pp. 1-5 
Figure 11. Measurement results at the distance of 170 m 
Figure 10. Measurement results at the distance of 100 m 
61
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-638-5
SIGNAL 2018 : The Third International Conference on Advances in Signal, Image and Video Processing

