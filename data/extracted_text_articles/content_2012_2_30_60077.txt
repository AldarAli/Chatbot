Mirage: A Real-time Affection Meter via Collaborative Memory Creation and 
Navigation  
Lyn Chao-ling Chen and Yi-ping Hung 
Image and Vision Lab 
Graduate Institute of Networking and Multimedia  
National Taiwan University 
Taipei, Taiwan 
d96944006@ntu.edu.tw hung@csie.ntu.edu.tw 
Abstract—This paper presents an interdisciplinary study on 
social science and computing technology to build a novel 
interactive device Mirage toward presenting the collaborative 
memories of a place. With the support of social science theory, 
the locative media builds a strong connection between the 
participants for sharing similar memories at the same place. 
Using the metaphor of magic crystal ball, we construct the 
Mirage coordinate by system calibration to obtain precise 3D 
directions and distances of hand motions. With the aid of 
computing technologies, participants use their hands to 
manipulate and to reverse the memory axis intuitively, and to 
control the speed of memory stream with the accurate hands 
positions. Through memory navigation, they contact with each 
other by affection communication and create the virtual social 
relationship between them. During the touching process, they 
gradually turn the world into their world with self-memories 
through memory creation, and their self-conscious be 
enhanced. Besides, the experience of attending the digital art 
exhibition helps us to attract the aesthetic people to be involved 
in the experiment that raises the diversity and quality of 
collected data. We also design the affection computation 
method for analysis the affection amplification effect between 
the participants, and the experiment proves the interesting 
social factor influence which we proposed in this paper.  
Keywords-Affective Computing; Collaborative Narrative; 
Human Facial Expression Recognition; Interactive Device; 
Locative Media;  Memory;  Psycogeography 
I. 
 INTRODUCTION  
Human world has concreted and preserved by many 
kinds of memories that form diverse cultures and histories of 
human beings. Ong’s extensive work [1] on orality and 
communication shows many of the characteristics of 
listening prior to print literacy and the recording and 
stockpiling of speech/sound. These memories with affections 
of people are evidences that they ever lived. In the new era 
of rapidly changing technologies, the types of memory 
creation have become various and rich, such as email, MSN 
messages, Twitter, or the social website Facebook. People 
like to share their life experiences with their families and 
friends. That is easier for them to contact with others to form 
a rich virtual social layer upon the real world. But, even from 
now, the major way of displaying the personal histories is 
limited by timeline, and the expression form of their feelings 
is still poor, for example just using the face symbols. That 
brings the issue how to reveal human affection within the 
abundant recorded memories intuitively and automatically.  
This research focuses on to develop a novel interactive 
device for collaborative memory creation and navigation. 
Using the metaphor of crystal ball, participants intuitively 
enter the magical memory space and control the time axis to 
reverse the world with bare hands. Through the memory 
navigation, they sense the strong connections with others 
who ever had similar experiences at the same place. With the 
magical power gift, during the touching process they 
gradually turn the world into their world with self-memories, 
as in the Genesis the God gives Adam life, and enhance their 
self-conscious. We also design the affection computation 
method for analysis the interesting affection amplification 
effect between the participants. 
Figure 1.  The Mirage in Being digital artwork exhibition 
The Mirage attended Being digital artwork exhibition 
held by MOCA museum [2] from December 3, 2011 to 
January 8, 2012 showing on Fig. 1. The experience helped us 
to collect plenty diverse data for experiment. 
This paper starts by revealing a new concept of virtual 
memory creation to open up a new way of memory 
navigation. We then propose Mirage as a novel interactive 
device to realize the collaborative creation and navigation. 
Section 2 provides pointers to related works, including the 
social science theory that supports the design principles for 
Mirage to meet our several expectations. Section 3 describes 
the system implementation including two models for 
38
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-220-2
CONTENT 2012 : The Fourth International Conference on Creative Content Technologies

affection computing. Section 4 presents a preliminary study 
of the system and the analysis on users’ feedbacks, followed 
by the conclusion and future work in Section 5.       
II. 
PRIOR ART 
A. The Virtual Social Relationship 
For the improvement of new technology, a rich virtual 
layer has generated upon the physical world which has 
unique meaning to an individual. As Shotter [3] said, “World 
as activities and events rather than substances and things,” 
and therefore, the virtual world formed from an individual’s 
cognition is more meaningful than the real world. That 
brings the topic to discuss the interesting virtual social 
relationships among the world. SecondLab [4] creates a 
remote lab that allows students to control a microbot 
working with real experience in the social 3D-based 
immersive environment, and creates the novel virtual social 
relationship. Moreover, the virtual interactive activity has 
realized in gameplay field. Uncle Roy All Around You [5] [6] 
held a city game by following online-player’s directions to 
find the mysterious Uncle Roy hidden in the city.  
From virtual social relationship creations, we find out 
that there is a connection within people, content, and location. 
As Salamensky’s theory [7], “a new kind of conversational 
space opens up… The particular mix of spatial metaphor and 
the dynamics of instantaneous communication… build a 
sense of belonging.” Under the premise, the digital content is 
meaningful to people with embedded location information, 
otherwise it is meaningless for the sense of belonging lost. 
Milgram [8] defines a Reality-Virtuality (RV) continuum as 
a way to define how new technologies could form new types 
of realities in the new age. The virtual layer provides us 
abundant resources for digging the new type of social 
relationship and we will further discuss these locative media.          
B. The Locative Media 
Locative media has been realized in the new era for the 
technology improvement. Many smartphones can show the 
locations of users’ near friends, moreover, they also like to 
share where they currently stay via the Facebook’s check-in 
function. It brings the trend that people start to pay a lot of 
attention to location information and it has meaning to them 
with the social aid. Harrison [9] declares the difference 
between the term “space” and “place.” Space is the structure 
of the world, it is a three-dimensional environment, in which 
objects and events occur and have relative positions and 
directions. A place, at the base of previous definition, is a 
space 
invested 
with 
understanding 
of 
behavioral 
appropriateness, cultural expectations, and so forth. Jacob 
[10] and Alexander [11] further illustrate that a place is 
considered including the people’s life experience there with 
deeply-echo social and historical meanings. That starts the 
investment to find out the connection between people and 
place they lived. Sonic City [12] is a real-time music creation 
system that generates different sounds according to the 
buildings or passenger users met on the street, through the 
discovery they are aware of their daily routes and the 
connection of the city is enhanced. However, it doesn’t reach 
to the virtual social layer with the life experiences of 
residents. Urban Tapestries [13] enables people to leave their 
path in the city generating a complex network. They provide 
the geography information on the map, but they can’t interact 
with each other to create virtual social relationship.  
Bakhtin [14] gives explanation of human’s view through 
dialogism. He claims that each person organizes the world 
through his unique experiences. That echoes Shotter’s point 
where the individuals construct their own world by their 
unique cognition. In prior work, Storylog [15] concretes the 
Michael Ende’s [16] Fantasica, in which people create 
virtual social relationship via collaborative narrative 
storytelling. That implies the interaction property of 
Salamensky’s theory. Each avatar they created from their 
unique cognitions is embedded with their true personalities, 
and their different cultural background supports Bakhtin’s 
view. Besides, they name the locations of story world 
creating the relations between people and location echoes 
Shotter’s theory.   
The world concreted from the people’s thoughts leads the 
locative media to the mental level and enables them to turn 
the real world into their own world. The power of turning 
space into “a sense of place” [17] depends on how deep of 
the inner mind people inject to the world.  For the reason, we 
focus on how to reveal the inner layer of people intuitively, 
the memories with their thoughts, minds, and affections.      
C. The Human Affections within Memories 
Memories contain people’s affections and record of their 
life traces. The early researches still narrow on the memory 
retrieval how to help people preserve and recall the valuable 
memories. iRemember [18] retrieves keywords from a huge 
vocal data recorded from everyday conversations with 
campus for two years. The transcript text brightness is 
proportional to recognition confidence that tries to recall 
people’s social experiences. Matthew [19] aims his work 
physically in the health filed to help people with the EMI 
(Elderly Mentally Ill) problems. Using the portable device 
combining with Microsoft SenseCam [20], an off-the-shelf 
voice recorder, and a GPS logger, he records everyday 
behaviors of patients then provides the helpful memory cues. 
But, it still needs the expert knowledge of caregiver to decide 
which good memory cues are.  
The rapid improvement of portable device makes the 
memory recording easy and brings the researches into 
lifelogging field. I Like to Log [21] also records data by 
SenseCam and automatically generates keyfarme images of 
people’s daily lives. It’s like diaries with specific names, 
events and time. The new problem is how to deal with the 
huge amount raw data recorded day after day, and most 
researches are disoriented by the huge log information. 
People keep their memories for sharing their feelings with 
others to form the meaningful lives. That is why we focus on 
the inner layer of people, their affections within memories. 
We try to find out their treasure memory fragments by 
human affection analysis. It was shown that image is a 
stronger material than text, or voice to reveal one’s affection 
state. This research identifies the affection state of people by 
human facial expression recognition and human behavior 
39
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-220-2
CONTENT 2012 : The Fourth International Conference on Creative Content Technologies

 
 
The Memory Flow  
User Viewing 
The Overture 
Self- 
Memory 
… 
Predesigned Images 
Past 
Memory 
Past 
Memory 
Past 
Memory 
Past 
Memory 
60  
Frames 
A user’s  
Memory Creation 
… 
60  
Frames 
60  
Frames 
60  
Frames 
60  
Frames 
60  
Frames 
60  
Frames 
60  
Frames 
The Genesis 
… 
Past 
Memory 
Past 
Memory 
Self- 
Memory 
Self- 
Memory 
Past 
Memory 
Self- 
Memory 
Self- 
Memory 
Self- 
Memory 
Self- 
Memory 
… 
60  
Frames 
60  
Frames 
60  
Frames 
60  
Frames 
60  
Frames 
60  
Frames 
60  
Frames 
60  
Frames 
60  
Frames 
The Genesis 
 
detection, and further analyzes the affection amplification 
effect between them in the common memory world.      
III. 
PROJECT DESCRIPTION 
A. User Scenario 
The memory flow consists of three parts and shows on 
the Fig. 2.  
• 
The Chaos: In idle mode, the crystal ball 
continuously displays a haze through particle 
generation to turn on people’s curiosity. It reveals 
the Chaos world as the initial state of memory world 
without any infections.   
• 
The Overture: The participant touches the crystal 
ball and the haze fades away then the door of 
memory world opens. It starts with a stream of 
predesigned images retouched by artist, and brings 
to participant the experience of passing through the 
time tunnel. In the meantime, it triggers the camera 
to capture his face images continuously.  
• 
The Genesis: After the overture, a tinkle sound alerts 
the participant that he arrives to the territory of 
memory world. It plays the memory fragments 
collected form the past visitors. With the magical 
power gift, he controls the time axis with 
acceleration speed, navigates in the depiction or 
flashback way, and continues or temporally stops to 
view the detail of a memory frame. During the 
touching process, the memory fragments pass 
through his fingers and he will be surprised to see 
own faces showing in the memory flow.  The more 
he involves in, the more he infects the world. The 
memory creation gives the world new element as 
God gives Adam life in Genesis, and finally, the 
world turns into his own world only with his 
memories. During the interaction process, once 
participant’s finger lefts, the world goes back to the 
initial Chaos state showing mysterious haze. 
However, what ever done is irreversible. 
 
Initialization 
Index Record 
Hand Motion Detection 
Information Fusion 
Score Computing 
Weighting 
Adjustment 
 
Emotion Model 
Facial Expression 
Recognition 
Activity Model 
Head Motion 
Detection 
 
Camera Input 
Affection Score 
Database 
The Genesis 
The Collaborative 
Memory Frames 
 
The Overture 
The Predesigned 
Images 
  
The Chaos 
Idle Mode 
Most  
4 Blocks 
The Self-memory 
Frames 
 
Index Update 
 
Figure 2.  Mirage system architecure 
B. Mirage System 
Mirage is an interactive device for collaborative memory 
creation and navigation. After alpha blending processing, the 
3D virtual memories fragments are reflected through a 
Fresnel lens and then are projected in a transparent acrylic 
ball. Using two cameras, we construct Mirage coordinate by 
system calibration to obtain precise 3D directions and 
distances of hand motions. With the specific information, 
users control memory axis and modulate memory stream 
with acceleration speed according to their hands positions. 
Besides, another camera is embedded for ambient capturing 
of their faces during the interaction.  
The system architecture of Mirage shows on Fig. 2. Once 
it detects the user’s hand motion, it triggers the camera to 
continuously capture one block of 60 memories frames. By 
recording the block index, we know the start and end points 
of the user’s memory creation. After one period capturing, 
the block index is updated. In the meantime that adds new 
elements to the current memory world by shifting and 
replacing a block of 60 memories frames. The continuous 
updating maintains the transition in the memory world and 
user can see the evidence of his influence. 
We display one block of past 240 to 180 frames to form 
the past memory stream, and the four blocks of past 240 to 1 
frames to form the current memory world. The interval was 
tested in the design phase and it creates best connection 
between the current and previous users that allows him 
almost to see the previous one’s memories. Therefore, there 
is the best chance within couple friends seeing each other’s 
memories and occurring to the interesting interaction with 
social meaning. Besides, the transition is a skill displaying 
the 
delayed 
memories 
instead 
of 
showing 
them 
simultaneously. That achieves the spirit of slow technology 
[22], which inspires the audiences to discover the meaning of 
artwork by themselves, not teaches them in advance. 
Figure 3.  The components of a user’s memory creation 
The correlation of user’s memory creation and the 
memory flow is shown on Fig. 3. A user’s memory blocks 
will be added one by one to the memory flow by the 
updating mechanism. The first three blocks of memory 
creation capturing in the Overture period are the baseline of a 
user’s affection. The record blocks correspond to the 
predesigned images by the artist for the art aesthetic. We 
only consider the next four blocks to analyze the previous 
one’s affection influence on a user, and ignore the rest blocks 
40
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-220-2
CONTENT 2012 : The Fourth International Conference on Creative Content Technologies

 
corresponding to repeated memories. For the first time, the 
user sees the content and it causes him strongest feelings. For 
the same reason, we choose the next eight blocks which 
contain both previous one’s memories and self-memories, 
and analyze the social factor influence among them. The 
number of rest blocks is without limitation until the end of a 
user’s interaction. We propose a real-time affection analysis 
method to measure the user’s affection level and to verify the 
affection amplification effect.    
C. The Affection Analysis Method 
We consider the facial expression and gesture classes 
from Argyle’s [23] six clues of people’s positive 
communication behaviors and define the human affection by 
emotion model and activity model. In emotion model, we 
define the positive degree of affection by facial expression 
recognition method, and in activity model we identify the 
strong degree of affection by head motion detection. Fig. 4 
shows the four possible affection states of a user. In low 
emotion condition, user is bored within low activity state, 
and is suddenly out of patience with high activity state. In 
high emotion condition, a user is immersed within low 
activity state, and is excited with high activity state.  
Figure 4.  Four possible affection states of a user 
From the observation, no matter which activity state is, 
it reveals a user with positive affection in high emotion 
condition, and with negative affection in low emotion 
condition. The difference is that the strong degree of 
affection that people’s motions generates stronger affection 
than the expressions. Therefore, the flow of affection 
computation is shown on Fig. 2. We combine the detection 
results into emotion and activity scores through information 
fusion, and dynamically adjust the emotion score by the 
activity score as weighting adjustment to enhance the 
previous result. Finally, we come out with the affection 
score A (1). 
a
e
S
S
A
×
=
, where Se ≥ threshold                    (1) 
)
(
a
e
S
S
A
× −
=
, where Se < threshold 
The parameters Se and Sa are emotion and activity score, 
respectively. The positive value represents the positive 
affection of a user and the negative value means the 
negative affection. The threshold of emotion score 0.65 has 
been tested with best identification to distinguish the 
expressiveness and blank faces in the design phase. We 
further describe the adopted methods in each model. 
In the emotion model, based on our previous work [24], 
we consider local and holistic face components. Besides, 
both local facial components and global face are adopted. 
We divide face into seven components including left eye 
(LE), right eye (RE), middle of eyebrows (ME), nose (NS), 
mouth and chin (MC), left cheek (LC), and right cheek (RC), 
and add upper face (UF) and holistic face (HF) components 
to the classification. Then we adopt manifold learning and 
fusion 
classifier 
to 
integrate 
the 
multi-component 
information. Given a face image I, a mapping M: Rd × c→ Rt 
is constructed (2), where c is the number of components, 
mi(．) is an embedding function learned from the manifold 
of component i, and Ii is a d-dimensional sub-image of the i-
th component. 
( )
( )
( )
( )
[
mc Ic ]
m I
m I
M I
,
,
,
2
2
1 1
‥‥
=
             (2) 
The multi-component information is encoded to a t-
dimensional feature vector M(I), where t ≥ c. To 
characterize the significance of components from the 
embedded features, a fusion classifier F: Rt → {Positive, 
Negative} is used based on a binary classifier SVM. After 
the LDE and SVM models construction, we do face 
registration and feature extraction of each component. Then 
we project each component’s feature to the corresponding 
manifold models and calculate the belonging probability of 
each class. Finally, we combine all probabilities as a new 
feature vector, and use it as the input of SVM classifier to 
come out the final result. Through the method, the positive 
affection degree of each memory frame can be recognized. 
In the activity model, for the continuous capturing, we 
adopt face tracking and head motion detection methods in 
each memory block. We run each memory frame through a 
face detection algorithm [25], and come out with the 
locations and sizes of all faces in the image. Then we detect 
face and calculate its movement to find the adapted mapping 
of face movement and head motion score by adjusting the 
variance of a Gaussian. For computing the activity score, 
firstly, we consider the persistent property of a calm state. 
We calculate the calm value of current frame inheriting 
from the previous adjacent frame (3). 
 
UP
c
c
V
S t
S t
+
−
=
)1
(
( )
,if static head             (3) 
)1
(
α
( )
−
×
=
S t
t
S
c
c
, else (where α<1) 
The initial value of Sc(t) is zero. The calm value 
increases stably without any head motion detection within 
41
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-220-2
CONTENT 2012 : The Fourth International Conference on Creative Content Technologies

 
=  #of frames that user is detected positive affections in memory blocks  
# of frames in memory blocks  
Positive Affection Rate    
(4) 
one second sliding window, otherwise it rapidly decreases α 
time (α=1/3 in experiment). Then we use its reciprocal as 
the activity score and define the strong degree of affection. 
When Sc is 0, we set Sa to 100 to avoid the zero divide error 
and define the range of affection score from -100 to 100. 
The higher affection score means more positive affection 
feedback to the corresponding memory blocks in the current 
memory flow; otherwise, the lower affection score 
represents the lesser responses. The method we proposed 
quantifies the affection level of a user and enhances the 
affection by weighting adjustment.  
D. The Mirage Elements 
From the social science support, the elements of Mirage 
are listed as following. 
• 
Time: The memory navigation is a narrative way 
that echoes Ong’s viewpoints and memories which 
are collected from the visitors is with time sequence 
embedded. Besides, the updating mechanism keeps 
the transition with attractive and magical powers, 
always with unknown things to be discovered.  
• 
Location: Nowadays the huge amounts of data are 
contributed without location information embedded. 
They drift on the internet without any meaning to 
others and cause the phenomenon of sense of place 
lost. On the contrary, the locative element binds all 
of the residents and forms the universe of Mirage.        
• 
Interaction: In Mirage, the participant gives the 
world meaning through memory creation and 
changes the architecture of universe via turning it 
into his own world. The architecture will continue 
changes for another participant involving, and will 
turn into a new world to flatter its new master.  
• 
Affection amplification: Through memory creation, 
the residents of Mirage are contacting each other 
even they are not really presented here in the reality. 
Their affections are amplified by the virtual social 
relationship, and it’s more obvious with the “familiar 
elements factor,” the self-memories and their 
friends’ memories.        
IV. 
EVALUATION RESULTS 
During the 37 days exhibition, we collected 347,400 
useful images from 1014 participants which consisted of 
5,790 memory blocks. The camera set were close to the user 
to capture the images with clear faces and expressions of 
participants, and the detail information also helped us to 
compute the affection elements. The special location in the 
culture region of Taipei city easily brings in many artists or 
those who are interested in art and being involved in the 
work. Besides, the nearby Metro station also brings a lot of 
travelers that also expands the diverse and dense properties 
of our data collection. The statistics result of the length of 
participants’ memory blocks is as follows: 38.06% users 
with less than 3 memory blocks reveal the slow technology 
property of the interactive device that they discovered the 
device by themselves and caused many small memory flows; 
39.05% users with 3 to 7 blocks reveal that many of them 
were interested in the past memory navigation and were 
aware of they are part of the memories in the memory flow; 
18.34% users with 7 to 15 blocks and 4.14% users with over 
15 blocks mean many users’ behaviors with high interaction 
properties and often with social factor influences. We 
observed the users interaction behaviors and found out 
interesting circumstances where people changed postures to 
find out the correlation of the delayed memory frames and 
played with their friends to see each other’s faces showing in 
the memory flow. These memory blocks often contain more 
than one face or interchange with the same several faces 
showing on Fig. 5. The virtual social relationship between 
the avatars in virtual memory world and them in the reality 
causes the interesting affection amplification. Therefore, we 
make two assumptions. One is that others’ affections 
amplify an individual’s affection. The other is that the 
familiar element generates strong affection amplification. 
 
Figure 5.  The memory fragments with social factor influence 
We are interested in the positive influence within the 
virtual social relationship.  Therefore, we only consider the 
positive affection state to define our positive affection 
detection rate (4), where the unit is frame.  
Using the affection method to analyze the collected data 
from three stages we mentioned before, the statistics results 
shows as follows. We calculate the original affection state 
of all users from the average of the first three memory 
blocks as the baseline for comparison, and the 63.5892% 
average rate shows that participants are curious about the 
device with high participation. Then from the average of the 
next four blocks we get the affection state after others’ 
affections influences, and the 70.5610% average rate proves 
the first assumption that most of the users’ affections are 
amplified by others’ positive affections through the memory 
navigation. Finally, from the average of the next eight 
blocks define the affection state after the social factor 
influence, and the 74.4864% average rate reveals the 
evidence of the “familiar elements” influences from the self-
memories or the last visitor’s memories. That reveals the 
evidence of social factor intervention and proves the second 
assumption. That is why even with the showing memory 
flow with low positive affection, it also amplifies the users’ 
affections with obvious influence. We also interviewed the 
participants how they felt about the memory navigation, all 
them thought it is interesting and they liked the novel 
42
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-220-2
CONTENT 2012 : The Fourth International Conference on Creative Content Technologies

experience of seeing themselves, and especially people 
whom they know being shown in the memory flow.  
V. 
CONCLUSION AND FUTURE WORKS 
We designed and built the interactive device Mirage to 
create an open, infinite and agnostic memory world. Using 
the metaphor of crystal ball, the users navigate the memory 
world intuitively to sense the connection of the past visitors. 
Moreover, with the magical power gift, they influence the 
world and become part of it through memory creation. The 
collaborative behavior concretes the universe of Mirage, 
which consists of the memories belonged to all of the 
residents in the memory world. The locative media property 
also creates the connection of the preserved memory 
fragments, and forms virtual social relationship between all 
of the participants by sharing common memories.       
We proposed a real-time affection computation system 
for analysis the affection amplification effect among the 
participants. The basic virtual social relationship constructed 
by the locative media plays an important role in the 
experiment. Their affections are amplified each other by 
sharing the similar experiences at the same place. Besides, 
the familiar elements provide obvious evidence of affection 
amplification. From the real-time affection meter mechanism, 
it enables us to add the memory fragments with high positive 
affection simultaneously to the showing memory flow in the 
next version. However, in the current version we keep the 
sequence of memory creation in the memory flow for 
observing the social factor influence.  
This work can be viewed as a pilot study in the field that 
first focuses on the place memory, the collaborative memory 
creation, and the affection amplification effect. During the 
exhibition, we observed the interaction behaviors of the 
participants. Most of them really liked the novel memory 
navigation experiences and felt that the memory creations 
are indeed interesting. Besides, they were not aware of the 
ambient recording that ensures the accurate and authentic 
properties of collected data in the experiment.  
The virtual social relationship can be expanded in our 
future work. For example, a crowd generate stronger 
atmosphere of a place than just single one, therefore, we can 
track every faces in the image to count the numbers as an 
affection adjustment factor. Besides, with the recent growth 
of number of smartphones, it’s common that people take a 
shot and share it to the internet immediately. For the reason, 
the affection analysis method can be applied to the internet 
photo album or the social website with locative information 
tagging, and provides a new display rule by human affection. 
With this pilot study, we believe that the development of 
collaborative memory brings new possibilities in the social 
computing field, and the human affection as the calendar of 
memory world helps to solve the problem of huge amount of 
raw data in the lifelogging field.  
REFERENCES 
[1] W. J. Ong, “Orality and literacy: the technologizing of the 
word,” Lodon. New York: Methuem, 1982. 
[2] MOCA Taipei. Retrived from 
http://www.mocataipei.org.tw/blog/post/27649791   
[3] J. Shotter, “Conversational realities: constructing life through 
languages,” Sage, London, 1993. 
[4] J. Garcia-Zubia, J. Irurzun, I. Angulo, U. Hernandez, M. 
Castro, E. Sancristobal, P. Orduna, and J. Ruiz-de-Garibay, 
“SecondLab: a remote laboratory under second life,” Proc. 
Education Engineering (EDUCON 2010), IEEE Press, 2010, 
pp. 351-356.  
[5] City-wide Performance. Retrieved from 
http://www.equator.ac.uk/index.php/articles/summary/c62/. 
[6] Blast Theory. Retrieved from http://www.blasttheory.co.uk. 
[7] S. I. Salamensky, “Talk, talk, talk: the culture life of  
everyday conversation,” Routledge, London and New York, 
2001, article by S. Turkle and S. L. Salamensky, “Techno talk: 
e-mail, the internet, and other conversations,” pp. 225-246. 
[8] P. 
Milgarm, 
H. 
Takemura, 
A. 
Utsumi, 
and 
F. 
Kishino,“Augmented Reality: a class of displays on the 
Reality-Virtually continnum,” Proc. Telemanipulator and 
Telepresence Technologies (SPIE), 1994, vol. 2351, pp. 282-
292. 
[9] S. Harrison and P. Dourish, “Re-place-ing space: the roles of 
place and space in collaborative systems,” Proc. ACM 
Conference on Computer-Supported Cooperative Work, 
Boston, MA, 1996, submitted for publication. 
[10] J. Jacobs, “The death and life of great American cities,” 
Random house, New York, 1961. 
[11] C. Alexander, “The timeless way of building,” Oxford 
University Press, New York, 1979, submitted for publication.  
[12] L. Gaye, R. Maze, and L. E. Holmquist, “Sonic city: the urban 
environment as a musical interface,” Proc. the 2003 
Conference on New Interfaces for Musical Expression, 
Montreal, Canada, 2003, NIME03-109.  
[13] G. Lane, “Urban tapestries: wireless networking, public 
authuring and social knowledge,” Proc. the Forth Wireless 
World Conference, July 17-18, 2003. 
[14] M. Crang, and N. Thrift, “Thinking space,” Critical 
Geographical Series, Routledge, London and New York, 
article by Holloway, Julian, and Kneale, J. M. Bakhtim, 
“Dialogics of space,” 2002. 
[15] J. L. Chen, “The never ending story: a collaborative narrative 
Storylog,” Proc. the International Computer Symposium, 
2006, pp. 745-752. 
[16] M. Ende and R. Manheim, “The neverending story,” (Reprint 
edition), ISBN 0-14-007431-7, 12, 60, Puffin, January 1, 1993. 
[17] T. Cresswell, “Place: a short introduction,” Blackwell 
publishing, Australia, 2004. 
[18] S. Vemuri, C. Schmandt, and W. Bender, “iRemember: a 
personal, long-term memory prosthesis,” Proc. the 3rd ACM 
workshop on Continuous archival and retrival of personal 
experences, 2006. 
[19] M. L. Lee and A.K. Dey, “Lifelogging memory appliance for 
people with Episodic Memory Impairment,” Proc. the 10th 
International Conference on Ubiquitous Computing, 2008, pp. 
44-53. 
[20] S. Hodges, L. Williams, E. Berry, S. Izadi, J. Srinivasan, A. 
Butler, G. Smyth, N. Kapur, and K. Wood, “SenseCam: a 
retrospective memory aid,” Proc. the 8th International 
Conference on Ubiquitous Computing, 2006, pp. 81-90. 
[21] N. Caprani, C. Gurrin, and N. E. O'Connor, “I like to log: a 
questionnaire study towards accessible lifelogging for older 
users,” Proc. the 12th International ACM SIGACCESS 
Conference on Computers and Accessibility, Orlando, Fl, 
October 25-27, 2010. 
[22] I. hallnas and J. Redstrom, “ Slow technology: designing for 
reflection,” Journal of Personal and Ubiquitous Computing, 
Springer-Verlag, 2000. 
43
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-220-2
CONTENT 2012 : The Fourth International Conference on Creative Content Technologies

[23] M. Argyle, “Bodily communication,” New York: Methuen & 
Co. Ltd, 1988. 
[24] W. Y. Chang, C. S. Chen, and Y. P. Hung, “Analyzing facial 
expression by fusion mani-folds,” Proc. Asian Conference on 
Computer Vision Conference, 2007. 
[25] P. Viola and M. J. Jones, “Robust real-time face detection,” 
Proc. International Journal of Computer Vision, 57(2), 2004, 
pp. 137-154.  
 
44
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-220-2
CONTENT 2012 : The Fourth International Conference on Creative Content Technologies

