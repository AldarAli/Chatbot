Active Cameras Resources Management Assisted by Wide Field of view Fixed 
Cameras for the Surveillance of Multiple Moving Targets 
 
Yacine Morsly  
Department of Robotic 
Ecole Militaire Polytechnique 
Algiers, Algeria 
ymorsly@yahoo.fr 
 
Mohand Said Djouadi     
Department of Robotic 
Ecole Militaire Polytechnique 
Algiers, Algeria 
msdjouadi@gmail.com  
 
 Nabil Aouf 
Department of Informatics and 
SensorsCranfield University 
Defence Academy, UK. 
n.aouf@cranfield.ac.uk 
 
 
Abstract—In this paper, we propose a novel approach to 
manage an active resources for a centralized active vision 
system assisted by a wide field of view fixed cameras 
(WFOV-FC). Indeed, since the WFOV-FC can provide only 
large coverage with low resolution, these later are used to 
generate spatiotemporal observation requests from all 
detected and tracked target in the surveillance zone.  The 
information gathered will be used to schedule the set of 
active Pan-Tilt-Zoom cameras (PTZ-AC) in order to collect 
high-resolution videos suitable for further biometric 
analysis. Based on the output of this biometric analysis, the 
same used set of active cameras is requested to maximize at 
the same time the coverage with close-up views of every 
target identified as a threat. We formulate PTZ multi-
cameras assignment and handoff as a planning problem 
whose solution achieves optimal cameras assignment in real 
time. Simulation results, show the efficiency of the proposed 
policy in satisfying both objectives at the same time 
Keywords-Multi-cameras 
systems; 
active 
and 
fixed 
cameras; assignment;  online scheduling 
I. INTRODUCTION 
There is an ever increasing demand for security 
monitoring systems in the modern world. Visual 
surveillance is one of the most promising areas in security 
monitoring for several reasons. It is easy to install, easy to 
repair, and the initial setup cost is inexpensive when 
compared with other sensor based monitoring systems, 
such as audio sensors, motion detection systems, thermal 
sensors, etc. [1]. 
Video surveillance systems are installed in locations 
ranging from multinational banking organizations to public 
institutions to small local stores, and there is a similar 
disparity in the level of sophistication of installed systems. 
The use to which these systems are put also varies widely 
with the intentions of the operators and the budget 
available for the implementation of the system. 
Earlier works in the field of cameras and videos 
technologies have made it possible to network numerous 
video cameras together by an operator in order to provide 
visual coverage of small and medium spaces such as banks 
and shops. However, as the size of the multi-cameras 
system grows and the level of activity in the public space 
increases, it becomes infeasible for human operators to 
monitor the multiple video streams and identify all events 
of possible interest, or even to control individual cameras 
in performing advanced surveillance tasks, such as    
 
 
zooming on a moving subject of interest to acquire one or 
more facial snapshots. Moreover, the cost of employment 
of a human operator outpaces the cost of installing and 
maintaining the multi-camera systems. Consequently, a 
timely challenge for computer vision researchers is to 
design multi-cameras systems capable of performing 
visual surveillance tasks automatically or at least with 
minimal human intervention. We regard the design of an 
autonomous multi-cameras system as a problem of 
resource allocation and scheduling, where the cameras are 
treated as resources required to complete the desired 
sensing tasks. 
Autonomous 
multi-cameras 
systems 
using 
only 
WFOV-FC can provide large, low resolution coverage of 
the scene. However, recognition and identification of 
targets usually require close-up views at high resolution 
which need PTZ-AC. The resulting proposed autonomous 
multi-cameras system is based on a set of WFOV-FC’s and 
a set of PTZ-AC’s as illustrated in Figure 1. The major 
challenge in this work is the control and scheduling of the 
set of PTZ-AC so that satisfying the tradeoff between three 
competing objectives: 
- Capture high quality video for as many as possible, 
preferably all, of the targets in the scene 
- Observe each target for as long or as many times as 
possible, since the chances of identifying and classifying a 
target improve with the amount of data collected about 
that target. 
- Maximize the coverage time of targets identified as a 
threats during their stay in the surveillance zone. 
Not considering one of the three objectives will 
conduct to the situation where each camera follows a 
single target for their entire stay in the scene, ignoring all 
other pedestrians. The second situation is that a camera 
briefly observes every target in turn and repeatedly, thus 
spending most of the time transitioning between different 
pan, tilt, and zoom settings. The third one leads to ignore 
appeared threats. 
This paper is organized as follows. Section II gives 
comprehensive background of the current and emerging 
approaches for camera selection and handoff. This is 
followed by presenting the adopted system architecture for 
an accurate autonomous video surveillance. In Section IV, 
we present the formulation of the challenge targeted as a 
machine scheduling problem. We next propose our 
scheduling policy in Section V. Finally, we describe 
123
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-207-3
SENSORCOMM 2012 : The Sixth International Conference on Sensor Technologies and Applications

simulation setup and results in Section VI and conclude the 
paper in Section VII.  
II.  RELATED WORK 
Previous work on multi-camera systems has dealt with 
issues related to low and medium-level computer vision, 
namely identification [2, 3], recognition [4, 5], detection 
and tracking of moving objects [6-13]. The importance of 
accurate detection, tracking, and data association is 
obvious, since tracking information is needed as the initial 
stage for controlling one or more PTZ cameras to acquire 
high-resolution imagery.  
However, in addition to detection and tracking, the 
acquisition of high-quality imagery, particularly for 
biometrics purposes, requires accurate calibration between 
the fixed and PTZ cameras in order to focus attention on 
interesting events that occur in the scene. The control or 
the schedule of active cameras set when there are more 
objects to be monitored in the scene than the active 
cameras is also a challenge for many researchers. Some of 
themes employ a WFOV-FC to control an active tilt-zoom 
camera. This configuration is often termed in the literature 
as master–slave. Many researchers use a master–slave 
camera configuration with two or more [19] cameras. In 
particular, most of the methods strongly rely on a direct 
camera calibration step. Basically these approaches are not 
autonomous since they need a human to deal with 
calibration marks. Nevertheless, few exceptions are 
discussed, where in order to  track  targets across a fixed 
and a PTZ camera, they used an affine transformation 
between consecutive pair of frames for stabilizing moving 
camera sequences, and an homography transformation for 
registering the moving and stationary cameras with the 
assumption that the scene is planar. 
A camera scheduling algorithm [14], would typically 
utilize tracking information, provided by one or more fixed 
cameras performing detection and tracking [16, 17], for 
computing a schedule that controls the assignments of 
targets to PTZ cameras over time. Each PTZ camera would 
then servo, based on calibration data, to aim itself at 
different targets in a timely fashion as specified by the 
schedule. 
A similar approach involving calibrated static and 
pan/tilt cameras is presented in [9]. Data from multiple 
static cameras is fused to estimate the 3D location of the 
pedestrian. An active camera uses calibration information 
to bring the target into the center of its view. After initial 
repositioning, the active camera autonomously tracks the 
target [6, 7], thereby avoiding the communication 
overhead associated with master-slave configurations. The 
active camera periodically sends its pan/tilt settings to the 
static cameras. The static cameras can use this information 
to decide whether or not the active camera is tracking the 
correct target. If it is not, the active camera is repositioned. 
Other authors, such Lim et al. [20], have proposed a 
number of different camera scheduling algorithms 
designed for different application goals, where they 
include, for example a scheme for scheduling available 
cameras in a task-dependent fashion , static and non static 
priority policies [15]. 
The work presented here, differs from the previous 
existing scheduling multi-cameras works in the following 
points: 
It can handle several PTZ-AC’s  
The different PTZ-AC’s are modeled as autonomous 
agents that are not driven by the WFOV-FC’s. 
The scheduling strategy supports both high quality 
videos recording and coverage insurance of targets and 
threats. 
III. SYSTEM ARCHITECTURE 
Figure 1 shows the architecture of the system. The 
system considered consists of "N"N  1 PTZ-AC’s 
and WFOV-FC’s. The WFOV-FC’s detect and label all 
moving objects in the scene. The states of the objects (e.g., 
size, position and velocity) in the 2D image space are 
tracked and predicted. Based on the prediction, the 
different observation requests are generated. Then the 
request assignment process assigns a subset of the 
targets/requests to each PTZ-AC by computing the 
relevance of the different PTZ-AC’s to the observed 
targets in the surveillance zone. Each PTZ-AC camera 
tracks the objects assigned to it by selecting the PTZ-AC 
parameter settings that best satisfy these requests to 
capture high resolution images/videos of the targets.  
 
Figure 1.  System Overview 
IV. PROBLEM STATEMENT 
We consider a multi-cameras system including 
"	
"calibrated WFOV-FC’s and "	" PTZ-AC’s.  
Let   \  1,2, … denote the set of targets 
observed at a given time by the multi-cameras system.  At 
that time, the state of a target is given by 
  
, 
 
where "" and "" represent the position and velocity, 
respectively, of observed target i. 
Let 
each 
PTZ-AC 
be 
described 
by 
a 
tuple , , , , ,  ,  . We assume 
therefore that the "3D position  of each PTZ-AC is 
known 
a 
priori. 
[, ], 
!, " and 
[ ,  ] represent the pan tilt and zoom limits, 
respectively, for each PTZ-AC.  
The problem is to find a schedule on  "N" PTZ-AC 
that minimizes the total unit penalty when target "I" with 
deadlines "d$" are released at time "r$" The targets require 
arbitrary processing times and pre-emption (pmtn) is 
124
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-207-3
SENSORCOMM 2012 : The Sixth International Conference on Sensor Technologies and Applications

allowed. So, minimizing the total unit penalty is akin to 
maximizing the number of targets successfully recorded 
prior to their deadlines. 
We can describe the camera scheduling problem 
proposed as: 
                               &∗  ()*+( ,&
                              1 
&
 ∈ & 
&  .&
/0 ∈ 10234456789, 0:;,  ∈ !1, 	"<                   2 
where & denote a feasible event defined as follows:   
                  &  =>
?@A,  ∪ =>
?@A, 0                         3 
=>
?@A,  − The recording of human target by a PTZ-
AC. 
=>
?@A, 0 − The recording of human target identified 
as a threat by a PTZ-AC. 
0: − Preset time that indicates the number of predicted 
plans depending on the predicted states of humans targets 
observed. 
The complexity of problem (1) is NP-hard [18]. Hence, 
we resort to a greedy algorithm for scheduling cameras to 
observe targets. 
The obvious non-clairvoyant online algorithms are 
Round Robin (RR) and Shortest Elapsed Time First 
(SETF). The idea of the RR is to devote identical 
processing resources to all jobs, whereas SETF devotes all 
resources to the job that has been processed the least. As 
SETF is known to perform poorly when jobs are not fully 
parallelizable [19], we used the weighted RR. 
The policy of using a weighted RR scheduling scheme 
is to assign jobs to multiple processors with different load 
capacities. Each processor is assigned a weight indicating 
its processing capacity and more jobs are assigned to the 
processors with higher weights.  
We model each PTZ camera as a processor whose 
weights, which quantify the suitability of a camera with 
respect to observing a target, are adjusted dynamically. 
These weights are assimilated to a combination of 
several quality measures. 
The computation of the relevance of a PTZ-AC to the 
task of recording close-up videos of selected targets for 
further identification and/or classification process, encodes 
an intuitive observation which is formalized by describing 
the relevance of a PTZ-AC to the task of observing a target 
in terms of quality factor"q". omitting superscripts 
t, i and E , the global quality is expressed as follows: 
            q  K 1     if >
?@A M NOP
qQRS. qU. qV . qW. qX                                      (4) 
where the different sub qualities are defined in the 
following subsections: 
A) PTZ limits ",YZA" : 
The turn and zoom limits of cameras should be taken 
into account when assigning a camera to observe a target.  
A camera that has more leeway to turn and zoom may be 
able to follow a target for a longer period of time. The 
mechanical limitation for each PTZ camera on its Pan Tilt 
Zoom parameter range is defined by: 
, , ,  ,  . 
qQRS  exp ^−α − α`a − bβ − βde
a −  bZ − Zde
ag         (5)   
                      α` 
 + 
2
                                       6 
                     βd 
Z87jk Z8lm
a
                                             7 
where: "α" and "β" are respectively, the pans, tilts angles 
corresponding to the location of the target. 
  " ", is the actual zoom setting of a given camera. 
  "Zo ",  is the desired zoom to record close-up videos.           
B) Observational range ",p": 
 It reflects the observational constraints of a camera. It 
is set to 0 when the human target is outside the 
observational range of a camera; otherwise, it is set to 1. 
                  qU  q
   1     if α ∈ !αr$s, αrt" and
               ∈ !βr$s, βrt" and
     Z ∈ !Zr$s, Zrt"
0                                    
          (8) 
where: !αr$s, αrt", !βr$s, βrt" and !Zr$s, Zrt" are the 
external vertical, horizontal rotations, and zoom factor. 
C)  Target-Camera Distance ",v" 
Tracking becomes harder as camera-to-target distance 
grows. The quality of captured imageries generally 
degrades as the distance"dwX", between the target and the 
camera increases or decreases consequentially. Hence, this 
quality measure is only based on "dwX". 
             qV  exp − ^bd2 − dde
^ag                            (9) 
where dd is the desired distance of a target to a camera that 
allows recording close-up videos. 
D)  View Angle ",y"  
 It is more desirable to select a camera that has frontal 
view of a target, in order to record high quality videos that 
will serve for identification purposes. This later is defined 
as it is the angle between the velocity vector of the target 
and the optical centre of a camera. 
                          qW  exp−σ                                (10) 
where σ is defined as the angle between the velocity 
vector of a target and the line that join the position of that 
target and a selected camera. 
E) Handoff candidate",2" 
Handoff candidate quality gives preference to handoff 
candidates in the vicinity of the camera currently observing 
the target. The idea is that nearby cameras have similar 
viewpoints, making appearance based target signature 
more relevant for the candidate camera.  
                         qX  exp−δ                                     (11) 
125
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-207-3
SENSORCOMM 2012 : The Sixth International Conference on Sensor Technologies and Applications

 where δ is the angle between the fixation vector of 
camera >
?@A and the fixation vector of the camera 
currently observing the target. 
V. MULTI-CAMERAS SCHEDULING ALGORITHM 
In this section, we describe the scheduling policy for 
scheduling a set of PTZ-AC’s in order to achieve the above 
cited challenge. Finding an optimal event that fits with the 
movement horizon of the targets/ threats, while 
maximizing the objective function (1) is a combinatorial 
problem. Our policy is based on some modifications in the 
well known Round Robin algorithm which yields to a 
novel heuristic able to satisfy the three points of our 
challenge. Algorithm 1 outlines our policy strategy: 
Data: set of PTZ-AC’s currently assigned to the 
different targets"V}~•€Xr" . Set of PTZ-AC’s cameras that 
are currently available"V•‚ƒƒXr". Set of targets that are 
currently not assigned a PTZ-AC "V„s•X…ƒV†U". Set of 
targets that are currently being followed by PTZ-
AC’s "V•X…ƒV_U". Set of threats that are currently not 
assigned a PTZ-AC "V„s•X…ƒV†Uw". Set of threats that are 
currently being followed by PTZ-AC’s "V•X…ƒV_Uw". 
Begin: 
Set ˆ}~•€Xr, ˆ„s•X…ƒV_U, ˆ‰2Š5v_p, ˆ„s•X…ƒV_Uw and  
ˆ‰2Š5v_p to ∅. 
 ˆ•‚ƒƒXr  >
?@A/   1, … , 	  
      For t= 1: 0:: … .. do 
Remove targets and threats that appears to have left 
the scene from ˆ„s•X…ƒV†U, ˆ‰2Š5v_p, ˆ„s•X…ƒVUw and  
ˆ•‰2Š5v_p. Move the corresponding cameras from 
ˆ}~•€Xr to ˆ•‚ƒƒXr 
For all New arrivals "" do 
Set "0‰_p7  0" (the timestamp of""). Set 
"042_p7  0" (times-recorded count on""). Add 
""  to ˆ•‰2Š5v_p 
         End for 
         For all Cameras ">
?@A" in the ˆ}~•€Xr do 
            if  0‰_p7 by a ">
?@A" is equal to 0:4é5:p                          
then Set "0‰_p7  0". Increment "042_p7". Move 
">
?@A"  from ˆ}~•€Xrtoˆ•‚ƒƒXr. Move ""    
from ˆ‰2Š5v_p to ˆ„s•X…ƒV_U  
              else 
if("0‰_p7" 
by 
a 
Camera 
">
?@A"   
is>= 0:4é5:p            and (ˆ„s•X…ƒV_U ≠ ∅ or     
ˆ„s•X…ƒV_Uw ≠ ∅ and (Camera ">
?@A"  is 
relevant to at least one of the targets in ˆ„s•X…ƒV_U 
or threats in ˆ„s•X…ƒV_Uw) or ("" times-recorded 
count ≥1 and a target "‘, ’ ≠ " in ˆ„s•X…ƒV_U has 
times-recorded count equal to 0 and Camera 
">
?@A"   is relevant to "‘" ) or threat "0‘, ’ ≠ " 
in ˆ„s•X…ƒV_Uw has times-recorded count equal to 0 
and Camera ">
?@A"   is relevant to "0‘" )then 
(Set "0‰_p7  0" and Move ">
?@A"    fromˆ}~•€Xr 
to ˆ•‚ƒƒXr and Move  ""      from ˆ•X…ƒV_Uto 
ˆ„s•X…ƒV_U ) or (Move ">
?@A"    from ˆ}~•€Xr to 
ˆ•‚ƒƒXr and Move  "0"      from ˆ•X…ƒV_Uwto 
ˆ„s•X…ƒV_Uw ) 
        End if, End for 
        For all Cameras ">
?@A"     in ˆ•‚ƒƒXr do 
         Compute ˆ‚ƒ“ƒ”sw_U which consists of the targets in              
          ˆ„s•X…ƒV_U that are relevant to ">
?@A". 
    Compute ˆ‚ƒ“ƒ”sw•– which consists of the targets in 
    ˆ„s•X…ƒV•– that are relevant to ">
?@A" 
       If  ˆ‚ƒ“ƒ”sw_Uw  ∅  then  
                If  ˆ‚ƒ“ƒ”sw_U  ∅  then Continue 
                  Elseif ˆ‚ƒ“ƒ”sw_Uw  ∅ and ˆ‚ƒ“ƒ”sw_U ≠ ∅                      
then Pick target ""    from ˆ‚ƒ“ƒ”sw_U with the 
highest probability of threat. Assign ">
?@A"      
to "". Move ">
?@A"     from ˆ•‚ƒƒXr to 
ˆ}~•€Xr. Move ""    from ˆ„s•X…ƒV to ˆ‰2Š5v 
                Elseif (ˆ‚ƒ“ƒ”sw_Uw ≠ ∅ and ˆ‚ƒ“ƒ”sw_U 
∅) or   (ˆ‚ƒ“ƒ”sw_Uw  ∅ and ˆ‚ƒ“ƒ”sw_U 
∅ ) then Pick target "0"    from ˆ‚ƒ“ƒ”sw_Uw 
with the highest probability of threat. Assign 
">
?@A"      to "0". Move ">
?@A"     from 
ˆ•‚ƒƒXr to ˆ}~•€Xr.  
End if, End for, End for 
Algorithm 1. Sheduling policy 
VI. SIMULATION RESULTS 
We simulate a monitoring area with up to 15 
autonomous targets that enter, travel for free inside, and 
leave the monitoring area of their own volition. We tested 
the scheduling strategy in various scenarios using from 1 
to 5 PTZ active cameras. 
Each target spends anywhere from 40 to 150 seconds in 
the monitoring space. The processing time judged 
satisfactory to capture sufficient frame for identification 
and classification purpose is set to 30 seconds, while the 
preemption cut-off time is set to 5 seconds. The targets are 
assumed to enter the monitoring area randomly. The 
simulation time is set to 180 seconds. 
As expected, we can see from Figure 2 that the 
probability of correct recording depends to the ratio 
between the number of targets and available cameras. 
However, we judge that the results are acceptable since the 
majority of obtained values are superior to 0.5. This is due 
in part to the use of the quality measure which exhibits 
high success rate for recording close up video and lower 
average lead time required by a PTZ-AC to fixate on a 
target and initiate video recording. 
 
126
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-207-3
SENSORCOMM 2012 : The Sixth International Conference on Sensor Technologies and Applications

 
Figure 2.  Average succes rate of correct recording 
 
Figure 3.  Average time of free cameras 
 
Figure 4.  Average succes rate of total threats covrage versus number of 
targts 
Figure 3 shows that average time of free cameras 
depends also to the above cited ratio. We can remark that 
the results are very encouraging since the highest obtained 
time which corresponds to the worst result; present an 
approximate rate of 0.04 in the total considered simulation 
time. 
Figure 4 represents the success rate of assuring total 
coverage of a number of threats (up to 7) while using 5 
cameras. We can remark that this rate decrease as the 
number of total target increase. Nevertheless, this result 
confirms the capacity of the elaborated policy to target 
several objectives at the same time and return an optimal 
scheduling solution at every time step.  
VII. CONCLUSION AND FUTURE WORK 
We have presented a novel approach to control 
multiple PTZ-AC’s assisted by a set of WFOV-FC in order 
to satisfy three main objectives in real time. The main 
novelty of our approach lies in capturing high quality 
video for as many as possible of the targets in the scene, 
while observing each target for as long or as many times as 
possible and at the same time maximizing the coverage 
time of targets identified as a threats during their stay in 
the surveillance zone. The problem was solved by using a 
probabilistic objective function that encapsulates a set of 
quality measures. The reported simulations demonstrate 
the effectiveness of the proposed policy in satisfying the 
above objectives in the same time. We are interested in 
conducting 
more 
detailed 
quantitative 
performance 
evaluation in the future by validating imageries captured 
online with biometrics tasks such as face detection or 
recognition that can be conducted offline. 
 
REFERENCES 
[1] N. Takemura and H. Ishiguro, “Multi camera vision for 
surveillance,”  Handbook of Ambient Intelligence and Smart 
Environments, Part II, pp. 149-169,  DOI: 10.1007/978-0-387-
93808-0_6, Springer Science+Business Media, LLC 2010. 
[2] C.-Y. Lin and al., “Multi-camera invariant appearance modeling 
for non-rigid object identification in a real-time environment,” 
Journal of Vision Communication and Image Representation, In 
Press, Corrected Proof, DOI: 10.1016/ j.jvcir, 2012. 
[3] O. Hamdoun and al., “Person Re-identification In Multi-camera 
System By Signature Based On Interest Point Descriptors 
Collected On Short Video Sequences,” 2nd ACM/IEEE 
International Conference on Distributed Smart Cameras (ICDSC-
08), Stanford, United States, pp. 162-168, DOI: 10.1109/ 
ICDS.2008.4635689, 2008. 
[4] J. Hensler, K. Denker, M. Franz, and G. Umlauf, “Hybrid Face 
Recognition Based on Real-Time Multi-camera Stereo-Matching,” 
ISVC, Part II, LNCS 6939, pp. 158–167, Springer-Verlag Berlin 
Heidelberg, 2011. 
[5] L. Fiore and al., “Multi-Camera Human Activity Monitoring,” Intel 
Robot Syst. Journal, vol. 52, pp. 5–43,  DOI: 10.1007/s10846-007-
9201-6, Springer Science + Business Media B.V., 2008. 
[6] R. Collins, O. Amidi, and T. Kanade, “An active camera system for 
acquiring multiview video,” in Proc. Int. Conf. Image Processing 
(ICIP), pp. 517–520, Rochester, N.Y., Sept. 2002. 
[7] O. Javed, Z. Rasheed, K. Shafique, and M. Shah. “Tracking across 
multiple cameras with disjoint views,” in Proc. IEEE International 
Conference on Computer Vision, pp. 952-957, 2003. 
[8] D. Comaniciu, V. Ramesh, and P. Meer, “Real-time tracking of 
non-rigid objects using mean shift,” in Proc. of the 2000 IEEE 
Conference on Computer Vision and Pattern Recognition (CVPR 
00), vol. 2, pp. 142–151, 2000. 
[9] S. Khan and M. Shah, “Consistent labeling of tracked objects in 
multiple cameras with overlapping fields of view,” IEEE 
Transactions on Pattern Analysis and Machine Intelligence, Vol. 
25, pp. 1355–1360, 2003. 
[10] J. Kang, I. Cohen, and G. Medioni, “Multi-views tracking within 
and across uncalibrated camera streams,” in Proc. First ACM 
SIGMM International Workshop on Video Surveillance, pp. 21–
33, ACM Press, New York, NY, 2003. 
[11] N. T. Siebel, “Designing and Implementing People Tracking 
Applications for Automated Visual Surveillance,”   PhD thesis, 
Dept. of Computer Science, university of Reading, UK, 2003. 
[12] T. Gandhi and M. Trivedi, “Calibration of a reconfigurable array of 
omnidirectional cameras using a moving person,” in Proc. 2nd 
Ot 
Ot/O 
127
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-207-3
SENSORCOMM 2012 : The Sixth International Conference on Sensor Technologies and Applications

ACM International Workshop on Video Surveillance and Sensor 
Networks, pp. 12–19, ACM Press, New York, NY, 2004. 
[13] D. Devarajan , R. J. Radke, and H. Chung, “ Distributed metric 
calibration of ad-hoc camera networks,” ACM Transactions on 
Sensor Networks Journal, vol. 2, pp. 380-403,  2006. 
[14] J. Costello, C. Diehl, A. Banerjee, and H. Fisher, “Scheduling an 
active camera to observe people,” in the proceeding of the ACM 
2nd international workshop on Video surveillance & sensor 
networks, ISBN/ 1-58113-934-9, pp. 39-45, 2004. 
[15] A. Hampapur, L. Brown, J. Connell, A. Ekin, N. Haas, M. Lu, H. 
Markl, S. Pankanti, A. Senior, C. Fe Shu, and Y.L. Tian, “Smart 
video surveillance,” IEEE Signal Processing Magazine, vol. 22, pp. 
38–41, 2005. 
[16] T. Zhao and R. Nevatia, “Tracking multiple humans in complex 
situations,” IEEE Transaction on Pattern Analysis and Machine 
Intelligence Journal, vol. 26, pp. 1208-1221, 2004. 
[17] T. Zhao and R. Nevatia, “Tracking multiple humans in crowede 
environment” in Proc. of the  IEEE CVPR, vol. 2, pp. 406-413, 
2004. 
[18] N. Krahnstoever, T. Yu, S. Lim, K. Patwardhan, and P. Tu, 
“Collaborative Real-Time Control of Active Cameras in Large 
Scale Surveillance Systems,” Workshop on Multi-camera and 
Multi-modal Sensor Fusion Algorithms and Applications  M2SFA2 
2008, Marseille, France, 2008. 
[19]  F. Qureshi and D. Terzopoulos, “Surveillance camera scheduling. 
“A virtual vision approach,” ACM Multimedia Systems Journal, 
Special Issue on Multimedia Surveillance Systems, vol. 12, pp. 
269–283, 2006.  
[20] S.N. Lim, L.S. Davis, and A. Mittal, “Constructing task visibility 
intervals for a surveillance system,” ACM Multimedia Systems 
Journal, Special Issue on Multimedia Surveillance Systems 12, 
2006. 
 
128
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-207-3
SENSORCOMM 2012 : The Sixth International Conference on Sensor Technologies and Applications

