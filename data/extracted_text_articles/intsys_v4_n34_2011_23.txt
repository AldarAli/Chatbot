343
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Virtual Reality Technologies: A Way to Verify and Design Dismantling 
 Operations 
First application case in a highly radioactive cell 
 
Caroline Chabal, Jean-François Mante, Jean-Marc Idasiak 
CEA, DEN, SDTC, LSTD 
30207 Bagnols-sur-Cèze, France. 
caroline.chabal@cea.fr, jean-francois.mante@cea.fr, jean-marc.idasiak@cea.fr 
 
 
Abstract - The CEA must manage the end of its nuclear fuel 
cycle facilities’ lifetime. Cleansing and dismantling actions are 
among its priorities. In order to address these issues, the CEA 
has created a dismantling division, which runs an R&D 
program to provide innovative tools. Intervention scenario 
simulation is one of these R&D projects, enabling defined 
scenarios to be run, their suitability for the environment or 
scenario key points to be verified, taking into account 
unexpected situations and providing technical answers. 
Simulation is a good means of visualizing and therefore 
understanding constraints, of testing different alternatives, and 
is a way to train workers prior to interventions. This paper 
describes an application of such a technology: dismantling a 
chemical cell in the APM (Marcoule Pilot Workshop) facility at 
Marcoule (France). This highly radioactive cell will be 
dismantled by a remote handling system using the Maestro 
slave arm. An immersive room has helped to design the 
dismantling scenarios. The article presents all the pieces of 
equipment in detail. Then, we focus on the processes of 
building the 3D model, especially the photogrammetric study 
step. Next, the software development we have done to couple 
the Maestro with a haptic interface and its carrier with game 
joysticks is described. All the remote handling is controlled in 
real time and with interactivity and detection collision. Thanks 
to force feedback and visual immersion, accessibility, 
operational trajectories and maintainability on the carrier 
have been verified. The overall scenario has been tested and 
problems have been found, which have meant modifications 
and updates of the final scenario to guarantee the system will 
work properly. The results are very encouraging. Finally, the 
perspectives for the project are mentioned, especially worker 
training and radioactive dose rate simulation. 
Keywords-virtual reality; dismantling operation; haptic 
interface; accessibility study; remote handling; collision 
detection; interactivity; real-time 
I. 
 INTRODUCTION 
The CEA is the French Atomic and Alternative Energies 
Commission. A leader in research, development and 
innovation, the CEA is active in four main fields: low carbon 
energies (including nuclear energy), IT and health 
technologies, very large Research Infrastructures (TGIR), 
defense and global security. It is part of the European 
research community, and its international presence is 
growing. 
Among other activities, it must manage the end of its 
nuclear fuel cycle facilities’ lifetime. Cleansing and 
dismantling actions are a CEA priority [2]. It has the 
objective of managing its legacy through exemplary 
Decommissioning & Decontamination programs for its old 
nuclear plants, in order to better prepare the future. The 
stakes are high. It must be shown that the nuclear industry is 
able to control the complete lifecycle of first generation 
facilities (built 1950-1960), from their construction, 
commissioning, operation, and shut down through to 
dismantling and site release. In parallel, the 2nd generation 
facility lifecycle must be managed, the 3rd generation started 
up and the 4th prepared for. 
The Marcoule site (Gard, France) is one of the biggest 
cleansing and dismantling worksite in the world. It was 
created in the 1960s, as part of France’s atomic energy 
program. Today, the D&D operations are dealing with G1, 
G2 and G3 shutdown reactors, workshops used to develop 
reprocessing and vitrification processes (APM), the first 
French spent fuel reprocessing plant (UP1) and the fast 
breeder demonstration reactor (Phenix). 
The CEA must carry out these operations while 
respecting three vital issues: worker protection by dose rate 
limitation, environment protection by research into lowering 
nuclear 
waste 
volume 
and 
activity, 
and 
financial 
management, which combines costs efficiency and respect of 
the regulations and ever-stricter safety requirements [3]. 
In order to address these three issues, the CEA has 
created a dismantling division, which runs an R&D program 
to provide innovative tools. This program focuses on 
development and industrialization of measurement tools and 
techniques to better characterize in situ radiological 
conditions, of remote handling and cutting tools, designed 
for highly radioactive environments, and of intervention 
scenarios simulation. The latter involves running defined 
scenarios and verifying their suitability for the environment. 
This simulation is possible thanks to Virtual Reality (VR) 
technologies, which enable a user to interact with a 
computer-simulated environment, whether that environment 
is a simulation of the real world or of an imaginary world. 
VR environments mostly based on visual immersion and 
displayed either on a computer screen or through 

344
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
stereoscopic displays, can also include additional sensory 
information, such as sound or touch. 
This paper describes how VR technologies, adapted to 
the nuclear decommissioning context, can provide useful 
support to engineers in charge of scenario design [1]. Before 
beginning the actual operations, such a set of tools is also 
well adapted to communicating and sharing information 
during project reviews, or to training workers and ensuring 
they are aware of the risks they could be exposed to.  
First, the chosen VR technologies will be presented. 
Secondly, the first application case will be presented and 
explained as well as the nuclear environment and the remote 
handling system used for dismantling. Then, we will 
describe the simulator developed to validate scenarios. 
In the last section, we will describe our first results and 
the perspectives. 
II. 
VIRTUAL REALITY AND DISMANTLING: THE STATE OF 
THE ART 
Virtual reality (VR) is a technology widely used in 
various fields. For instance, in medicine, the primary use of 
VR in a therapeutic role is its application to various forms of 
exposure therapy, from phobia treatments to newer 
approaches to treating Posttraumatic stress disorder [4]. 
Other research fields in which the use of virtual reality is 
being explored are physical medicine, pediatrics or surgery 
training [5]. In industry, VR can be applied to new product 
design (electronics, CAD, Computer Aided Manufacturing, 
naval, automotive or aerospace design, etc.), for urban 
regeneration and planning or in Archeology to rebuild 
destroyed monuments. Applied to the nuclear industry, VR 
provides an intuitive and immersive human-computer 
interface, to verify intervention scenarios and train future 
operators. Some research has led to development of 
applications for maintenance training [6], or to new 
methodologies for disassembly evaluation of CAD models 
designs for maintenance [7]. Some works have also focused 
on using VR as a training program for simulating refueling 
operations while reducing the doses received by workers 
[8]. Lastly, some studies target decommissioning assistance 
thanks to VR, in the Chernobyl NPP dismantling, for 
example [9]. Our work is slightly different because it is the 
first time that a whole dismantling scenario has been 
simulated via VR technologies and especially with force 
feedback, which gives more confidence, reliability and 
reality to the simulated scenario. 
III. 
THE MARCOULE IMMERSIVE ROOM 
The CEA created the Marcoule immersive room (Fig. 1) 
at the end of 2008 in order to validate maintenance or 
dismantling operations. It is a resource shared by all the CEA 
decommissioning projects described in the introduction 
(APM, Phenix, UP1), and can be used for project reviews, 
for accessibility, ergonomics or scenario feasibility studies, 
and for training workers. 
The team works on new plant design as well as 
dismantling projects. 
 
 
Figure 1.  Marcoule immersive room. 
The CEA Marcoule immersive room groups all the 
technologies enabling user immersion in a virtual 
environment and interaction. The figure below shows the 
immersive room configuration (Fig. 2). The main pieces of 
equipment will be described hereafter. 
 
 
Figure 2.  Marcoule immersive room configuration. 
A. The hardware 
The Marcoule immersive room is equiped with VR pieces 
of equipment based on the following technologies. 
1) Screen  
The immersive room is equipped with a stereoscopic 
visualization system with a 3.7m x 2.3m image wall, giving 
the user a 3D vision of the virtual environment. The two 
Projection Design video-projectors (resolution 1920x1200) 
create the images and are each controlled by a separate PC 
(slaves 1 and 2 above). The result is a definition of 2 mm 
pixels. The size of the screen means it is very comfortable to 
work on life-size simulations. 

345
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
2) Stereoscopy  
Stereoscopy refers to a technique for creating or 
enhancing the illusion of depth in an image by presenting 
two offset images separately to the left and right eye of the 
viewer. Both of these 2D offset images are then combined in 
the brain to give the perception of 3D depth. Three 
strategies have been used to accomplish this: the viewer 
wears eyeglasses to combine separate images from two 
offset sources (passive stereoscopy), the viewer wears 
eyeglasses to filter offset images from a single source 
separated for each eye (active stereoscopy), or the light 
source splits the images directionally into the viewer's eyes 
(auto stereoscopy). 
After examining the options available, we have chosen 
the Infitec (INterference FIlter TEChnology) passive 
stereoscopic technology. Infitec GmbH is a German 
company that owns a technique for channel separation in 
stereo projection based on interference filters [10]. 
 
 
Figure 3.  Infitec technology principle. 
Special interference filters (dichromatic filters) in the 
glasses and in the projector form the main item of technology 
and have given it this name. The filters divide the visible 
color spectrum into six narrow bands - two in the red region, 
two in the green region, and two in the blue region (called 
R1, R2, G1, G2, B1 and B2). The R1, G1 and B1 bands are 
used for one eye image, and R2, G2, B2 for the other eye 
(Fig. 3). The human eye is largely insensitive to such fine 
spectral differences, so this technique is able to generate full-
color 3D images with only slight color differences between 
the two eyes. 
This technology presents many advantages: first, the 
quality of the generated picture is very high and stereoscopy 
is good when the user turns his head compared to other 
passive stereoscopic technologies; second, good user comfort 
because the glasses are very light and there is no visual 
tiredness. The only drawback of this technology is the slight 
color alteration generated, which is not an issue in our 
application.  
3) Motion capture 
Motion capture is the position measurement of bodies that 
move in a defined space. Tracking systems, based on 
various measurement principles, are available, e.g., 
mechanical, magnetic, optical (VIS or IR) and acoustic 
trackers, and systems based on inertial or gyro sensors. In 
the group of contactless trackers, i.e., trackers that do not 
work with mechanical digitizers, the highest accuracy is 
provided by optical trackers. Optical tracking does not 
suffer from image distortions due to ferromagnetic metals, 
like electromagnetic techniques, or from drift problems, like 
inertial sensors. ART GmBH is a German manufacturer of 
high-end tracking solutions, specialized in infrared optical 
tracking for professional applications. This technology was 
chosen for its accuracy and technical reliability.   
 
 
Figure 4.  ART tracking architecture. 
The user who shall be tracked is equipped with markers, 
which are light reflectors. Intelligent tracking cameras, 
scanning a certain volume, detect the light that comes from 
the markers and calculate 2D marker positions (image 
coordinates) with high accuracy (Fig. 4). 
These data are handed over to a central ARTtrack 
Controller, 
which calculates the positions of rigid 
arrangements of several markers. The result of each 
measurement gives coordinates that describe the position of 
the markers, and hence the position of the body carrying the 
markers [11]. 

346
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
 
Figure 5.  Flystick (left) and tracked glasses (right). 
A flystick (Fig. 5) is a wireless interaction device for 
virtual reality (VR) applications. DTrack software takes up 
the flystick button and joystick events and correlates them 
with the 6DOF output data. This makes the matching of all 
data very user-friendly. 
For head tracking in passive stereo systems, tracking 
targets must be attached to the stereo glasses (Fig. 6). As a 
result, when the user moves his head, the point of view of the 
simulation changes as if a genuine movement had taken 
place within the VR surroundings. 
4) Haptic device 
A haptic system reproduces the sensations of touch and 
of effort applied to an object in a VR application. The device 
enables greater possibilities of immersion in handling virtual 
objects in 3D. Force-feedback interfaces are substituted for 
the traditional keyboard and mouse during tasks such as 
ergonomic studies or the simulation of maintenance or 
mechanical assembly operations. Actions involving the 
insertion of mechanical parts within a cluttered space can 
therefore be carried out very quickly and naturally, whereas 
they would require a lot more time and user skill with a 
keyboard and mouse.  
We chose to equip the room with a haptic interface, the 
Virtuose 6D35-45 (Fig. 6). This device has been developed 
by Haption, a CEA spin-off, and is the only product on the 
market today, which offers force feedback on all six degrees 
of freedom (DOF) (three translations and three rotations), 
together with a large workspace and high torques [12] (the 
volume is equivalent to a 40 cm side cube). It is especially 
recommended for scale 1 manipulation of virtual objects 
such as assembly/disassembly simulations, ergonomic 
studies, or maintenance training. 
 
 
Figure 6.  Virtuose 6D35-45. 
 
B. The software  
In order to run the simulation, the Marcoule immersive 
room is equipped with specific software, described below. 
1) Techviz 
We use TechViz XL, developed by the French company 
TechViz, in order to capture the OpenGL flow from an 
application, generate stereoscopic images and send them to 
both projectors. It works especially well with 3DSMax, 
SolidWorks or Virtools. It is used to display 3D models on 
any display solution (CAVE, HMD, visualization wall …). 
TechViz XL offers the ability to work directly within 3D 
applications and to see 3D model displays in real-time on an 
immersive room [13]. 
2) 3DVIA Virtools 
3DVIA Virtools produced by Dassault Systèmes is used 
to manage a simulation. It is a complete development and 
deployment platform with an innovative approach to 
interactive 3D content creation. The 3DVIA Virtools 
production process facilitates prototyping and robust 
development up to large-scale, immersive or online, lifelike 
experience delivery. Thanks to its development environment 
and its Software Development Kit (SDK), we can create 3D 
real-time applications and add our own functionalities [14]. 
3) The IPSI physics engine  
A physics engine is an independent software library 
applied 
to 
classical 
mechanics 
problem 
resolution 
(collisions, falls, forces, kinematics...). The purpose is to 
give a « physical » existence to graphical objects. One of the 
most robust and reliable principles is based on 3D model 
voxelisation. The word voxel means volume element (by 
analogy with "pixel") and voxelize an object means finding 
all the voxels ("small cubes"), which are inside the object. 
We can move from a surface representation to a volume 
[15]. The figure below shows that depending on the voxel 
size, model voxelisation is more or less faithful to the 
graphical object (Fig. 7). 
 
 
Figure 7.  Examples of voxellistion with 2 different voxel sizes. 
In this voxelized environment, the physics engine 
generates the forces to be applied to avoid objects inter-
penetration. IPSI is a physics engine provided by Haption, 
based on voxelisation, and enables the testing of 

347
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
intersections between volumetric solids, in order to calculate 
trajectories and impact points. The real-time collision 
detection disables penetration between objects.  It also 
offers kinematic chains creation and haptic interface plug-in 
with force feedback [16]. 
IV. 
FIRST APPLICATION: CELL 414 
We chose to implement the first application case on the 
Cell 414 decommissioning project. 
A. Presentation of the project 
The vitrification process currently used in La Hague was 
developed by the CEA in the Marcoule Pilot Workshop 
(APM facility). It was a prototype plant for reprocessing 
spent fuel, first commissioned in 1962, with production 
activities shut down in 1997. The plant is currently 
undergoing clean-up and dismantling. 
 
Cell 414 is one of the 760 places in APM and one of the 
30 very high radioactive cells. It was a chemical unit used to 
process liquids from irradiated fuel dissolution operations. It 
is a particularly large cell: 20m long, 4m wide and 6m high. 
There are approximately 5km of pipes to remove (Fig. 8). 
The total weight is estimated to be 18 tons of waste. The 
present high level of radioactivity rules out direct manual 
dismantling, so the choice of a remote handling system 
called Maestro has been made.  
 
 
Figure 8.  Very complex cell interior seen from a porthole. 
The first step of decommissioning is to remove high 
level radioactivity. Data was gathered from an initial 
inventory: hot spots were identified with a gamma camera. 
These hot spots like the dosing wheels, the centrifuges, the 
pulsed filter and some parts of the pipes have to be removed 
first in order to reduce cell radioactivity (Fig. 9): 
 
Figure 9.  Pieces of equipment to be dismantled. 
B. The remote handling system 
The remote handling system is made up with the Maestro 
system and a carrier specifically designed for the 
dismantling. 
1) The Maestro system 
The Maestro system is the result of 10 years of 
collaboration between the CEA and Cybernetix, in charge of 
its manufacturing [17]. This advanced remote manipulator is 
used when human intervention is not possible, as in nuclear 
or offshore hostile environments. Maestro is dedicated to 
many tasks like inspection, maintenance, dismantling, 
cleaning, etc. Dexterity, accuracy and strength are its main 
advantages. It can be used in either robotic mode (automatic 
sequence) or in manual remote control mode with or without 
force feedback management. 
 
 
 
Figure 10.  The Maestro slave arm (left) and the Maestro master arm 
(right). 
This system is made up of two parts: the master arm and 
the slave arm. The master arm is a device allowing the 
control of the slave arm end-effecter in Cartesian mode with 
a complete force feedback. This device is a Virtuose 6D40-
40 from Haption Erreur ! Source du renvoi introuvable.. 

348
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The slave arm is a hydraulic robot with six degrees of 
freedom (Fig. 10). 
The Cell 414 dismantling project will be the first 
worksite where Maestro will be used to dismantle a whole 
cell. 
2) The carrier 
The carrier was especially designed for Cell 414 
dismantling, and will enable the Maestro system to reach all 
parts of the cell.  
It works on three axes, using existing rails to move along 
the cell (20m), with vertical (3m) and rotating movements. A 
crane-type handling bracket is also set up on the carrier to 
hold parts during dismantling and for other handling 
operations. This carrier is currently undergoing tests (Fig. 
11). 
 
 
Figure 11.  The carrier.  
3) The surrounding rooms 
Corridor 417, which is adjacent to Cell 414, will be used 
to assemble, maintain and disassemble remote handling 
pieces of equipment and will be the parking and transfer 
zone. A radiation-proof safety door between Cell 414 and 
Corridor 417 provides radioactivity containment (Fig. 12). 
 
 
Figure 12.  Control room and maintenance corridor. 
During the dismantling, operations will be realized with 
indirect vision from the control room located in Room 245 
(Fig. 12), via audio and video equipment installed inside 
Cell 414 and on the remote handling system. The control 
room includes four control screens, which display the 
images from the six in situ video cameras, two set up in the 
cell and four on the carrier. 
V. 
FROM REAL TO VIRTUAL: THE STEPS TO BUILD THE 
SIMULATION 
In order to verify accessibility and maintainability on the 
carrier and to validate technical choices, it was decided to 
design the dismantling scenarios using a simulator and the 
VR technologies available in Marcoule.   
A. Step one: build the 3D models 
1) Cell 414 and surroundings 
First, 3D models of the environment had to be built. As 
the 2D facility plans available were not sufficiently up-to-
date to design a precise digital mock-up, a photogrammetric 
technique was used.  
The photogrammetic reconstruction enabled a 3D model 
to be built up, using the parallax obtained between the 
images acquired depending on the different points of view. 
It implements the correlation calculation between the digital 
images to give a 3D reconstruction of the model. After an in 
situ photo campaign, processing consisted of identifying and 
digitalizing the points with common physical details on the 
photos, as well as the apparent contours of lines and 
cylinders. This reconstruction is semi-automatic, and is 
carried out from basing trade elements (tube valve, nut, 
screw, elbow…). 
The Cell 414 photogrammetric study was carried out by 
the subcontractor ESIC SN [18], as the model obtained is 
compatible with standard CAD software (Microstation, 
SolidWorks). It consisted in taking 700 photos along the 
existing rails (Fig. 13), for one week. The 3D reconstruction 
lasted four weeks.  The model obtained is accurate to about 
5 cm. Nevertheless, the photos taken do not allow all the 
pipes to be seen, especially those located behind other 
elements. 

349
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
                      
 
Figure 13.  6 of 700 photos taken during the measurement campaign. 
To import 3D models into 3DVIA Virtools, they must be 
in a specific format, .NMO. Therefore 3DSMax was used, 
as it provides an exporter from .MAX format to .NMO 
format used by Virtools.  
Next, the modeling of the building containing Cell 414 
was made based on the plans of construction in SolidWorks. 
We also designed Cell 417 and Control Room 245. 
Finally, we merged these parts to obtain a whole model 
in 3DSMax software. The images below enable the 
comparison between a real photo and a VR view of the same 
scene. We can see that the 3D simulation is very close to 
reality (Fig. 14). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 14.  A real photo (left) and 3D view (right). 
2) The robots 
Concerning the robots previously described, we obtained 
the CAD model made by Cybernetix, the manufacturer. The 
modeling is in SolidWorks format and we did the necessary 
conversions to use it in 3DSMax (Fig. 15). 
 
Figure 15.  Carrier 3D model. 
3) Simplification of the complete model 
When all the models were merged, the result proved to be 
too big to manage easily and generated performance 
slowness in the 3D rendering. This first model contained 
more than 10 million faces. It had to be simplified to reach 
correct display performances. Whereas the civil engineering 
and Cell 414 internals could not be simplified, the reduction 
of the remote handling model was not complicated. It was 
the manufacturer’s model and included modeling of all the 
elements down to screws and nuts. For accessibility studies, 
it is not necessary to have such accuracy. It is therefore 
possible to remove fastenings (screws, nuts, washers…), fill 
holes by deleting drilling or simplifying extrusion profiles, 
and suppressing non visible, hidden objects or those 
contained in others. 
4) Results 
The example below (Fig. 16) illustrates the simplification 
of a part: screws, grooves, rounded edges and holes have 
been removed. The overall shape is respected and the 
number of faces decreases from 2693 to 98.  
 
Figure 16.  Example of part simplication 
This step was very useful because without distorting the 
model, the simplification of every part of the carrier model 
leads to 180 000 faces, instead of 2.5 million. 
As a result, the final 3D model has 1.2 million faces, 
compared to 10 million before simplification. 
B. Step two: develop the simulator 
In order to verify accessibility, we need to be able to 
pilot kinematics chains and detect collisions with the 
 

350
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
environment in real time. We have developed a physics 
module, integrating IPSI in 3DVIA Virtools, by using a 
specific script language and functions called Building Block 
(BB).  
1) Kinematics creation 
A robot is shown by 3D objects linked by father-child 
kinematic links. Objects called “axes” make up the robot 
skeleton. There are two types of 1DOF motion that can be 
applied on these axes: rotation around x, y or z and 
translation (in the direction of x, y or z). These movements 
can be used on a single axis and are limited by minimal and 
maximal end stops, applied on the object pivot. Virtual 
robots can then be manipulated with their constraints as in 
reality. 
The Maestro arm has 6 rotation DOF, as shown in the 
figure below (Fig. 17): 
 
Figure 17.  Maestro kinematics 
The carrier can move all along the cell (20 m). The 
lifting mechanism enables the support platform to be raised. 
This platform has one rotation axis (±90°). The carrier 
therefore has three DOF, two translations and one rotation, 
as illustrated below (Fig. 18): 
 
Figure 18.  Carrier kinematics 
Lastly, the handling bracket, which holds parts being 
dismantled, has three DOF; one rotation (±90°), one 
translation (extension of the bracket arm) and one other 
translation enabling the pulley to be lowered (see Fig. 19): 
 
Figure 19.  Handling bracket crane kinematics 
Each robot has its own object hierarchy and they are 
attached to each other: The Maestro base is fastened to the 
carrier’s object #5 (the support platform) and the bracket 
crane base is on the carrier’s object #3 (Figure 20. 20). A 
Maestro tool is attached to Maestro object #6.  
 
Figure 20.  Robots’ hierarchies 
2) Maestro tools 
All the tools below can be connected to the Maestro end-
effecter. They are all used in the dismantling scenarios 
either to cut, like the saw or the grinder, or to grasp pieces 
of equipment, like the clamp. Collisions and contacts with 
the environment can be felt on each of them (Figure 21. ).  
 
 
Clamp  
 
Shears  
 
Nibbler 
Hydraulic saw  
 
Grinder  
 
Drill 

351
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Figure 21.  Tools to be used to dismantle 
3) The simulator 
The simulator was created with Virtools for the graphical 
part and IPSI for the physical part., with a Dynamic Link 
Library (DLL) to interface IPSI functions.  
In the simulation initialization, all the 3D objects we 
want to add to the physical simulation are sent to IPSI as 
well as the information about robots (hierarchies, degrees of 
freedom, end stops etc.). The kinematics of the Maestro arm 
and the carrier were then created.  
The graphical representation of the objects is updated in 
Virtools by IPSI, which calculates the new position in real-
time. During the simulation life, we use a callback function 
to match graphical and physical objects (Figure 22. ).  
 
Figure 22.  graphics and physical simulation coupling 
C. Step three: control the simulation 
To control the robots, two gaming joysticks are used to 
pilot the carrier and the crane (Figure 23. ). The first one 
controls the carrier’s three DOF and the second those of the 
crane. These controls are very similar to the interface, which 
will be used for the final dismantling system. Each robot is 
controlled axis by axis (the articular mode). 
 
 
Figure 23.  Gaming joysticks used to pilot the carrier and the crane. 
The Maestro arm has been coupled to the Virtuose 6D 
35-45 haptic interface. The Virtuose enables manipulation 
of the Maestro end-effecter, and thus control of the Maestro 
extremity, while respecting the kinematics chain and all the 
end-stops. The Maestro arm is not piloted axis by axis like 
the carrier and the handling bracket crane, but it is used in 
the Cartesian mode via the Virtuose, as it will be during the 
actual dismantling operation. The Virtuose sends force-
feedback when the Maestro is in collision with a 
« voxelized » element of the environment. The operator can 
also feel when one or several axes reaches end stop: the user 
manipulation is blocked on the axis concerned. 
D. Step four: add interactive functionalities  
An interactive real-time simulator was developed into 
which the whole cell, the Maestro slave arm and the carrier 
are loaded. The Maestro arm and its carrier can be 
maneuvered using the joysticks and the Virtuose. Any of the 
six available tools can be connected to the Maestro arm or 
changed, as necessary.  
The points of view of the six cameras can also be 
displayed in the simulator. It has been checked that every 
part of the cell is visible and controllable. Sound simulation 
has been added, to reproduce the sound received by the in 
situ microphone: the operator will be able to hear the sound 
of collisions in the monitoring room. This sense will be very 
useful to operators when piloting the system; therefore a 
specific sound has been associated with each tool and 
collision, to enhance the information sent to the user.  
 
 
Figure 24.  MMI 
The current value of each robot’s axis is displayed and 
written in red if it corresponds to the end stop value. The axis 
is also highlighted and a sound is heard. 
A menu enables specific functions to be launched, such 
as tool grasping, MMI configuration or automatic scenarios; 
the carrier entry in the cell for example (Fig. 24). 
VI. 
FIRST RESULTS 
This part describes the first results, coming from the 
simulation of the dismantling scenarios. 
A. Gamma-3D superimposition  
This consists in superimposing radiological imaging data 
and 3D environment (Fig. 25 and 26). An in situ 
measurement campaign was carried out in 2006 and enabled 
identification of about twenty radioactive hot spots in the 
cell, with ambient dose between 15 and 25mGy/h. The 
dominant radioelement is 137Cs (80%). The image of each 
gamma 
hot 
spot 
has 
been 
superimposed 
on 
the 
corresponding 3D object.  
 
3D rendering 
Robots’ axis 
position 
Menu 
Cameras’ 
points of view 

352
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 25.  Hot spots on dosing wheels 
 
Figure 26.  Hot spots on centrifuges. 
This superimposition has allowed better understanding 
of every hot spot’s location in the environment. 
We developed a function that generates a more or less 
intense Geiger sound, depending on the dose rate received 
in every point of the cell, with each hot spot taken into 
account. This calculation is based on the minimization of 
the dose rate absorbed with the distance from the radioactive 
source: the dose rate absorbed is proportional to the number 
of particles, which penetrate a mass element given by time 
unit. To reduce this number, one way is to increase the 
distance between the operator and the radioactive source. If 
the source is considered as a point, the dose rate absorbed 
follows the law of the squared distance inverse (Fig. 27). 
 
 
Figure 27.  Equation of the squared distance inverse. 
This formula has been implemented and applied to the 
navigation camera. When it moves, the dose rate changes, 
depending on the distance from hot spots. The possibility to 
activate or deactivate a source has been added, to see the 
influence of each of them. 
B. Global accessibility study 
Tests carried out on the system had two objectives: first, 
to check that the carrier design was suitable for the Cell 414 
environment, and second, to verify the whole dismantling 
operation design. 
Two 
interface 
problems 
preventing 
the 
forward 
movement of the carrier were quickly identified: while the 
first obstacle could be avoided by raising the Maestro base, 
the second will have to be dismantled by existing in-cell 
equipment before the carrier enters the cell (Fig. 28). 
 
Figure 28.  Interference between carrier and environment. 
C. Verification of the overall scenario 
The dismantling scenarios take into account that the 
Maestro ideal position is the configuration called “elbow at 
the top”; as illustrated below (Fig. 29).  It guarantees tool 
maximal maneuverability by reducing the risk of working 
from an end stop. They also consider each cutting tool 
footprint (which are very variable from one to the other) to 
adapt the scenario depending on the means. 
 
 
Figure 29.  Maestro “elbow at the top”. 
The overall scenario is divided into five sub-scenarios, 
each managing the dismantling of specific pieces of 
equipment as illustrated in the graph below (Fig. 30): 

353
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 30.  Dismantling flowsheet. 
1) Centrifuge dismantling 
This first scenario is quite complex, because the pieces of 
equipment to be dismantled are located under a jutting 
block, in a zone, which is very difficult to reach; the pieces 
of equipment are quite big and heavy, which has raised 
questions about how to dismantle the structure. This 
scenario needs specific handling tools to help remove parts, 
as the pulley cannot be used under the jutting block. 
The detailed dismantling scenario from the carrier entry 
to the centrifuges’ cutting has been verified. We found 
several technical key points, which need to be clarified in 
order to prove the feasibility of the task. The following 
section presents some of these key points.  
First example: the simulation ran the waste basket loading 
before the Cell 414 entry: the pulley cable enters in collision 
with the embedded tool holder. The bracket arm needs to be 
extended to avoid this situation, as shown below (Fig. 31). 
 
Figure 31.  Interference between cable and tool holder. 
Second example: to enter Cell 414, the handling bracket 
has to be in a rearward position, but then has to turn to be in 
forward position to be close to the Maestro arm. The crane 
must carry out a half-turn in the beginning of the cell. The 
simulation showed that this half-turn cannot be done in one 
step, but has to advance enough not to hit the fixed camera 
(Fig. 32), then turn and pull back the telescopic arm and 
finally go back to continue the half-turn (Fig. 33). 
 
 
Figure 32.  Interference between the bracket crane and the environment. 
 
 
Figure 33.  Handling bracket crane half-turn. 
The simulation study also showed that the space near the 
centrifuges is very limited and the waste basket can only be 
put down in one specific zone, as illustrated in the next 
figure (Fig. 34): 
 
Figure 34.  Limited zone to unload waste basket near centrifuges. 
 Dismantle the 4 upper 
dosing wheels 
 Dismantle the pulsed filter 
 Dismantle the hot spots 
       Impossible to put down 
       Carrier route 
       Possible to put down 
 Dismantle the 2 lower 
dosing wheels 
 Dismantle the 3 
centrifuges 

354
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
We have also proved that dismantling the centrifuges in 
situ with the hydraulic shears would not be feasible as 
originally planned. In fact, the shears footprint is too big and 
it cannot access the centrifuges. A new scenario was 
proposed, consisting in removing the centrifuges from under 
the jutting block, bringing them close to the cutting table, 
where there is more space and cutting them up with the 
hydraulic shears. This scenario has been validated and 
approved by the dismantling project engineers. 
Another example: the simulation enables Maestro 
configuration during tool grasping on the embedded tool 
holder to be shown. To grasp tools, the arm must have “the 
elbow at the bottom”, two axes must be close to end stops 
and the support platform must have a 45 degree orientation 
(Fig. 35). This configuration is not optimal and needs a large 
footprint in the cell. While it is not an issue in the half-turn 
zone, it causes interferences with an embedded camera near 
the cutting table: the camera orientation needs to be modified 
in order not to touch the table (Fig. 36).  
 
Figure 35.  The tool grasping 
 
Figure 36.  Interference between camera and cutting table. 
Other such situations have been found and embedded 
tool grasping is not possible in some parts of the cell. This 
kind of problem had not been identified before, and the 
manufacturer has had to take these issues into account. 
Thus, from the first simulation runs, the project has 
already provided vital information to implement in its 
dismantling scenarios. The chosen VR technologies have 
proved their worth, and the various capabilities of the 
Maestro system and carrier will continue to be tested as the 
dismantling project enters its next phase. 
VII. LIMITS AND PERSPECTIVES 
The results are quite satisfying, but some limits exist and 
some developments can be made to use the simulation to 
train the future operators. 
A. Current limits 
First, the mismatch of information relevant to reality can 
affect safety and performance. For instance, if the modeling 
accuracy for the robot or the cell is not high enough, we 
cannot be sure that the scenarios that have to be tested with 
the simulator are reproducible in practice. The robot model 
comes directly from the manufacturer’s CAD model, so it 
can be considered as identical to the actual robot. The 
modeling uncertainty comes from 3D reconstruction. It is 
known that photogrammetry is accurate with 5cm precision. 
The most difficult task is to obtain a true model of the cell. 
The present model created by photogrammetry is accurate 
enough for the first steps of scenario study, but because of 
the layout of the cell, the complete model of the pipes could 
not be rebuilt with this technique. Only the first row of pipes 
was modeled, so the cell modeling will have to be updated 
after the first steps of dismantling if we want to match the 
reality. 
Next, we are limited by the physics engine, which is 
directly dependent on the computing power. With the current 
hardware, we cannot physicalize the robots and the whole 
cell with a high precision for collision detection and get a 
real-time simulation. Therefore, only the robots and some 
key parts of the cell have been physicalized. These parts 
depend on the scenario being tested. Collision detection 
precision has to be inferior or equal to 10mm, so that the 
accessibility studies can be realistic.  
B. Add the radioactivity dose rate information 
The CEA, in collaboration with Euriware, a French 
company, has developed an application called NARVEOS 
[20] capable of calculating the radioactivity dose rate. It is 
specifically 
used 
to 
simulate 
scenarios 
in 
nuclear 
environments. In NARVEOS, we can import a 3D model of 
a nuclear facility, specify the kinds of materials (steel, lead, 
concrete …) of each 3D object and add radioactive pieces of 
information to the 3D model: sources coming from the in 
situ measurement campaign mentioned earlier in this article, 
protection screens defined by the material of each object, and 
measurement points where we want to have the calculation 
done. From this data, NARVEOS is able to calculate the 
radioactive dose rate received by the measurement points in 
real-time and interactively. In the following figure (Fig. 37), 
sources and protection screens have been added and the 
measurement point has been located on the operator’s chest. 
It is controlled interactively via mouse and keyboard. The 
curve below displays the changes to the dose rate received by 
the operator depending on the motion he makes.  

355
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 37.  NARVEOS GUI 
In the near future, it is hoped to assemble the 
functionalities of NARVEOS within our simulator. Thus, it 
will be possible to follow in real-time the decrease of the 
radioactivity levels during decommissioning and calculate 
the new levels after the removal of hot spots. It will also be 
used to simulate decreasing operator dose rates, and to know 
when safe manual dismantling will be possible. 
C. Train the operators 
From the beginning of this project, the idea of training 
operators was predominant. The models are very close to the 
reality and we can work with a life-size simulation. 
Currently, the control of the robots with the joysticks plus 
the Virtuose device allows the real robot motion in the cell to 
be tested. For instance, the most suitable carrier positions can 
be found to work at optimal efficiency with the Maestro 
slave arm. The simulation can also be used to increase the 
operators’ awareness of the risks they could be exposed to, 
like collisions between the carrier and its environment, or 
robot damage.  
Moreover, the main purpose of the training is to avoid 
nuclear incidents, like possible worker irradiation. Therefore, 
the radioactivity dose rate simulation will help to train 
operators and inform them about where the radioactive areas 
are located.  
Another advantage of the training is to show operators 
that there is no direct vision, so they will get used to working 
with only video and sound monitoring from the cell. 
VIII. CONCLUSION 
This project has shown that VR technologies can 
contribute to improving knowledge regarding project 
preparation and validating technical choices. It can even be 
used to design scenarios. With this first application case, 
several technical key points to be solved have been 
identified, in order to improve the dismantling scenarios and 
be sure that the real operation will be without foreseeable 
problems.  
The simulator involved is generic and can load any 3D 
model of a building. A comprehensive robotics library has 
also been compiled and enables VR versions of scenarios to 
be run with any of these systems, in order to test alternative 
solutions. We are already working on another dismantling 
project and using our development to help choose the best 
remote handling slave arm adapted to the dismantling 
operations involved. Our work there takes place earlier in the 
dismantling project because the scenarios are not yet defined 
as the likely technical solutions have not been decided on. 
The VR study will simulate different technical alternatives 
and indicate the best solution. 
Our simulator will also be useful for the operators’ 
training. As the operation will not be easy because of the 
complexity of the cell and of the remote handling system, 
training the future operators via a VR simulation will allow 
them to better know the environment to be dismantled and 
how to use the different pieces of remote handling 
equipment. They will therefore better understand the 
difficulties and key points of the scenario.  
Given the first results, the CEA has proved that VR tools 
open 
up 
new 
perspectives 
for 
studies 
and 
for 
decommissioning cost and deadline management, as well as 
for communication between project teams, contractors and 
Nuclear Safety Authorities.  
REFERENCES 
[1] C. Chabal, A. Proietti, JF. Mante, and JM. Idasiak, “Virtual Reality 
Technologies: a Way to Verify Dismantling Operations, First 
application case in a highly radioactive cell”, ACHI, Digital World, 
Le Gosier, France, pp. 153-157, 2011. 
[2] P. Guiberteau, “Démantèlement au CEA. Dismantling at the CEA.”, 
4th European Forum on Radiation Protection, La Grande Motte, 
France, pp. 8, 2010. 
[3] IAEA Safety Standards Series, “Decommissioning of Nuclear Fuel 
Cycle Facilities”, Safety Guide, No WS-G-2.4. 
[4] B.K. Wiederhold and M.D. Wiederhold. “Three-Year Follow-Up for 
Virtual Reality Exposure for Fear of Flying” CyberPsychology & 
Behavior, volume 6 issue 4, pp. 441-445, 2003. 
[5] F. Yaacoub, “Development of virtual reality tools for arthroscopic 
surgery training”, Université Paris-Est, Phd thesis in computer 
science, Paris, France, 2008. 
[6] J.R.Li, L.P. Khoo, and S.B.Tor, “Desktop virtual reality for 
maintenance training: an object oriented prototype system (V-
REALISM)”, Computers in Industry, vol 52, issue 2, pp. 109-125, 
2003. 
[7] R. Gadh,H. Srinivasan, S. Nuggehalli, and R. Figueroa, “Virtual 
disassembly-a software tool for developing product dismantling and 
maintenance systems”, Reliability and Maintainability Symposium, 
1998. Proceedings., pp. 120-125, 1988. 
[8] J. Ródenas, I. Zarza, M. C. Burgos, A. Felipe, and M. L. Sánchez-
Mayoral, “Developing a virtual reality application for training nuclear 
power plant operators: setting up a database containing dose rates in 
the refuelling plant”, Radiation Protection Dosimetry, volume 111 
issue 2, pp. 173-180, 2004. 
[9] Institute for Energy Technology, datasheet on Chernobyl NPP 
decommissioning 
assistance 
project, 
http://www.ife.no/departments/visual_interface_technologies/projects
/chnpp/view . 
[10] H. Jorke and M. Fritz, “INFITEC- a new stereoscopic visualisation 
tool by wavelength multiplex imaging”,  Journal of Three 
Dimensional Images, vol.19, pp. 50-56, Japan, 2005. 
[11] ARTracking, http://www.ar-tracking.de  

356
International Journal on Advances in Intelligent Systems, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/intelligent_systems/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[12] F. Gosselin, C. Andriot, J. Savall, and J. Martin, “Large workspace 
Haptic 
Devices 
for 
Human-Scale 
Interaction: 
A 
Survey”, 
EuroHaptics, LNCS 5024, pp.523-528, 2008. 
[13] C. Limousin, J. Sebot, A. Vartanian, and N. Drach, “Architecture 
optimization for multimedia application exploiting data and thread-
level parallelism”, Journal of Systems Architecture, vol. 51, issue 1, 
pp. 15-27, 2005. 
[14] 3DVIA, http://www.3ds.com/products/3dvia/3dvia-virtools/welcome/ 
[15] M.W. Jones and R. Satherley, “Voxelisation: Modelling for Volume 
Graphics”, proceedings VMV’2000, pp. 319-326, 2000. 
[16] Haption, 
IPSI 
datasheet. 
Available 
from  
http://www.haption.com/site/eng/images/pdf_download/Datasheet_IP
SI.pdf. 
[17] O. David, Y. Measson, C. Rotinat, F-X. Russotto, and C. Bidard, 
“Maestro, 
a 
Hydraulic 
Manipulator 
for 
Maintenance 
and 
Decommissioning Application”, ENC, Bruxelles, Belgium, pp. 54-61, 
2007. 
[18] Haption, 
Virtuose 
6D35-45 
datasheet, 
Available 
from 
http://www.haption.com/site/pdf/Datasheet_Virtuose_6D35-45.pdf.  
[19] ESIC SN, MEEX datasheet, Available from http://www.esic-
sn.fr/spip.php?article14.  
[20] J-B. Thevenon, L. Lopez, C. Chabal, and J-M. Idasiak, “Using 
simulation for intervention design in radiating environment: first 
evaluation of NARVEOS”, GLOBAL, Paris, France, pp.153-157, 
2009. 

