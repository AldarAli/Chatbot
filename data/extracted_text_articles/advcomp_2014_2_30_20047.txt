Rice-Planted Area Detection by Using Self-Organizing Feature Map
Sigeru Omatu
Department of of Electronics, Information, and
Communication Engineering
Osaka Institute of Technology
Osaka, JAPAN 535–8585
Email: omtsgr@gmail.com
Mitsuaki Yano
Department of of Electronics, Information, and
Communication Engineering
Osaka Institute of Technology
Osaka, JAPAN 535–8585
Email: yano@elc.oit.ac.jp
Abstract—This paper considers a classiﬁcation of estimation of
rice planted area by using remote sensing data. The classiﬁcation
method is based on a competitive neural network and the
sattelite data are remote sensing data observed before and
after planting rice in 1999 in Hiroshima, Japan. Three RADAR
Satellite (RADARSAT) and one Satellite Pour l’Observation de
la Terre(SPOT)/High Resolution Visible (HRV) data are used
to extract rice-planted area. Synthetic Aperture Radar (SAR)
back-scattering intensity in rice-planted area decreases from
April to May and increases from May to June. Thus, three
RADARSAT images from April to June are used in this study.
The SOM classiﬁcation was applied the RADARSAT and SPOT
to evaluate the rice-planted area estimation. It is shown that
the Self-Organizing feature Map (SOM) of competitive neural
networks is useful for the classiﬁcation of the satellite data by
SAR to estimate the rice planted area.
Keywords–Remote Sensing; RADAR Satellite; Synthetic Aper-
ture Radar; Self-Organizing Feature Map
I.
INTRODUCTION
We have noticed that rice is the most important agricultural
product and widely planted in the wide area in Japan. But,
it is still difﬁcult to estimate rice-planted areas every year.
Therefore, the development of a system for monitoring the
rice crop will be prefarable. Satellite remote sensing images by
optical sensors like LANDSAT TM or SPOT HRV, have been
used to estimate a rice-planted area. However, these optical
sensors have been unable to get necessary data at a suitable
time because it is often cloudy or rainy during the rice planting
season in Japan [1][2][3][4].
On the other hand, SAR penetrates through the cloud
covered. Hence, it can observe the land surface under all
weather conditions [5][6][7][8]. The back-scattering intensity
of C-band SAR images, such as RADARSAT or ERS1/SAR,
changes greatly from non-cultivated bare soil condition before
rice planting to inundated condition just after rice planting [1].
In addition, RADARSAT images are rather sensitive to the
change of rice biomass in a growing period of rice [9][10].
Thus, a rice area estimation is expected to be achieved in
an early stage. In previous works [2][3][4], we attempted to
estimate rice-planted area using RADARSAT ﬁne-mode data in
an early stage. The estimation accuracy of a rice-planted area
by Maximum Lkelihhood Method (MLH) was approximately
40% by comparing with the estimated area by SPOT multi-
spectral data. In this study, we attempt to detect the rice-
planted area from RADARSAT data using SOM that is the
unsupervised classiﬁcation [11].
In Section II, test site and remote sensing data used here
will be explained and in Section III, data correction of geo-
metric distortion will be shown. In Section IV, SOM algorithm
will be explained and in Section V, evaluation indexes will be
introduced. In Section VI, training results will be shown and
in Section VII, selection of training iteration will be discussed.
After that, in Section VIII, classiﬁcation results will be shown
and in Section IX, experimental results will be shown. Finally,
in Section X, we will conclude the results and state some future
aspects.
II.
TEST SITE AND DATA
The test area has a size of about 7.5×5.5 km in Higashi-
Hiroshima, Japan shown, as a white block in Fig. 1; the
enlarged image is shown in Fig. 2. This site is located at
the eastern part of Hiroshima, Japan. Three multi-temporal
RADARSAT ﬁne-mode (F1F) images, taken on April 8, May
26, and June 19, in 1999 were used as the test data. SPOT/HRV
multi- spectral data taken on June 21, 1999 were used to
generate a reference image for rice-planted area extraction.
Three merged RADARSAT and one SPOT images in a
part of the test site are shown in Figs. 3 and 4. The land
surface condition in the rice-planted area of April 8 is a non-
cultivated bare soil before rice planting with rather rough soil
surface. The surface condition of May 26 is almost smooth
water surface just after rice planting, and that of June 19 is
a mixed condition of growing rice and water surface. It is
found that the rice-planted areas are shown in a dark tone
in the RADARSAT image. The RADARSAT raw data were
processed using Vexcel SAR Processor (VSARP) and single-
look power images with 6.25 meters ground resolution were
generated. Then, the images were ﬁltered using median ﬁlter
with 7×7 moving window. All RADARSAT and SPOT images
were overlaid onto the topographic map with 1:25,000 scale.
As RADARSAT images are much distorted by foreshortening
due to topography, the digital elevation model (DEM) with
50 meters spatial resolution issued by Geographical Survey
Institute (GSI) of Japan [2] was used to correct foreshortening
of RADARSAT images.
The speciﬁcations of RADARSAT-1/SAR ﬁne mode pa-
rameters and SPOT-2/HRV parameters are given by Table I
and Table II, respectively.
36
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

Figure 1.
RADARSAT ﬁne mode image of Higashi-Hiroshima, Japan where
the area enclosed by a white line denotes the analised area.
Figure 2.
RADARSAT ﬁne mode image of Higashi-Hiroshima where the
area enclosed by a white line in Fig. 1 is enlarged..
III.
DATA CORRECTION OF GEOMETRIC DISTORTION
SAR or SPOT data observe the land surface from an
oblique position as shown in Fig. 5. In Fig. 5, θ denotes
incident angles and in case of optical remote sensing data,
a deformation D at the height h is given by D = h tan θ. In
case of SAR remote sensing data, it becomes D = h/ tan θ.
Therefore, we must correct the remote sensing data according
to the hight of the target pixcel. We adopt the mesh data
Figure 3.
SPOT-2/HRV image(1999/6/21, R:Band 3, G:Band 2, B:Band 1)
where the area enclosed by a white line denotes the test area 息 CNESS 1999.
Figure 4.
SPOT-2/HRV image(1999/6/21, R:Band 3, G:Band 2, B:Band 1)
in the test site 息 CNESS 1999.
TABLE I.
THE PARAMETERS OF RADARSAT-1/SAR FINE MODE
PARAMETERS
Launching agency
Canadian Space Agency
Launching date
1995/11/04
Attitude
798km
Repeat cycle
24 days
Frequency
53GHz
Polarization
HH
Resolution
8m
Observation range
45km
TABLE II.
THE PARAMETERS OF SPOT-2/HRV PARAMETERS
Launching agency
CNES
Launching date
202/05/4
Attitude
822km
Repeat cycle
26 days
Band width
Multi-spectral mode
XS1 0.50-0.59 µ m
XS2 0.61-0.68 µ m
XS3 0.79-0.89 µ m
Resolution
5m
Observation range
60km
published at GSI of Japan[2].
37
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

DP
=
a1P + a2L + a3h + a4
(1)
DL
=
b1P + b2L + b3h + b4.
(2)
Here, DP and DLare distortions of pixel and line directions,
P and L denote coordinate values of pixel and line directions,
respectively. Furthermore, h is the hight of area and ai, i =
1, 2, 3, 4 and bi, i = 1, 2, 3, 4 are regression coefﬁcients.
IV.
SOM ALGORITHM
We brieﬂy summarize the algorithm for SOM. The struc-
ture of SOM consists of two layers. One is an input layer and
the other is a competitive layer. The total input to a neuron j
is denoted by netj and modeled by the following equations:
netj
=
n
∑
i
wjixi = (wj1, wj2, . . . , wjn)(x1, x2, . . . , xn)t
=
WjXt
(3)
Wj
=
(wj1, wj2, . . . , wjn), X = (x1, x2, . . . , xn)
(4)
where (·)tdenotes the transpose of (·) and xi and wji show
an input in the input layer and a weighting function from the
input xi to a neuron j in the competitive layer, respectively.
For simplicity, we assume that the norms of X and Wj are
equalt to one, that is,
∥x∥ = 1,
∥Wj∥ = 1, j = 1, 2, . . . , N
(5)
where ∥ · ∥ shows Eucridean norm and N denotes the total
number of neurons in the competitive layer.
When an input vector X is applied to the input layer, we
ﬁnd the nearest neighboring weight vector Wc to the input
vector X such that
∥Wc − X∥ = min
i
∥Wi − X∥.
(6)
The neuron c corresponding to the weight vector Wc
is called a winner neuron. We select neighborhood neurons
within the distance d which are shown in Fig. 6 and a set of
indices for neurons located in the neighborhood of c is denoted
by Nc. Then, the weighting vectors of the neurons contained
in Nc are changed such that those weighting vectors could
become similar to the input vector X as close as possible. In
other words, the weighting vectors are adjusted as follows:
∆Wj
=
η(t)(Wj − X)
∀j ∈ Nc
(7)
∆Wj
=
0
∀j /∈ Nc
(8)
θ
θ
D
SAR
h
OPS
θ
D
h
θ
Figure 5.
The principle of distortion of remote sensing data depending on
the hights in case of optical sensory data and SAR data.
 
Input layer 
   d 
  c 
  Nc 
Competitive  
Layer 
Figure 6.
SOM structure of the neural network.
where
∆Wj
=
Wj(new) − Wj(old)
(9)
η(t)
=
η0(1 − t
T ),
d(t) = d0(1 − t
T ). (10)
Here, t and T denote an iteration number and the total iteration
number for learning, respectively. η0 and d0 are positive and
denote initial values of η(t) and d(t), respectively where d(t)
denotes an Euclid distance from the winner neuron c.
V.
EVALUATION OF SOM
We will introduce two criteria, namely, precision and recall
to ﬁnd a suitable SOM. The precision is deﬁned by
Pr = R
N × 100(%)
(11)
and the recall is deﬁned by
Rr = R
C × 100(%)
(12)
where Pr and Rr denote the precision rate and the recall rate,
respectively and N is a trial number, R is a correct classiﬁed
number, and C is a total correct number. As shown in Fig. 7,
if we try to increase Pr, then, Rr will decrease. Therefore, we
adopt a criterion f-measure deﬁned by
fm = 2 × Pr × Rr
Pr + Rr
× 100(%).
(13)
VI.
TRAINING OF SOM
In order to ﬁnd a suitable size of competitive layer, we
assume map size m as 3×3, 4×4, 5×5, 6×6, and 7×7. We
take an initila learning rate α0=0.2 and an initial value of
neighborhood d0=2. Furthermore, we assume initial values
of connection weights as random numbers of [0.1, 0.9] and
itelation number t=5. The training results of SOM are shown
38
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

X
X
Correct region
N
C
R
Classification region
Figure 7.
Classiﬁcation region for the precision and the recall.
in Fig. 8 and Fig. 9 for SPOT remote sensing data and
RADARSAT remote sensing data, respectively.
3 x 3
4 x 4
5 x 5
6 x 6
7 x 7
Figure 8.
Learning results for SPOT remote sensing data.
3 x 3
4 x 4
5 x 5
6 x 6
7 x 7
Figure 9.
Learning results for RADARSAT remote sensing data
After taining the neural network of SOM, we calculate
the Pr, Rr, and fm for SPOT and RADARSAT remote
sensing data. The results are shown in Table III and Table IV,
respectively. From Table III, we can see that the classiﬁcation
result of the map size 4×4 is highest value of fm=84.49. Thus,
in case of a small number of category, we can set small number
of neurons in the competitive layer. From Table IV, we can
see that fm becomes largest in case of 4×4.
TABLE III.
Pr,Rr, AND fm FOR SIZES OF SPOT REMOTE SENSING
DATA
Size of map
Pr
Rr
fm
3times3
98.95
64.67
78.22
4times4
100
73.15
84.49
5times5
93.62
76.65
84.29
6times6
85.65
68.65
76.21
7times7
96.16
63.00
76.13
TABLE IV.
Pr,Rr, AND fm FOR SIZES OF RADARSAT REMOTE
SENSING DATA
Size of map
Pr
Rr
fm
3times3
63.08
47.72
54.34
4times4
60.99
51.38
55.77
5times5
62.73
46.41
53.35
6times6
60.48
51.02
55.35
7times7
47.63
64.70
54.87
VII.
SELECTION OF TRAINING ITERATION
We consider the iteration t for learning. Here, we count
t=1when an input image of 1,800,000 pixels of 1,500pixels
per line ×1,200 lines has been trained. In this experiment, we
take t=1 (1,800,000 training), t=5 (9,000,000 training), t=10
(18,000,000 training), t=20 (36,000,000 training). Except for
t, we take a size of neurons in the competitive layer as 4×4,
α0=0.2, and an initial vector W0 of weighting functions are
random numbers of [0.1, 0.9]. The results are shown in Table
V and Table VI for SPOT and RADARSAT remote sensinr
data, respectively.
TABLE V.
Pr, Rr, AND fm FOR ITERATIONS OF SPOT
Iteration
Pr
Rr
fm
1
100
64.67
78.22
5
100
73.15
84.49
10
100
76.65
84.29
20
100
68.65
76.21
TABLE VI.
THE VALUES OF Pr,Rr, AND fm FOR ITERATIONS OF
RADARSAT
Iteration
Pr
Rr
fm
1
58.40
50.29
54.04
5
60.99
51.38
55.77
10
61.00
51.31
55.74
20
61.01
51.34
55.76
From Table V, we can see the maximum value of fm=84.55
is obtained when t=5 for SPOT remote sensing data and from
Table VI, the maximum value of fm=55.77 is obtained when
t=5. Therefore, we set t=5 in what follows.
VIII.
CLASSIFICATION RESULTS
A rice-planted area was extracted by using SOM from three
temporal RADARSAT images and one SPOT image. SOM is
a classiﬁcation method based on competitive neural networks
without teacher. It was applied to the remote sensing data by
using the parameters as shown in Table VII. RADARSAT and
SPOT images were classiﬁed into 16 categories by SOM. Then,
we labeled the categories into a rice-planted area, a forest area
and an urban area.
IX.
EXPERIMENTAL RESULTS AND DISCUSSION
In order to make the proposed method effective, we classify
the satellite image data by SOM. Fig. 10 shows the classiﬁca-
tion image by SPOT and Fig. 11 shows the classiﬁcation image
by RADARSAT. By comparing Fig. 10 with Fig. 11, one can
see that the rice-planted area by RADARSAT was extracted
less than that by SPOT. The speckle noise was still seen in the
image of rice-planted area, the majority ﬁlter with 7×7 window
was applied to the rice extracted images by RADARSAT and
SPOT. For the evaluation of the rice-planted area extraction,
we deﬁned two indices, True Production Rate (TPR) and False
Production Rate (FPR). The TPR and FPR are calculated by
TPR
=
α
α + β × 100
(14)
FPR
=
γ
α + γ × 100
(15)
where α means the number of relevant rice-planted area
extracted, β means the number of relevant rice-planted area not
TABLE VII.
THE PARAMETERS OF SOM
Neurons
Training iterations
η0
d0
4 × 4
1080,000
0.03
2
39
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

extracted, and γmeans the number of irrelevant rice-planted
area extracted. Extraction rice-planted area of SPOT image
by supervised MLH was used as reference rice-planted area
image.
Figure 10.
Classiﬁcation result of SPOT image by SOM (White: rice, Light
gray: forest, Dark gray: urban).
Figure 11.
Classiﬁcation result of RADARSAT image by SOM (White: rice,
Light gray: forest, Dark gray: urban).
Table VIII shows the results of TPR and FPR by SOM
and MLH classiﬁcation for SPOT data and RADARSAT data.
From this results we can see that in case of RADARSAT data,
the values of TPR (extraction rate of rice-planted area) are,
50.97% and 60.96% for MLH and SOM, respectively. This
Figure 12.
Extraction result of rice-planted area by SPOT data.
Figure 13.
Extraction result of rice-planted area by multi temporal
RADARSAT data.
means that SOM is better than MLH for extraction of rice-
planted area by about 10%. As for FPR (misclassiﬁcation rate)
SOM is also better than MLH by about 3%. The SPOT data
is very ﬁne images like 5m per pixel and we can assume the
image of SPOT reﬂects almost all land surface. Using SPOT
data TPR and FPR are 70.41% and 21.51%, respectively. Thus,
we could extract rice-planted area a certain level in practice
fron Table VIII.
Figs. 12 and 13 show the extraction result of rice-planted
area by SPOT and RADARSAT, respectively. The results show
that ﬁne rice-planted area could be extracted by using SOM
40
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

compared with MLH from there ﬁgures.
TABLE VIII.
THE RESULTS OF TPR AND FPR FOR RICE-PLANTED
AREA EVALUATION
Comparison data
Classiﬁcation method
TPR(%)
FPR(%)
SPOT
SOM
70.4
21.51
RADARSAT
MLH
50.97
51.44
RADARSAT
SOM
60.97
48.59
X.
CONCLUSION AND FUTURE WORK
Rice-planted area extraction was attempted using multi-
temporal RADARSAT data taken in an early stage of rice
growing season by SOM classiﬁcations. The SOM is unsuper-
vised classiﬁcation whose computational time is shorter than
the other supervised classiﬁcation method like MLH [3] or
LVQ [4][11]. We have been engaged with image analysis on
remote sensing data analysis. Especially, we are concentrated
on SAR data analysis to land cover classiﬁcation by using
neural network classiﬁcation methods. Since the SAR data is
completely different with optical sensor images, it is difﬁcult
to obtain usual land cover map although it can observe the
earth at any time and under any weather conditions such as
rainy or cloudy occasion. Thus, we must develop the special
attention to get suitable classiﬁcation results. In this paper,
we have developed a method to allocate seasonal data to get
the color image and show the change of rice ﬁeld area in a
visual way. It takes much time for extraction of features of
SAR images, we must speed up the classiﬁcation. we are now
developing nearest neighbor algorithm. As for this results, we
will show the results near future. The future study, we will
apply this proposed and other neural network method to other
SAR data due to the extraction rice-planted area. As we could
obtain more high resolution images, we are checking the preset
results for those big data and trying to make senario for them.
ACKNOWLEDGMENT
This work was supported by JSPS KAKENHI Grant-in-Aid
for Challenging Exploratory Research (25630180). The authors
would like to thank JSPS to support this research work.
REFERENCES
[1]
Y. Suga, Y. Oguro, and S. Takeuchi, “Comparison of Various SAR Data
for Vegetation Analysis over Hiroshima City”, Advanced Space Research,
vol. 23, August, 1999, pp. 225–230.
[2]
Y. Suga, S. Takeuchi, and Y. Oguro, “Monitoring of Rice-Planted Areas
Using Space-borne SAR Data”, Proceedings of IAPRS, XXXIII, B7,
February, 2000, pp. 741–743.
[3]
S. Omatu, “Rice-Planted Areas Extraction by RADARSAT Data Using
Learning Vector Quantization Algorithm”, Proceedings of ADVCOMP
2013, Sep., 2013, pp. 19–233.
[4]
T. Konishi, S. Omatu, and Y. Suga, “Extraction of Rice-Planted Areas
Using a Self-Organizing Feature Map ”, Artiﬁcial Life and Robotics,
2007, vol. 11, pp. 215–218.
[5]
I. H. Woodhouse, Introduction to Microwave Remote Sensing. CRC
Press, London, Nov. 2005, ISBN: 0-415-27123-1.
[6]
C. M. Ryan, T. Hill, E. Woollen, C. Ghee, E. Mitchard, G. Cassells,
J. Grace, I. H. Woodhouse, and M. Williams, “Quantifying Small-Scale
Deforestation and Forest Degradation in African Woodlands Using Radar
Imagery ”, Global Change Biology, vol. 18, pp. 243–257, 2012 ISSN:
1365-2486.
[7]
E. T. A. Mitchard, S. S. Saatchi, L. J. T. White, K. A. Abernethy,
K. J.Jeffery, S. L.Lewis, M. Collins, M. A.Lefsky, M. E. Leal, I. H.
Woodhouse, and P. Meir, “Mapping Tropical Forest Biomass with Radar
and Spaceborne LiDAR in Lope National Park, Gabon: Overcoming
Problems of High Biomass and Persistent Cloud”, Biogeosciences, vol.
9, pp. 179-191, 2012, doi: 10.5194/bg-9-179-2012.
[8]
C. H. Chen, Ed.,Signal and Image Processing, London, Jan. 2007,
chapter 27, pp. 607–619, M. Yoshioka, T. Fujinaka, and S. Omatu,SAR
Image Classiﬁcation by Support Vector Machine , ISBN: 0-8493-5091-3.
[9]
M. Bicego and T. L. Toan, “Rice Field Mapping and Monitoring with
RADARSAT Data”, International Journal of Remote Sensing, vol. 20,
April, 1999, pp. 745–765.
[10]
S. C. Liew, and P. Chen, “Monitoring Changes in Rice Cropping System
Using Space-borne SAR Imagery”, Proceedings of IGARSA’99, Oct.,
1999, pp. 741–743.
[11]
T. Kohonen, “Self-Organizing Maps”, Springer, 1997, pp. 206–217,
ISBN 3-540-62017-6.
41
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

