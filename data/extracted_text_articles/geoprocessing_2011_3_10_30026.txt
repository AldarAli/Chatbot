Water
Water
Water
Water Area
Area
Area
Area Extraction
Extraction
Extraction
Extraction from
from
from
from RGB
RGB
RGB
RGB Aerophotograph
Aerophotograph
Aerophotograph
Aerophotograph Based
Based
Based
Based on
on
on
on Chromatic
Chromatic
Chromatic
Chromatic and
and
and
and
Textural
Textural
Textural
Textural Analysis
Analysis
Analysis
Analysis
Meng Zhao
Huazhe Shang
Wenchao Huang
Lizhi Zou
Yongjun Zhang
School of Remote Sensing and Information Engineering,
Wuhan University
Wuhan, China
zmatwhu@yahoo.cn
754773310@qq.com
423036600@qq.com
867750650@qq.com
yongjun_zhang@sina.com
Abstract
Abstract
Abstract
Abstract—
—
—
—When
When
When
When
triangulating
triangulating
triangulating
triangulating
RGB
RGB
RGB
RGB
aerophotograph,
aerophotograph,
aerophotograph,
aerophotograph,
iiiiffff
automatically
automatically
automatically
automatically and
and
and
and randomly
randomly
randomly
randomly selected
selected
selected
selected matching
matching
matching
matching pass
pass
pass
pass points
points
points
points
unfortunately
unfortunately
unfortunately
unfortunately locates
locates
locates
locates into
into
into
into water
water
water
water areas,
areas,
areas,
areas, these
these
these
these points,
points,
points,
points, limited
limited
limited
limited by
by
by
by
their
their
their
their inaccuracy,
inaccuracy,
inaccuracy,
inaccuracy, will
will
will
will decrease
decrease
decrease
decrease the
the
the
the precision
precision
precision
precision of
of
of
of triangulation.
triangulation.
triangulation.
triangulation.
Therefore,
Therefore,
Therefore,
Therefore, extraction
extraction
extraction
extraction of
of
of
of water
water
water
water area
area
area
area beforehand
beforehand
beforehand
beforehand isisisis conducive
conducive
conducive
conducive to
to
to
to
eliminate
eliminate
eliminate
eliminate water
water
water
water falling
falling
falling
falling pass
pass
pass
pass points
points
points
points and
and
and
and guarantee
guarantee
guarantee
guarantee the
the
the
the quality
quality
quality
quality of
of
of
of
aerotriangulation.
aerotriangulation.
aerotriangulation.
aerotriangulation. AAAA new
new
new
new methodology
methodology
methodology
methodology to
to
to
to extract
extract
extract
extract water
water
water
water area
area
area
area
from
from
from
from RGB
RGB
RGB
RGB aerophotograph
aerophotograph
aerophotograph
aerophotograph
isisisis put
put
put
put forth
forth
forth
forth
in
in
in
in this
this
this
this paper.
paper.
paper.
paper.
Procedure
Procedure
Procedure
Procedure initiates
initiates
initiates
initiates by
by
by
by segment
segment
segment
segmenting
ing
ing
ing the
the
the
the whole
whole
whole
whole aerophotograph
aerophotograph
aerophotograph
aerophotograph
into
into
into
into homogenous
homogenous
homogenous
homogenous and
and
and
and united
united
united
united segments
segments
segments
segments.... Subsequently,
Subsequently,
Subsequently,
Subsequently, compute
compute
compute
compute
chromatic
chromatic
chromatic
chromatic and
and
and
and textural
textural
textural
textural features
features
features
features of
of
of
of every
every
every
every segment
segment
segment
segment and
and
and
and compare
compare
compare
compare
each
each
each
each segment
segment
segment
segment’’’’ssss features
features
features
features to
to
to
to sampled
sampled
sampled
sampled water
water
water
water segments
segments
segments
segments’’’’ features.
features.
features.
features.
Finally
Finally
Finally
Finally extract
extract
extract
extract those
those
those
those segments
segments
segments
segments whose
whose
whose
whose chromatic
chromatic
chromatic
chromatic and
and
and
and textural
textural
textural
textural
features
features
features
features are
are
are
are similar
similar
similar
similar to
to
to
to sampled
sampled
sampled
sampled segment
segment
segment
segmentssss’’’’ as
as
as
as water
water
water
water areas.
areas.
areas.
areas. This
This
This
This
methodology
methodology
methodology
methodology has
has
has
has aaaa relatively
relatively
relatively
relatively obvious
obvious
obvious
obvious merit
merit
merit
merit in
in
in
in effectiveness
effectiveness
effectiveness
effectiveness and
and
and
and
generality.
generality.
generality.
generality.
Keywords
Keywords
Keywords
Keywords—
—
—
—CIELAB
CIELAB
CIELAB
CIELAB;;;;
chromatic
chromatic
chromatic
chromatic
analysis
analysis
analysis
analysis;;;;
textual
textual
textual
textual
analysis
analysis
analysis
analysis;;;;
watershed
watershed
watershed
watershed segmentation
segmentation
segmentation
segmentation;;;; ISODAT
ISODAT
ISODAT
ISODATAAAA
I.
INTRODUCTION
Aerotriangulation is a key step in aerophotogrammetry.
The basic goal of aerotriangulation is to compute all
elements of exterior orientation and pass points of a region
by block adjustment. The accuracy of matching points on
aerophotograph directly relates to the precision of block
adjustments and the final production of aerotriangulation.
However, water areas, influenced by wind force and gravity,
are
usually
in
irregular
motion. If
automatically
and
randomly selected matching pass points (a few pass points
selected beforehand to compute the exterior orientation
elements) unfortunately falls into water areas, these points,
limited by their inaccuracy, will decrease the precision of
triangulation.
Therefore,
extraction
of
water
areas
beforehand is conducive to eliminate water falling pass
points and guarantee the quality of aerotriangulation. In this
paper, we concentrate on extracting water areas from RGB
aerophotograph and mark them.
Multispectral aerophotograph and remote sensing image
can synthesize information of different spectrums to extract
water region. J. Deng operated different bands of SPOT-5
images to extract water area [1]. H. Xu modified MNDWI
value to extract water area from multispectral remotely
sensed data [2]. In contrast to multispectral data, RGB
aerophotograph (every pixel of the image is consisted of red,
green and blue values) has only three bands and little extra
spectrum information. Consequently, until recently, no
effective methodology has been proposed to extract water
area from RGB aerophotograph. In order to supply such a
gap, we put forth a methodology in this paper to extract
water area from RGB aerophotograph.
With
the
enhancement
of
image
resolution,
aerophotographs contain more abundant space information
as well as geometric and textual features, which create a
favorable condition for extracting objects via chromatic and
textual analysis. W. Ma and B. S. Manjunath had used
textural analysis to create a texture thesaurus for browsing
large aerophotographs and achieved relatively good retrieval
effect [3]. Other trials include W. Niblack’s querying image
using color, texture and shape [4]. All these researches
manifest a fact that chromatic and textural analyses are
effective in extracting and retrieving objects.
Enlightened by chromatic and textural analysis, we
propose a new series of procedures to extract water areas
from
RGB
aerophotographs.
Procedure
initiates
by
segmenting the whole aerophotograph into homogenous and
united
regions.
Subsequently,
compute
chromatic
and
textural features of every region and then compare each
region’s feature to sampled water regions’ features. Finally
extract those segments whose chromatic and textural features
are similar to sampled segments’ as water areas. This
methodology has a relatively obvious merit in effectiveness
and generality.
Water areas on aerophotographs are usually homogenous
and united; therefore water regions after segmentation
always are homogenous and united. We have no need to care
about the accuracy in segmentation of other objects because
they contribute little to
water
extraction. We choose
watershed segmentation algorithm (Section Ⅲ ) because it
can
help
attain
satisfactory
segmentation
result.
The
homogenous and united characteristic of water region also
provides pleasing condition to conduct chromatic analysis
(Section Ⅱ) and textural analysis (Section Ⅳ). Chromatic
and textural features of every region will be added to its own
feature vector (Section Ⅴ ). Water appears differently on
photographs. In order to automatically recognize water areas,
we need to sample water regions of all appearances
beforehand and classify them. ISODATA algorithm (Section
Ⅴ ) is employed to classify those samples into several
categories. If the distance is within a threshold between a
certain region’s feature vector and any one of those
46
GEOProcessing 2011 : The Third International Conference on Advanced Geographic Information Systems, Applications, and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-118-2

categories’, then this segment will be identified and extracted
as water area.
RGB aerophotograph consists of three channels (Red,
Green, and Blue) and they are closely pertinent to each other.
We need to integrate them into one channel in order to
conduct image segmentation and textural analysis. In this
paper, we utilize CIELAB color space to integrate those
three channels, which decreases their pertinence as well as
provides prerequisites for image segmentation and textural
analysis later on.
Any color is unable to be both green and red or both blue
and yellow. This principle prompts the CIELAB color space.
CIELAB color space inherits the XYZ standard color system.
CIELAB indicates distinctions between light and dark, red
and green, and blue and yellow by using three axes: L*, a*,
b*. The central vertical axis represents lightness (L*) whose
value ranges from 0 (black) to 100 (white). On each axis the
value runs from positive to negative. On a-a' axis, positive
values indicate amounts of red while negative indicate
amounts of green. On the b-b' axis, yellow is positive and
blue is negative. For both axes, zero is neutral [5].
“Texture” refers to the arrangement or characteristic of
the constituent elements of anything. A texture feature is a
value, computed from the image of a region, which
quantifies gray-level variation within the region. According
to Kenneth [6], a texture feature value is irrelevant to
region’s position, orientation, size, shape and brightness
(average gray level). Therefore, the shape and size of
segmented area do not interfere with the result of chromatic
and textural analysis.
According to Julesz [7] and his deduction, human texture
discrimination is based on the second order statistic of image
intensities, which gave rise to the emergence of a popular
textural descriptor: co-occurrence matrix. A co-occurrence
matrix counts the exact times of different grey level pairs of
pixels, separated by a certain distance (one pixel, two pixels,
etc.). The (i, j) element of the co-occurrence matrix P for a
certain region is the number of times, divided by M, that
gray levels i and j occur in two pixels separated by that
distance and lying along that direction in the region, where
M is the number of pixel pairs contributing to P. The P
matrix is N by N, where the gray scale has N shades of gray
[6].
Watershed segmentation is an approach based on the
concept
of
morphological
watersheds.
In
such
a
“topographic”
interpretation,
every
pixel’s
gray
level
denotes its “height”. For a particular regional minimum, the
set of points at which a drop of water, if placed at the
location of any of those points, would fall with certainty to a
single minimum is called the catchment basin. And the
points at which a water drop would be equally likely to fall
to more than one such minimum constitute crest lines on the
topographic surface and termed watershed lines. Assume
that a hole is punched in each regional minimum and that
the entire topography is flooded from below by letting water
rise through the holes at a same rate. When the rising water
from different catchment basins is about to merge, a dam is
built to prevent the merging. The flooding will finally reach
a stage when only the tops of the dams are visible above the
water lines. These dam boundaries correspond to the divide
lines of the watersheds. Therefore, they are boundaries
extracted by a water shed segmentation algorithm [7].
II.
CIELAB COLOR SPACE AND CHROMATIC ANALYSIS
There are two steps to transform RGB color space to
CIELAB color space [5]. The first step is to apply the
following matrix to convert RGB color space to CIEXYZ
color space.
X
0.412453
0.357580
0.180423
R
Y
0.212671
0.715160
0.072169
G
Z
0.019334
0.119193
0.950227
B
=
⋅
⎡ ⎤
⎡
⎤ ⎡ ⎤
⎢ ⎥
⎢
⎥ ⎢ ⎥
⎢ ⎥
⎢
⎥ ⎢ ⎥
⎢ ⎥
⎢
⎥ ⎢ ⎥
⎣ ⎦
⎣
⎦ ⎣ ⎦
(1)
Subsequently, (X*, Y*, Z*) need to be calculated.
When
n
n
X / X , Y / Y , Z / Zn
> 0.008856
,
3
n
X
X / X
=
(2)
3
n
Y
Y / Y
=
(3)
3
n
Z
Z / Z
=
(4)
When
n
n
X / X , Y / Y , Z / Zn
≤ 0.008856
,
n
X*
7.787 (X / X )
0.138
=
⋅
+
(5)
n
Y*
7.787 (Y / Y )
0.138
=
⋅
+
(6)
n
Z*
7.787 (Z / Z )
0.138
=
⋅
+
(7)
n
n
n
(X ,Y , Z ) = (0.312779, 0.329184, 0.358037) represents
the white reference point, which indicates a completely matte
white body.
Then L*, a*, b* can be calculated through following
equations:
L
= 116 Y * 16
⋅
−
(8)
a*
= 500 (X*-Y*)
⋅
(9)
b*
= 200 (Y * Z*)
⋅
−
(10)
The application of CIELAB color space in this paper
can be briefly illustrated using diagramⅠ.
DIAGRAM
Ⅰ
APPLICATION OF CIELAB COLOR SPACE
The L* component of CIELAB color space can be used
in watershed segmentation (Section Ⅲ). L* component can
also be used in textual analysis (Section
Ⅳ ). We use
equations mentioned above to convert every pixel on an
47
GEOProcessing 2011 : The Third International Conference on Advanced Geographic Information Systems, Applications, and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-118-2

aerophotograph from RGB color space to CIELAB color
space. Then form a gray image by using the L* component
of every pixel’s CIELAB color space. Although the gray
photograph is no longer quantified 256 gray levels, L*
component brings unexpected results in chromatic analysis
and textural analysis later on.
Segmented areas usually have similar color space and
we can use the average a*, b* of all pixels in a region to
represent
its
chromatic
feature.
Experiments
have
demonstrated that chromatic feature between non-water
areas and water areas is obvious, which means a*, b* can be
employed to chromatically describe a region. We utilize a*
and b* as parameters to describe a segmented region
chromatically in feature vector (Section Ⅴ). If regions have
similar chromatic feature with sampled water areas, they are
possibly water areas we want to extract.
III.
IMAGE SEGMENTATION
In our methodology, we replace the 256 gray level with
L*
component
of
CIELAB
color
space.
Using
this
replacement, we could form a gray picture by synthesizing
three channels of RGB aerophotographs. Compared to
simply using average gray level of three channels to form a
gray photograph, the usage of L* component can decrease
fragments after segmentation and attain a relatively clear
and accurate edge.
(a)
(b)
Figure 1.
Comparison of Segmentation: (a) is attained by using the
average gray level of RGB to form a gray picture. (b) is attained by using
L* component of CIELAB color space to form a gray picture
In Fig. 1, (b) shows a correct and clear boundary between
water area and non-water area, while result (a) displays an
inaccurate
boundary.
This
manifests
effectiveness
and
correctness of the L* component in segmenting RGB
aerophotographs.
IV.
TEXTURAL ANALYSIS
In our methodology, we replace traditional 256 scale gray
with the L* component of CIELAB color space. We attain
two advantages by this substitute. First of all, the RGB
components of aerophotograph has been integrated into one
L* component, which ranges from 0 to 100; in addition, the
dimension
of
co-occurrence has
been
decreased
from
256*256 to 101*101. Traditionally, we reduce quantization
level of the input data (e.g., from 8-bit data with values from
0-255 to 5-bit data with values from 0 to 31) when creating
co-occurrence matrices so that the matrices will not become
too large. But this method usually causes texture information
loss, especially detailed information. Taking advantage of
the
L*
component
of
CIELAB
color
space,
the
co-occurrence matrices will decrease its dimension with
relatively little textural information loss.
Haralick proposed 14 features based on co-occurrence
matrices [8]. The angular second-moment feature (ASM) is a
measure of homogeneity of the image.
(
)
2
ASM
p i,  j
i
j
= ∑∑
(11)
p(i, j) is the joint probability of gray pair (i, j) in
co-occurrence P.
Texture is an innate property of virtually all surfaces [8].
Although water seems homogenous and with little obvious
texture, texture feature can still be utilized to discriminate
water area from other non-water area because water area has
a bigger homogeneity than other objects.
In a homogeneous image, there are very few dominant
gray-tone transitions. Hence the P matrix will have some
entries of large magnitude and the ASM feature will be
relatively bigger. In contrast, an image with irregular textures
will have a large number of small entries and hence the ASM
feature will be smaller [8]. Because water areas are usually
homogeneous and united, so the ASM feature for water areas
is relatively bigger than other objects. So we employ ASM as
a textural descriptor.
In order to avoid texture rotating, we compute the
average value of ASM in four directions (0°, 45° ,90°
and 135°) to texturally describe a region. ASM is added to
the feature vector (SectionⅤ).
V.
CLASSIFICATION AND WATER EXTRACTION
A. Feature Vector
A vector is a quantity that has magnitude and direction
and that is commonly represented by a directed line segment
whose
length
represents
the
magnitude
and
whose
orientation in space represents the direction. Feature vector
in this paper denotes that the quantity consists of a region's
feature values. We define feature vector as following:
48
GEOProcessing 2011 : The Third International Conference on Advanced Geographic Information Systems, Applications, and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-118-2

(
FV = ASM,  a*,  b *)
FV
FV
FV
(12)
Different regions have different chromatic and textural
features; therefore every segmented region possesses its
exclusive FV
FV
FV
FV, which represents its uniqueness among other
regions. However, slight difference in FV
FV
FV
FV exists among
regions with similar textural and chromatic features, which
means we could use classification algorithm to categorize
regions with similar feature vectors. Every region's FV
FV
FV
FV has
to be computed for later extraction.
B. Sampling and Unsupervised Classification Using
ISODATA Classification
Practical experience tells us that variances, such as
contamination, fluctuation, ship transportation, etc, render
water display different color and texture feature on RGB
aerophotographs. Therefore, the segmented image has more
than one kind of water. From the segmented image we need
to sample a certain number of water regions via our practical
experience. Such experience can simply tell water regions
apart from other regions like forest and residence, however,
it is less reliable when applied to discriminate differences
within waters. To settle down this problem, we propose to
use ISODATA algorithm to automatically classify sampled
water regions into several categories.
The ISODATA algorithm [9], abbreviated for Iterative
Self-Organizing Data Analysis Technique, is a modification
of
the
k-means
clustering
algorithm.
ISODATA
is
self-organizing because it requires relatively little human
input. Therefore it is a good choice to substitute human
perception to classify waters.
ISODATA algorithm begins by setting a certain amount
of cluster centers for all the samples. Then classify all
samples by shortest distance algorithm. Modify the centers
of every cluster. If two clusters' separation distance in feature
space is below a user-specified threshold, then the two
cluster centers should be merged into one and reclassify all
the samples. If the current iterative time is odd or the amount
of clusters is half fewer than expected, then split the cluster
that has the maximum subparameter of standard deviation
vector and reclassify all samples. If the current iterative time
is even or the amount of clusters is twice bigger than
expected, then merge two clusters whose separation distance
is the closest and reclassify all samples. When the iterative
time has reached maximum time, then the whole algorithm
stops. We have conducted quite a number of experiments
and find that the result of classification is satisfactory if only
the maximum standard deviation and minimum distance
between cluster means are properly set (details, [9]). In our
methodology,
every
segment's
FV
FV
FV
FV
is
the
sample
in
ISODATA algorithm.
C. Water Extraction
Each sampled water region has its unique FV
FV
FV
FV. As
discussed above, similar water regions have slight difference
in FV
FV
FV
FV; therefore, ISODATA algorithm will automatically
classify regions with analogous FV
FV
FV
FV into one same class.
After the completion of ISODATA algorithm, each class has
a cluster center vector (CCV
CCV
CCV
CCV) and a standard deviation
vector (SDV
SDV
SDV
SDV). Both have the same dimensions as FV
FV
FV
FV. The jth
class's CCV
CCV
CCV
CCVj and SDV
SDV
SDV
SDVj can be computed out using following
equations.
W
j
j
i 0 W
=
= ∑
FV
FV
FV
FV
CCV
CCV
CCV
CCV
(13)
W
j
j
j
2
i 0
2
(
)
W
=
−
= ∑
FV
CCV
FV
CCV
FV
CCV
FV
CCV
SDV
SDV
SDV
SDV
(14)
(Where W is the number of regions in jth class and FV
FV
FV
FV
denotes the ith region's FV
FV
FV
FV.)
According to statistical principles, when the amount of
samples in each class has reached a certain level, the
distribution of segments’ vectors in every class is subject to
Gauss distribution. Nearly all members of the class fall
within CCV
CCV
CCV
CCVj ±3·SDV
SDV
SDV
SDVj. Ideally, we can sample numerous
regions within a class and work out its CCV
CCV
CCV
CCV and SDV
SDV
SDV
SDV. Then
compare remaining regions’ feature vectors to the class
center. If a region’s feature vector falls within CCV
CCV
CCV
CCV±3·SDV
SDV
SDV
SDV,
we identify it belonging to the class.
Unfortunately it is impossible to sample enough water
regions to form Gauss distribution within a class, but we can
still eliminate those non-water regions by checking whether
their FV
FV
FV
FVs locate within a threshold of a certain class’s CCV
CCV
CCV
CCV.
We define a parameter "ratio" to mark the dynamic range of
each CCV
CCV
CCV
CCV, that is to say regions with CCV
CCV
CCV
CCV falling into
CCV
CCV
CCV
CCV±ratio·SDV
SDV
SDV
SDV will be extracted as water area.
VI.
TRIALS AND RESULTS
In order to test the feasibility of our methodology, we
conduct following five trials. We define three indexes to
evaluate the result of extraction. First index is “w-w”, which
means pixels extracted as water using methodology in this
paper and perceived as water by human eyes. Second index
is “w-n”, which means pixels extracted as water using
methodology in this paper but perceived as non-water by
human eyes. Third index is “n-w”, which means pixels
extracted as non-water using methodology in this paper but
perceived as water area by human eyes.
Trial
Trial
Trial
Trial 1:
1:
1:
1: The following Fig. 2 is the water extraction effect
of Fig. 1 (b). We have 9 samples of water segments.
ISODATA algorithm classifies those 9 samples into 3
different types. The final extraction is attained when ratio is
set at 1.1.
49
GEOProcessing 2011 : The Third International Conference on Advanced Geographic Information Systems, Applications, and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-118-2

Figure 2.
Extraction Result of Trial 1 by setting the ratio at 1.1
TABLE I.
EVALUATION
OF
TRIAL 1
Fig. 2
w-w
w-n
n-w
Total Pixels
Pixels
260018
2108
18
262144
Percentage
99.2%
0.79%
0.01%
100.0%
Trial
Trial
Trial
Trial 2:
2:
2:
2: The following Fig. 3 (a) is taken of somewhere in
Shenzhen, China. We notice that the segmentation of water
area is homogenous and united in Fig. 3 (b). We have 8
samples of water segments. ISODATA algorithm classifies
those 8 samples into 2 different types. The final extraction is
attained when ratio is set at 1.2 as Fig. 3 (c) shows.
(a)
(b)
(c)
Figure 3.
Extraction Result of Trial 2: (a) is the original aerophotograph
of Shenzhen, China. (b) is the result of watershed segmentation. (c) is the
final extraction of water by setting the ratio at 1.2
TABLE II.
EVALUATION
OF
TRIAL 2
Fig. 3 (c)
w-w
w-n
n-w
Total Pixels
Pixels
3941135
70597
43726
4055458
Percentage
97.2%
1.7%
1.1%
100.0%
Trial
Trial
Trial
Trial 3:
3:
3:
3: To test the effectiveness in the combination of
chromatic
and
textural
analysis,
we
conduct
another
extraction using the aerophotograph in Trial 1. When
conducting chromatic analysis only, the feature vector will
be shortened to have only a* and b* parameters. When
conducting textural analysis, the feature vector will be
shortened to have only ASM parameter. We also selected 8
same water areas as samples in trial 1. In chromatic
extraction only, ISODATA classifies those 8 samples into 3
classes and the extraction result is Fig. 4 (a). In textural
extraction, ISODATA classifies those 8 samples into 4
classes and the extraction result is Fig. 4 (b). For both trials,
the ratio is set 1.2 as the ratio set in trial 1. From the result
we can see that the chromatic extraction or textural
extraction individually can not attain an effect as good as
the combination of them. The percentage of w-n and n-w is
50
GEOProcessing 2011 : The Third International Conference on Advanced Geographic Information Systems, Applications, and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-118-2

a nightmare for correctively extract water areas compared to
the combination of both chromatic and textural analysis.
(a)
(b)
Figure 4.
Extraction Result of Trial 3: (a) is attained using ony
chromatic analysis when ratio is set 1.2. (b) is attained using only textural
analysis when ratio is set 1.2
TABLE III. EVALUATION
OF
TRIAL 3
Fig. 4 (a)
w-w
w-n
n-w
Total Pixels
Pixels
2601923
391245
425432
3418600
Percentage
76.1%
11.4%
12.5%
100%
Fig. 4 (b)
w-w
w-n
n-w
Total Pixels
Pixels
2615619
398715
743726
3758060
Percentage
69.6%
10.6%
19.8%
100.0%
Trial
Trial
Trial
Trial 4444: In order to test the generality of this methodology,
we use the CCV
CCV
CCV
CCV generated in trial 1 to extract water area
from another aerophotograph (Fig. 5 (a)) taken of the same
area. Because they are the same region, therefore their
chromatic and textural features are similar. The following
result (Fig. 5 (b)) is attained when ratio is set 1.2.
(a)
(b)
Figure 5.
Extraction Result of Trial 4:(a) is the orginal RGB
aerophotograph. (b) is attained using the CCV
CCV
CCV
CCV generated in trial 1 when
ratio is set 1.2.
TABLE IV. EVALUATION
OF
TRIAL 4
Fig. 5 (b)
w-w
w-n
n-w
Total Pixels
Pixels
1437772
26133
10216
1474121
Percentage
97.5%
1.8%
0.7%
100.0%
Trial
Trial
Trial
Trial 5555: In order to further test the generality of this
methodology, we apply it to extract water areas from
aerophotograph
with
many
fluctuations.
Following
aerophotograph (Fig. 6 (a)) is taken of somewhere in
Qingdao. The biggest characteristic of this aerophotograph
is its rippled surface. As a result of this irregular fluctuation,
the segmentation result (Fig. 6 (b)) is not very satisfactory.
There are many fragments in water area, but we can
manually merge those fragments into united one in order to
improve the result of segmentation. We choose 12 water
samples from Fig. 6 (b). ISODATA algorithm automatically
classifies those samples into 4 categories. When ratio is set
1.5, we can attain a pleasing result (Fig. 6 (c)).
(a)
51
GEOProcessing 2011 : The Third International Conference on Advanced Geographic Information Systems, Applications, and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-118-2

(b)
(c)
Figure 6.
Extraction Result of Trial 5: (a) is the orginal RGB
aerophotograph. (b) is the result of segmentation. (c) is the final result of
extraction.
TABLE V. EVALUATION
OF
TRIAL 5
Fig. 6 (c)
w-w
w-n
n-w
Total Pixels
Pixels
316823
10192
716
327731
Percentage
96.7%
3.1%
0.2%
100.0%
VII.
CONCLUSION
It
is
innovative
to
combine
watershed
segmentation,
CIELAB color space and chromatic and textural analysis as
well as ISODATA classification together to extract water
from
RGB
aerophotograph.
Through
numerous
experimental
comparisons,
we
discover
that
ratio
set
between 1.1 and 1.8 is optimal for water extraction.
However, it is undeniable that ripples or ship transportation
will cause a few fragments after segmentation, which put
sand in the wheel of chromatic analysis and textural analysis
because feature values of those fragments are not accurate
and not representative. Although merging those fragments
into united and homogenous areas is a good solution to this
problem,
it
demands
much
more
time
and
manual
involvements. This is what we could do to improve the
result of water extraction later on.
ACKNOWLEDGMENT
Special thanks to Professor Yongjun Zhang’s guide in
this research and the cooperation of our team members.
REFERENCES
[1]
J. Deng, “An Effective Way for Automatically Extracting Water
Body Information from SPOT-5 Images”, Journal of Shanghai
Jiaotong University (Agricultural Science), vol. 23, no. 2, pp.
198-201, 2005, June.
[2]
H. Xu, “A Study on Information Extraction of Water Body with the
Modified Normalized Difference Water Index(MNDWI)”, Journal of
Remote Sensing, vol. 9, no. 5, pp. 589-595, 2005, September.
[3]
W. Ma and B. S. Manjunath, “A Texture Thesaurus for Browsing
Large Aerial Photographs”, Journal of the American Society for
Information Science, CA, vol. 49, no. 7, pp. 633-648, 1999.
[4]
Niblack W, Barber R et al., “The QBIC project: Querying images by
content using color, texture and shape”, Proc of SPIE: Storage and
Retrieval for Image and Video Database, San Jose, CA, pp. 58-70,
1994.
[5]
A. R. Robertson, “Historical development of CIE recommended color
difference equations”, Color Research and Application, 15(3), pp.
458-461, 1990.
[6]
K. R. Castleman, Digital Image Processing, New Jersey: Prentice
Hall, Inc., a Simon&Schuster Company, pp. 499, 1996.
[7]
B. Julesz, “Experiments in the visual perception of texture”, Scientific
Americian, vol. 232, pp. 34-43, 1992, May.
[8]
R. M. Haralick and K. S. Dinstein, “Textural Features for Image
Classification”, IEEE Transactions on Systems Man and Cybernetics,
pp. 610-621, 1973, November.
[9]
J. R. Jensen, Introductory Digital Image Processing-A Remote
Sensing Perspective, 3rd ed., New Jersey: Prentice Hall, pp. 383-389,
1995.
52
GEOProcessing 2011 : The Third International Conference on Advanced Geographic Information Systems, Applications, and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-118-2

