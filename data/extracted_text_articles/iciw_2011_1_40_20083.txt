Minimizing Human Interaction Time in Workﬂows
Christian Hiesinger, Daniel Fischer, Stefan F¨oll, Klaus Herrmann, Kurt Rothermel
University of Stuttgart
Institute of Parallel and Distributed Systems (IPVS)
Universit¨atstr. 38, D-70569 Stuttgart
{chrisitan.hiesinger,daniel.ﬁscher,stefan.foell,klaus.herrmann,kurt.rothermel}@ipvs.uni-stuttgart.de
Abstract—Many business scenarios require humans to interact
with workﬂows. To support humans as unobtrusively as possible
in the execution of their activities, it is important to keep the
interaction time experienced by humans as low as possible.
The time required for such interactions is inﬂuenced by two
factors: First, by the runtime of the services that are used by a
workﬂow during an interaction. Second, by the time required to
transfer data between workﬂow servers and services that may
be distributed in a global network. We propose an algorithm
that computes a suitable distribution of a workﬂow in such a
network. The goal of our algorithm is to minimize the time
required for interactions between a human and a workﬂow.
Current approaches in the domain of workﬂow optimization pay
little attention towards optimizing a workﬂow to increase the
usability for humans. We show the feasibility of our approach
by comparing our algorithm with two non-distributed approaches
and a distributed approach which is based on a greedy algorithm
and show that our algorithm outperforms these approaches.
Index Terms—Workﬂow distribution, human interaction, per-
vasive workﬂows.
I. INTRODUCTION
By using workﬂows, organizations are able to automate
and optimize their business processes [1]. In many business
scenarios, activities have to be executed by humans. Therefore,
it is important to integrate humans into workﬂows.
Such integration can adhere to different patterns. In the
simplest of cases, a human is notiﬁed by the workﬂow system
about currently available activities and provides some sort
of feedback when he has completed them. However, more
complex interaction patterns may require a human to query
the workﬂow system for information throughout the execution
of the activities. The time needed to provide the desired
information is experienced by the human as waiting time.
An important design principle from the area of Pervasive
Computing is to support humans as unobtrusively as possible
[2], [3]. Therefore, applying workﬂows in this area requires
that such waiting times are minimized.
The time is dependent on two factors: First, on the runtime
of services that need to be executed in order to provide a hu-
man with the desired information. Second, on the time required
to transfer data between workﬂow servers and service hosts
participating in the execution of a workﬂow. New technologies
like Cloud Computing support organizations in focusing on
their core business [4] and lead to the necessity of using remote
This research has been supported by FP7 EU-FET project ALLOW (con-
tract number 213339).
service providers within workﬂows. However, communicating
data to remote networks may create extensive waiting times
due to limited bandwidth and signiﬁcant propagation delay.
In this paper, we propose an algorithm for distributing
a workﬂow over a set of workﬂow servers such that the
interaction time experienced by humans is minimized. Ex-
isting approaches for workﬂow optimization do not take this
factor into account [5], [6], [7]. Our algorithm is based on
a two-phase list-scheduling approach. In phase 1, an initial
distribution is computed that is based on estimated values
for activity execution and data transfer times. In phase 2, the
initial solution is reﬁned based on a hill-climbing algorithm.
We show that our algorithm improves the interaction time
between humans and workﬂows by up to 80% compared to an
approach in which the complete workﬂow is run on a single
machine. Furthermore, we report an improvement of up to
10% compared to an existing greedy approach. We also show
that our algorithm scales better with an increasing number of
tasks compared to this approach.
The remainder of this paper is organized as follows. In
Section II, we introduce our system model and deﬁne the
problem of workﬂow placement in a formal way. Thereafter,
in Section III, we discuss related work in the area of workﬂow
placement. In Section IV, we describe our placement algorithm
that we evaluate in Section V. Finally, we conclude the paper
and give some outlook on future work in Section VI.
II. SYSTEM MODEL AND PROBLEM DESCRIPTION
In this section, we describe our system model in a formal
way. Our goal is to distribute a workﬂow among local networks
(domains) administered by various service providers which
are connected to each other via a global network. We split
our system model into a network model and a workﬂow
model. Thereafter, we formalize our goal of minimizing the
time to execute so called human interaction patterns as an
optimization problem.
A. Network Model
We assume a set of domains D, each representing a local
network consisting of a set of hosts. A domain d ∈ D
provides a set of service types Sd. Services of the same
type may be available (replicated) in different domains and
S = S
∀d∈D Sd. Note that we model the functionality a
human h provides as a special service sh ∈ S. We assume a
workﬂow server and a domain controller in each domain. The
22
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3

domain controller serves as an information service. It provides
the link properties of all relevant communication links and a
service discovery mechanism. This can be achieved by means
of an overlay network between all domain controllers in the
network. Services, workﬂow server and domain controller may
be replicated inside a domain to allow for provisioning of
quality of service guarantees, but for simplicity we treat each
of them as being unique within the respective domain.
We assume that each domain is able to communicate to any
other domain via the Internet. We denote the bandwidth and
propagation delay between two arbitrary domains d1, d2 ∈ D
as β(d1, d2) and δ(d1, d2), respectively. The bandwidth and
propagation-delay between two hosts in the same domain is
assumed to be constant and denoted as β(d, d) and δ(d, d),
respectively. We assume that ∀d ∈ D, ∀di, dj ∈ D, di ̸= dj :
β(d, d) ≫ β(di, dj) ∧ δ(d, d) ≪ δ(di, dj), i.e. inter-domain
delay dominates intra-domain-delay which reﬂects typical
communication properties found in interconnected LANs.
B. Workﬂow model
A
workﬂow
is
a
directed
acyclic
graph
W
=
(A, s, C, ρ, θA, θD). A denotes the set of activities in the
workﬂow. The functionality of an activity is deﬁned by means
of the function s : A → S which maps an activity a ∈ A to a
required service type s ∈ S.
The control ﬂow is speciﬁed by means of the set C ⊂
A × A and deﬁnes the logical order of activities. We refer
to activities that model conditional or parallel behaviour as
structural activities. A conditional and parallel split is modeled
as an activity with more than one outgoing control ﬂow link.
The set of outgoing control ﬂow links of an activity a ∈ A
is denoted as Ca. For a given control ﬂow link c = (ai, aj),
ρc is the probability that aj will be executed if ai has been
executed. This value can be derived from execution traces of
the workﬂow. For a conditional split, the workﬂow is executed
following only a single alternative, i.e. the conditions |Ca| > 1
and P
c∈Ca ρ(c) = 1.0 hold. For a parallel split, all outgoing
branches are executed in parallel, i.e. the conditions |Ca| > 1
and ∀c ∈ Ca : ρc = 1 hold. The latter also holds for all other
links originating from a non-structural activity.
The average amount of data that needs to be transferred
from a workﬂow server executing an activity a ∈ A to a
service required by a is denoted as θS(a). We assume that the
values of θS(a) cover the amount of data required for the input
parameters as well as for the result of the respective service
call. Similarly, θA(a1, a2) speciﬁes the average amount of data
that has to be exchanged between two activities a1, a2 ∈ A.
We assume that the functions θA and θS are deﬁned either by
means of estimations by a workﬂow designer or by learning
them from past executions of the workﬂow. In the following,
we refer to communication relationships between activities as
well as between an activity and a service as data links and
subsume them in the sets LAA ⊂ A × A and LAS ⊂ A × S,
respectively.
A Human Interaction Pattern (HIP) is a connected subgraph
of a workﬂow. It starts with a single entry activity which
 
Fig. 1.
Human Interaction Pattern
expects input data from a human and ends with a single exit
activity which generates output data for the same human. This
is a natural assumption as we focus on interaction patterns that
resemble queries. An example for a HIP is given in Figure 1.
Arrows show control ﬂow links while circles and rectangles
represent activities and services, respectively. The single entry
activity is a1 (a conditional split). The single exit activity is
a4. Note that there may be several HIPs in a single workﬂow.
C. Problem description
Our goal is to ﬁnd a mapping function µ : A → D
of activities to domains that minimizes the average required
communication time for all HIPs in a workﬂow. We focus only
on activities that are part of a HIP. All other activities may be
distributed according to other optimization goals (e.g. network
load). Each execution of the workﬂow takes only a single route
through the workﬂow. A route is a connected subgraph of a
workﬂow that contains all activities visited in one execution.
For example, a1, a2, a4 as well as a1, a3, a4 are both valid
routes in the HIP shown in Figure 1.
Because we do not know this route in advance, we cannot
optimize our mappings for it. Therefore, we solve the most
general case and aim for minimizing the expected execution
time of a HIP. Let R be the set of all routes of a HIP. The
probability for the execution of r ∈ R can be calculated as
ϱr = Q
∀c∈r ρc. Furthermore, let ϕµ
r be a function that deﬁnes
the execution time for r under the mapping µ. Then, our goal is
to ﬁnd a mapping µ such that the following sum is minimized:
X
∀r∈R
ϱr · ϕµ
r
(1)
In the following, we describe how ϕµ
r is calculated. In a
parallel split, only the branch which results in the largest
execution time is relevant for the overall execution time of
the ﬂow. We refer to the subgraph of r that contains only this
longest branch for every parallel split as the critical path of a
route. The time to execute a route of a HIP is inﬂuenced by
three factors: The time κA required to transfer data between
the activities, the time κS required to transfer data between
activities and their mapped services, and by the time κX
required to execute the corresponding services. Thus, we have
ϕµ
r = κA + κS + κX.
For the computation of κA, we have to distinguish two
cases. First, two activities that exchange data may be mapped
to the same domain and, thus, to the same workﬂow server
according to our system model. In this case, κA is negligible
because no data has to be sent over the network. Second, two
23
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3

activities may be mapped to different domains. In this case,
the time required equals the sum of the propagation delay of
the communication link between the respective domains and
the time required for transmitting the data on the respective
data ﬂow link. Let Lcrit ⊆ LAA ∪LAS be the set of data links
on the critical path of a route r, then
κA =
X
∀(ai,aj)∈Lcrit
δ(µ(ai), µ(aj)) +
θA(ai, aj)
β(µ(ai), µ(aj)).
(2)
For the computation of κS, we proceed analogously. Given
an activity a placed in domain d, let ξ(a) be a function
that returns the domain, among all domains that provide an
instance of service type s(a), which can be accessed with
lowest interaction time (ideally, µ(a) = ξ(a)). Then,
κS =
X
∀(a,s)∈Lcrit
δ(µ(a), ξ(a)) +
θS(a)
β(µ(a), ξ(a)).
(3)
We assume that service providers guarantee a certain execution
time as part of a SLA. For the computation of κX, we
accumulate the expected runtime required for the services
mapped to the activities on the critical path.
Our problem is a generalization of the problem of task allo-
cation in heterogeneous distributed systems (TAHDS) which
is known to be NP-hard [8].1 Therefore, we propose to use a
heuristic algorithm to solve the problem because an exhaustive
search of an optimal placement for example by means of
backtracking is not feasible.
III. RELATED WORK
Bauer and Dadam [6] propose an algorithm for assigning
workﬂow activities to servers in order to reduce network load.
They introduce a cost model based on estimated execution data
and employ a greedy algorithm. First, each activity is greedily
placed on a workﬂow server that minimizes the cost for its
execution. Then, a hill-climbing algorithm is used to eliminate
data transfers between neighbouring activities which have been
placed on different servers. In this approach activities are
initially placed without taking their data links into account.
Thus, it is unlikely that suitable sets of service providers are
found in our scenario. We will show that our heuristic performs
better than a version of this algorithm adapted to our problem.
We refer to this adapted version as Greedy approach.
Son et al. [5] propose an algorithm for minimizing com-
munication cost based on multi-level graph partitioning. A
workﬂow is divided into several fragments. However, their
solution assumes homogeneous communication links which
is not valid in the Internet.
In parallel computing, tasks have to be assigned to CPUs
in order to optimize their execution. Many solutions assume
that activities are not depending on each other, which leads to
a Bin-Packing problem. Obviously, this assumption does not
hold for our problem. More sophisticated approaches apply
list scheduling algorithms [8], [9]. We adopted the basic idea
1see Appendix for proof of problem complexity
of these algorithms while dropping their basic assumption of
homogeneous communication links.
In the area of grid computing, list scheduling algorithms
are employed under the assumption of heterogeneous network
links among loosely coupled computing systems [7], [10].
However, these algorithms assume variable task execution
times to have a major inﬂuence on the overall execution of
the task graph. In our scenario, we assume that tasks are
services and that quality of service guarantees specify the time
required for their execution. Hence, in our case the overall
execution time mainly depends on the communication links
between workﬂow servers, rendering respective algorithms like
e.g. HEFT inappropriate.
IV. HEURISTIC PLACEMENT ALGORITHM
We propose a 2-phase algorithm based on a list-scheduling
approach in order to ﬁnd a mapping µ that minimizes the
runtime of HIPs. Since HIPs are independent of each other,
we map each HIP separately.
As soon as activity a is mapped to domain d, activities with
a communication dependency to a have to communicate with
d. Thus, they should not be assigned to the best domains in
a greedy fashion. Instead, we have to take this dependency
into account and map each activity depending on its inﬂuence
on the runtime of a HIP: The more inﬂuence it has on the
runtime, the earlier it is mapped.
According to our system model, the bandwidth and prop-
agation delay between domains vary and the time required
for communication depends on the network link used. Addi-
tionally, there may be services which are available in many
domains while other services are only available in few do-
mains. Therefore, it is not known which data link is the most
expensive (in terms of communication time) until all activities
have been mapped. Therefore, we use a heuristic to estimate
the cost of each data link before the actual mapping. Since
HIPs are independent of each other, we run the algorithm for
each HIP in a workﬂow as soon as it is known from which
domain the human accesses the workﬂow.
In a ﬁrst phase, we assign weights to the data links to
reﬂect their estimated costs. Then, we sort the links in de-
scending order of their weights to ensure expensive activities
are mapped to domains ﬁrst. To derive an initial mapping, we
iterate over the sorted list and map the activities to domains
such that their execution time is minimized. The ﬁnal mapping
is created by optimizing the initial mapping through hill-
climbing. The overall algorithm (called Link Weight Activity
Assignment (LWAA)) is depicted in Listing 1.
A. Weighting and Ordering
The weight of a data link l for the initial mapping is
calculated by virtually placing l on each of the possible
network links between any pair of domains and by calculating
the average time consumed over all these virtual mappings.
Let lAA = (ai, aj) be a data link between two activities
and let lAS = (a, s(a)) be a data link between an activity and
its required service. We distinguish between the average time
24
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3

Listing 1 LWAA Algorithm
1: // Let ˆµ be the associative array that represents µ
2: // At the beginning ∀a : ˆµ(a) =⊥ holds
3: LDF = weightDataLinks(LAA ∪ LAS)
4: /* Initial mapping */
5: while LDF ̸= {} do
6:
l = Link with highest weight in LDF
7:
if l ∈ LAA then
8:
handleActivityToActivityDataLink(l, LDF, ˆµ)
9:
else if l ∈ LAS then
10:
handleActivityToServiceDataLink(l, LDF, ˆµ)
11:
end if
12:
LDF = LDF \ {l}
13: end while
14: /* Optimize mapping */
15: hillClimbing()
weightW (lAA) required to communicate between workﬂow
servers and the average time weightS(lAS) required to access
a service from a workﬂow server that controls the correspond-
ing activity. To compute weightW (lAA), we consider every
possible mapping of two activities ai and aj:
weightW (lAA) =
1
|D|2
X
∀dk,dl∈D:k̸=l
θA(ai, aj)
β(dk, dl) + δ(dk, dl)
(4)
Note that if both activities are mapped to the same domain,
no data needs to be transferred.
Similarly, we compute an estimate of the delay created
by service data links. In this case, we consider all possible
mappings and calculate the average transmission time:
weightS(lAS) =
1
|D|
X
∀d∈D
θS(a)
β(d, ξ(a)) + δ(d, ξ(a))
(5)
The resulting list of data links is sorted in descending order.
B. Initial mapping
For the initial mapping of each activity to a domain, the
algorithm proceeds through the list of data links, in descending
order of their weights and maps each activity that has not
already been processed. Links connecting two activities (LAA)
and links connecting an activity to a service (LAS) are handled
differently (cf. Listing 1 lines 8 and 10).
Listing 2 shows the handler procedure for links (a, s) ∈
LAS. This handler ﬁnds the domain d that exhibits the least
cost for calling service s residing in d when placing activity a
in d. Listing 3 shows how to handle a data link (a, a) ∈ LAA.
We aim at placing both activities in the same domain such
that no data has to be transferred over the network. However,
we also do not want to reduce the degree of freedom for the
placement more than required. We have to distinguish three
Listing 2 Handle activity to service data link
procedure
handleActivityToServiceDataLink(l, LDF , ˆµ)
1: (a, s) := l //get corresponding service and activity
2: ˆµ(a) := MinArgd∈D:s∈Sdδ(d, d) +
θS(a)
β(d,d))
Listing 3 Handle activity to activity data link
procedure
handleActivityToActivityDataLink(l, LDF , ˆµ)
1: (ai, aj) := l //get activities the data link connects
2: if (ˆµ(ai) =⊥) ∧ (ˆµ(aj) =⊥) // Both activities unmapped then
3:
if ∃d ∈ D : s(ai) ∈ Sd ∧ s(aj) ∈ Sd then
4:
a′ := Merge(ai, aj)
5:
// Sorted insert of new service data link
6:
LDF := LDF ∪ {(a′, s(a′))}
7:
// remove service links of ai and aj
8:
LDF := LDF \ {(ai, s(ai)), (aj, s(aj))}
9:
end if
10: else if (ˆµ(ai) ̸=⊥) ∧ (ˆµ(aj) =⊥) //First activity mapped then
11:
if s(aj) ∈ Sˆµ(ai) then
12:
ˆµ(aj) := ˆµ(ai)
13:
end if
14: else if ˆµ(ai) =⊥) ∧ (ˆµ(aj) ̸=⊥) //Second act. mapped then
15:
if s(ai) ∈ Sˆµ(aj) then
16:
ˆµ(ai) := ˆµ(aj)
17:
end if
18: end if
19: // If both activities are mapped nothing has to be done.
5
4
θA
3
‘
{
} 4
θA
3
a2
a3
a1
5
4
1
3
a4
4
3
3
s2
s3
s1
s4
a‘ = {a2 , a3}
a1
4
1
a4
4 + 3 = 7
3
3
s‘ = {s2 , s3}
s1
s4
θS
θS
Fig. 2.
Merging of unassigned activities
different cases: 1) None of the activities is mapped 2) Only
one of the activities is mapped 3) Both activities are mapped.
The ﬁrst case is handled in lines 2−9 of Listing 3: we check
if there exists a domain hosting both service types required by
the activities. If such a domain exists, we merge both activities.
The procedure of merging is depicted in Figure 2. The result
of merging two activities ai, aj ∈ A is a new activity a′ with
a corresponding data link to a virtual service s(a′) = s′ which
serves as a container for both s(ai) and s(aj). Each operation
performed on s′ has to be performed for all services in s′.
This is illustrated in Figure 2. a2 and a3 are merged into a
new activity a′ with a data link to service type s′ = {s2, s3}.
The weight of the newly created data link is the sum of the
weights of the original links. All other links remain unchanged.
Note, that we do not map the merged activities to a domain
right away as it may be merged with further activities.
We only merge if there exists a domain hosting the services
required by both activities because the service access of a2
and a3 needs to be restricted to their own domain in order
to save communication time. Using the workﬂow in Figure 2
(left), we explain the rationale behind this idea. Assume that
D = {d1, d2} with Sd1 = {s1, s2} and Sd2 = {s3, s4} and
none of the activities is currently assigned to any domain. Ac-
cording to the ranking of data links, the link between (a2, a3)
has to be processed ﬁrst. If created a merger a′ = {a2, a3},
we would have to map a′ either to d1 or d2. Thus, either
(a2, s2) or (a3, s3) would be mapped to an inter-domain link
25
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3

 
Fig. 3.
Hill-climbing
because there exists no domain hosting s2 and s3. The data
transferred via the link (a2, a3) is either the output data of
s2 or the input data for s3. Consequently, we would omit
the time required to transfer the data between both activities.
However, we would have to transmit the same amount of
data via a communication link in the global network which
would require the same amount of time that has been saved.
Furthermore, through merging in this case we would limit the
degree of freedom as, afterwards, we could not map a2 and
a3 separately.
It may happen that only one of both activities is already
mapped to a domain. This is covered in lines 10 to 18 of
Listing 3. Analogously to the previous case, we map the
unmapped activity to the domain of the already mapped
activity only if this domain hosts the required service. Finally,
it is also possible that both activities are already mapped to a
domain. In this case, we do nothing since the currently handled
data link must have a lower priority than the data links that
led to a mapping of the respective activities to domains.
C. Optimized mapping
After the initial mapping is completed, we adjust it to the
actual bandwidth/propagation delay in the network using a
hill climbing algorithm in oder to further reduce the time
consumed by transferring data via the global network. The
principle of the algorithm is depicted in Figure 3.
First, we extract the clusters of the initial mapping. A cluster
AF ⊂ A is the largest set of activities that form a connected
graph with ∀ai, aj ∈ AF : µ(ai) = µ(aj). In Figure 3,
there exist three clusters in the initial mapping, namely f1,
f2 and f3. We calculate the time required for the HIP if all
activities of a cluster are mapped ﬁrst to the domain of its
preceding and then to the domain of its succeeding cluster. The
possible alternatives and the time required for each alternative
are depicted in rows 2 to 4 of Figure 3. The best alternative
is selected as new preliminary mapping. This procedure is
repeated until no mapping which requires less time can be
found.
We only remap complete clusters because it is unlikely that
remapping single activities results in a performance gain. If
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 1.1
 10
 20
 30
 40
 50
 60
Relative comm. time
Number of activities
Static
Simple
LWAA w/ HC
(a) Non-partitioned placement
 0.8
 0.85
 0.9
 0.95
 1
 1.05
 10
 20
 30
 40
 50
 60
Relative comm. time 
Number of activities
Greedy
Greedy w/ HC
LWAA
LWAA w/ HC
(b) Partitioned placement
Fig. 4.
Comparison with other placement approaches
this would be the case the initial mapping would have come
to a different conclusion.
V. EVALUATION
In this section, we describe our evaluation setup and results.
We generate networks as well as workﬂows according to our
models discussed in Section II. As the algorithm is executed
for each HIP separately, we restrict the generation process to a
workﬂow consisting of a single HIP. The number of activities
between the human activities varies between 0 and 60.
We simulate 50 different domains. The bandwidth for com-
munication within each domain is set to 1 GBit/s assuming a
Gigabit Ethernet. For the communication between humans and
workﬂow servers, we assume a 54 MBit/s WLAN connection.
The bandwidth of communication links between domains is
set to be between 2 MBit/s (E1) and 34 MBit/s (E3) to reﬂect
the SLAs between service providers.
We assumed a uniform delay to simplify our simulation.
Since the delay between domains is only inﬂuencing the
ordering of the weighted data links, this does not change the
qualitative results.
We have 200 service replicas drawn from 20 services
according to a Zipf distribution. The services are randomly
assigned to the 50 domains. We use a Zipf distribution because
there may be few very popular services available in many
domains, while there are many more specialized services
which are only provided in a few domains.
For the generation of workﬂows we use a grammar that is
able to generate sequences, conditional and parallel structures.
The rules of the grammar are chosen randomly until the
desired number of activities is reached. The values for ΘS are
generated randomly according to a uniform distribution with
a maximum of 100 MByte to allow for a wide variety of data
ﬂow links. The values for ΘA are implicitly deﬁned by ΘS to
26
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3

 0
 10
 20
 30
 40
 50
 60
 70
 10
 20
 30
 40
 50
 60
Time in ms
Number of activities
Greedy w/ HC
LWAA w/ HC
(a) Time consumption
 0
 50
 100
 150
 200
 250
 300
 350
 400
 10
 20
 30
 40
 50
 60
MByte
Number of activities
(b) Tolerable data amount per migr.
Fig. 5.
Performance analysis
guarantee a consistent data ﬂow meaning that all data received
by an activity is sent via its outgoing data ﬂow links to other
activities. The assignment of activities to (human) services is
also chosen uniform randomly.
We compare our algorithm with four other approaches:
• Static maps all all activities of a HIP to a random domain.
• Simple maps all activities of a HIP to the human’s current
domain.
• Greedy proceeds through all activities, searches for the
domain reachable with the highest bandwidth hosting the
next required service and maps the activity to this domain.
• Greedy w/ HC enhance Greedy with a subsequent hill-
climbing (cf. Figure 3). This is an adapted version of the
algorithm proposed by Bauer et al. [6].
In Figure 4(a), comparison of our distribution algorithm
(LWAA) with the non-partitioned approaches (Static and Sim-
ple) is shown. We compared the relative gain of using our
algorithm. The reference (at 1.0) is the Static. Figure 4(a)
shows that, for an increasing number of activities per HIP,
our algorithm quickly converges to around 20% of the time
required for Static. This is because in the non-partitioned
approaches a lot of expensive service calls have to use low
quality network links. Thus, they consume a lot of time for
communication as only the services that are located in the
same domain can be accessed in a performant way.
Figure 4(b) depicts the effectiveness of our algorithm
compared to the greedy approaches. The initial placement
computed by our algorithm is between 12% and 16% better
than the placement computed by the Greedy approach. This is
due to the fact that our algorithm takes the data ﬂow between
activities into account and, thus, computes suitable clusters
which is not done in the Greedy approach. The Greedy w/ HC
approach performs better than the LWAA algorithm without
subsequent hill-climbing. This is due to the fact that clusters
are assigned to domains without taking the communication
links of the individual domain into account. The results show
that our algorithm is better compared to the Greedy w/ HC
approach by 8% to 10% due to the better initial placement.
We compare our algorithm to the greedy approach in
terms of the required computation time in Figure 5(a). Both
algorithms show very similar execution times at ﬁrst, until the
effort for the subsequent hill-climbing starts to dominate at
around 35 activities. This is because of the fact that LWAA w/
HC builds activity clusters, reducing the number of clusters
left for the hill-climbing compared to Greedy w/ HC.
If the source activity of a data link is mapped to another
domain than its target activity, data has to be transferred
between workﬂow servers during the execution of a workﬂow.
This process is called migration. The amount of data that
has to be transferred in a migration may differ, for example,
depending on whether the workﬂow management system has
to transfer additional logging data for compensations. This
is not accounted for in our simulation and would impact
the performance of our algorithm negatively. Therefore, we
measured the amount of data that can be sent additionally
for each migration before the Static or Simple approach
outperform our distribution approach. Figure 5(b) shows that
this amount can be about three times the maximum amount of
data that occurs in the data ﬂow, indicating that considerable
migration overhead can be tolerated by our algorithm.
VI. CONCLUSION
We proposed an algorithm that minimizes human interaction
time in workﬂow systems based on a list-scheduling approach
for mapping activities to network domains. We compared
our algorithm LWAA w/ HC to non-partitioned and greedy
approaches and showed that it improves interaction time by
up to 80%. Hence, LWAA w/ HC reduces the interaction time
of humans with workﬂows signiﬁcantly and, thus, increases
the processing throughput considerably. This can result in
competitive advantages in a business environment. Addition-
ally, it helps opening areas like pervasive computing for
workﬂow technologies since it renders workﬂow technology
less obtrusive.
In our future work, we will investigate how workﬂow
distribution can help minimizing the energy consumption of
mobile devices used for interacting with the workﬂow. In this
case, executing a partial workﬂow on such a device avoids the
energy-intensive transfer of data to the infrastructure.
REFERENCES
[1] F. Leymann and D. Roller, Production Workﬂow: Concepts and Tech-
niques.
Prentice Hall International, 1999.
[2] M. Weiser, “The computer for the 21st century,” in Scientiﬁc American
265(3): 94-104, 1991.
[3] S. Schuhmann, K. Herrmann, and K. Rothermel, “A Framework for
Adapting the Distribution of Automatic Application Conﬁguration,” in
Proc. of the 2008 ACM Int. Conference on Pervasive Services (ICPS
2008), Sorrento, Italy, July 6-10, 2008.
ACM, Juli 2008, Konferenz-
Beitrag, pp. 163–172.
[4] M. Armbrust, A. Fox, R. Grifﬁth, A. D. Joseph, R. Katz, A. Konwinski,
G. Lee, D. Patterson, A. Rabkin, I. Stoica, and M. Zaharia, “Above the
clouds: A berkeley view of cloud computing,” University of California
at Berkeley, Tech. Rep., February 2009.
[5] J. H. Son, S. K. Oh, K. H. Choi, Y. J. Lee, and M. H. Kim, “GM-WTA:
an efﬁcient workﬂow task allocation method in a distributed execution
environment,” J. Syst. Softw., vol. 67, no. 3, pp. 165–179, 2003.
[6] T. Bauer and P. Dadam, “Efﬁcient distributed workﬂow management
based on variable server assignments,” Lecture Notes in Computer
Science, vol. 1789/2000, pp. 94–109, 2000.
[7] S. H. H. Topcuoglu and W. M. You, “Performance-effective and low-
complexity task scheduling for heterogeneous computing,” IEEE Trans-
actions on Parallel Distributed Systems, vol. 13, pp. 260–274, 2002.
[8] Y. Kopidakis, “On the task assignment problem: two new efﬁcient
heuristic algorithms,” Journal of Parallel and Distributed Computing,
vol. 42, no. 9, pp. 21–29, 1997.
27
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3

[9] A. Billionnet, M. C. Costa, and A. Sutter, “An efﬁcient algorithm for a
task allocation problem,” J. ACM, vol. 39, no. 3, pp. 502–518, 1992.
[10] A. Radulescu and A. J. C. Van Gemund, “Fast and effective task
scheduling in heterogeneous systems,” in Proc. of the 9th Heterogeneous
Computing Workshop. Washington, DC, USA: IEEE Computer Society,
2000, pp. 229–238.
APPENDIX
PROBLEM COMPLEXITY
Our problem is a generalization of the problem of task allo-
cation in heterogeneous distributed systems (TAHDS) which
is known to be NP-hard [8]. In TAHDS, we have a set
of processors P and a set of tasks T. Two arbitrary tasks
i, j ∈ T have communication costs cij, and eip represents the
cost of executing task i on processor p. The problem is to
ﬁnd a mapping of tasks to processors such that the sum of
communication and execution costs is minimized. Note that
communication costs between two tasks only occur if they are
placed on different processors.
In the following, we reduce TAHDS to our problem in order
to show that our problem is NP-hard as well. We map T
to A and P to D, i.e. each task corresponds to an activity
and each processor to a domain. We deﬁne a unique service
for each activity and replicate it on every domain. We set
the propagation delay between and within domains to zero.
Furthermore, we set the bandwidth within each domain to ∞,
i.e. hosts within a domain can communicate instantly. The
bandwidth between domains is set to a constant βconst. The
time to execute service replica s = s(a) running on domain
d is set to eip where a is the activity corresponding to task
i and d the domain corresponding to processor p. ΘA is
chosen such that ΘA(ai, aj)/βconst = cij where tasks i and
j correspond to activities ai and aj, respectively. Obviously,
an algorithm that is capable to solve our problem is also
able to solve TAHDS and hence, our problem is NP-hard.
Therefore, we propose to use a heuristic algorithm to solve the
problem because an extensive search of an optimal placement
for example by means of backtracking is not feasible.
28
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3

