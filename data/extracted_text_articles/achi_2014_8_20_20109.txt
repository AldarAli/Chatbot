Characteristics, Attributes, Metrics and Usability Recommendations: A Systematic 
Mapping 
 
Franciela Nissola 
Graduate Program in Applied Computer 
UNIVALI – Universidade do Vale do Itajaí 
Itajaí, Brazil 
nissolainf@gmail.com 
Fabiane Barreto Vavassori Benitti 
Graduate Program in Applied Computer 
UNIVALI – Universidade do Vale do Itajaí 
Itajaí, Brazil 
fabiane.benitti@univali.br
 
 
Abstract— The research scenario concerned about software 
usability addresses a wide range of characteristics, attributes 
and evaluation models. As result, we can observe the 
evaluators difficult in order to select the characteristics that 
best apply to the product that is being evaluated. By this way, 
this paper presents a systematic mapping in order to identify 
the main characteristics of usability evaluation related to web, 
desktop and mobile devices environments. As results, we 
selected 31 papers in order to perform data extraction and way 
possible to produce a list of 28 evaluation characteristics. 
Keywords-Usability Evaluation; Systematic Mapping. 
I. 
 INTRODUCTION 
Usability is a characteristic of a certain product related to 
the ease of use, speed of learning, control and management 
of error, solving the tasks that proposes to carry out with 
efficiency, effectiveness and mainly offering a high degree 
of satisfaction for its users [1][2]. By relying on the type of 
user and the experience of this, as well as the tasks 
performed and the execution environment of the system, 
usability is a system property that is not constant [3]. 
Usability is a quality of use, measured for a given context in 
which software is operated. Thus, the same software can 
provide a good usability for an experienced user, but bad 
usability for a beginner, or vice versa, or it can also be easy 
to operate if the system is only used sporadically, but 
difficult when used frequently [4]. 
Despite all these concepts for usability, yet there is no 
consensus among the researches for a model that clearly 
describes all its features. This knowledge gap is one reason 
why the majority of usability studies are either simplified or 
specific (studies that are performed in certain contexts) [5]. 
Along with the various concepts related to usability and 
addressed in the researches, it is clear that usability is treated 
as a determinant of success or failure of any software 
product, because it allows to generate greater efficiency by 
the users performing their tasks, helps in reducing training 
costs and allows that the integration of software system in 
the work environment of the users can be made in a more 
positive and less traumatic way [6].  
Another relevant aspect of usability is perceived by the 
vast amount of research found in this area. It has an 
extensive set of features, attributes and models of usability 
evaluation available [7][8][9]. Each of these valuation 
models presents its specific set of characteristics, and the 
same feature may have been addressed in several models or 
be disregarded. Another situation found in these publications 
are characteristics or attributes of usability presented with 
different nomenclatures, but with the same concept and 
similar concepts between models.  
Note that the evaluation models are often refined and 
developed to a level where specific execution environments 
are considered for the evaluation of the usability [10]. 
However, even with this refinement of the models and 
attributes per execution environment, yet are different 
attributes of usability evaluation addressed to the same 
specific execution environment. The use of specific attributes 
of usability according to the execution environment makes 
the evaluation of the usability more consistent, provides a 
greater investment guarantee and also the professionals 
involved in the production of software for this environment 
can use these attributes as drivers for creating software with 
better quality [11]. 
All these different ways of evaluation emerged as a 
contribution to the evolution of usability evaluation, 
providing to the software development organizations a varied 
set of criteria that can be applied to specific project types 
[12]. Although it became evident through research that the 
introduction of usability practices in software development 
processes are beneficial, many companies oriented to 
development face difficulties to actually apply these 
practices, because it is a complex issue, which has evaluation 
methods underutilized and difficult to understand for 
development teams. This difficulty is manly in the definition 
of the model and attributes that should be applied in the 
evaluation process, due to the large amount of existing 
research [12][13]. 
In the research, the models have some limitations when 
compared with each other and still there is relatively little 
information to support the selection of a set of attributes to 
evaluate the usability by the evaluators. Moreover, it is not 
always clear how the usability attributes presented in the 
various models are more or less advantageous than others 
[8]. Based on this scenario, this article presents a systematic 
mapping on the characteristics and attributes of usability 
evaluation proposed in primary studies between the years 
2005 and 2012 for the execution environments Web, 
Desktop and Mobile Devices, consisting an important step to 
meet, broadly, the dismembering of the usability concept, 
178
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

considered 
by 
many 
researches 
under 
different 
environments, being an important step in the reach for a 
model that integrates all aspects identified. 
The terms: characteristic, attribute, and recommendation 
metric, cited in this article, are used to classify the various 
aspects, quality and information related to usability, obtained 
through this systematic mapping. It was chosen to use a 
hierarchical structure for the presentation of issues related to 
usability found in the articles evaluated, considering that 
other models in the literature also use hierarchical structure 
to present information related to usability (Model QUIM, 
[8]). 
It´s assumed in this systematic mapping of the literature 
that the features are on top of the hierarchical structure 
mentioned, representing a more comprehensive view of the 
quality related to usability. The attributes are below the 
features and represent the information in a more granular 
form. In this systematic mapping a feature may or may not 
be related to one or more attributes and the same attribute 
may be related to more than one feature. Finally, on the basis 
of the hierarchical structure, are the metrics that represent the 
information used for the evaluation of the attribute more 
objectively, and the recommendations, which aims to guide 
the development/evaluation of interfaces through good 
practices, for example, layout and menu structure, pattern of 
presentation for links, font color for text, etc.  
This article aims at presenting the results of a systematic 
survey of the literature involving characteristics, attributes 
and usability found recommendations, aiming to know, in an 
impartial manner, the state of the art concerning these 
aspects of usability, in relation to different platforms. 
Therefore, the protocol for a systematic mapping of the 
literature used in this paper is presented in Section II, along 
with the implementation procedures and discussion of the 
results. Finally, the last section summarizes the findings and 
presents some possible future work. 
II. 
SYSTEMATIC MAPPING OF THE LITERATURE 
The main reason to perform a systematic mapping of the 
literature is to increase the quality of material used about the 
subject of interest, increasing the success of the 
investigation, avoiding unnecessary duplication of effort and 
errors.  
 A systematic mapping follows a defined sequence of 
methodological steps, which in turn provide a high scientific 
value to the results. In execution of a systematic mapping, 
there is the establishment of criteria, search strategies and a 
description of all the elements previously required to hold 
the methodological conduction of the activities [14]. Thus, 
the following sections detail each step performed. 
A. Planning 
In order to map the attributes of usability evaluation in 
execution environments Web, Desktop and Mobile Devices, 
the following question was established: Which attributes are 
related to the usability of software products when 
considering different execution environments (among those 
contemplated in this research: web, desktop and mobile 
devices)? 
To answer the research question there were four research 
bases; quote: (i) ACM Digital Library, (ii) IEEExplore 
Digital Library, (iii) ScienceDirect, and (iv) SpringerLink. At 
each base, the following search string was executed: 
(usability) AND (attribute OR factor OR criteria OR metric 
OR 
measurement 
OR 
method 
OR 
evaluation 
OR 
requirement) AND (web OR internet OR www OR desktop 
OR ‘mobile device’). 
The language adopted in the survey was English, being 
the predominant language in the study area. Regarding the 
reliability of the content on those studies, it is considered that 
the works have already gone through preliminary review and 
assessment that allowed their inclusion in searchable 
databases. The process will be through search of primary 
studies published in proceedings, journals and periodicals 
available in international databases. After obtaining the 
references of the studies obtained in this four bases, some 
selection and exclusion criteria that would help to limit the 
items that could help to answer the research question were 
adopted (see Table I). 
TABLE I.  
SELECTION CRITERIA AND EXCLUSION 
Selection Criteria 
SC1. Studies available on some web source (among the sources cited in 
this article); 
SC2. Studies that meet at some level, the research question. Studies that 
show usability attributes, applied to a software product, related to at 
least one of the execution environments covered by the survey; 
SC3. Studies that show evidence of implementation of the proposed 
attributes; 
SC4. Studies that show the conceptualization of the proposed attributes 
(the concept can be in the primary study itself or pointed 
location/directed by the authors); 
SC5. Complete studies published in proceedings and journals since 
2005; 
Exclusion Criteria 
EC1. Studies that do not show attributes of usability in at least one of 
the execution environments covered by the survey or don´t make clear 
the execution environment; 
EC2. Studies that do not conceptualize the attributes used; 
EC3. Studies that show a specific application domain, such as e-
government, e-commerce, or focus on a specific user profile, for 
example, elderly, impaired vision, etc.; 
EC4. Summaries of studies will not be selected; 
EC5. Studies that don´t show the evidence of application; 
CE6. When a study has multiple publications in journals or proceedings, 
the most complete version of the study will be used; 
 
B. Conduction and Extraction 
The conduction of the systematic mapping was done 
from September 2012 until March 2013, consisting of the 
execution of the search protocol. The conduction process 
observed the steps shown in Figure 1, from 345 potential 
studies, 65 studies were selected. The conduction of the 
studies was done in three steps: 
 
Selection 
and 
cataloging 
preliminary 
studies 
collected: a preliminary selection of publications 
made from the application of the search string in the 
search sources selected. 
179
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

 
 
 
Selection of relevant documents: a preliminary 
selection using the search string does not guarantee 
that all the material that was collected is used in the 
research context. Thus, after the identification of 
publications obtained through the search engines, the 
studies were analyzed according to the criteria 
established for inclusion and exclusion. 
 
Extraction of information of relevant documents: 
after setting the final list of relevant documents, the 
necessary information related to the research 
objective is extracted. 
 
Figure 1.  Process of selecting primary studies. 
Among the 65 studies selected for full reading, we have 
the following scenario of events in each of the evaluated 
databases: IEEExplore Digital Library: 45,16%, ACM 
Digital Library: 22,58%, ScienceDirect: 19,35%, and 
SpringerLink: 12,91%. 
From the set of primary studies selected to perform data 
extraction, the following information was extracted for 
analysis: 
 
Title: identifies the selected study. 
 
Year: provides a temporal view of the attributes of 
usability evaluation. 
 
Database: identifies the origin of the selected study. 
 
Execution Environment: identifies the execution 
environment for the attributes shown in the study 
evaluated. In this topic, the studies were classified 
as: (I) web, (II) desktop and  (III) mobile device. 
 
Reference type: identifies the sources used to 
support the model of usability evaluation presented 
in the study. 
 
Structure addressed in the model: identifies the 
structure presented by the study evaluated, related to 
the presentation of the attributes of usability. 
 
List of attributes: compilation of the attributes of 
usability evaluation cited in the studies analyzed. 
 
Metric or recommendations: identifies whether the 
study has evaluate metrics or recommendations to 
guide the evaluation of usability. 
 
Assessment technique: identifies the technique used 
to evaluate the model or usability attributes 
addressed in each study rated. It was used the 
classification of evaluation techniques proposed by 
[4], as shown in Figure 2. 
 
Figure 2.  Usability evaluation techniques. 
 
Context: identifies the application context of the 
usability study. In this topic, the studies were 
classified as: (I)non-explicit,(II)academic/university 
and ( III ) business. 
 
Participants: identifies the number of respondents 
who rated the attributes or usability model presented. 
In the process of selection of studies, the snowball 
technique [15] was applied. The application of this type of 
technique is to add in the research being conducted, studies 
referenced by the selected primary studies that may 
contribute to the research. Thus, when a primary study 
(among 31 selected) referenced another study that contains 
models, metrics and recommendations that could contribute 
to the research, this study referenced was also included. 
Appendix I is a listing of all studies, employing the 
technique of snowball nine studies were included (#35, #36, 
#37, #38, #39, #40, #41, #42, #43). 
C. Results and Discussions 
This section presents the main results obtained from 31 
primary studies selected. Figure 3 shows the number of 
studies that were selected for data extraction in each year of 
the time interval considered in this systematic mapping 
(2005-2012). Over the years,  it is observed that continuous 
studies have been published in this area and the research 
180
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

 
output remained, highlighting the importance of this area of 
research forward.  
 
Figure 3.  Number of evaluated annually. 
In Figure 3, it can be seen that the occurrence of studies 
related to web runtime environment remained almost 
constant during the time period evaluated. This amount of 
studies related to web routine environment can be attributed, 
among other factors, to the grown of the Web, its 
popularization and its importance as a means of global 
communication.  
In contrast, the execution environment desktop has the 
lowest incidence of studies to define a set of attributes to 
evaluate the usability. Among other factors, the rise of the 
Web previously mentioned, contributes to the unpopularity 
of the desktop environment and, therefore, to decrease 
research on this. In relation to mobile devices, it´s expected a 
growth of studies related to this execution environment, 
considering the growth of these environments (a report from 
Cisco predicts that mobile devices will exceed the number of 
people in 2013 and by 2017 there will be about 1.4 devices 
per capita) [16]. 
Regarding execution environments addressed in 31 
studies evaluated, there´s the following scenario: 71% of the 
studies are related to the web environment, the mobile 
devices 23% and 6% related to the desktop environment. 
As for the reference of the valuation models or list of 
attributes of usability evaluation presented in the studies 
evaluated, there´s the following scenario: 
a) No reference model: 41,93% of the studies 
evaluated showed a list of attributes that were evaluated, 
using one of the techniques discussed in Figure 2, in a 
software product. 
b) Adapted: 32.26% of the evaluated studies adapted a 
valuation model or list of attributes. In this group there is 
the use of ISO9241, ISO25000, and Nielsen heuristics[2]. 
c) Existence: 25.81% of the assessed studies used an 
existing model in the literature. In this group, it is important 
to highlight the use of ISO9241, heuristics and Nielsen 
Microsoft Usability Guidelines (MUG). 
The scenario found as the reference of models or 
attributes of evaluation presented by this mapping, further 
enhances the already mentioned problem regarding the large 
amount of studies presented in which each author addresses 
their specific list of attributes and evaluates them not relating 
this list with models already existent, adapting or improving 
them. 
It was also found that these 31 studies evaluated do not 
address a specific structure, for example, a framework model 
or categorization, to the listed attributes. The structure found 
in these studies, as the presentation attributes of usability 
evaluation is in the form of a simple list of attributes. 
Regarding the application context of the studies 
evaluated, it´s observed that most of the selected studies did 
not indicate the context in which the attributes have been 
applied. Among the studies evaluated in this systematic 
mapping 74.19% do not make it clear which is the 
application context of the attributes addressed. 
The context of business application was not used in any 
of the studies selected for this mapping. This scenario refers 
to the need to extend research regarding the evaluation of 
characteristics and attributes of usability in business 
contexts, facilitating the application, in a practical way, of 
the researches conducted. 
During the evaluation of the articles selected for data 
extraction, it was checked for the presence of objective 
recommendations, to assist the evaluation of characteristics 
and attributes presented. However, the present scenario is not 
favorable regarding obtaining such advice. Of the 31 articles 
evaluated, 83.87% of them do not show metrics/objective 
recommendations for usability. Only 16.13% of the 
evaluated studies have some kind of metric/recommendation 
for usability. Table II presents the recommendations and 
metrics found in the studies evaluated in this systematic 
mapping. The objective recommendations found in the 
analyzed studies still have certain subjectivity (according to 
the evaluation of the authors of this article). It was observed 
that not all recommendations were related to some 
characteristic or attribute of usability, in this case it was 
chosen to categorize as “General Properties”. 
TABLE II.  
RECOMMENDATIONS AND METRICS OF USABILITY 
Characteristics/Attributes 
Recommendations/Metrics 
Prevention of errors 
6 Recommendations [#3] 
Integration of Communication 
3 Recommendations [#22] 
Attractiveness 
3 Recommendations [#22] 
From User Control 
2 Recommendations [#22] 
22 Recommendations [#43] 
Security 
4 Recommendations [#22] 
Flexibility 
2 Recommendations [#40] 
2 Metrics [#5] 
Effectiveness 
6 Metrics [#5] 
Efficiency 
6 Metrics [#5] 
Navigation/guidance 
12 Metrics [#5] 
Satisfaction 
2 Metrics [#5] 
181
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

 
Characteristics/Attributes 
Recommendations/Metrics 
Aesthetic design 
52 Recommendations [#43] 
Commands 
40 Recommendations [#43] 
Textual information 
23 Recommendations [#43] 
Message 
34 Recommendations [#43] 
Consistency interaction 
33 Recommendations [#43] 
Window 
62 Recommendations [#43] 
Interface/Layout 
8 Recommendations [#43] 
Font 
2 Recommendations [#43] 
Colors 
4 Recommendations [#43] 
Ícons 
8 Recommendations [#43] 
Animation and Transition 
7 Recommendations [#43] 
Graphic elements 
7 Recommendations [#43] 
Sound 
8 Recommendations [#43] 
User Experience 
29 Recommendations [#43] 
Components 
65 Recommendations [#43] 
General Properties 
5 Recommendations[#22] 
15 Metrics [#5] 
6 Metrics [#3] 
 
Among 
the 
31 
studies 
evaluated, 
28 
distinct 
characteristics of usability evaluation were found. Of these, 
one has the following scenario of events for execution 
environment: 
a) Web: 28 characteristics; 
b) Desktop: 5 characteristics; 
c) Mobile Devices: 11 characteristics. 
Appendix II has a full list of features and attributes per 
runtime environment, obtained through systematic mapping. 
In this appendix are presented the characteristics and 
attributes of usability evaluation which were obtained from 
the mapping studies conducted. One of the criteria for 
selection of studies was presenting the conceptualization of 
the attributes used to evaluate the usability. Based on this 
concept, we observed attributes with the same concept, but 
with different nomenclatures in different studies and group 
these attributes into a single information structure. 
It was also observed that some studies had a more 
comprehensive view of the quality of information related to 
usability, for these cases, we used the characteristics 
structure, which, in turn, is a sort of aggregator of 
information. The characteristics of the structure in Appendix 
II were present in at least one study evaluated, or when a 
more comprehensive study presented information structure 
composed of more granular information (attributes), this 
structure was maintained. 
In this table, using a mark with the letter “x”, the possible 
relationships between features and attributes discussed by 
several authors in the studies evaluated are also presented. A 
nomenclature of the characteristics and attributes discussed 
in studies with some minor adjustments when the same 
characteristic or attribute was discussed in more than one 
study in which a different nomenclature was showed, but 
with the same concept presented, was used. 
In Appendix II, along with the naming of features and 
attributes, there is also the presentation of information from 
references that cited such characteristics or attributes 
(references are identified with the hash (#) concatenated with 
the numbering of the bibliographic reference used) 
facilitating the reader find an indication of which study 
addressed what characteristic and attributes, and you can also 
check the amount of referrals every feature or attribute has. 
The reference for the primary study selected in which the 
feature or attribute was found is also mapped in this table. 
There are several ways to evaluate the usability of an 
application and, in the context of this article, the 31 studies 
evaluated were classified in Figure 2. The result, illustrated 
in Figure 4, shows the number of studies related to the use of 
the techniques of usability evaluation in each execution 
environment evaluated. The application of the questionnaire 
assessment technique was the most used among the studies 
evaluated. This type of technique is based on questionnaires 
to evaluate the user satisfaction or dissatisfaction with the 
system and its operation. It is a technique quite relevant, 
considering that the user is the person who knows more the 
software, and because of that, nothing is more befitting than 
to seek their opinions to guide project reviews [4]. 
Trials of interaction were also widely used, the second 
among the most widely used techniques for the assessment 
of the selected studies. It has been in the execution 
environment web site for greater application of techniques 
for usability evaluation cited. A test of interaction consists of 
a trial use of the system which involved subjects 
representative of the target population to evaluate the 
technique. In tests of interaction, participants perform typical 
tasks involved in their activities with a version of the desired 
system [4]. 
 
Figure 4.  Evaluation Techniques for Runtime Enviroment. 
Along with the information extraction of the usability 
evaluation techniques used in the selected studies, it was 
verified the number of people involved in these evaluations. 
It was found that such evaluations occurred either on a list of 
182
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

attributes or on a model (consisting of features and 
attributes) of usability evaluation and the number of people 
involved in these evaluations did not follow a pattern in 
relation to the quantity displayed. For the group of studies 
that evaluated a list of attributes, there are since evaluations 
with groups of four people to evaluations with groups 
consisting of 215 people. The same is true for the group of 
studies that evaluated a model of usability, working with 
groups with 7 people to groups with 179 people involved in 
the usability evaluation proposed. 
In both cases (List of Attributes or Model), the evaluation 
technique most used was the prospective technique of 
evaluation by using questionnaires, as already mentioned. 
This technique is based on questionnaires to those involved 
in the evaluation and is facilitated with a view that those 
involved respond to a questionnaire on a specific web 
address and may be performing this evaluation activity 
anytime. However, it´s necessary to emphasize that 
satisfaction questionnaires have a low return rate of 
responses, which indicates the need to develop/use a small 
number of questions, as well as using succinct questions and 
a space for the user to insert free comments and suggestions 
[4].  
III. 
CONCLUSION AND FUTURE WORK 
The systematic mapping of the literature described in this 
article has covered features, attributes and metric/usability 
recommendations 
found 
in 
each 
of 
the 
execution 
environments evaluated in studies found between 2005 and 
2012 in four databases of the area.   
This systematic mapping of the literature has shown the 
large amount of features and attributes discussed by several 
authors in various studies related to usability, considering 
that it was verified a total of 28 features and 76 different 
attributes that can be used by those involved with a usability 
evaluation in one of the environments mentioned. 
The great quantity of features and attributes of usability 
evaluation is also diverse when studies for the same 
execution environment are being verified. Among the studies 
reviewed, it wasn´t found a pattern  or a set of characteristics 
and unique attributes of evaluation among the authors that 
check specific execution environments. In addition, different 
terms to refer to the same usability attribute are found, and 
the construction of an ontology is a perspective for future 
work. 
Few studies have metrics or objective recommendations 
to assist in the evaluation of usability. Among the studies 
evaluated (31 selected and 9 added by snowball), only about 
12.5% have metrics or recommendations to assist, through 
good practices, the development of interfaces.  
Thus, the choice of features and attributes that best apply 
to a particular evaluation, among this diverse group found, is 
not a trivial task, given that often the people involved with 
the evaluation do not have necessary expertise in the area of 
usability that can assist and facilitate the evaluation work 
and, therefore, the make the best choice.  
Still, when the people involved with the evaluation of 
usability have a set of characteristics and attributes to 
evaluate, sometimes it is not clear what and how the 
interface should be evaluated or even how the interface 
should be constructed to meet certain characteristics and 
attributes.  
Given this scenario of complexity in the choice of 
features and attributes of usability, companies often do not 
apply methods of usability evaluation in their software 
projects/products for not having specialized team to select 
the best form of evaluation, as well as the best attributes for 
evaluation, producing sometimes software with low 
usability. 
The results of this systematic mapping clarify even more 
the need for a model of usability evaluation to guide those 
involved in the assessment, to provide objective guidelines 
for the evaluation of interfaces and indicate the execution 
environment for which those guidelines are valid. Another 
perceived need is related to the application of usability 
evaluation in business contexts, favoring the practical 
application of the researches. 
It is necessary a model or tool that assists in the process 
of evaluation and selection of evaluation attributes, 
facilitating the application of usability evaluations of 
projects/software products. 
Finally, it is important to analyze the threats inherent to 
the process adopted in this research, which mainly consists in 
the disposal of three studies for not having access to the full 
text. Another threat is about the mapping conduction, which 
was performed by a single investigator, but the planning 
stages and discussion involved two researches. To mitigate 
this threat, it was performed, after the conducting conclusion, 
an analysis of the disposed titles, and in specific cases, an 
abstract by a second researcher (as a way of review) was 
made. It´s also necessary to consider that the result presented 
is restricted to a specific search string in a set of four data 
sources limited to search for terms in English. The expansion 
of the terms, language and databases can reveal new features, 
attributes, metrics, and recommendations.   
REFERENCES 
[1] International Organization for Standardization. ISO 9241-11:1998, 
“Ergonomic requirements for office work with visual display 
terminals (VDTs), Part 11: Guidance on usability. Geneva, 
Switzerland: 1998. 
[2] J. Nielsen, Usability Engineering, London, UK: Academic Press, 
1993. 
[3] B. Shackel and S. Richardson, Human factors for informatics 
usability-background and overview, 1rd ed., vol. 1. Cambridge 
University Press: New York, 1991, pp. 1–19. 
[4] W. de Abreu Cybis, Usability Engineering: An ergonomic approach, 
LabUtil: Laboratorio de Utilizabilidade de Informatica, 2003. 
[5] E. Mosqueira-Rey, D. Alonso-Ríos, and V. Moret-Bonillo, “Usability 
taxonomy and context-of-use taxonomy for usability analysis,” Proc. 
IEEE Symp. Conference on Systems, Man and Cybernetics 
(SMC'09), 
IEEE 
Press, 
Oct. 
2009, 
pp. 
812-817, 
doi: 
10.1109/ICSMC.2009.5346929. 
[6] A. M. S. Filho, “Human Perception in Human-Computer Interaction,” 
in Revista Espaço Acadêmico, vol. 25,  2003. 
[7] S. Winter, S. Wagner, and F. Deissenboeck, Engineering Interactive 
Systems: A Comprehensive Model of Usability,  vol. 4940. Springer-
Verlag: Berlin, Dec. 2008, pp. 106–122. 
183
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

[8] A. Seffah, M. Donyaee, R.B. Kline, and H. K. Padda, “Usability 
measurement and metrics: A consolidated model,” Kluwer Academic, 
vol. 14,Jun. 2006, pp. 159-178, doi: 10.1007/s11219-006-7600-8. 
[9] O. Signore, “A comprehensive model for Web sites quality,” Proc. 
IEEE Symp. Web Site Evolution (WSE 2005), IEEE Press, Sep. 
2005, pp. 30-36, doi: 10.1109/WSE.2005.1. 
[10] A. Fernandez, E. Insfran, and S. Abrahão, “Usability evaluation 
methods for the web: A systematic mapping study,” Information and 
Software Technology, vol. 53, Aug. 2011, pp. 789-817, doi: 
10.1016/j.infsof.2011.02.007. 
[11] R. Fitzpatrick, “Additional Quality Factors for the World Wide Web,” 
Proc. and Cybernetics – Part A: Systems and Humans, 1999, pp. 29-
386. 
[12] C. Lallemand, “Toward a closer integration of usability in software 
development: a study of usability inputs in a model-driven 
engineering process,” ACM SIGCHI symposium on Engineering 
interactive computing systems (EICS '11), Jul. 2011, pp. 299-302, 
doi: 10.1145/1996461.1996541. 
[13] J. O. Bak, K. Nguyen, P. Risgaard, and J. Stage, “Obstacles to 
usability evaluation in practice: a survey of software development 
organizations,” Proc. Nordic conference on Human-computer 
interaction: building bridges (NordiCHI '08), IEEE Press, Oct. 2008, 
pp. 23-32, doi: 10.1145/1463160.1463164. 
[14] B. Kitcheman, Guidelines for performing Systematic Literature 
Reviews in Software Engineering. Durham, UK: University of 
Durham, 2007. 
[15] S. Jalali and C. Wohlin, “Systematic literature studies: database 
searches vs. backward snowballing,” Proc. ACM-IEEE international 
symposium on Empirical software engineering and measurement 
(ESEM 
'12), 
IEEE 
Press, 
Sep. 
2012, 
pp. 
29-38, 
doi: 
10.1145/2372251.2372257. 
[16] Cisco. Cisco Visual Networking Index: Global Mobile Data Traffic 
Forecast Update, 2012-2017, 2013. 
 
Appendix I – Primary Studies Included in the Mapping  
[#1]G.Lindgaard, C.Dudek, D.Sen, L.Sumegi, P.Noonan," An exploration of relations between visual appeal, trustworthiness and perceived usability of 
homepages"(2011) [#2]R.West,K. Lehman, "Automated summative usability studies: an empirical evaluation"(2006) [#3]A.T.Neto, T.J.Bittar, R.P.M.Fortes, 
and K.Felizardo, "Developing and evaluating web multimodal interfaces - a case study with usability principles"(2009) [#4]A.Seffah, M.Donyanee, 
R.B.Kline, H.K.Padda, "Usability measurement and metrics: A consolidated model" (2006) [#5]P.A.Davis, F.M.Shipman, "Learning usability assessment 
models for web sites" (2011) [#6]C.Ryan, A.Gonsalves, "The effect of context and application type on mobile usability: an empirical study"(2005) 
[#7]A.Fernandez, S.Abrahão, E.Insfran, "Towards to the validation of a usability evaluation method for model-driven web development"(2010) 
[#8]A.P.Massey, V.Khatri, V.Vamesh, "From the Web to the Wireless Web: Technology Readiness and Usability"(2005) [#9]A.Anandhan, S.Dhandapani, 
H.Reza, K.Namasivayam, "Web Usability Testing ? CARE Methodology"(2006) [#10]T.Tirapat, T.Achalakul, "Usability Assessment for Hyperlink 
Methods"(2006) [#11]T.Conte, J.Massolar, E.Mendes, G.H.Travassos, "Usability Evaluation Based on Web Design Perspectives"(2007) [#12]A.P.Massey, 
V.Khatri, M.M.Montoya-Weiss, "Online Services, Customer Characteristics and Usability Requirements"(2008) [#13]H.Y.Kao, "Usability Testing of AMC 
Hospital's Website for Home Users: Case Study for On-Site Registration Design"(2007) [#14]A.Granie, I.Mitrovic, N.Marangunie, "Usability Evaluation of 
Web Portals"(2008) [#15]T.Conte, J.Massolar, E.Mendes, G.H.Travassos, "Web usability inspection technique based on design perspectives"(2009) 
[#16]U.K.Yusof, L.K.Khaw, H.Y.Chang, B.J.Neowa, "Balancing between usability and aesthetics of Web design"(2010) [#17]A.Al-Wabil, L.Al-Husian, 
R.Al-Murshad, A.Al-Nafjan, "Applying the Retrospective Think-Aloud Protocol in Usability Evaluations with Children: Seeing Through Children’s 
Eyes"(2010) [#18]W.F.W.Ahmad, S.Sulaiman, F.S.Johari, "Usability Management System (USEMATE):A Web-Based Automated System for Managing 
Usability Testing Systematically"(2010) [#19]M.Freeman, M. Bowden, "Usability as a Panacea"(2010) [#20]L.Punchoojit, T.Chintakovid, "Influence of Age 
Group Differences on Website Cultural Usability"(2012) [#21]M.A.Mayz, D.M.Curtino, A.de la Rosa, "Avoiding laboratories to collect usability data: two 
software applications"(2012) [#22]A.Oztekin, "A decision support system for usability evaluation of web-based information systems"(2011) [#23]X.Fang, 
C.W.Holsapple, "An empirical study of web site navigation structures' impacts on web site usability"(2007) [#24]A.Fernandez, S.Abrahão, E.Insfran, 
"Empirical validation of a usability inspection method for model-driven Web development"(2013) [#25]M.Allen, L.M.Currie, S.Bakken, V.L.Patel, 
J.J.Cimino, "Heuristic evaluation of paper-based Web pages: a simplified inspection usability methodology"(2006) [#26]C.K.Coursaris, K.Hassanein, 
M.M.Head, N.Bontis, "The impact of distractions on the usability and intention to use mobile devices for wireless data services"(2012) [#27]E.K.Delice, 
Z.Gungor, "The usability analysis with heuristic evaluation and analytic hierarchy process"(2009) [#28]A.Holzinger, M.Errath, "Mobile computer Web-
application design in medicine: some research based guidelines"(2007) [#29]M.Vigo, A.Aizpurua, M.Arrue, J.Abascal, "Quantitative assessment of mobile 
web guidelines conformance"(2011) [#30]W.Oyomno, P.Jappinen, E.Kerttula, K.Heikkinen, "Usability study of ME2.0,"(2012) [#31]D,Schreiber, 
M.Hartmann, F.Flentge, M.Mühlhäuser, M.Görtz, Thomas Ziegert, "Web based evaluation of proactive user interfaces"(2008) [#35]J.Nielsen, "Usability 
Engineering"(1993) [#36]ISO/IEC FDIS 25010, "Systems and software engineering – Systems and Software Quality Requirements and Evaluation 
(SQUARE) – System and software quality models"(2010) [#37]MICROSOFT, "Windows Enviroment" [#38] T.V.Raman,"Design principles for multimodal 
interaction"(2003) [#39]L.M.Reeves, J.Lai, J.A.Larson, S.Oviatt, T.S.Balaji, S.Buisine, P.Collings, P.Cohen, B.Kraal, J.C.Martin, M.Mctear, T.Raman, 
K.M.Stanney, H.Su, Q.Y.Wang, "Guidelines for multimodal user interface design"(2004) [#40]A.Fernandez, E.Insfran, S.Abrahão,"Integrating a Usability 
Model into Model-Driven Web Development Processes"(2009) [#41]J.M.C.Bastien, D.L.Scapin, "Ergonomic Criteria for the Evaluation of Human-
Computer Interfaces"(1993)  [#42]ISO9241-11,"Ergonomic requirements for office work with visual display terminals (VDTs) – Part 11: Guidance on 
usability" (1998) [#43]K.Keeker, Improving Web Site Usability and Appeal, 1997". 
Appendix II – List of Characteristics and Usability Attributes Mapped 
Mobile Devices
Desktop
Web
 
 
 
184
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

Recursos visuais
Efficiency #42 #2 #35 #3 #40 #4 #5 #6 
#7 #9 #10 #11 #13 #14 #16 #17 #18 #19 
#20 #21 #24 #26 #27 #29 #30 #31 #6 
#17
Effectiveness #42 #2 #40 #4 #5 #7 #10 
#11 #13 #14 #17 #18 #20 #21 #24 #26 
#29 #30 #31 
Satisfaction #42 #2 #40 #4 #5 #6 #7 #10 
#13 #14 #16 #17 #18 #20 #21 #24 #26 
#29 #30 #31
Consistency interaction #39 #3 #28 #41 
#43
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
Textual information #25 #28 #43
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
Devices #43
Font #43
Animations and Transitions #43
Graphic elements #43
Sound #43
Components #43
Icons #28 #43
Emotion #8 #12
Promotion #8 #12
Compatibility #41 #19
Commands #43
Message #43
Windows #43
Coordination #23
Pattern  #35 #3 #4 #7 #11 #14 #15 #19 #24 #27 #25  #36
Aesthetic design #35 #3 #36 #4 #7 #11 #14 #15 #19 #24 
Colors #28 #43
Scope #30
Importance code #41 #19
Symmetry #1
Balance #1
Contrast #1
Interface/Layout #23 #43
Functionality #23
Quality Content #8 #12 #22 #23
Correction of Errors #41 #19
Objective#8 #12
Structure #8 #12
Brevity #41 #19
Community #8 #12
Sophistication #8 #12
Support for the user to recognize, diagnose and recover 
errors. #35 #3 #4 #7 #11 #14 #15 #19 #24 #27
Error Treatment  #39 #3
Error prevention #4 #7 #14 #15 #19 #24 #27
Quality of Error Messages #41 #19
Number of Errors #6 #28 #30
Error protection #41 #19 #36 #4 #7
Interaction state shared #38 #3
Predictability #38 #3
Adaptation at middle #38 #3 #9
Design Input Output #38 #3
Comments #39 #3
Prevention of errors #35 #3
Attractiveness #36 #4 #22 #7 #40
Explicit user action #41 #19
Solicitation #41 #19
Grouping and distinguish items  #41 #19
Synchronism #38 #3
Visible transition #38 #3
Fault Tolerance #40 #4
Safety Features #40 #4
Assurance #40 #4
User Experience #43 #41 #19
Density #1 #41 #19
Customization #23 #8 #12
Temporal behavior #40 #4
Use of resources #40 #4
Accuracy  #40 #4
Completeness #40 #4
Enjoyability #40 #4
Familiarity #40 #4
User guidance #40 #4
Self-Description #40 #4
Simplicity #40 #4
Controllability #40 #4
Privacy #40 #4
Legibility #41 #19 #40 #4
Navigability #40 #4
Flexibility #40 #4 #41 #19
Charge Time #40 #4
Consistency #40 #4
Operability #41 #19 #36 #4 #7
ATTRIBUTES
Feedback #41 #19 #40 #4 #39 #3 #8 #12
Load minimal memory #40 #4
Operability #40 #4
Minimal Action #40 #4
Trustworthiness  #40 #4 #16 #22
Accessibility #40 #4 #36 #7
Universality #40 #4
Utility #40 #4
Workload (Memory)  #41 #19 #25 #30
Adaptability  #6 #41 #19 #8 #12 #30 #36 
#4 #7
Documentation #35 #3 #4 #7 #11 #14 #15 #19 
#24 #27
Management Errors #41 #19
Ease of use #4 #6 #7 #8 #9 #12 #24 #27
Productivity #40 #4
Learnability #40 #4 #6 #16 #20 #35 #3 #36 
#4 #7 #11 #14 #15 #41 #19 #24 #27
security  #40 #4 #22 #35 #3 #4 #7 #11 #14 
#15 #41 #19 #24 #25 #27 
Flexibility  #35 #3 #5 #7 #11 #14 #19 #24 #27
Multimodal  #3 
Mapping between system and real world #35 
#3 #4 #7 #11 #14 #15 #19 #24 #27
Liberty  #35 #3 #4 #7 #11 #14 #15 #19 #24 
#27
Minimalist  #35 #3 #4 #7 #11 #14 #15 #19 
#24 #25 #27
Help #35 #3 #4 #7 #11 #14 #15 #19 #24 #27 
CHARACTERISTICS
Integration of Communication  #22
From User Control  #41 #19 #22 #23 #35 #3 
#4 #7 #11 #14 #15 #19 #24 #27 
Navigation / guidance #5 #22 #28 #41 #19
Visibility of System Status #35 #3 #4 #7 #11 
#14 #15 #19 #24 #27
 
185
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

