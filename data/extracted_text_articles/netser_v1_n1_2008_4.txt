40
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
Adaptive Congestion Detection and Control at the Application Level for VoIP
Teck-Kuen Chua and David C. Pheanis
Computer Science and Engineering
Ira A. Fulton School of Engineering
Arizona State University
Tempe, Arizona 85287-8809
Email: TeckKuen.Chua@gmail.com or David.Pheanis@ASU.edu
Abstract
For decades, researchers have worked extensively in
the area of congestion control for packet-switched net-
works.
Many proposed solutions take advantage of the
congestion-control mechanism in Transmission Control
Protocol (TCP), and these approaches work well for net-
works that have heavy TCP trafﬁc.
However, these ap-
proaches are not universally effective — they fail com-
pletely for protocols that do not implement congestion-
control mechanisms.
In particular, these approaches do
not work with the User Datagram Protocol (UDP). Real-
time media-streaming technologies such as Voice over In-
ternet Protocol (VoIP) and video conferencing use UDP
and therefore do not respond well to existing congestion-
avoidance techniques. We propose a new, adaptive, respon-
sive, end-to-end technique to implement application-level
congestion detection and control for real-time applications
such as VoIP. Unlike existing methods, which rely on packet
loss as a signal to reduce the transmission rate, our solution
proactively reacts to network congestion to prevent packet
loss, thus improving the QoS of applications that employ
our algorithm.
Keywords: VoIP, QoS, congestion detection, congestion
avoidance, adaptive transmission control, real-time media.
1. Introduction
In a packet-switched network, a router connects multi-
ple ingress streams to various egress ports. When a heavy
burst of network trafﬁc occurs, congestion builds up at the
routers, which form the bottlenecks of the network. When
congestion in a router becomes severe enough, the incom-
ing packets consume all of the buffer resources in the router
and leave no room for additional inbound packets, thus re-
sulting in lost packets.
The output rate at an egress queue in a router can be only
as fast as the serialization rate of the hardware. When an
egress queue receives packets from multiple ingress ports at
a combined rate that is higher than the serialization rate of
the egress port, the egress queue grows, eventually causing
congestion. When the egress queue becomes full, the router
has to discard all additional packets destined for that egress
queue. This dropping of packets is an unwelcome condition
known as tail drop.
Dropped packets are undesirable at any time, of course,
but tail drop is especially undesirable because it leads to an
adverse effect called global synchronization. Global syn-
chronization occurs when tail drop causes all of the trans-
mitting devices to receive congestion signals at the same
time. The transmitting devices consequently reduce their
transmission rates in unison, and the link utilization quickly
falls well below the optimal level due to the sudden, si-
multaneous reduction in transmission rates from all of the
senders. When congestion eases, the transmitting devices
increase their transmission rates all at once, leading to an-
other episode of severe congestion in the network.
Researchers have done considerable work in this area
and have proposed numerous solutions to manage and
avoid congestion in a packet-switched network. Proposed
congestion-avoidance methods include Random Early De-
tection (RED) [1] and its variants [2] [3] [4] [5], and pro-
posed approaches also include BLUE [6], Stochastic Fair
BLUE (SFB) [7], Generalized Random Early Evasion Net-
work (GREEN) [8], and Explicit Congestion Notiﬁcation
(ECN) [9].
Each of these suggested techniques exploits
the transmission-control mechanism in Transmission Con-
trol Protocol (TCP). Since real-time IP applications gener-
ally use the User Datagram Protocol (UDP) as the transport
protocol, however, these proposed congestion-control ap-
proaches are almost entirely ineffective at curbing real-time
media trafﬁc.
We propose a new application-level adaptive congestion-
detection and congestion-control mechanism for avoiding

41
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
congestion with real-time IP applications such as Voice
over Internet Protocol (VoIP)1.
We start by explaining
how existing congestion-avoidance algorithms work with
TCP, and we discuss the problems that existing approaches
have with UDP and the intrinsic challenges of congestion
control with real-time applications. Then we present our
new application-level adaptive congestion-detection and
congestion-control solution for real-time IP applications,
and we provide measurements that demonstrate the effec-
tiveness of our system.
2. Existing approaches
Congestion has been a serious problem in packet-
switched networks since packet switching ﬁrst came into
existence. The importance of the congestion problem is ev-
ident from the extensive amount of work that researchers
have done to provide ways of avoiding or at least managing
congestion. In this section we examine a few well-known
congestion-avoidance techniques and show how these meth-
ods alleviate congestion in packet-switched networks, so
this section provides a basis for understanding the new real-
time congestion-control technique that we present later.
2.1. Random Early Detection (RED)
Random Early Detection (RED) is an active queue-
management (AQM) technique with the aim of achieving
low average delay and high throughput [1]. RED uses the
average queue size as an early indication of congestion and
signals the transmitting devices to reduce their transmis-
sion rates temporarily before the congestion actually oc-
curs.
When the average queue size exceeds a predeter-
mined minimum threshold, RED starts dropping randomly
selected packets. The probability of dropping packets in-
creases either linearly or exponentially as the average queue
size grows beyond the minimum threshold. When the aver-
age queue size passes a predetermined maximum threshold,
RED starts dropping all incoming packets. RED uses the av-
erage queue size over some period of time instead of using
the instantaneous queue size, so the technique can absorb
spikes or short bursts of network trafﬁc without overreact-
ing.
When a TCP host detects packet loss, the host temporar-
ily slows down its transmission rate.
TCP increases its
transmission rate quickly when all packets reach the des-
tination, an indication that the period of congestion has
passed. RED randomly selects packets to drop, thereby dis-
tributing the packet loss among assorted hosts at various
times. As a result, the hosts reduce their transmission rates
at different times and avoid global synchronization.
Weighted RED (WRED) incorporates the IP precedence
feature into the RED algorithm. WRED gives preferential
1Patent pending
handling to packets that have higher priority. When conges-
tion is building, WRED randomly selects packets with lower
priority as the ﬁrst packets to discard. This scheme cre-
ates differentiated QoS characteristics for different classes
of service.
Some researchers have proposed dynamic RED imple-
mentations that adapt to ever-changing network condi-
tions. For example, adaptive RED [2], Dynamic Weighted
Random Early Drop (DWRED) [3], and other similar ap-
proaches are adaptive RED variants that are designed to ad-
dress the sensitivity weaknesses of RED. Both the through-
put and the average queue size of RED are very sensitive
to the trafﬁc load and RED parameters [10][11], so RED
produces unpredictable results in volatile network environ-
ments.
Flow-based RED (FRED) [4] includes a mechanism to
enforce fairness in resource utilization for each active ﬂow
of trafﬁc. This technique uses information such as destina-
tion addresses, source addresses, and ports to classify traf-
ﬁc into different ﬂows. The ﬂow-based algorithm maintains
state information for every active ﬂow, and the algorithm
uses the ﬂow information to ensure that each active ﬂow
gets a fair portion of the buffer resources. Flows that mo-
nopolize resources receive heavier penalties when packet
dropping becomes necessary.
Stabilized RED (SRED) [5] is another ﬂow-based RED
approach where the algorithm provides a method to esti-
mate the number of active ﬂows and to identify misbehav-
ing ﬂows without keeping per-ﬂow state information. SRED
controls buffer usage by tuning the drop probabilities based
on the estimated number of active ﬂows.
2.2. Stochastic Fair BLUE (SFB)
BLUE is an AQM approach that uses packet-loss and link-
utilization information instead of average queue length in
the congestion-avoidance algorithm [6]. BLUE uses a sin-
gle probability to drop or mark packets. If the link is idle or
the queue becomes empty, BLUE decreases the drop/mark
probability. On the other hand, if the queue consistently
loses packets due to buffer overﬂow, BLUE increases the
drop/mark probability. As a result of the increased prob-
ability, we drop or mark more packets and therefore send
out congestion notiﬁcations at a higher rate. This adaptive
procedure allows BLUE to learn the correct rate for sending
congestion signals to the transmitting hosts.
Stochastic Fair BLUE (SFB) uses the BLUE algorithm to
protect TCP ﬂows against ﬂows — such as UDP ﬂows —
that do not respond to congestion notiﬁcations [7].
SFB
maintains a small amount of ﬂow-related state information
in order to enforce fairness among all the ﬂows. The SFB
algorithm quickly drives the drop/mark probability to a very
high value, perhaps even one, for an unresponsive ﬂow. In
contrast, TCP ﬂows usually maintain low drop/mark prob-

42
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
abilities because TCP ﬂows reduce their transmission rates
in response to congestion notiﬁcations. When the SFB tech-
nique identiﬁes an unresponsive ﬂow by observing a high
drop/mark probability, SFB applies a bandwidth-limiting
policy on that particular ﬂow. The rate-limit policy enforces
an allowable amount of data that the ﬂow can enqueue into
the buffer, and SFB therefore drops more packets of the un-
responsive ﬂows. In simpliﬁed terms, the SFB algorithm
identiﬁes unresponsive ﬂows and subjects them to rate lim-
iting while allowing responsive TCP ﬂows to perform nor-
mally with low drop/mark probabilities.
2.3. GREEN
Generalized Random Early Evasion Network (GREEN)
is a proactive queue-management (PQM) method that ap-
plies a mathematical model of the steady-state behavior
of a TCP connection to drop or mark packets proactively.
GREEN attempts to maintain low packet loss and high link
utilization while reducing latency and delay jitter. Based on
the mathematical model, GREEN is able to give each ﬂow
its fair share of bandwidth at the router. The router can use
GREEN to identify and police ﬂows that do not respond to
congestion notiﬁcation.
Using the mathematical model that Mathis et al. [12] rec-
ommend, Feng et al. [8] derive a mathematical model for a
drop probability that allows a fair share of bandwidth for ev-
ery ﬂow. Equation 1 shows that Feng’s fair-share drop prob-
ability depends on the number of active ﬂows, N, and the
round-trip time, RTT. A GREEN router sends out conges-
tion notiﬁcations more aggressively when there are more ac-
tive ﬂows (larger N) or when the round-trip time is shorter
(smaller RTT). In the equation, MSS is the maximum seg-
ment size, L is the outgoing link throughput of a router, and
c is a constant that depends on the acknowledgment strategy
(i.e., delay or every packet).
p =
N × MSS × c
L × RTT
2
(1)
2.4. Explicit Congestion Notiﬁcation (ECN)
The Internet Engineering Task Force, IETF, has proposed
Explicit Congestion Notiﬁcation (ECN) as an alternative
to using packet loss for signaling congestion [9]. Instead
of dropping packets as congestion increases, routers us-
ing this congestion-avoidance algorithm set the congestion-
indicator bit in an IP packet to signal congestion. When
a receiving device receives a packet with the congestion-
indicator bit set, the receiving device uses the transport-
level acknowledge message to communicate the congestion
indication to the transmitting device. Upon receiving the ex-
plicit congestion notiﬁcation, the sending device decreases
its transmission rate temporarily until the trafﬁc condition
of the network improves.
Using IP ECN instead of the traditional packet-loss ap-
proach can obviously reduce packet loss and thereby im-
prove performance. However, the ECN technique requires
explicit support from both communicating devices to be
successful, and both devices have to agree to use this
scheme. In addition, all of the routers in the entire network
must support this method for ECN to be effective. Outdated
routers that do not support ECN might drop packets with the
ECN bit set, thus causing the IP ECN approach to fail.
2.5. (Pre-) Congestion Notiﬁcation (PCN)
The Congestion and Precongestion Notiﬁcation Working
Group of IETF has developed an Internet draft for a Pre-
Congestion Notiﬁcation (PCN) architecture [13]. PCN is an
architecture for ﬂow admission and/or termination based on
(pre-) congestion information that nodes in a Diffserv do-
main provide. The aim of PCN is to protect the QoS of
inelastic ﬂows within the Diffserv domain. The PCN ap-
proach gives an “early warning” of potential congestion in
the PCN domain before there is any signiﬁcant congestion.
If the ﬂow rate through a PCN-enabled interior node ex-
ceeds the PCN threshold rate, the node marks all packets
with PCN threshold-rate markings.
If the ﬂow rate ex-
ceeds the PCN excess rate, the node marks some packets
with PCN excess-rate markings while marking all remain-
ing packets with PCN threshold-rate markings. These (pre-)
congestion markings propagate to PCN egress nodes, and
the PCN boundary nodes use this (pre-) congestion infor-
mation to make decisions on ﬂow admission and/or termi-
nation. Fig. 1 shows how the PCN admission and termina-
tion controls operate in a PCN domain with three encoding
states as the rate of PCN trafﬁc increases.
Note that PCN applies to a Diffserv domain with PCN-
enabled nodes, so PCN is not a general solution for all en-
vironments.
3. Problems with existing approaches
Real-time IP applications, such as VoIP and IP video
conferencing, use the Real-time Transport Protocol (RTP)
to transport real-time media packets, and RTP runs on top
of UDP. Unlike TCP, UDP does not support acknowledge
(ACK) messages in the protocol, nor does UDP implement
any transmission-control mechanism to allow the network
to alter the transmission rate of a ﬂow.
Lacking ACK messages, an application that uses UDP
as the transport protocol has no way to determine when a
router drops any of the packets that the application sends.
Packet loss is a reliable indication of congestion, but UDP
transmitters, being unable to detect packet loss, cannot re-
act to congestion in the network. Even if a transmitter could

43
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
Marking Behavior
PCN Mechanisms
Rate of PCN traffic 
on bottleneck link
(as below)
(as below, and also 
drop
some PCN packets)
Scheduler rate
(for PCN traffic)
Some packets
excess-traffic marked
and
remaining packets
threshold-marked
Terminate some
admitted flows
and
Block new flows
PCN excess rate
(equals PCN-
supportable rate)
All packets
threshold-marked
Block new flows
PCN threshold rate
(equals PCN-
admissible rate)
No packet PCN-marked
Admit new flows
Figure 1. PCN technique
somehow detect the occurrence of packet loss, UDP does
not have a mechanism to control its transmission rate. Con-
sequently, UDP applications do not respond well to any of
the existing congestion-control algorithms.
Even congestion-avoidance techniques that try to en-
force fairness, as ﬂow-based RED and SFB do, are not fully
effective against UDP streams, which do not respond to
congestion-control mechanisms. Since UDP ﬂows are not
responsive to congestion-control signals, these ﬂows simply
monopolize the resources of the router in an environment of
congestion. Consequently, these streams receive harsh pun-
ishment in the form of many lost packets, and they therefore
suffer greatly reduced Quality of Service (QoS).
TCP-Friendly Rate Adaptation Based on Loss (TRA-
BOL) is an application-level congestion-control algorithm
designed speciﬁcally for UDP-based applications [14].
TRABOL employs a technique that is similar to the approach
of TCP, but TRABOL implements congestion control at the
application level while TCP uses the protocol level. Like
TCP, TRABOL relies on lost packets to adjust the sender’s
transmission rate. Unlike TCP, however, TRABOL uses the
loss rate computed over a period of time at the receiver side
as feedback to tell the sender how to adjust the transmission
rate. If the period for calculating the loss rate in TRABOL
is too large, the sender could react to the congestion too
late or simply adjust the transmission rate incorrectly. If
the period for calculating the loss rate in TRABOL is too
small, on the other hand, the system could overreact to mi-
nor disturbances that do not really indicate congestion. In
this case, the ﬂow rate would oscillate needlessly. Further-
more, TRABOL does not address the real-time criterion of
real-time UDP-based applications such as VoIP.
The inherent characteristics of real-time applications
such as VoIP present additional challenges to the imple-
mentation of transmission control. Real-time IP applica-
tions typically produce output data at a constant rate, and
we need to transport the continuous output stream to the re-
ceiving endpoint with minimal delay to maintain the useful-
ness of the data and a high QoS. Delivering only part of the
output stream to reduce the output data rate inevitably de-
grades QoS. Holding back the real-time data transmission
in order to wait for the end of a congestion period increases
delay variation (i.e., jitter) and lengthens the end-to-end de-
lay, further impairing QoS.
4. Our congestion-control mechanism
We propose a solution that allows real-time IP applica-
tions to implement adaptive congestion control in the face
of congestion while meeting all of the intrinsic challenges of
real-time media systems. Our solution consists of two inde-
pendent components, congestion detection/notiﬁcation and
adaptive transmission control. Unlike existing approaches
that implement congestion control at the protocol level, our
technique implements the solution at the application level.
As a result, we do not need to change existing protocols or
the existing infrastructure to put our approach into practice.
4.1. Congestion detection/notiﬁcation
Network congestion normally occurs at the routers, and
detecting congestion at the router bottleneck is probably the
detection approach that provides the most reliability and
accuracy. Therefore, the router is the best device for per-
forming congestion detection. Since the router is the ﬁrst
network device that can observe congestion, the router can
deliver a notiﬁcation of congestion sooner than any other
device in the network. However, the innumerable routers of
the Internet are beyond our control, so deploying new pro-
cedures for congestion detection and notiﬁcation in all the
routers of the Internet is impractical.
Our solution employs congestion detection at the receiv-
ing endpoint. We merely require both communicating end-
points to agree on the scheme of congestion detection and
notiﬁcation instead of requiring many devices beyond our
control to cooperate with our algorithm.
When congestion occurs at the router, the average queue
size in the router grows.
High queue occupancy at the
router increases the transmission delay of the packets since
a packet takes more time to work its way through a longer
router queue, and packets arrive at the destination later than
anticipated. Real-time IP applications commonly transmit
data packets at constant intervals, so data packets arrive at
the receiving endpoint with consistent periods and minimal
variation if the network is idle. Therefore, an increase in
the time between the arrivals of consecutive packets at the
destination is a good indication of congestion [15].

44
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
If congestion is severe enough, a router that implements
a congestion-avoidance algorithm, such as RED or its vari-
ants, starts to drop packets to curb the congestion. Conse-
quently, data packets disappear from the network, and the
receiving endpoint can use packet loss as a clear indication
of congestion. If the routers on the transmission path imple-
ment IP ECN, the receiving endpoint can recognize the set
ECN ﬂag as a sign of congestion.
Statistics that we have collected over a period of several
months on the Internet and on a corporate local-area net-
work (LAN) show that even a lightly loaded router experi-
ences sudden microbursts of trafﬁc. These abrupt and brief
periods of congestion are severe enough to cause the router
to drop packets, but the times between the arrivals of previ-
ous consecutive packets do not always show any early sign
of congestion. This kind of unforeseen and acute congestion
is different from the congestion that builds over a longer pe-
riod of time, and our congestion-detection algorithm must
be able to detect both types of congestion effectively.
The receiving endpoint can recognize slowly building
congestion in the network by implementing an algorithm
to detect inter-packet delays that are longer than usual. In
order to detect variations in inter-packet delays, of course,
the receiver must know the arrival rate of the packets. The
transmitting party or parties can reveal the transmission-rate
information during the negotiation process at the start of a
session, or the receiver can quickly and easily calculate the
arrival rate of packets after the session starts.
When congestion builds up gradually, the detection algo-
rithm easily detects the pattern of growing inter-packet ar-
rival times before the congestion can cause any noticeable
harm. When the ﬁltered arrival time between consecutive
packets exceeds a predetermined threshold, the receiver de-
clares a state of congestion.
Unfortunately, there may be no warning sign of grow-
ing inter-packet arrival times before a microburst suddenly
causes a lost packet, and the inter-packet arrival time would
not reveal this problem until the arrival of the next packet
after the lost packet(s). Therefore, the detection algorithm
employs a time-out procedure to detect a delayed or miss-
ing packet immediately. The time-out mechanism declares
a congestion condition when a packet has not arrived at
the receiver by some predetermined time after the estimated
packet-arrival time but before the estimated arrival time of
the subsequent packet. The time-out procedure detects a
congestion condition well ahead of the transmission time of
the subsequent packet, so the transmitter can delay trans-
mission brieﬂy to avoid losing more packets. With the in-
clusion of the time-out feature, the algorithm detects sudden
microbursts as well as slowly growing episodes of conges-
tion.
Additionally, the system uses packet sequence numbers
to detect out-of-order packets and considers an out-of-order
packet to be an indication of a lost packet even though the
“lost” packet may arrive later or may have previously ar-
rived out of order. When packets are out of order, we cer-
tainly have congestion.
Upon detecting congestion, the receiver sends the trans-
mitter a congestion notiﬁcation containing an estimate of
the severity of the congestion. This notiﬁcation tells the
transmitter that congestion is present and to what degree
congestion is present. The receiver can piggyback the no-
tiﬁcation message with the next data packet that the re-
ceiver transmits to the sender, thereby avoiding the unde-
sirable effect of adding notiﬁcation packets to a network
that is already congested. Both ends of a VoIP system con-
tinually send packets to each other at brief intervals, typ-
ically twenty milliseconds, so timely notiﬁcation without
any added packets is entirely feasible.
Our extensive study of the characteristics of packet-
switched network trafﬁc shows that network congestion is
direction dependent. In other words, a congestion condition
on the path from A to B does not necessarily imply a sim-
ilar congestion condition on the path from B to A. In fact,
we often observe relatively idle trafﬁc on the opposite di-
rection of a congested network path. Therefore, sending a
congestion notiﬁcation from the receiver to the transmitter
typically does not elevate the severity of the congestion.
Nevertheless, the network may drop the packet contain-
ing the congestion notiﬁcation, so the receiver should send
multiple congestion notiﬁcations.
However, each of the
notiﬁcation packets for the same occurrence of congestion
must contain the same unique identiﬁer so the sender reacts
only once to the ﬁrst notice it receives and ignores the rest.
The receiver can stop transmitting the notiﬁcation messages
when it observes a lower transmission rate from the sender,
or the receiver can stop transmitting the notiﬁcation mes-
sages after some duration, especially when the congestion
subsides.
4.2. Our implementation of congestion detection
Our congestion-detection algorithm measures and evalu-
ates the inter-packet arriving intervals, so the algorithm not
only detects congestion in the network but also estimates the
severity of the congestion. Additionally, our algorithm an-
ticipates future congestion that is likely to occur soon after
an episode that is part of a longer period of network conges-
tion. Our detection procedure computes the absolute value
of the difference between the inter-packet arriving interval
and the original inter-packet transmission interval. Then we
pass the resultant value through a simple ﬁrst-order inﬁnite
impulse response (IIR) ﬁlter to obtain the severity of the
congestion in the network.
Equation 2 shows the ﬁrst-order IIR ﬁlter that our algo-
rithm uses. Yn is the current output value of the ﬁlter, and
it is the estimate of the severity of the congestion in the net-

45
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
CurrentTime = GetCurrentTime();
Xn = ABS((CurrentTime -
PrevPacketArrTime) -
PacketTransmissionInterval);
if (NOT Timeout)
{ PrevPacketArrTime = CurrentTime; }
if (LostPacket OR Timeout)
{ Xn = MIN(Xn, MAX Xn LIMIT);
Xn = MAX(Xn, Yprevious); }
if (Xn >= Yprevious)
{ C1 = 0.9;
C2 = 0.1; }
else
{ C1 = 0.03;
C2 = 0.97; }
Yn = (C1 * Xn) + (C2 * Yprevious);
if (Yn >= CONGESTION THRESHOLD)
{ DeclareCongestion(Yn); }
Yprevious = Yn;
Figure 2. Pseudo code of congestion-detection algorithm
work. Yn−1 is the previous output value of the ﬁlter, so it
provides feedback. Xn is the current input sample to the
ﬁlter, and it is the absolute value of the difference between
the current inter-packet arriving interval and the inter-packet
transmission interval. C1 and C2 are coefﬁcients of the IIR
ﬁlter.
Yn = (C1 × Xn) + (C2 × Yn−1)
(2)
Fig. 2 shows an excerpt from the pseudo code for our
congestion-detection algorithm [16]. Our implementation
uses an IIR ﬁlter with fast-rise and slow-decay characteris-
tics. The fast-rise characteristic of the ﬁlter allows the mea-
surement of congestion severity to increase quickly when
congestion builds up. The slow-decay characteristic of the
ﬁlter allows the congestion-severity value to fall gradually
after the network congestion subsides, thus anticipating the
likely prospect that network congestion might persist or that
additional network congestion might occur shortly after the
current episode of congestion. In comparison to an episode
of moderate congestion, a period of severe congestion raises
the measurement of congestion severity to a higher value,
and a higher congestion-severity value requires a longer
time to decay to a level below the congestion threshold. We
can use different C1 and C2 coefﬁcients to adjust the rise
rate and decay rate of the IIR ﬁlter if necessary. A slower
decay rate allows the system to anticipate congestion that
might occur further into the future.
Fig. 3 illustrates inter-packet arriving intervals that are
typical for data that we captured from the Internet during
highly congested periods. The transmitting endpoint was
transmitting one VoIP packet every twenty milliseconds in
this experiment, and the receiving endpoint observed erratic
inter-packet arriving intervals ranging from zero millisec-
onds (i.e., two or more packets arriving at about the same
time) to ninety milliseconds or more during this period of
severe congestion. The receiving endpoint even observed
lost packets and, in some cases, out-of-order packets.
Fig. 4 illustrates the output from our congestion-
detection mechanism for the inter-packet arriving intervals
of Fig. 3. As we can see in Fig. 3, the receiving endpoint
repeatedly observed extreme delays in the arriving pack-
ets. These extreme delays produce signiﬁcant congestion-
severity values that remain above the congestion threshold
throughout the slow decay of the IIR ﬁlter. Our congestion-
detection algorithm therefore reports that congestion con-
tinues throughout the entire episode of network congestion.
Fig. 5 shows inter-packet arriving intervals that we cap-
tured from a corporate LAN. As with the previous experi-
ment, the transmitting endpoint transmits a VoIP packet ev-
ery twenty milliseconds. During this period, the receiving
endpoint observed three episodes of mild to serious con-
gestion. Using the data in Fig. 5, our congestion-detection
algorithm generates the output that appears in Fig. 6.
4.3. Adaptive transmission control
The real-time application at the transmitting endpoint
implements the adaptive transmission-control mechanism.
Upon receiving a congestion notice from the endpoint at
the receiving end of the transmission, the transmitting end-

46
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
0
10
20
30
40
50
60
70
80
90
100
1
5
9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89 93 97
Packet Number
Inter-Packet Arriving Time (ms)
Figure 3. Inter-packet arriving interval (Internet)
0
10
20
30
40
50
60
70
1
5
9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89 93 97
Packet Number
Congestion Severity (ms)
Xn
Congestion Severity
Figure 4. Estimate of congestion severity (Internet)
point lowers its transmission rate to reduce bandwidth con-
sumption. This reduction of the transmission rate is not as
simple for a real-time application such as VoIP as it is for a
TCP application, though, because the transmitting endpoint
must deliver all of the real-time data with minimal delay to
maintain a high QoS.
One straightforward approach for reducing bandwidth
consumption is to switch to a different compression algo-
rithm that can compress the real-time data to a greater de-
gree and thereby produce an output stream with a lower
bit rate. Generally, real-time VoIP applications already use
compression algorithms to compress real-time data before
sending the data across the network because uncompressed
voice data typically consumes too much bandwidth. The
transmitting endpoint can further reduce bandwidth con-
sumption by switching to a different compression algorithm
that achieves a lower bit rate. The greater compression typi-
cally results in a slight QoS penalty, but this penalty is mild
in comparison to the extreme QoS penalty that occurs as a
result of the packet loss that normally stems from network
congestion. This compression-switching approach requires
both communicating endpoints to support the same set of
compression schemes.
Various alternative data-compression algorithms have
differing bandwidth requirements, and some compression
algorithms support multiple compression ratios.
For ex-
ample, the ITU-T (International Telecommunication Union
Standardization Sector) standard G.729 compresses audio
data to 8 kbps [17], G.729 with annex D compresses audio
data to 6.4 kbps, and G.729 with annex E compresses audio
data to 11.8 kbps. The ETSI (European Telecommunica-
tions Standards Institute) GSM 06.90 standard, GSM adap-
tive multi-rate (GSM-AMR), supports multiple bit rates of
4.75 kbps, 5.15 kbps, 5.9 kbps, 6.7 kbps, 7.4 kbps, 7.95
kbps, 10.2 kbps, and 12.2 kbps [18]. A transmitter can re-
duce bandwidth by simply switching to a different compres-
sion algorithm in the same family.
Another method for reducing bandwidth usage is to
transmit the same data with fewer transmissions, thus reduc-
ing packet-header overhead. The sending endpoint achieves

47
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
0
5
10
15
20
25
30
35
1
5
9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89 93 97
Packet Number
Inter-Packet Arriving Time (ms)
Figure 5. Inter-packet arriving interval (LAN)
0
2
4
6
8
10
12
14
16
1
5
9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89 93 97
Packet Number
Congestion Severity (ms)
Xn
Congestion Severity
Figure 6. Estimate of congestion severity (LAN)
this goal by covering a longer period of time with the data
that it packs into each IP packet. For example, a VoIP end-
point that transmits twenty milliseconds of audio data per
IP packet can cut the number of transmissions by a factor of
two if the endpoint sends forty milliseconds of audio data
per IP packet. This approach signiﬁcantly lowers bandwidth
consumption by reducing the amount of bandwidth that the
transmitter consumes with packet-header overhead. Obvi-
ously, this technique achieves its goal at the cost of adding
a slight delay to the real-time data stream, but this approach
does not trim or further compress any audio data.
A VoIP endpoint that packages twenty milliseconds of
G.729 compressed audio per IP packet requires 24.0 kbps,
including the overhead of the IPv4, UDP, and RTP head-
ers at forty bytes per packet. If the VoIP endpoint pack-
ages forty milliseconds of G.729 compressed audio per IP
packet, the required bandwidth diminishes to only 16.0
kbps, including header overhead. This simple scheme re-
sults in a tremendous bandwidth saving of 8.0 kbps or 33%.
This approach does introduce an additional twenty millisec-
onds of delay into the audio stream, of course, but the ef-
fect of this small added delay on QoS is typically insignif-
icant [19].
In fact, this method can actually reduce the
overall delay because the technique alleviates queue de-
lays in the routers, often more than compensating for the
small delay between consecutive transmissions.
Table 1
shows the bandwidth consumptions and savings with dif-
ferent amounts of compressed G.729 audio data in each IP
packet.
The transmitting endpoint can simultaneously employ
both of the bandwidth-reduction techniques that we have
proposed since the two methods are independent of each
other. The transmitting device can switch to a compression
algorithm that produces a lower bit rate, and the transmitter

48
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
Table 1. G.729 Bandwidth utilization
Audio Length
Bandwidth
Packets
%
(milliseconds)
(kbps)
per Second
Savings
10
40.000
100.00
-
20
24.000
50.00
40.00%
30
18.667
33.33
53.33%
40
16.000
25.00
60.00%
50
14.400
20.00
64.00%
can concurrently package more data into each IP packet to
lower the number of transmissions and save bandwidth on
the packet-header overhead.
The congestion-severity information in the congestion
notiﬁcation that the receiver sends to the transmitter allows
the transmitter to gauge its response according to the sever-
ity of the congestion. Using the congestion-severity infor-
mation, the transmitting endpoint selects the bandwidth-
reduction method that is most appropriate for the level of
congestion, thereby maintaining optimal link utilization and
throughput while simultaneously curbing congestion.
When network congestion recedes, the transmitting end-
point adjusts its transmission rate back to the original set-
ting. The receiving endpoint detects the improvement in
the congestion, and the receiving endpoint conveys this in-
formation to the transmitting endpoint. After learning that
the trafﬁc condition has improved, the transmitting endpoint
increases its transmission rate to reduce delay and improve
the grade of service. The transmitting endpoint can alter-
natively operate with the optimized transmission procedure
for a predetermined period of time. When the ﬁxed duration
for using the lower transmission rate expires, the transmit-
ting endpoint automatically resets its transmission rate.
5. Measure of improvement
To illustrate the effectiveness of our technique, let us ex-
amine the performance improvement that we can achieve.
Consider a scenario in which the router throughput is 10.0
Mbps and we have 700 VoIP streams going through the
router. If we use G.729 to compress the audio data and
pack 20 milliseconds of audio into each IP packet, we re-
quire 16.80 Mbps of bandwidth, 6.80 Mbps more than the
router can handle. As a result, the router drops an average
of 20.238 packets per second for each ﬂow. That drop rate
translates into more than 400 milliseconds of lost audio data
in each second for each ﬂow, a devastating loss of more than
40%!
If the VoIP applications employ our solution and begin to
package 40 milliseconds of audio data into every IP packet,
we require only 11.20 Mbps for all 700 audio streams com-
bined. That bandwidth reduction cuts the drop rate to 2.679
packets per second per ﬂow for an average of about 107 mil-
liseconds of audio loss in a second for each ﬂow, a tolerable
loss rate of just 10.7%. If the VoIP applications switch to use
G.729 with annex D and also pack 40 milliseconds of audio
per IP packet, the required bandwidth decreases to 10.08
Mbps. In this case, each audio stream loses an average of
only 0.198 packets per second for a loss rate of just 0.79%,
almost zero loss! Fig. 7 illustrates the loss comparison for
the case that we have examined.
6. Delay versus packet loss
Since one aspect of our adaptive transmission control
increases the overall delay by using larger, less-frequent
packets, we must consider the potential negative impact of
increasing the delay versus the positive impact of reduced
packet loss.
We can use the ITU-T G.107 E-Model to analyze the QoS
impact of the additional delay that our transmission-control
method introduces into the audio stream. The E-model is
an analytical model that evaluates the conversational quality
of a telephony system. The E-model includes many items
(e.g., room noise, echo, and circuit noise) that are indepen-
dent of both packet loss and delay, but we isolate the effect
of delay and thereby determine the quality differences that
are due to the delay variations.
When the total delay does not exceed 100 milliseconds,
the E-model indicates that there is no degradation at all
due to the delay. This case is the relevant case for most
VoIP systems since designers try to make the delays low
enough to eliminate or at least minimize the effects of de-
lays. The delay degradations remain insigniﬁcant until the
overall delay reaches a level of about 200 milliseconds, and
the degradation grows as the delay approaches the talker-
overlap threshold of 250 milliseconds. The worst case oc-
curs when an added delay of 20 or 40 milliseconds above
the base delay pushes the total delay beyond the talker-
overlap threshold, in which case the MOS rating degrades

49
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
G.729
(20ms)
G.729
(40ms)
G.729 D
(40ms)
0
10
20
30
40
% Average Loss Per Flow
Figure 7. Loss-analysis case study
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
0
50
100 150 200 250 300 350 400 450 500
Base One-Way Absolute Delay, Ta (ms)
Additional Delay Impairment
(R Factor of E-Model)
Ta + 20ms
Ta + 40ms
Figure 8. E-model evaluation of delay impairment
by approximately 0.1 for an added delay of 20 millisec-
onds or by 0.2 for an added delay of 40 milliseconds. This
worst-case situation is not important for practical applica-
tions, though, because any system that is close to the talker-
overlap threshold is already a marginal system for VoIP.
Fig. 8 illustrates the added delay impairment — in units
of the R-factor of the E-Model — that results from the in-
troduction of delay increases of 20 milliseconds and 40 mil-
liseconds. Based on the E-model, the increase of 20 mil-
liseconds in the delay in the audio stream typically has zero
impairment to at most 2.5 units of R-factor — about 0.1 in
Mean Opinion Score (MOS) — of impairment in the QoS.
In our research on packet loss in a real network, we eval-
uated the MOS ratings of G.729 streams transmitting at a
20-millisecond interval in a simulated real-network envi-
ronment. Our study showed that a difference of 30% (e.g.,
from 10% to 40%) in the loss of audio data translates to a
difference in QoS impairment of more than one full unit on
the MOS scale [19]. Fig. 9 illustrates the MOS ratings of a
G.729 stream with various degrees of packet loss in a real
network.
Our results show that adding a small delay to reduce
packet loss is clearly a good tradeoff. The QoS degradation
from the added delay is typically zero or at most minus-
cule while the resulting QoS improvement from the reduced
packed loss is signiﬁcant.
7. Conclusion
Congestion control and congestion avoidance are pop-
ular research topics, so investigators have done consider-
able work in these areas. However, most of the well-known
congestion-avoidance techniques exploit the transmission-
control mechanism in TCP. Therefore, these approaches are

50
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
2.0
2.2
2.4
2.6
2.8
3.0
3.2
3.4
3.6
3.8
4.0
0%
10%
20%
30%
Network Packet Loss (%)
MOS Rating
Figure 9. MOS ratings with packet loss
not effective for real-time IP applications, which typically
use UDP as the transport protocol. The intrinsic character-
istics of real-time media applications pose additional inher-
ent problems to the already-challenging congestion-control
issue.
Our new technique for congestion detection and adap-
tive transmission control for real-time IP applications such
as VoIP is an application-level approach. For that reason,
we can implement our solution on the current infrastructure
using existing protocols. Our method requires only simple
upgrades to the implementations of the transmitting and re-
ceiving endpoints. As the network becomes congested, the
communicating endpoints using our method reduce band-
width utilization to adapt to the congested environment.
When the congestion subsides, the endpoints adapt to the
improvement in the trafﬁc condition and return to their orig-
inal transmission settings.
Since our method is an application-level approach that
runs on the endpoints, the implementation is fully scalable
with respect to the size of the network and the number of
ﬂows. Each endpoint performs a simple task that demands
very little in terms of processing power or memory. To-
gether, all of the endpoints in the system cooperate to alle-
viate the problems that congestion poses for real-time ap-
plications such as VoIP.
In contrast to existing congestion-avoidance techniques,
which simply identify and impose heavy penalties on un-
responsive real-time ﬂows, our technique cooperatively
lessens the bandwidth consumption of these ﬂows by lower-
ing their transmission rates. As a result, real-time IP appli-
cations that use our approach experience fewer lost packets
and achieve higher QoS.
References
[1] S. Floyd and V. Jacobson, “Random Early Detec-
tion Gateways for Congestion Avoidance,” IEEE/ACM
Transactions on Networking, Vol. 1, No. 4, August
1993, pp. 397–413.
[2] Wu-Chang Feng, Dilip D. Kandlur, Debanjan Saha,
and Kang G. Shin, “A Self-Conﬁguring RED Gate-
way,” Proc. IEEE Conference on Computer Commu-
nications, INFOCOM 1999, New York, New York,
March 1999, pp. 1320–1328.
[3] Eric Horlait and Nicolas Rouhana, “Dynamic Conges-
tion Avoidance Using Multi-Agent Systems,” Proc.
Mobile Agents For Telecommunication Applications,
MATA 2001, Montr´eal, Canada, August 2001, pp. 1–
10.
[4] Dong Lin and Robert Morris, “Dynamics of Random
Early Detection,” Proc. ACM Conference on Applica-
tions, Technologies, Architectures, and Protocols for
Computer Communication, SIGCOMM 1997, Cannes,
France, September 1997, pp. 127–137.
[5] T. Ott, T. Lakshman, and L. Wong, “SRED: Stabilized
RED,” Proc. IEEE Conference on Computer Commu-
nications, INFOCOM 1999, New York, New York,
March 1999, pp. 1346–1355.
[6] Wu-Chang Feng, K. Shin, D. Kandlur, and D. Saha,
“The BLUE Active Queue Management Algorithms,”
IEEE/ACM Transactions on Networking, Vol. 10, No.
4, August 2002, pp. 513–528.

51
International Journal On Advances in Networks and Services, vol 1 no 1, year 2008, http://www.iariajournals.org/networks_and_services/
[7] Wu-Chang Feng, Dilip D. Kandlur, Debanjan Saha,
and Kang G. Shin,
“Stochastic Fair BLUE: A
Queue Management Algorithm for Enforcing Fair-
ness,” Proc. IEEE Conference on Computer Commu-
nications, INFOCOM 2001, Anchorage, Alaska, April
2001, pp. 1520–1529.
[8] Wu-Chun Feng, Apu Kapadia, and Sunil Thulasi-
dasan, “GREEN: Proactive Queue Management over
a Best-Effort Network,” IEEE Global Telecommuni-
cations, GLOBECOM 2002, Vol. 21, No. 1, November
2002, pp. 1784–1788.
[9] IETF RFC-2481, A Proposal to Add Explicit Conges-
tion Notiﬁcation (ECN) to IP, January 1999.
[10] M. May, J. Bolot, C. Diot, and B. Lyles, “Reasons
Not to Deploy RED,” Proc. International Workshop
on Quality of Service, IWQoS 1999, London, UK, June
1999, pp. 260–262.
[11] Vishal Misra, Wei-Bo Gong, and Donald Towsley,
“Fluid-Based Analysis of a Network of AQM Routers
Supporting TCP Flows with an Application to RED,”
Proc. ACM Conference on Applications, Technologies,
Architectures, and Protocols for Computer Communi-
cation, SIGCOMM 2000, Stockholm, Sweden, August
2000, pp. 151–160.
[12] M. Mathis, J. Semke, J. Mahdavi, and T. Ott, “The
Macroscopic Behavior of the TCP Congestion Avoid-
ance Algorithm,” ACM Computer Communication Re-
view, Vol. 27, No. 3, July 1997, pp. 67–82.
[13] IETF Internet draft,
Pre-Congestion Notiﬁcation
(PCN) Architecture, October 2008.
[14] S. Bangolae, A. Jayasumana, and V. Chandrasekar,
“TCP-Friendly Congestion Control Mechanism for a
UDP-Based High-Speed Radar Application and Char-
acterization of Fairness,” Proc. IEEE Communication
Systems, ICCS 2002, Singapore, November 2002, pp.
164–168.
[15] P. Maryni and F. Davoli, “Load Estimation and Con-
trol in Best-Effort Network Domains,” Journal of Net-
work and Systems Management, Volume 8, Issue 4,
December 2000, pp. 527–541.
[16] T. Chua and D. Pheanis, “Application-Level Adaptive
Congestion Detection and Control for VoIP,” Proc.
IARIA International Conference on Networking and
Services, ICNS 2007, Athens, Greece, June 2007, pp.
84–89.
[17] ITU-T Recommendation G.729, Coding of Speech at
8 kbit/s Using Conjugate-Structure Algebraic-Code-
Excited Linear-Prediction (CS-ACELP), March 1996.
[18] ETSI GSM 06.90, Digital Cellular Telecommunica-
tions System (Phase 2+); Adaptive Multi-Rate (AMR)
Speech Transcoding, 1998.
[19] T. Chua and D. Pheanis, “QoS Evaluation of Sender-
Based Loss-Recovery Techniques for VoIP,” IEEE
Network, Vol. 20, No. 6, November/December 2006,
pp. 14–22.

