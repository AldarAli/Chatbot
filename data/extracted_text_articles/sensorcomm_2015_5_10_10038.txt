Classification of Human Interactions with Tools Using a Tool-Mounted Wireless
Sensor Node to Support Sustainable Manufacturing
Andreas Tilhein, The Duy Nguyen, Jörg Krüger
Institute for Machine Tools and Factory Management,
Technische Universitaet Berlin
Berlin, Germany
e-mail: theduy.nguyen@iwf.tu-berlin.de
Eduard Wagner, Stephan Benecke, Klaus-Dieter Lang
Research Center for Microperipheric Technologies,
Technische Universitaet Berlin
Berlin, Germany
e-mail: eduard.wagner@win.tu-berlin.de
Abstract—In this contribution, a customized wireless sensor
node with onboard acceleration sensor is applied to support
optical
motion
analysis
systems.
An
integrated
signal
processing algorithm to classify interactions between user and
tool is developed for the specific use case of a cordless
screwdriver. Results of the first demonstrator evaluation are
discussed with respect to further development of the sensor
architecture for smart tools.
Keywords-Human-centered automation; smart tools; wireless
sensors; sustainable manufacturing
I.
INTRODUCTION
Despite
many
efforts
to
automatize
manufacturing
processes, the human worker is still an essential element in
the production line. Humans possess unique skills which
recently no robot or machine tool can imitate. Especially
when it comes to flexible production, such as in mass
customization, employing machines becomes extremely
costly due to the need to frequently reconfigure the
equipment. On the other hand, qualification and education
are essential in order to have flexible workers. Especially
industrialized countries with an ageing workforce fear the
loss of know-how due to the expected retirements of many
experienced workers in the next years. This leaves a lack of
staff able to teach the inexperienced beginner. Instead of
compensating
this
loss
with
simple
technological
substitution, systems of human centered automation solve
the problem by automatically supporting workers in their
tasks. These systems enhance the workers’ skills, e.g., by
amplifying the force or intuitively teach them.
As a core component of these aids, an intelligent sensor
system is introduced which is able to provide sufficient
information to recognize the actions of the human in order to
react appropriately, e.g., by activating actuators or notifying
the user. Optical systems suit most of these tasks due to their
non-invasive operation principle making bulky equipment to
wear obsolete. However, when interacting with objects, e.g.,
tools, the detection becomes hard due to high variance in
appearance and occluded view. Hence, it is proposed to add
an additional three-axial acceleration sensor directly at the
objects to support the optical systems.
As a dedicated use case for the setup, a teaching system
is chosen, which interactively provides the user with
information about the currently conducted assembly task.
The sensor information provided here is used to identify the
current work step, sequence and proper execution in order to
provide the user with feedback. On the basis of the results
achieved with the prototypical setup, further developments of
wireless sensors are discussed with respect to the defined
use-case.
II.
RELATED WORK
Past work has focused on gesture recognition or object
interactions involving the use of either a complex system of
acceleration sensors in combination with RFID sensors
[1][2], a microphone [3][4], a gyroscope and a magnetic field
[5] or a force sensor [6]. Multi-sensor approaches have been
shown to improve recognition performance [7], however,
they require more equipment.
Normally accelerometers have been attached to a part of
the body or the object whose movement is considered as
characteristic for the activity performed [8]. Only the authors
in [9] have a tool mounted accelerometer. More commonly
used was a wrist worn sensor [1][3][4]. However, a
significant disadvantage of attaching the sensors to the body
is that, depending on their size and weight, they can
noticeably limit the freedom of movement.
As diverse as these sensor combinations, a variety of
algorithms have been implemented to detect movement
patterns. A variety of approaches to obtain characteristics of
the acceleration data for classification have been employed.
One option to extract features from the acceleration signal
involves their direct derivation from the time domain of the
signal. This includes common statistic techniques, such as
simple
integration
methods,
mean,
standard
deviation,
skewness, kurtosis, and eccentricity. Furthermore, some
researchers have analyzed the signal's frequency spectrum to
identify the dominant frequencies. A more recent approach is
the wavelet analysis [8]. Here, the original signal is
decomposed into a series of coefficients, which contain
spectral and temporal information about the original signal.
Based on these coefficients, temporal instances with a
change in the frequency response of the original signal can
be identified [10]. Several researchers have shown that the
extraction of features from the time domain of the signal
allowed classification performances partly >90% [8][11].
Moreover, since for low sampling frequencies, the detection
of time dominant features is superior to the detection of
91
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

frequency dominant features [12], we follow a time domain
approach.
For the most human activities, hand movements are
significant. Yet recognizing the relevant ones in a continuous
data stream is difficult. One reason is the hand's high degree
of freedom: the same gesture can be performed in different
ways. In addition, hands are the most active parts of the
body, being constantly in motion even without containing
relevant information [3].
Since
optical
sensors
have
their
problems
with
classifying fast movements [7] and since they are susceptible
to obstruction [4], realizing such a recognition component
only with vision based methods is difficult. Especially in a
workshop, the distinction between man and tool for the
detection of human interactions with tools is problematic.
The implementation of micro system technology (MST)
for the described tasks of sensing allows for innovative
approaches with respect to the described application. The
inclusion
of
sensor
interface,
data
processing,
radio
frequency communication and autonomous power supply
enables numerous tasks that can be added to the already
existing functionalities. Moreover, the high miniaturization
potential of MST solutions supports applications that require
minimum system size and –weight for least interference with
the subordinate technical system and already existing
periphery. Small distributed systems are mainly applied for
the process monitoring of production equipment [13], but
also logistics support with electronic functions beyond RFID
identification are a growing sector. Benefits on sustainability
from employing an increased number of micro system
technology in industrial environments such as manufacturing
are currently addressed
within the framework of the
Collaborative Research Center (CRC) 1026, e.g., [14]. A
broader look at the trade-off between benefits and impacts of
the additional micro systems as well as the inclusion of
teaching tools into sustainability assessment will be part of
the ongoing research within CRC1026.
III.
CONDUCTION OF THE STUDY
As physical instantiation of the demonstrator, a three-
axial acceleration sensor with
wireless communication
capabilities was attached to a hand-held drilling machine
(Fig.1).
Figure 1.
Sensor module attached to drilling machine (right). Pathway of
processing the sensor-data till final decision (left).
Five typical drilling activities were examined:
•
Picking up the drilling machine from a work table,
•
putting down the drilling machine on a work table,
•
successively rotating the drilling machine in the
sagittal and frontal plane by 90°,
•
switching on the drilling machine without contacting
the work piece,
•
and
switching
on
the
drilling
machine
with
contacting the work piece.
In
order
to
develop
algorithms
that
allow
the
identification of movement/acceleration patterns, the referred
activities were recorded five times with short interruptions
between each measurement followed by five continuous
measurements in a row.
IV.
SENSOR HARDWARE AND DATA AQUISITION
The proposed first generation of a sensor node (Tab. II
top) is based on open source hard- and software using
Arduino UNO R3 board with ATmega328 microcontroller, a
customized
acceleration
sensor
layer
(ADXL326)
and
integrated
Bluetooth
communication
interface
(BLUETOOTH-SHIELD V2.2). With this setup, wireless
communication
with
a
central
personal
computer
is
established to transmit all acceleration data required for the
classification of human interactions. Through a micro-USB
port the Arduino-microcontroller is programmed using
customized
firmware,
covering
all
data
assessment
(temperature, 3-axes acceleration), ID of the node and the
communication with the Bluetooth interface. Due to the
universal functionality of soft- and hardware of the sensor,
energy demand is still comparatively high with approx.
110mW in active mode when operating continuously. The
applied
hardware
can
therefore
be
considered
as
a
demonstrator on primary stage for the evaluation of the
described scenario of a MST equipped drilling machine. The
measurement routine applied is described in the following
sections.
V.
PRE-PROCESSING
In this section, the pre-processing of the raw data stream
is briefly explained. The raw sensor data which is mean
adjusted and smoothed. Since the size of the sliding window
affects the accuracy and delay of classification, it should be
adapted to the characteristic duration of the activities of
interest [4]. In order to identify the time intensive activities
like picking up or putting down the drilling machine, as well
as moments of rest properly, a sliding window with two
window sizes of 0.6 s and 1.2 s and a minimal overlap of 1/fs
is chosen. With the objective to limit the dynamic range of
the acceleration signal to a comparable interval and to
implement a state-independent classification, it is essential to
align the basic level of acceleration for different machine
states on a uniform level. This is realized by a mean
adjustment with a signal's outcoming arithmetic mean of
zero. The acceleration signal is affected by short frequency
signal changes. In order to ensure a reliable detection of
92
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

individual activities, signal smoothing is indispensable. For
this purpose, a moving average filter has been chosen as it
allows efficient computation and quick responses to changes
in the amplitude [13]. Despite its simplicity, the moving
average filter is optimal for reducing random noise while
retaining a sharp step response. On the downside, it allows
inacceptable frequency separation [16]. The size of the
window in the averaging process has been chosen according
to the recommendations in [13]. For fast movements, the
recommended time frame ranges from 25 ms to 50 ms, for
slow movements, time frames from 100 ms to 200 ms are
recommended. Since the activities considered in this work
include both – fast and slow movement patterns, an
empirical based time frame of 160 ms has been chosen.
VI.
FEATURE EXTRACTION
While the selection of features is a critical task for a good
recognition performance [4], this paper does not focus on the
search for the best possible features. Rather, the goal is to
develop
an
algorithm
which
leads
to
an
acceptable
recognition performance for the underlying problem using
low computational effort. One of the main challenges of the
pattern recognition task is to distinguish between relevant
and non-relevant activities [4]. Characteristic features which
allow such discrimination are essential for the classification
task. Irrelevant data should be discarded at the same time
[17][18]. To do so, the short window activity is quantified by
the empirical activity measure (Act) described in [19]. The
faster
the
movement,
the
greater
the
change
in
the
acceleration signal is. Act uses these changes of the
acceleration
vector
to
detect
the
sensor's
movement
represented by a single indicator. While in a static state of
approximately zero, the empirical activity of the sensor
increases when the sensor is moved. By combining the
acceleration of all sensor axes to create one single indicator,
movements and non-movements can be distinguished, even
if the acceleration changes along one axis. If Act does not
meet an empirically determined threshold, the window is
classified
as
non-relevant.
Otherwise,
the
activity
is
considered relevant and will be examined more in detail.
The goal of implementing a minimum activity criterion is
to separate relevant from random, non-relevant information
of the acceleration signal. But separation turned out to be
difficult, since many diverse movements of the drilling
machine exceed the minimum activity threshold, although
this information is non-relevant. A comparison of the
empirical activity measures of high-frequency and low-
frequency ranges of the acceleration signal turned out to be
the solution to this problem. It utilizes the circumstance that
human movements are characterized by low frequencies [8],
fast machine movements by high frequencies. The separation
of high and low frequency signal components is carried out
by computing the deviation between the smoothed and the
original signal.
A.
Picking up/ Putting down
If, at the beginning of a machining sequence, the machine
is in an upright position, the smoothed vertical component of
the acceleration signal is checked for a characteristic pattern
for picking the drilling machine up (Fig. 2). A simple
template matching algorithm consisting of a successively
scaled sine-function-section turned out to be sufficient for
detecting the picking up. As comparison criteria, the
maximum and the mean absolute deviation between the
smoothed signal and the sine-function are used. For not
having to apply the procedure to each data-point within the
considered window, the moving standard deviation of the
vertical signal component is examined for whether it exceeds
a sequence of empirical thresholds. If the picking up of the
drilling machine has already been recognized and if the
machine is in an upright position, a template matching
algorithm is carried out to recognize whether the drilling
machine is put down. Except a customized template, this
procedure corresponds to that of picking the drilling machine
up.
Figure 2.
Example signals for activity ‘Picking up’ (top) and ‘Putting
down’ (bottom).
B.
Rotating the drilling machine
To determine whether the drilling machine was rotated in
the sagittal or frontal plane, the mean acceleration along all
sensor axes in a short time window were calculated and
compared with their previous results. If there was an
acceleration change of at least ± 0.5 g, activities in the
current window were classified as rotating the drilling
machine.
Figure 3.
Example signal for activity ‘Rotate’.
93
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

C.
Switching on the drilling machine
If the previously described activities have not been
recognized, the signal is analyzed for patterns of drilling
movements. The distinction between switching the drilling
machine on with and without contact to the work piece is
decided via the sensor's horizontal acceleration (Fig. 3). If
the drilling machine is switched on with contact to the work
piece, low-frequency resonances at high amplitudes along
the horizontal axis are observed. This discrepancy is
quantified by the empirical activity measure, isolated applied
on the horizontal axis.
Figure 4.
Example signals for activity ‘Switch on without contact’ (left)
and ‘Switch on with contact’ (right).
VII.
CLASSIFICATION AND POST PROCESSING
Although there are a number of classifiers for pattern
recognition, to make the classification as understandable and
as easily extendable as possible, a simple decision tree has
been chosen for classification. A simple decision tree allows
a classification of user activities in real time [20] and
provides,
in
terms
of
movement
detection,
a
good
compromise
between
accuracy
and
computation
time
[21][1].
In the first step, the current window of the acceleration
signal is analyzed for patterns indicating ‘rotation of the
drilling machine’. This action can potentially generate an
empirical activity higher or less the minimum empirical
activity. If this is not the case, there is no relevant
information in the observed window. If it exceeds, the
drilling machine's position in relation to the vertical axis is
identified. If the drilling machine has not yet been picked up
from the worktable, the current window is analyzed for
typical acceleration patterns for picking up the drilling
machine.
In the next step, if the direction of gravitational force is in
alignment with the vertical axis and if the drilling machine is
already picked up from the working table, the current
window is analyzed for patterns of putting the machine
down. With sufficient match, the section is assigned
accordingly. If there is no match, a comparison of the
empirical activity measures of the high- and low-frequency
ranges of the acceleration signal is carried out to determine
whether there was movement in the window or the drilling
machine has been switched on. In a predominance of the
high-frequency activity, there is, depending on the empirical
activity of the horizontal axis, a switched on drilling machine
with or without contacting the work piece in the observed
window.
A subsequent post-processing of the classification results
on the basis of empiricism and context knowledge has been
indispensable. For this purpose, the classification results of a
series of multiple windows are linked adequately to a unitary
class.
A.
False positive detection of putting down
The false positive detection of putting down the drilling
machine is based on the assumption that it indicates the end
of a machining process. After that there should be no action
until the machine is picked up again. If a signal section has
been wrongly assigned to ‘putting down’, and within a
certain time period another empirical minimum activity
threshold exceeding acceleration has taken place, the false-
positive
detection
corrects
the
wrong
‘putting
down’
classification result to ‘movement’. The threshold is based
on the obtained training data and has been determined by the
empirical activity that delimits the hand held from the down
put drilling machine. The reason for the wrong assignment is
the similarity of the acceleration pattern of ‘movement’ and
‘putting down’.
B.
False negative detection of putting down
Depending on the user and surface, there is a large
variety of corresponding acceleration patterns for ‘putting
down’ movement of the tool. Since a correct assignment of
these patterns is difficult with the developed algorithm, it is
necessary to correct the classification result in case the
‘putting down’ of the drilling machine has not been
recognized. Similarly to the false positive detection, the false
negative detection is based on the assumption that ‘putting
down’ indicates the end of a machining process, with no
subsequent changes in the acceleration signal. Hence, if
‘putting down’ has not been detected, and if the empirical
activity is not exceeding the threshold mentioned before for
several time windows, the prior detected activity must have
been ‘putting down’.
C.
Minimum length for drilling
To avoid a false recognition of ‘rotating the drilling
machine’ instead of ‘drilling’, an empirical based minimum
duration for drilling is used.
D.
Putting down priority and majority rule
Due to the similarity of the characteristics occurring
during ‘putting down’ with those of moving or switching the
drilling machine on, short sequences of nearby windows
occur in which an assigned ‘putting down’ is confused with
another activity. In such cases, the putting down priority
assigns ‘putting down’ to the entire window sequence. In
sequences of nearby windows with different assignments to
‘movement’ or ‘switching’ the drilling machine with or
without work piece contact, the majority rule assigns the
entire sequence to the activity most frequently encountered
in the sequence.
94
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

VIII.
EVALUATION
The performance of the classification algorithm has been
evaluated by determining classification accuracy (percentage
of correctly classified test data). Test data from three male
and one female operator have been analyzed. Three operators
are
right-handed.
One
is
left-handed.
Each
canditate
performed a predetermined sequence of following activities:
•
picking up the drilling machine from a work table,
•
four times of switching the drilling machine on
without contacting the workpiece, each in a varied
state,
•
four times of switching the drilling machine on with
contacting the workpiece, each in a varied state,
•
putting down the drilling machine on a work table.
Tab. I shows the recognition results in an aggregated
confusion matrix. For a sampling frequency of 82 Hz with an
overall performance of 96 %, 100 % recognition accuracy
has been achieved for ‘picking up’, ‘putting down’ and
‘rotating’.
Since
all
these
activities
have
similar
characteristics, the only confusion was at distinguishing
‘switching the drilling machine on’ and ‘with or without
contact to the work piece’. However, accuracies of 89% and
91% respectively could still be achieved.
TABLE I.
RECONGNITION ACCURACY OF THE IMPLEMENTED
ALGORITHM FOR SELECTED MOVEMENTS
Picking up
Rotating
Switching on
(no contact)
Switching on
(contact)
Putting down
Movement
Total
Class
Accuracy (%)
40
0
0
0
0
0
40
Picking up
100,00
0
400
0
0
0
0
400
Rotating
100,00
0
0
145
7
1
7
160
Switching
on
(no
contact)
90,63
0
0
13
143
0
4
160
Switching
on
(contact)
89,38
0
0
0
0
40
0
40
Putting
down
100,00
40
400
158
150
41
11
800
Total
96,00
Recognition accuracy was then evaluated for different
sampling frequencies between 1 Hz to 82 Hz. It could be
shown, that for sampling rates below 12 Hz recognition of
movement patterns was not successful (Fig. 4).
Figure 5.
Recognition of movement patterns
However, when sampling rates increase above 12 Hz,
movements of ‘putting down’ and ‘rotating’ have been
correctly assigned with an accuracy larger than 93 % for
‘picking up’ - Since the high frequency ranges of the
acceleration signal gets lost with a decreasing sampling rate
[12], the recognition performance for switching the drilling
machine on with or without work piece-contact decreases. At
lower sampling rates these have been wrongly identified as
simple ‘movements’.
IX.
CONCLUSION AND OUTLOOK
In this paper, an algorithm for the identification of
acceleration patterns occurring during human interactions
with
drilling
machines
has
been
presented.
Five
characteristic drilling activities have been examined in a
mock up workshop scenario. Data have been gathered from a
single tool-mounted three axis acceleration sensor.
With
a
suitable
combination
of
techniques
of
preprocessing of the acceleration signal, feature extraction
from the time domain of the signal, classification and post-
processing,
high
classification
accuracies
have
been
achieved. At a sampling frequency of 82 Hz, the algorithm
performs with an overall accuracy of 96 %, with an accuracy
of 100 % for picking up; putting down and rotating the
drilling machine. For patterns such as ‘putting down’ even
further opportunities arise with respect to the realization of
low-power sensor systems with reduced sampling rates.
The
presented
sensor
functionalities
are
currently
implemented in advanced MST setups focusing on size
reduction and minimized power demand (Tab. II).
95
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

TABLE II.
FURTHER GENERATIONS OF MST STRUCTRES REDUCING
SIZE AND POWER DEMAND
V1 - Arduino based sensor node with custom layers
Purpose:
Functional
demonstrator
for
further
specification of MT requirements
Function:
Low
resolution
temperature
sensing,
acceleration, ID, communication (Bluetooth)
Technology:
Commercial
sensor
platform,
customised sensor layers
Power
consump.:
110mW
in
active
mode;
continuous operation
V2 – Custom sensor node with optimized circuitry
Purpose: Evaluation of design approach, debugging,
circuitry optimization
Function:
Precision
temperature
sensing,
3D
acceleration, orientation (compass), identification,
optical
indication
of
active
status,
RF-
communication (2,4GHz IEEE 802.15.4)
Technology:
PCB,
4-Layer,
one-sided
SMD
assembly
Power consump.: 58mW in active mode, 30µW in
advanced deep sleep mode; Net power consumption
100µW-500µW depending on duty cycle
V3 – Mini. sensor using advanced packaging tech.
Purpose: Demo. of miniaturisation potentials
Technology: Size-optimized routing; embedded
active and passive devices, bare-Die assembly
Function & Power consump.: as V2
ACKNOWLEDGMENTS
This
work
was
funded
by
the
Deutsche
Forschungsgemeinschaft
(German
Research
Foundation)
within the Collaborative Research Centre (SFB) 1026.
REFERENCES
[1]
T. Gu, S. Chen, X. Tao, J. Lu, “An Unsupervised Approach to
Activity
Recognition
and
Segmentation
based
on
Object-Use
Fingerprints”, Data and Knowledge Engineering 69 (2010), pp. 533 -
544.
[2]
P. Lukowicz, A. Timm-Giel, M. Lawo, O. Herzog, “Toward Real-
World Industrial Wearable Computing”, IEEE Pervasive Computing
6, 4, 2007, pp. 8 - 13.
[3]
J. A. Ward, P. Lukowicz, G. Tröster, “Gesture Spotting Using Wrist
Worn Microphone and 3-Axis Accelerometer”, In: Proceedings of the
2005 Joint Conference on Smart Objects and Ambient Intelligence:
Innovative Context-Aware Services: Usages
and
Technologies,
Grenoble, 12.10. - 14.10.2005.
[4]
J. A. Ward, P. Lukowicz, G. Tröster and T. E. Starner, Activity
Recognition of Assembly Tasks Using Body-Worn Microphones and
Accelerometers. IEEE Transaction on Pattern Analysis and Machine
Intelligence 28, 10, 2006, pp. 1553 - 1567.
[5]
T. Stiefmeier, et al., “Event-Based Activity Tracking in Work
Environments”, In: IFAWC - 3rd International Forum on Applied
Wearable Computing 2006. Hrsg.: Ottein, H. Berlin, Offenbach:
VDE, 2006, pp. 1 - 10.
[6]
V. Stanford, “Wearable Computing Goes Live in Industry”, IEEE
Pervasive Computing 1, 4, 2002, pp. 14 - 19.
[7]
S. Zhou, et al., “2D Human Gesture Tracking and Recognition by the
Fusion of MEMS Inertial and Vision Sensor”, IEEE Sensors Journal
14 (2014) 4, pp. 1160 - 1170.
[8]
A. Godfrey, R. Conway, D. Meagher, G. ÒLaighin, “Direct
Measurement of Human Movement by Accelerometry”, Medical
Engineering and Physics 30, 2008, pp. 1364 - 1386.
[9]
B. Hartmann, C. Schauer, N. Link, “Worker Behavior Interpretation
for Flexible Production. World Academy of Science”, Engineering
and Technology 3, 2009, pp. 494 - 502.
[10] S. Mallat and W. L. Hwang, “Singularity Detection and Processing
with Wavelets”, IEEE Transactions on Information Theory 38, 2,
1992, pp. 617 - 643.
[11] P. Pirttikangas, K. Fujinami, T. Nakajima, “Feature Selection and
Activity Recognition
from
Wearable Sensors”,
In: Ubiquitous
Computing Systems - Third International Symposium. Hrsg.: Youn,
H. Y.; Kim, M.; Morikawa, H. Berlin, London: Springer, 2006, pp.
516 - 527.
[12] A. Krause, et al., “Trading off Prediction Accuracy and Power
Consumption
for
Context-Aware
Wearable
Computing”,
In:
Proceedings of the Ninth IEEE International Symposium on Wearable
Computers, Los Alamitos, 18.10. - 21.10.2005.
[13] M. Yamaji, Y. Ishii, T. Shimamura, S. Yamamoto, “Wireless Sensor
Network for Industrial Automation”, Ubiquitous Field Computing
Research Center Yokogawa Electric Corporation, Tokyo, 2008.
[14] K.-D. Lang, et al., “Development of microsystem enhanced machine
tool structures for lightweight and accuracy optimised (LEG²O)
frames”,
TU-Berlin,
Research
Center
for
Microperipheric
Technologies, 2014.
[15] N. Popovic, “Modellbasierte Erfassung der dreidimensionalen Kinetik
der Bewegungen der oberen Extremitäten”, Aachen, Diss., 2012.
URL:
http://darwin.bth.rwth-
aachen.de/opus3/volltexte/2013/4553/pdf/4553.pdf (last access: 2015-
06-25).
[16] S. W. Smith, “The Scientist and Engineer's Guide to Digital Signal
Processing”, San Diego: California Technical Publishing, 1997.
[17] R. O. Duda, P. E. Hart, D. G. Stork, “Pattern Classification”,
Weinheim: Wiley, 200.1
[18] A. Kosmala, “HMM-basierte Online Handschriftenerkennung – Ein
integrierter Ansatz zur Text- und Formenerkennung”, Duisburg,
Diss.,
2000.
URL:
http://duepublico.uni-duisburg-
essen.de/servlets/DerivateServlet/Derivate-5152/inhalt.htm
(last
access: 2014-06-25).
[19] A.
Volmer,
“Unterdrückung
von
Bewegungsartefakten
bim
Langzeitmonitoring
zur
Anwendung
in
Personal-Healthcare-
Systemen”,
Berlin,
Diss.,
2011.
URL:
opus4.kobv.de/opus4-
tuberlin/files/2765/volmer_achim.pdf
(last
access:
2015-06-25).
[20] Y.-H. Hong, I.-J. Kim, S. C. Ahn, H.-G. Kim, “Mobile Health
Monitoring
System
Based
on
Activity
Recognition
Using
Accelerometer”, Simulation Modelling Practice and Theory 18, 2010,
pp. 446 - 455.
[21] J. Baek, G. Lee, W. Park, B.-J. Yun, “Accelerometer Signal
Processing for User Activity Detection”, In: Knowledge-Based
Intelligent Information and Engineering Systems. 8th International
Conference. Hrsg.: Negoita, M. G. et al. Berlin, London: Springer,
2004, pp. 610 - 617.
[22] U. Maurer, A. Smailagic, D. P. Siewiorek, M. Disher, “Activity
Recognition and Monitoring Using Multiple Sensors on Different
Body Positions”, In: Proceedings of the International Workshop on
Wearable and Implantable Body Sensor Networks. IEEE Computer
Society, Washington, 03.04. - 05.04.2006
96
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

