Usability of An Immersive Authoring Tool: An Experimental Study for the 
Scenarization of Interactive Panoramic Videos 
Daniel Xuan Hien Mai, Guillaume Loup, Jean-Yves Didier 
IBISC Lab 
Univ Evry, Université Paris Saclay 
Evry, France 
e-mail: danielxuanhien.mai@univ-evry.fr, guillaume.loup@univ-evry.fr, jeanyves.didier@univ-evry.fr 
 
 
Abstract— The need for remote education and reduced 
learning costs has led to rapid development of virtual 
immersive learning environments. However, creating these 
environments using authoring tools still requires trainers to 
have a range of technical skills. Recently, a new approach has 
been developed that allows trainers to construct educational 
scenarios using panoramic video-based immersive authoring 
tools. This approach demands fewer technical skills compared 
to the modeling of 3D environments. To evaluate the usability 
of the Human-Computer Interaction (HCI) of this approach 
between two different types of interfaces, our experimental 
study was conducted. This study compared a Virtual Reality 
(VR) interface, which consists of a Head-Mounted Display 
(HMD) and its controllers, to a traditional Windows, Icons, 
Menus, Pointer (WIMP) interface in creating interactive 
scenarios. Both quantitative and qualitative measures were 
collected and later quantified to evaluate effectiveness, 
efficiency, user satisfaction, and motivation towards the 
interfaces. The results of the study showed that: (1) there was a 
better correlation between the trajectories of 3D objects 
positioned by the user (in this study, the trainer) and the 
entities targeted in the panoramic video using an immersive 
interface; (2) there was a significant difference in task 
execution time between the VR interface and the traditional 
WIMP interface; (3) trainers had greater satisfaction and 
motivation towards the VR interface compared to the 
traditional 
WIMP 
interface, 
despite 
symptoms 
of 
cybersickness. 
Keywords- panoramic videos; authoring tools; virtual reality; 
WIMP 
interface; 
immersive 
environments; 
interaction 
techniques. 
I. 
 INTRODUCTION 
Investment by major technology companies in recent 
years, and growing demand for immersive environments in 
the domains of entertainment, communication, and education 
have created a strong impetus for the development of Virtual 
Reality (VR). Additionally, new technological breakthroughs 
have made VR hardware devices, such as VR headsets and 
omnidirectional cameras more accessible to the public. 
However, the development of VR applications in general and 
immersive environments for human learning in particular 
still presents many challenges, both in terms of processes and 
production 
tools, 
requiring 
the 
participation 
of 
a 
multidisciplinary team ranging from designers, artists, 
programmers and so forth [1]. These tools often require 
trainers to have certain expert knowledge for effective use to 
achieve the desired results. 
Depending 
on 
the 
interaction 
needs, 
immersive 
environments will be designed differently, where each 
interaction scenario is a sequence of user interactions with 
the environment [2]. Therefore, interaction design methods 
and different forms of information representation will impact 
user experience as well as interaction outcome. Immersive 
environments based on panoramic videos are thus the 
proposed solution that simulates interactive scenarios close 
to the real environment, and enhances users' sense of 
presence when they use Head-Mounted Display (HMD) [3]. 
The panoramic video can be enriched by adding interactive 
elements such as text information, sounds, 2D/3D objects, as 
well as questions, in order to not only improve the user 
experience [4], but also integrate narrative and educational 
elements into the interactive scenarios. These additional 
elements require a particular structure tailored to the spatial 
and temporal dimensions of the panoramic video [5]. While 
2D video editing tools primarily focus on the temporal 
dimension, creating interactive panoramic videos requires a 
more comprehensive set of tools that handle both spatial and 
temporal dimensions. 
A suitable authoring tool will actively aid trainers in 
constructing the learning content [6]. New requirements for 
authoring tools for interactive scenarios based on panoramic 
videos have led to the concept of an exclusively immersive 
tool. Thanks to this approach, trainers, instead of using the 
traditional Windows, Icons, Menus, Pointer (WIMP) 
interface, can now use the VR interface to create and modify 
the content of the interactive scenario. This immersive 
environment will allow trainers to have learner-like access to 
quickly obtain a set of information and to self-assess the 
results of their work throughout the design process [7]. 
However, it remains to be determined whether the new 
interactive VR interface differs in terms of usability and user 
motivation compared to the traditional WIMP interface. To 
answer this question, our experiment was carried out to 
evaluate and compare the effectiveness and efficiency of 
trainer interactions with an authoring tool, based on a defined 
scenario, using both the traditional WIMP interface and the 
VR interface. The satisfaction and motivation of trainers 
towards the tool were assessed through questionnaires 
collected after the experiment. 
It is worth noting that conducting experiments on 
usability and motivation are important for evaluating the 
174
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

effectiveness of the tool and identifying any potential issues 
that may arise when using the tool in real-world scenarios. 
In Section II, we present a discussion of related work. 
Section III presents our research hypotheses. Section IV 
details the method, then Section V presents the results of the 
experiment. Our conclusions and future work are presented 
in sections VI and VII. The references close the article. 
II. 
BACKGROUND AND RELATED WORK 
A. Authoring tools and interactions with panoramic videos 
The interactive design that complements panoramic 
videos presents not only technical challenges (with respect to 
video asset management, video environment fidelity, and 
natural navigation) but also design challenges [8]. These 
issues include designing non-intrusive and non-distracting 
user interfaces, creating effective navigation and orientation 
mechanisms, and incorporating engaging elements into the 
design. 
In addition, the feeling of immersion can affect the 
difference in visual navigation effectiveness between the 
traditional WIMP and VR interfaces [9]. One of the main 
tasks of the designers is to overlay a 3D object upon the 
panoramic video. To ensure consistency between these two 
entities, a predetermined trajectory based on the timeline of 
the panoramic video [5] must be defined. This requires 
capturing the spatiotemporal motion of the designers, which 
allows them to specify the movements of the 3D object. 
For user interaction studies, in the absence of a specific 
classifier, the object of research is usually the end user or, in 
this context, the learner. Research work in the context of 
panoramic videos is most often devoted to the effect of 
motion parallax [10][11] the perception of content, as well as 
different methods of rendering and displaying panoramic 
videos and incorporating 3D entities to improve user 
experience [12]. 
Recently, several studies have been dedicated to 
designing panoramic video tools in VR, where users act as 
trainers. T. Adão et al. performed an experiment to evaluate 
the usability of a rapid prototyping tool [13] through tasks 
such as adding and removing 3D objects in space and time. 
Another experiment was carried out to evaluate the 
continuity of integrating video animations, 3D objects as 
well as 3D sounds [14] by utilizing non-complex interaction 
techniques. 
Pakkanen et al. proposed a comparison of three models 
of interaction techniques (remote control, pointing with head 
orientation, and hand gestures) in VR for controlling 
panoramic video playback [15]. The results of this study 
showed that the participants experienced a reduction in 
nausea on their second attempt. This suggests that 
cybersickness survey results may be influenced by 
participants' previous experience (working time) in the VR 
environment. Regarding the usability of the three types of 
interactions, the remote control was found to be more 
accurate and users liked it more than the other two types of 
interactions. 
The Fonseca & Kraus experiment [16] evaluated learners' 
attitudes and behaviors after watching panoramic videos in 
both VR and mobile platforms, making it one of the few 
studies that cover multiple platforms. The conclusion of this 
research mentioned a more positive emotional impact on the 
user when they viewed panoramic videos in a virtual reality 
environment compared to an equivalent environment on a 
tablet. The experiment did not assess participants' interactive 
behaviors, but only focused on behavioral analysis of 
perception after receiving narrative information. 
As a case study of panoramic video authoring tools, the 
research by Coelho & Melo [7] is remarkable when it comes 
to evaluating the usability of three different types of 
interfaces: WIMP, VR, and tangible. Results showed that 
participants' gender had no effect on dependent factors. 
Regarding the usability, the VR and tangible interfaces had a 
higher level of satisfaction than the WIMP interface. 
However, the WIMP interface had the lowest task execution 
time and the authors concluded that this was due to 
participants' greater familiarity with the keyboard and 
mouse. The effectiveness was not determined conclusively 
as the experimental procedure only took into account the 
number of performed errors, which was not statistically 
significant. 
These experiments have shown that running the same 
interaction technique on different types of environments or 
interfaces will have different usability results. The 
requirement for spatiotemporal coherence in interaction is a 
critical element of panoramic video-based immersive 
environments. It is thus necessary to compare the interaction 
technique specific to authoring tools on panoramic videos, 
between the traditional WIMP interface and the VR 
interface, through a new experimental study. 
B. The immersive authoring tool Wixar[17] 
To accurately compare the usability of two types of 
interfaces, the analysis and evaluation of interaction 
techniques must be performed on the same authoring tool to 
balance the workload between the two types of interfaces 
and ensure uniformity of statistical data. 
Most authoring tools support the WIMP interface, but a 
limited number support the VR interface [6]. In order to limit 
differences in statistical data of two different interfaces, we 
chose the Wixar authoring tool for our experiment. Wixar is 
a multi-platform authoring tool already on the market, 
offering a range of options for creating scripted content for 
interactive panoramic videos. It aims to empower trainers 
without programming skills to design immersive learning 
environments using panoramic videos. 
The selected interaction techniques for this experiment, 
including visual perception (head movement or camera 
rotation with keyboard buttons), navigation (joystick or 
mouse movement), and selection and manipulation, are 
commonly used in panoramic video contexts. 
Wixar offers both a PC version and a VR version with 
the same user interface (UI). The PC version uses a mouse 
for navigation instead of a joystick and keyboard buttons for 
rotation instead of head movement, making it a suitable 
comparison to the VR version. These standard human-
computer interfaces do not negatively affect the outcome of 
175
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

the experiment. The selected user interfaces (Figure 2) will 
not negatively impact the results of the experiment. 
Hence, Wixar is a suitable authoring tool for evaluating 
the usability of WIMP and VR interactive interfaces, as it 
satisfies the requirements and purpose of this experiment. 
III. 
RECHEARCH HYPOTHESIS 
Our first hypothesis (H1) is that the difference in 
navigation 
(viewpoint 
changing) 
and 
selection 
and 
manipulation (trajectory recording) actions during task 
execution between the VR and WIMP interfaces will lead to 
a difference in usability between them. In the context of this 
experiment, operations requiring spatiotemporal coordination 
of panoramic videos are supposed to have better accuracy 
and execution time in VR compared to WIMP. 
Our second hypothesis (H2) is that the use of a VR 
headset for the authoring tool will not significantly increase 
mental load or symptoms of cybersickness compared to a 
traditional WIMP interface. 
Our third hypothesis (H3) is that participants using the 
VR interface will exhibit higher motivation than those using 
the WIMP interface in this experiment. 
IV. 
METHOD 
A. Participants 
The participants in the experiment ranged in age from 20 
to 50 years old, with an average age of 30.7 years. Both 
groups, VR and WIMP, had 15 participants each and were 
evenly distributed in age. All participants had a good 
command of French, enabling them to comprehend 
information presented in the language and engage in 
conversations throughout the experiment. The informed 
consent form, which included details on withdrawal rights, 
confidentiality rights, benefits, and potential risks of the 
study, was understood by all participants. 
This study was approved by the Paris-Saclay research 
ethics committee and participants signed the consent form 
after being fully informed of the progress of the experiment. 
B. Wixar Authoring Tool 
We utilized Wixar version 1.4, which was released in 
July 2021, that offers both WIMP and VR interfaces. The 
main steps of using Wixar are outlined in Figure 1. The 
trainer's process of designing an application was divided into 
three phases: 1) Adding media resources, such as panoramic 
videos, audios, and 360 images, 2) Integrating and 
configuring the interaction techniques offered by Wixar, and 
3) Releasing a new immersive educational environment. 
 
Figure 1.  Wixar Operation Process 
In this experiment, different panoramic video scenes 
were provided and a preview of the scenario to be enacted 
was presented to the participant beforehand. 
C. Material 
Devices used in this experiment included: a laptop 
computer equipped with the Wixar 1.4 PC authoring tool; an 
Oculus Quest 2 headset equipped with the Wixar 1.4 VR 
authoring tool. To ensure hygiene, the equipment was 
thoroughly cleaned before each participant's session and 
participants were instructed to sanitize their hands and wear 
a respiratory protection mask throughout the entire 
procedure. 
D. Measurements 
Our team had developed an algorithm which was then 
integrated into Wixar 1.4 to gather quantitative data on user 
behavior during task performance. 
Questionnaires were used to collect demographic 
information (identified only by participant number) and data 
on cybersickness (SSQ [18], NASA-TLX [19]), satisfaction 
(SUS) [20], and motivation (SIMS) [21]. 
The obtained data was then analyzed to evaluate the 
usability of two different types of interfaces during 
participant interactions. Usability, as defined by ISO 9241-
11 [22], is “the extent to which a system, product or service 
can be used by specified users to achieve specified goals 
with effectiveness, efficiency and satisfaction in a specified 
context of use”. This definition highlights three criteria that 
must be considered during the construction of the experiment 
so that the results obtained can be analyzed with precision 
afterwards: (1) Effectiveness: accuracy and completeness 
with which users achieve specified goals (2) Efficiency: 
relationship between the results and the resources used to 
achieve them. (3) Satisfaction: comfort and subjective 
evaluation of user interaction. 
Specifically in this experiment, effectiveness was linked 
to the precision of the participant's manipulation, efficiency 
was measured by the time it took to perform tasks and 
finally, satisfaction was assessed through questionnaires. 
E. Scenarios & Procedure 
The participants were divided into two groups, each 
corresponding to a different interface (WIMP and VR). 
Participants were asked to position themselves in front of a 
PC or to wear an Oculus Quest 2 headset. After starting the 
Wixar 1.4 application, the participant faced 5 task sequences. 
The main tasks involved positioning and configuring a 
virtual object on a fish in a panoramic video by 
superimposing a virtual marker on the fish. The fish had 
different, increasingly complex trajectories step by step, such 
as linear movement, slight wave, underfoot, around space 
variable acceleration, and vertical movement (Figure 2). 
176
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

 
Figure 2.  Fish with different trajectories 
Following the 5 sequences, the participant was invited to 
complete the questionnaires. The total duration of each 
experiment was approximately 45 minutes. 
F. Quantitative data 
During the experiment, participant behavior data was 
automatically collected, including head movements, joystick 
or mouse movements, the operations concerning the creation, 
deletion and movement of objects, and the recording of 
movement of the virtual marker tracking the fish. 
These data were subsequently analyzed to compare the 
effectiveness and efficiency between the two interface types. 
G. Questionnaires (qualitative data) 
1) Before their activity 
The experiment used the NASA-TLX scale, translated 
into French by Ganier, F., Hoareau, C., & Devillers in 2013 
[23], to assess the workload involved. 
In virtual reality immersion research, cybersickness is 
frequently evaluated. The French questionnaire used in this 
study was proposed by Kennedy, R.S. et al. in 1993[18]. 
2) After their activity 
The F-SUS scale is the French version of the SUS 
(System Usability Scale) proposed by Gronier, G., & Baudet, 
A. in 2021 [24]. This scale is widely used to measure the 
usability of interactive systems. 
And 
finally, 
this experiment also assessed the 
participants' motivation through the SIMS situational 
motivation scale (French version suggested by Lambert-Le 
Mener, M. (2012) [25]). 
H. Analysis method 
The space of a virtual reality application that uses 
panoramic videos is usually designed using polar coordinates 
[5]. Thus, all the spatial parameters of the added virtual 
objects are saved as polar coordinates (quaternion rotation). 
During the experiment, the movement of the virtual 
marker while tracking a fish in the video was recorded for 
each frame, and then resampled to a fixed frame rate of 50 
FPS for ease of analysis. 
At time t in the video, marker m had position pm and fish 
f had position pf. The distance dt (pm, pf) represented the 
distance between the marker and the fish at time t. 
The participants were instructed to place the marker on 
the fish, but we realized that the targeted part of the fish 
(e.g., 
head, body, 
tail) varied among 
participants. 
Consequently, we did not use the dt index directly for the 
analysis. Instead, we used the relative distance between two 
consecutive periods t+1 and t, i.e. ∆t+1, t = | dt+1 – dt | with the 
goal of making the ∆ as small as possible. Our objective was 
to measure and compare the variations and the stability of the 
recorded trajectories considering the targeted trajectory. 
V. 
RESULTS 
The collected quantitative and qualitative data were 
normalized to select appropriate parameters and then 
analyzed with SPSS (version 25, IBM Corp). 
A Student Test was performed for the bivariate 
correlation test if the sample met the covariance criteria. 
Conversely, if the sample did not meet the criteria, a Mann-
Whitney non-parametric test was used. 
Data were collected on two experimental groups, each 
with 15 participants, corresponding to two types of WIMP 
and VR interactive interfaces. 
A. Effect of interactive interface on effectiveness 
The average difference (∆) used for the effectiveness 
tests on the 5 tasks (corresponding to 5 different trajectories 
in 5 scenes from s1 to s5). Effectiveness is inversely 
proportional to the ∆ coefficient, so as seen in Figure 3, the 
VR group recorded more stable trajectories than the WIMP 
group. The results were consistent across all 5 trajectory 
types. 
 
Figure 3.  Distribution of Mean Trajectory Differences for VR and WIMP 
Groups per Sequence 
177
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

The 
Mann-Whitney 
U 
tests 
revealed 
significant 
differences between the WIMP and VR groups in the 
average ∆ in 4 trajectories s1, s2, s4 and s5. A similar result 
was found in the Student Test on ∆s3 (Table I) with a 
significant Levene's Test result of 0.001687. The hypothesis 
that there is a difference in variance between the two groups 
(WIMP and RV) was accepted, indicating a significant 
difference in the mean of the two groups (significant T-Test 
result of 0.01585). 
TABLE I.  
STATISTICAL SIGNIFICANCE TESTS BETWEEN VR AND 
WIMP GROUPS FOR MEAN DIFFERENCE IN TRAJECTORY ACROSS 5 MISSIONS 
 
Group 
Shapiro-
Wilk 
Mann-
Whitney U 
Levene 
Test 
T-Test 
∆s1 
VR 
0.379511 
0.000841 
-- 
-- 
WIMP 
0.037481 
∆s2 
VR 
0.181733 
0.004494 
-- 
-- 
WIMP 
0.001477 
∆s3 
VR 
0.527049 
-- 
0.001687 
0.01585 
WIMP 
0.245281 
∆s4 
VR 
0.338854 
0.000622 
-- 
-- 
WIMP 
0.000542 
∆s5 
VR 
0.700370 
0.005114 
-- 
-- 
WIMP 
0.000039 
B. Effect of interactive interface on efficiency 
Regarding execution efficiency, the group using VR 
completed tasks faster than the group using WIMP interface 
(Figure 4). 
  
 
Figure 4.  Distribution of Execution Time Differences for VR and WIMP 
Groups by Sequence 
The Mann-Whitney U Tests (Table II) indicated 
significant differences between the WIMP and VR groups in 
terms of execution time for s2, s3, s4, and s5. The tests 
showed no significant difference for s1 (Sig.=0.351). 
TABLE II.  
STATISTICAL SIGNIFICANCE TESTS BETWEEN VR AND 
WIMP GROUPS FOR MEAN DIFFERENCE IN TRAJECTORY ACROSS 5 MISSIONS 
 
Group 
Sig. Shapiro-Wilk 
Sig. Mann-Whitney U 
∆s1 
VR 
0.000030 
0.350688 
WIMP 
0.023687 
∆s2 
VR 
0.021897 
0.001130 
WIMP 
0.020213 
∆s3 
VR 
0.001141 
0.005114 
WIMP 
0.043944 
∆s4 
VR 
0.010367 
0.000125 
WIMP 
0.169789 
∆s5 
VR 
0.000014 
0.000205 
WIMP 
0.574785 
 
However, when comparing data for scene s1 to other 
scenes, we observed that the VR group completed the task in 
a relatively shorter amount of time. 
C. Satisfaction 
Results of the F-SUS questionnaire to assess satisfaction 
rate showed no significant difference between the VR group 
(M=79.6, S.D.=11.7) and the WIMP group (M=76.8, 
SD=15.4). Despite the high diversity of opinions shown by 
the significant values of the standard deviations, the averages 
of the SUS [26] indicated that both systems resulted in an 
acceptable level of user satisfaction. 
D. Cybersickness 
The outcome of the Cybersickness Questionnaire (SSQ), 
which measured symptoms of nausea and oculomotor 
disorders, showed a significant difference between the VR 
and WIMP groups. The Shapiro-Wilk normality test led to a 
Mann-Whitney U evaluation, revealing that participants 
using the low-cost VR headset experienced significant 
cybersickness. These results were further confirmed by the 
questions regarding oculomotor disorders, where a Levene’s 
Test and T-test established a greater feeling of oculomotor 
disorders among the VR group than the WIMP group (as 
shown in Table III). 
TABLE III.  
EVALUATION OF CYBERSICKNESS SYMPTOMS 
 
Group 
Shapir
o-Wilk 
Mann-
Whitney U 
Levene 
Test 
T-
Test 
Nausea 
VR 
0.009 
0.001 
-- 
-- 
WIMP 
-- 
Oculomotor 
VR 
0.150 
-- 
0.447 
0.023 
WIMP 
-- 
178
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

E. Motivation 
Results of the SIMS questionnaire made it possible to 
identify the type of user motivation using the Situational 
Motivation Scale. Regarding intrinsic motivation, there was 
a significant difference between the VR group (M=23.8 and 
SD=2.9) and the WIMP group (M=19.7 and SD=5.4). A 
second significant difference was discovered between the 
VR group (M=8.9 and SD=4.6) and the WIMP group 
(M=13.9 and SD=7.1) for external regulation. These two 
differences highlighted a greater sense of autonomy for the 
VR group compared to the WIMP group (Table IV).  
TABLE IV.  
STATISTICAL SIGNIFICANCE TESTS BETWEEN VR AND 
WIMP GROUPS FOR MEAN DIFFERENCE IN TRAJECTORY ACROSS 5 MISSIONS 
 
Group 
N 
Medium 
S.D 
T-Test 
Intrinsic Motivation 
VR 
15 
23.80 
2.883 
0.017 
WIMP 
15 
19.73 
5.496 
Identified regulation 
VR 
15 
20.73 
5.663 
0.121 
WIMP 
15 
17.53 
5.276 
External regulation 
VR 
15 
8.93 
4.559 
0.031 
WIMP 
15 
13.87 
7.080 
Amotivation 
VR 
15 
9.33 
4.065 
0.225 
WIMP 
15 
11.93 
7.015 
 
Although differences in identified regulation and 
amotivation were not significant, the values remained 
consistent with the results for the other motivations. 
VI. 
DISCUSSION 
Our first hypothesis has been supported by the results of 
the study, which showed that the VR interface was more 
effective, efficient, and satisfactory than the WIMP interface 
in performing various tasks. This conclusion contradicted the 
findings of Coelho and Melo [7], who evaluated the usability 
of three different interfaces (WIMP, VR, and tangible). The 
difference between the two studies can be attributed to the 
nature of the interaction being tested. Indeed, our work 
focused on a particular interaction, the trajectory of objects 
and the spatiotemporal relationship in a panoramic video-
based immersive environment. We collected quantified data, 
namely the trajectory and the duration of the missions. 
Conversely, whereas Coelho and Melo only counted the 
number of errors during task execution, which showed no 
statistically significant differences. 
The analysis demonstrated that the marker-to-fish 
tracking using VR was more stable than the one using 
WIMP, resulting in higher effectiveness of VR interaction. 
This was due to better coordination of viewpoint change 
(navigation) and trajectory recording (selection and 
manipulation) in both spatial and temporal dimensions of the 
panoramic video. The VR interface allowed for better spatial 
perception and object movement speed compared to WIMP. 
For object motion tracking, findings of our study also 
revealed that if coordination of spatial and temporal motion 
was not maintained at all times (which happened on the 
WIMP interface when the fish moved out of the viewing 
area), an interrupt action was necessary. This affected not 
only the recorded trajectory results but also the execution 
time of the experiment tasks. Spatial navigation (change of 
viewpoint) 
when 
combined 
with 
simultaneous 
and 
uninterrupted trajectory recording, resulted in better 
performance of the VR interface in terms of time and 
accuracy. 
The assumption which can be made at this stage is that 
the mouse sensitivity (Dots Per Inch - DPI) on the WIMP 
interface was not adjusted to match participants' usage 
habits, which led to poor accuracy results. Indeed, feedback 
from left-handed participants and from the participants who 
were accustomed to using touchpads supported this 
assumption. Regardless, if true, it still highlighted the VR 
interface's advantage in better adapting to the user's natural 
movements. 
According to the cybersickness analysis, levels of nausea 
and oculomotor disorder were more pronounced on the VR 
interface than on the WIMP interface. The experimentation 
process for the 5 tasks was long, so we did not detail this 
aspect as deeply as the study conducted by Pakkanen et al. 
[15] where participants repeated the tasks to assess their 
adaptation to the immersive environment over time. 
The Situational Motivation Scale questionnaires showed 
a significant difference in intrinsic motivation and external 
regulation between the VR and WIMP groups, with the VR 
group exhibiting higher results. This indicated a higher sense 
of autonomy and better motivation to complete tasks in the 
VR group. 
VII. CONCLUSION 
The goal of our experiment was to evaluate and compare 
the usability of the VR interface of an HMD and its 
controllers to that of the classic WIMP interface by 
conducting the same set of tasks for designing interactive 
scenarios for panoramic videos. So as to fulfill this aim, 
evaluations of the effectiveness, efficiency and user 
satisfaction for each of the interfaces were carried out. 
The experiment findings showed better results in terms of 
motion tracking as well as interaction execution time on the 
VR interface than on the WIMP interface. The level of 
satisfaction was comparable between the two groups and fell 
within acceptable range, with no significant difference 
observed. In terms of usability, the VR interface, thanks to 
its superior spatiotemporal coordination of interactions, 
seemed better suited than the WIMP interface. 
Although the VR interface had its issues with 
cybersickness, trainers still reported a higher level of 
satisfaction and motivation while performing tasks in VR as 
compared to the traditional WIMP interface. 
The immersive environment based on interactive 
panoramic videos not only includes space-time interactive 
objects, but also other objects, such as text and sound. 
Therefore, the creation of these objects using an authoring 
tool requires further evaluation of cross-platform usability. 
In the future, we will examine and evaluate the system's 
adaptability to various scenarios, with the aim of developing 
179
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

a model for a scripting assistant to aid trainers in the process 
of building an immersive learning environment. 
REFERENCES 
[1] 
Sundström, Y. (2013). Game design and production: 
frequent problems in game development. 
[2] 
J. L. Rubio-Tamayo, M. Gertrudix Barrio, and F. García 
García, “Immersive Environments and Virtual Reality: 
Systematic Review and Advances in Communication, 
Interaction and Simulation,” Multimodal Technologies and 
Interaction, vol. 1, no. 4, Art. no. 4, Dec. 2017, doi: 
10.3390/mti1040021. 
[3] 
M. G. Violante, E. Vezzetti, and P. Piazzolla, “Interactive 
virtual technologies in engineering education: Why not 360° 
videos?,” Int J Interact Des Manuf, vol. 13, no. 2, pp. 729–
742, Jun. 2019, doi: 10.1007/s12008-019-00553-y. 
[4] 
T. Chambel, M. N. Chhaganlal, and L. A. R. Neng, 
“Towards immersive interactive video through 360° 
hypervideo,” in Proceedings of the 8th International 
Conference on Advances in Computer Entertainment 
Technology, New York, NY, USA, Tháng Mười Một 2011, 
pp. 1–2. doi: 10.1145/2071423.2071518. 
[5] 
P. R. C. Mendes, Á. L. V. Guedes, D. de S. Moraes, R. G. 
A. Azevedo, and S. Colcher, “An Authoring Model for 
Interactive 360 Videos,” in 2020 IEEE International 
Conference on Multimedia & Expo Workshops (ICMEW), 
Jul. 
2020, 
pp. 
1–6. 
doi: 
10.1109/ICMEW46912.2020.9105958. 
[6] 
M. Khademi, M. Haghshenas, and H. Kabir, “A Review On 
Authoring Tools,” presented at the Proceedings of the 5th 
International Conference on Distance Learning and 
Education, IPCSIT, Sep. 2011, vol. 12, pp. 40–44. 
[7] 
Coelho, Hugo, et al. “Authoring tools for creating 360 
multisensory videos—Evaluation of different interfaces,” 
Expert Systems, vol. 38, no. 5, p. e12418, 2021, doi: 
10.1111/exsy.12418. 
[8] 
L. Argyriou, D. Economou, V. Bouki, and I. Doumanis, 
“Engaging Immersive Video Consumers: Challenges 
Regarding 360-Degree Gamified Video Applications,” in 
2016 15th International Conference on Ubiquitous 
Computing and Communications and 2016 International 
Symposium on Cyberspace and Security (IUCC-CSS), Oct. 
2016, pp. 145–152. doi: 10.1109/IUCC-CSS.2016.028. 
[9] 
G. Robertson, M. Czerwinski, and M. van Dantzich, 
“Immersion in desktop virtual reality,” in Proceedings of 
the 10th annual ACM symposium on User interface 
software and technology - UIST ’97, Banff, Alberta, 
Canada, 1997, pp. 11–19. doi: 10.1145/263407.263409. 
[10] 
A. Serrano et al., “Motion parallax for 360° RGBD video,” 
IEEE Transactions on Visualization and Computer 
Graphics, vol. 25, no. 5, pp. 1817–1827, May 2019, doi: 
10.1109/TVCG.2019.2898757. 
[11] 
B. Luo, F. Xu, C. Richardt, and J.-H. Yong, “Parallax360: 
Stereoscopic 360° Scene Representation for Head-Motion 
Parallax,” IEEE Transactions on Visualization and 
Computer Graphics, vol. 24, no. 4, pp. 1545–1553, Apr. 
2018, doi: 10.1109/TVCG.2018.2794071. 
[12] 
T. Rhee, L. Petikam, B. Allen, and A. Chalmers, “MR360: 
Mixed Reality Rendering for 360° Panoramic Videos,” 
IEEE Transactions on Visualization and Computer 
Graphics, vol. 23, no. 4, pp. 1379–1388, Apr. 2017, doi: 
10.1109/TVCG.2017.2657178. 
[13] 
T. Adão et al., “A rapid prototyping tool to produce 360° 
video-based 
immersive 
experiences 
enhanced 
with 
virtual/multimedia elements,” Procedia Computer Science, 
vol. 
138, 
pp. 
441–453, 
2018, 
doi: 
10.1016/j.procs.2018.10.062. 
[14] 
K. Choi, Y.-J. Yoon, O.-Y. Song, and S.-M. Choi, 
“Interactive and Immersive Learning Using 360° Virtual 
Reality Contents on Mobile Platforms,” Mobile Information 
Systems, vol. 2018, p. e2306031, Oct. 2018, doi: 
10.1155/2018/2306031. 
[15] 
T. Pakkanen et al., “Interaction with WebVR 360° video 
player: Comparing three interaction paradigms,” in 2017 
IEEE Virtual Reality (VR), Mar. 2017, pp. 279–280. doi: 
10.1109/VR.2017.7892285. 
[16] 
D. Fonseca and M. Kraus, “A comparison of head-mounted 
and hand-held displays for 360° videos with focus on 
attitude and behavior change,” in Proceedings of the 20th 
International Academic Mindtrek Conference, New York, 
NY, 
USA, 
Oct. 
2016, 
pp. 
287–296. 
doi: 
10.1145/2994310.2994334. 
[17] 
“Wixar 
- 
Your 
Human 
Resources 
Metaverse.” 
https://www.wixar.io/ (accessed Mar. 13, 2023). 
[18] 
R. S. Kennedy, N. E. Lane, K. S. Berbaum, and M. G. 
Lilienthal, 
“Simulator 
Sickness 
Questionnaire: 
An 
Enhanced Method for Quantifying Simulator Sickness,” The 
International Journal of Aviation Psychology, vol. 3, no. 3, 
pp. 203–220, Jul. 1993, doi: 10.1207/s15327108ijap0303_3. 
[19] 
S. G. Hart and L. E. Staveland, “Development of NASA-
TLX (Task Load Index): Results of Empirical and 
Theoretical Research,” in Advances in Psychology, vol. 52, 
P. A. Hancock and N. Meshkati, Eds. North-Holland, 1988, 
pp. 139–183. doi: 10.1016/S0166-4115(08)62386-9. 
[20] 
J. Brooke, SUS: A “Quick and Dirty” Usability Scale. CRC 
Press, 1996, pp. 207–212. doi: 10.1201/9781498710411-35. 
[21] 
F. Guay, R. J. Vallerand, and C. Blanchard, “On the 
Assessment 
of 
Situational 
Intrinsic 
and 
Extrinsic 
Motivation: The Situational Motivation Scale (SIMS),” 
Motivation and Emotion, vol. 24, no. 3, pp. 175–213, Sep. 
2000, doi: 10.1023/A:1005614228250. 
[22] 
I. ISO, “9241-11: 2018 Ergonomics of Human-System 
Interaction—Part 11: Usability: Definitions and Concepts,” 
International 
Organization 
for 
Standardization. 
https://www. iso. org/obp/ui/\# iso: std: iso, vol. 9241, no. 
11, 2018. 
[23] 
F. Ganier, C. Hoareau, and F. Devillers, “Évaluation des 
performances et de la charge de travail induits par 
l’apprentissage 
de 
procédures 
de 
maintenance 
en 
environnement virtuel,” Le travail humain, vol. 76, no. 4, 
pp. 335–363, 2013, doi: 10.3917/th.764.0335. 
[24] 
G. Gronier and A. Baudet, “Psychometric Evaluation of the 
F-SUS: Creation and Validation of the French Version of 
the System Usability Scale,” International Journal of 
Human–Computer Interaction, vol. 37, no. 16, pp. 1571–
1582, Oct. 2021, doi: 10.1080/10447318.2021.1898828. 
[25] 
M. L. L.-L. Mener, “The academic performance of 
university students in their first-year : influence of cognitive 
abilities 
and 
motivation,” 
phdthesis, 
Université 
de 
Bourgogne, 2012. Accessed: Mar. 13, 2023. [Online]. 
Available: https://theses.hal.science/tel-00780578 
[26] 
A. Bangor, “Determining What Individual SUS Scores 
Mean: Adding an Adjective Rating Scale,” vol. 4, no. 3, 
2009. 
 
180
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

