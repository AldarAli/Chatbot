A Semantic Representation for Process-Oriented Knowledge Management to 
support Production Planning based on Function Block Domain Models  
and a Three-level Mediator Architecture 
Benjamin Gernhardt,  
Franz Miltner, Tobias Vogel, 
Matthias Hemmje 
Multimedia and Internet Applications  
University of Hagen 
Hagen, Germany 
e-mail: firstname.lastname@fernuni-
hagen.de 
 
Holger Brocks 
 
InConTec GmbH 
 
Burghaslach, Germany 
e-mail: holger.brocks@incontec.de 
 
Lihui Wang 
Sustainable Production Systems 
Royal Institute of Technology  
Stockholm 
Stockholm, Sweden 
e-mail: lihui.wang@iip.kth.se 
 
 
Abstract—Semantic approaches for knowledge representation 
and management as well as knowledge sharing, access and re-
use can support Collaborative Adaptive Production Process 
Planning (CAPP) in a flexible, efficient and effective way. 
Therefore, semantic-technology based representations of such 
CAPP knowledge integrated into a machine readable process 
formalization is a key enabling factor for sharing such 
knowledge in cloud-based semantic-enabled knowledge reposi-
tories supporting CAPP scenarios as required in the CAPP-4-
SMEs project. Beyond that, Small and Medium Enterprises 
(SMEs) as represented in CAPP-4-SMEs request for a stand-
ardized CAPP-oriented product-knowledge- and production-
feature representation. That can be achieved by applying so-
called Function Block (FB) based knowledge representation 
models. Web-based and at the same time Cloud-based technol-
ogies, tool suites and application solutions which are based on 
process-oriented semantic knowledge-representation method-
ologies, such as Process-oriented Knowledge-based Innovation 
Management (German: Wissens-basiertes Prozess-orientiertes 
InnovationsManagement, WPIM) can satisfy these needs. In 
this way, WPIM can be applied to support the integration and 
management, as well as the access and re-use in a machine 
readable and integrated representation of distributed CAPP 
knowledge. On the other hand that knowledge is shared within 
a cloud-based centralized semantic-enabled knowledge reposi-
tory. Furthermore, semantic knowledge representation and 
querying will add value to the knowledge-based and computer-
aided re-use of such machine-readable knowledge resources 
within CAPP activities. Finally, it will pave the way towards 
further automating planning, simulation and optimization in a 
semantic-web for CAPP. 
Function Blocks; DPP; CAPP; Process Planning; Process-
oriented Knowledge Management; Knowledge-based Process-
oriented Innovation Management; WPIM 
I. 
 INTRODUCTION, MOTIVATION AND PROBLEM 
STATMENT 
In [1], the general concept of developing a knowledge-
based and process-oriented CAPP support by using the 
WPIM method as a basis was proposed. The WPIM ap-
proach offers the possibility of modeling and representing 
innovation processes in a machine-readable semantic format 
and furthermore enables annotating the process representa-
tion in a semantic way with further knowledge resources. 
This whole representation structure can then later be ac-
cessed by means of semantic queries. However, so far WPIM 
has only been applied in domains like design and develop-
ment. It also includes Product Life Cycle Management 
(PLM) support but it has not yet been practically applied in 
the domain of CAPP. In parallel to the development of 
WPIM, Wang et al. have introduced a method for represent-
ing web-based Distributed Process Planning (DPP) activi-
ties in [3], [4] and [5]. In the following we will use slightly 
adapted excerpts from [3] to introduce the necessary con-
cepts and rationale of the DPP method. The DPP method 
includes also the concepts of Meta Function Blocks 
(MFBs), Execution Function Blocks (EFBs) and Opera-
tion Function Blocks (OFBs). Furthermore, Helgoson et al. 
explain in [6] that ―Today, machining-feature based ap-
proaches combined with artificial-intelligence (AI) based 
methods are the popular choices for process planners‖. Their 
introduced approach is already based on a DPP modeling-
method but does not yet support machine-readability and 
semantic interoperability of such models as it could be 
achieved by utilizing representations as available in nowa-
days semantic web technologies and as e.g., supported by 
WPIM. This means, while the proposed DPP approach is 
very useful and valid in terms of representing the product 
and machining features within MFBs, EFBs and OFBs but 
nevertheless it does not yet support semantic-web based 
cross-organizational and cross-domain knowledge sharing. 
However, this is necessary to make such knowledge more 
widely available e.g., to be shared in collaborations of SMEs 
within CAPP activities. This DPP knowledge is not so far 
available in a machine-readable semantic representation at 
all. The interoperability of such a representation with tech-
nologies of the semantic-web and therefore with other appli-
cations and tools, like e.g., from the area of Artificial Intelli-
gence (AI) and Machine Learning (ML), cannot easily be 
achieved. 
Moreover, this knowledge cannot easily be automatically 
shared, managed, accessed, exchanged and re-used within 
47
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

collaborations that take advantage of cloud-based semantic 
repositories of CAPP-knowledge. In general, therefore can 
also not easily be accessed online virtually in real-time dur-
ing computer-supported CAPP activities within latest (SoA) 
ICT infrastructures across knowledge domains and organiza-
tional borders.  
At the same time, if such a semantic and process-oriented 
CAPP-knowledge representation utilizing semantic-web 
technologies would exist then it could be very well supported 
by other semantic-web enabled technologies and correspond-
ing methods, like, e.g., WPIM and in this way interoperabil-
ity. Therefore an integration of cloud-based semantic CAPP 
knowledge repositories with other e.g., AI and CAPP-
support technologies paradigm could be achieved by means 
of integrating them based on the semantic web software de-
velopment paradigm. 
In consequence, this insight requires the application of 
semantic technologies and corresponding methods like e.g., 
WPIM. Process-oriented semantic representation of CAPP 
knowledge wherein the product and machining features are 
formalized within MFBs, EFBs and OFBs like domain-
specific representations i.e., domain models of the DPP 
knowledge domain could support the CAPP knowledge do-
main. 
The remainder of this paper is based on this insight and is 
applying and implementing the necessary DPP and semantic-
web integration approach within a mediator architecture. 
Such architectures are typical for semantic-web repositories 
and solving semantic integration challenges as well as inte-
grating several local knowledge sources into a global, poten-
tially cloud-based, semantic repository. This can then be 
considered a semantic and cloud-based CAPP-knowledge 
repository which has been implemented in a very (technolog-
ically) open and distributed way. From the point of view of 
WPIM, the domain models for MFBs, EFBs and OFBs can 
be covered by a semantic integration in this repository with 
the existing WPIM domain concepts of WPIM-Master Pro-
cesses, -Process Instances, -Tasks and –Activities (ex-
plained in Section 2.5). Thus, it is allowed for the integration 
of WPIM- and DPP-based knowledge modeling as well as 
for the semantic representation of DPP knowledge to become 
available as a knowledge-based support to CAPP activities. 
In the rest of this paper, we will also describe this integration 
more in detail. Because of that, this paper covers the follow-
ing aspects: 
First of all, the state-of-the-art of FB-based production 
planning models and in detail the proposed DPP method 
including the necessary planning processes producing and 
handling MFBs, EFBs and OFBs will be revisited. Further-
more, we describe the state-of-the-art w.r.t. Process Ontolo-
gies and more accurate the WPIM-Ontology. We will carry 
out a comparison of the DPP modeling approach of Wang et 
al. [3] with the expressiveness of the WPIM-Ontology and 
we will introduce the prototypical extension of the WPIM-
Ontology to cover i.e., semantically wrap and integrate the 
DPP planning processes and there resources including MFB, 
EFB and OFB concepts of the DPP-model. We discuss and 
analyze all these already mentioned different approaches in 
Section 2. The integrating role of WPIM in the domain of 
process planning will be explained in Section 3. 
Furthermore, we will outline our mediation approach to a 
DPP-based distributed knowledge representation. This will 
result in an extension of the WPIM tool suite and applica-
tion solution by means of a mediator architecture to support 
the integration into a centralized and potentially cloud-based 
global CAPP repository. We illustrate this in Sections 4 and 
5. In this way, such a repository that can then support in the 
future cross-domain and cross-organizational CAPP pro-
cesses, tasks, and activities in terms of knowledge sharing 
and online process-driven access support. 
In Section 6, we present the theoretical basis of our three 
level mediator architecture. Finally, discussions, future work 
and conclusions are given in Section 7. 
II. 
STATE OF THE ART AND ANALYSIS 
The following paragraphs will briefly summarize and an-
alyze the state-of-the-art of FB based DPP modeling. The 
section is based on a slightly adapted excerpt from [3] and 
WPIM-based semantic process-modeling. It also introduces 
the necessary concepts of information integration and media-
tion as well as of mediator architectures as a background for 
the integration and mediation approach to be applied for the 
integration of DPP and WPIM. 
A. Function Blocks 
FBs are initially defined in the IEC 61499 standard [7], 
which explains the usage, development and implementation 
of FBs in distributed industrial process measurement and -
control systems in a component-oriented approach [8]. IEC 
61499 was developed jointly from the existing concepts of 
FB diagram in the Programmable Logic Controllers (PLC) 
language standard IEC 61131-3 [9] and standardization work 
concerning Fieldbus [9]. It was developed after the need for 
a common model for the application of software modules 
called FBs had been raised. FB diagrams were initially intro-
duced (in IEC 61131-3) to solve problems with textual pro-
gramming, ladder diagrams, and the reuse of common tasks. 
In the new standard of IEC 61499, an FB is an event-
triggered component containing algorithms and an Execu-
tion Control Chart (ECC) with inputs and outputs of data 
and events. Algorithms are executed when triggered by input 
events, reading data from the input data and producing new 
output data. The algorithm execution and scheduling is con-
trolled by the ECC functioning like a finite state machine and 
at the end of algorithm execution an output event is created. 
As basic building blocks, many FBs can be combined in a 
distributed network to create complex control applications 
with their data/event interfaces interconnected to control the 
flow of data and events. One FBs output event could then be 
the input event of another FB. A common way of describing 
or viewing an in summary, FB can be considered as a model 
of software or process representation, treating the encapsu-
lated behavior in a form that is similar to an electronic cir-
cuit. A literature review related to the FB related research 
targeting the areas of machining and assembly is available in 
[3][4], as well as an introduction into Distributed Process 
48
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

Planning (DPP) as an important stepping stone towards sup-
porting CAPP with DPP methodology. 
B. Distributed Process Planning & Meta Function Blocks 
Furthermore, as outlined in more detail in [3], the re-
quired functionality for implementing a web-based DPP 
system is consisting of three core components of the DPP, 
namely the planning processes of Supervisory Planning 
(SP), Operation Planning (OP) plus a new Execution Con-
trol Planning (ECP), which are explicitly modeled in a 
conceptual ICAM Definition for Function Modeling 
(IDEF0, where 'ICAM' is an acronym for Integrated Com-
puter Aided Manufacturing) process formalization model 
together with their inter-relationship and dataflow. Meta 
Function Blocks (MFBs) are used in this research to encap-
sulate machining sequences (of setups and machining fea-
tures) and are the output of Supervisory Planning. As its 
name suggested, an MFB only contains generic information 
about process planning of a product. It is a high-level pro-
cess template, with suggested cutting tool types and tool 
path patterns, for subsequent manufacturing tasks. 
C. Execution and Operation Function Blocks 
Within the DPP methodology, Execution Function 
Blocks (EFBs) are the FBs that are ready to be downloaded 
to a specific machine. Basically, an EFB can be created by 
instantiating a series of MFBs associated with a task. Each 
manufacturing task corresponds to its own set of EFBs, so 
that the monitoring functions can be conducted for each task 
unit. Furthermore, the DPP methodology offers the concept 
of an Operation Function Blocks (OFBs). The structure of 
an OFB is the same as that of an Execution Function Block 
(EFB). However, an OFB specifies and completes EFB with 
more detailed, machine-specific data about machining pro-
cesses and operation sequences. Moreover, operation plan-
ning module can override and update the actual values of 
variables in the EFB, so as to make it locally optimized and 
adaptable to various events happened during machining 
operations. Wang et al. use the two different terms of EFB 
and OFB in [3] to distinguish a given FB, because they are 
two separate entities with different level of detail in con-
tents, fulfilling different level of execution, residing in dif-
ferent systems, and moreover, they may be deployed in 
physically distributed Computerized Numerical Control 
(CNC) controllers. In other words, a FB holds a set of pre-
defined algorithms that can be triggered by an arriving event 
to the FB. Thus, a decision can be made by executing the 
algorithm. 
D. WPIM 
The concept of WPIM was developed to support captur-
ing and usage of knowledge around innovation processes [1] 
[2][10]. It assumes that innovation has both a knowledge 
and process perspective, which needs to be used in a com-
bined manner. Therefore, activities of a process can be an-
notated with resources, such as experts and documents [10]. 
The web-based WPIM application and corresponding 
tool suite [28] allows the integration and mediation of se-
mantic representations of process structures and specific 
knowledge resources. To support CAPP, the so far used 
domain of innovation-processes needs to be extended to be 
able to represent collaborative production planning process-
es that are built on the basis of distributed production plan-
ning processes. What actually are more detailed representa-
tions and therefore domain models for one of the phases of 
so-called innovation value chains. Therefore, activities in 
the generic collaborative production planning process need 
to be expressed in terms of distributed planning processes. 
That processes are annotated with resources, such as experts 
and formal representations of their tacit knowledge as well 
as 
documents 
capturing 
and 
bearing 
externalized 
knowledge. Future collaborative production planning pro-
cesses will in this way be enabled to benefit from reusing 
and instancing these annotated generic planning processes 
as well as from underlying semantically annotated represen-
tations of planning activities and planning knowledge re-
sources. The semantic schema of the WPIM application and 
the corresponding tool-suite is based on the Resource De-
scription Framework (RDF) [11] and enables semantic-
based searching by using the SPARQL Protocol And RDF 
Query Language (SPARQL). These enabling technologies 
provide a well-defined formal semantic description of 
knowledge. Using these explicit and machine readable rep-
resentations 
of 
knowledge 
in 
distributed 
cross-
organizational environments as known from the require-
ments of collaborations in the SME domain can improve 
collaboration between heterogeneous partners and add value 
to an advanced and even more integrated CAPP.  
The WPIM application and the corresponding tool suite 
is using four layers for knowledge representation. It offers 
the opportunity to get on a top layer a brief overview of the 
innovation i.e., in the case of the CAPP planning process 
and if needed to navigate to deeper more detailed process 
descriptions, accompanying knowledge resources, docu-
ments as well as annotated attributes and features. The un-
derlying ontology in the WPIM application and correspond-
ing tool suite offers a machine-readable structure for con-
cepts that can also be read and understood by human ex-
perts. Ontologies offer the opportunity to order concepts 
hierarchically as in e.g., a taxonomy but furthermore add 
non-hierarchical relationships between such concepts. For 
example, coming from a functional point of view for some 
applications the two concepts mechanical cutting and laser 
cutting can be understood as replaceable concepts. The Web 
Ontology Language (OWL) [12][13] allows to model con-
cepts in classes and e.g., this replaceable relationship be-
tween these two classes of cutting technology. A production 
planner using semantic search/reasoning for cutting methods 
will find both options of cutting and also will get the hint 
that these two concepts can potentially substitute each other. 
In this way, representing such knowledge in a machine-
readable semantic way can pave the way towards applying 
AI methods as can e.g., be build by means of automated 
semantic reasoning over semantic knowledge representa-
tions. Additionally, with the concepts of Master Processes 
(German: Masterprozess, MP, see Figure 1), Process In-
stances (German: Prozessinstanz, PI, see Figure 1) as well 
as Activities and Tasks the separation of modeling and cap-
49
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

turing generic and instance specific (in the domain of 
CAPP, this means e.g., knowledge related to a certain ma-
chine vendor) knowledge is supported. In this way, the pro-
cess artifact representation toolbox of WPIM allows re-
using process steps and their associated knowledge in a 
seamless way. 
III. 
WPIM IN THE DOMAIN OF PROCESS PLANNING 
WPIM was originally developed to support innovation 
processes by providing existing innovation process 
knowledge in an explicitly represented form to innovation 
process experts as well to computer agents i.e., computing 
machines and their software programs. In the field of inno-
vation processes, the usage and potential of semantically 
represented processes as enabled by WPIM has already been 
elaborated. Furthermore, WPIM has already been applied to 
represent PLM data in the field of technical products. In 
both domains next to executing processes also planning pro-
cesses has been modeled and used for representation. Se-
mantics as offered by WPIM have the advantage of being 
easily exchangeable and machine readable. This helps e.g., 
to plan cross-organizational and distributed innovation pro-
cesses. 
The following  
Figure 1 describes the interaction of a MP with its PIs. If 
such processes need to be represented in WPIM, in a first 
step the user selects classes in the WPIM ontology reposito-
ry to register an instance of a process resource. This means, 
the user e.g., selects the process classification systems to be 
used as the global set of ontologies into which the 
knowledge resource structure and contents are to be 
mapped. In a second step, the user selects attributes for each 
selected resource class for populating virtual objects in these 
classes with content resources. This implies, the user has 
also e.g., to map the attributes of the resources to specific 
ontologies. Thus, indicating that an attribute’s contents 
(their range) is mapped to an ontology, such as mapping a 
resource attribute onto an expert ontology. Finally, the user 
selects the populating methods or populates the resource 
instances and their specific content manually.  
 
 
 
Figure 1. Master Process and Process Instances [2] 
 
This means, the user maps the attributes of contents to 
classes in the ontology manually or semi-automatically us-
ing word-matching or other provided techniques e.g., map 
―hole‖ from a product property ontology concept to the 
―drilled hole‖ concept in the machining feature ontology. 
However, before such mappings can be established the 
sources’ local data schemas must first be registered. For 
example, in our implementation we used the two activity-
based schemas displayed in Figure 1 for representing the 
MP and PI resources. 
The next two sections describe in detail what an activity-
based MP is and how activity-based executions of this MP 
(i.e., PIs) are defined. 
A. Master Processes 
A MP is a generic high-level description of a process. In 
WPIM, from a data set point of view, a MP describes a data 
structure and attributes of a higher level template for a pro-
cess. The representation approach goes beyond the sole rep-
resentation of the process structural schema but describes 
process structures and their attributes by using semantic 
representations. As WPIM offers such semantic descriptions 
of MPs, the semantic MP schema exists as a generic and 
formal description of a process, independent of generated 
data instances during a certain execution of the process. As 
an example, a MP defines next to a well-defined structure of 
contained activities. Resources, which will be involved dur-
ing execution the process. For instance, this can be experts, 
documents or, in the case of a CAPP adaptation, could be 
production machines and their production activities. 
B. Process, Activity and Task Instances 
When executing a process, data is gathered. WPIM de-
scribes this, from the data set point of view, as a PI. The 
Activity structure that exists in WPIM and is displayed in  
Figure 2 is used to store all outgoing and incoming data 
as well as Activity states. Beyond that, WPIM also allows to 
describe and represent PIs including their Activities in a 
semantic, machine-readable format. Furthermore, WPIM 
PIs are ordered in a chronological way. That means, if a first 
instance is e.g., executed, the Lessons Learned during that 
execution can be stored within the higher level MP and this 
gathered information can be provided for the following pro-
cess execution within the next PI (see Figure 1). 
An activity needs well defined inputs to generate a re-
quired output. Activities within WPIM contain one to many 
tasks. An instance of an Activity defines a cluster of tasks 
e.g., an Activity can bundle tasks that are assigned to a sin-
gle resource. Such an assignment can contain planning tasks 
that need to be executed by an expert (e.g., a planner) or 
tasks can also be assigned to a resource like a machine in 
order to represent the execution of a machine operation. 
In a WPIM context, a Task structure is an action that 
can-not be further split into sub-actions. WPIM offers a se-
mantic data representation to archive status and values when 
performing a Task. Such a Task can for example, represent 
an operation that can be executed by a machine and create a 
specified result. By having such a semantic representation 
containing incoming and outgoing status, progress attributes 
and result specification, WPIM allows to delegate a Task 
instance to various executing entities. An example, in the 
50
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

context of planning tasks, it’s to finalize a plan by signing 
the plan and setting it into action. A Signature to release a 
plan is a very unique task and it is obvious, that such a sign-
ing task cannot be split – either the plan is released via sig-
nature or it is not signed and therefore not released. 
 
 
 
Figure 2. Visualization of an Activity as a set of Tasks 
 
As displayed in  
Figure 2, an Activity consists of at least one up to many 
Tasks. These Tasks represent the transformation of an input 
of the Activity into an output. 
IV. 
SEMANTIC INTEGRATION AND INFORMATION 
MEDIATION WITHIN KNOWLEDGE-BASED INFORMATION 
SYSTEM ARCHITECTURE 
Mediators are a standard approach in the construction of 
information system architectures. They have originally been 
introduced by Wiederhold in [14] as early as in 1991 when 
the web was still in its infancies and the semantic web did 
not even exist. However, since then, the use and application 
of these architectures in building web-based information 
systems supporting, data, information, and knowledge inte-
gration has grown into a de-facto standard. It is widely used 
in all types of scientific and industrial infrastructures sup-
porting data, information, content and knowledge sharing, 
management and access for re-use. In the following, we will 
introduce the different levels of interoperability that can be 
addressed by mediator architectures in terms of integration. 
Furthermore, we will introduce markup languages as a 
means of defining global schemata and semantics for the 
purpose of semantic information integration and exchange. 
Finally, we will introduce mediator architectures of different 
types at increasing levels of detail supporting increasing lev-
els of integration. 
A. Levels of Interoperability and Integration 
As outlined, e.g., in [15] data, information and 
knowledge integration can be understood at varying levels 
of interoperability and heterogeneity. In the following, we 
will describe this a bit more in detail based on a slightly 
adapted excerpt from [15]. When trying to share distributed 
and heterogeneous data, a number of technical challenges 
must be overcome. Consider, for example, two systems hav-
ing data sets that should be made interoperable. One can 
employ standards and technologies to overcome the various 
kinds of heterogeneities and to facilitate interoperability at 
different levels. At the systems level, one may find different 
operating systems (Linux, MS Windows, MacOS, etc.), dif-
ferent data transport protocols (FTP or HTTP, which are 
built on top of a stack of internet protocols called TCP/IP 
etc.) or higher-level protocols for discovery and interopera-
tion of web services. The Differences in system platforms 
and operating systems are usually overcome by standardiz-
ing protocols for data transport and remote service execu-
tion. For the latter, for example, one can employ web ser-
vice descriptions (WSDL, 2001), which specify the input 
and output parameters of a web service. System level in-
teroperability can also be achieved at the grid or cloud ser-
vice level. Grid and cloud services extend the basic web-
service infrastructure and include additional features such as 
user authentication for secure data access. Apart from the 
generic issues of data access, transport and remote execu-
tion, there are also a number of application specific system 
level issues e.g., the choice and architecture of the mapping 
technology for the integration and mediation of information 
and knowledge resources (server-side, client-side, mixed). 
At the syntactic level, one has to consider heterogeneities 
such as different data file formats, depending on the type of 
content or knowledge resource and corresponding represen-
tation format of the information and knowledge representa-
tion. The Extensible Markup Language (XML) [16] pro-
vides a simple and very flexible syntax for structuring many 
kinds of data, metadata, content and knowledge resources to 
enable their exchange. Defining such a new structure in 
XML syntax can be done in different ways. For example, 
one can provide an XML Document Type Definition (DTD) 
or an XML Schema Definition (XSD, XML Schema) 
[16][17] to specify the allowed nesting structure and (in 
XML Schema) the data types of XML elements. 
In this way, XML not only yields a data, information, 
content and knowledge resource exchange syntax but also 
prescribes a schema for the exchanged resource. However, 
additional explicit representations of semantics such as do-
main specific integrity constraints have to be encoded by 
other means. The Resource Description Framework (RDF) 
[11] can be seen as an XML dialect for encoding labeled, 
directed graphs and in particular ontologies as an example of 
a standardized semantic vocabulary. For querying databases 
and query languages, such as the Standardized Query Lan-
guage (SQL) [18] for relational databases) or XQuery (for 
XML databases) [19] are used, each of which come with 
their own syntax for query expressions. Differences at the 
syntactic level i.e., heterogeneity of the underlying data 
models of sources are usually resolved either by adhering to 
a standard or by using format converters that can translate 
from one format to another. At the schema level, heterogene-
ities can exist because the same (or at least similar) data can 
be represented using vastly different schema structures (even 
when the same file format or syntax is used). For example, 
two datasets may be organized in different ways across two 
relational databases i.e., the table and column structure may 
be very different although the content (at the conceptual lev-
el) of the databases may be very similar. Similarly, different 
DTDs or XML Schemas can be used to describe the same 
data for XML databases. To overcome schema level hetero-
geneities, we can again apply two approaches, schema stand-
ardization or schema transformation. For the latter, i.e., 
51
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

schema transformation, database query languages in general 
and XQuery in particular provide powerful means to express 
complex queries and transformations. Thus, (XML) query 
languages play an important role in database mediators. Fi-
nally, at the semantic level, we consider issues such as dif-
ferences in terminology, different classification schemes and 
differences in the definition and constraints for the various 
concepts that are relevant to the data sets being integrated. 
Therefore, the main approach for reconciling semantic heter-
ogeneities is the use of agreed-upon ontologies, which in 
their simplest form provide a controlled vocabulary with 
more or less formal descriptions of the pertinent concepts. In 
more sophisticated forms, ontologies include formalizations 
(often through logic formulas) of properties of concepts and 
―inter-dependencies‖ of concepts. A prominent emerging 
standard for ontologies is OWL, which comes in three in-
creasingly expressive variants: OWL Lite, OWL DL and 
OWL Full [20]. OWL is also an interesting example of how 
several interoperability levels and standards may be inter-
twined: for example, OWL DL builds upon the RDF model 
and syntax which in turn is usually denoted in XML syntax. 
B. Mediator Architectures 
Database mediator systems can be used to provide uni-
form access to distributed heterogeneous data sets, and 
thereby overcome a number of the interoperability challeng-
es mentioned above. Figure 3 depicts a typical mediator 
architecture in which a number of local data sources are 
―wrapped‖ as XML sources and subsequently combined into 
an integrated global view. Thus, a client application or the 
end user is provided with the illusion of querying a single, 
integrated (or global) database with one integrated schema. 
Mediators are software components that serve to simpli-
fy, reduce, combine and explain data. They are mainly used 
for providing a common access level onto different distribut-
ed data sources. The source wrappers not only provide a uni-
form syntax, but also reconcile system aspects e.g., by means 
of a unified data access and query protocol [15]. 
 
Mediator
Data Sources
Client
Client
Query
Result
Wrapper
Wrapper
Wrapper
 
Figure 3. Mediator architecture integrating data sources 
 
In a conventional relational or XML-based mediator sys-
tem, interoperability is facilitated at the structural level. Dif-
ferences in schema can be reconciled by corresponding 
schema transformation as part of the view definitions for the 
global view. However, terminological differences or other 
semantic differences are not adequately handled at the pure-
ly structural e.g., XML level. To this end, source schema 
and contents can be registered to an ontology, which en-
codes additional ―knowledge‖ about the registered concepts. 
In the next section, we will explain more in detail how by 
means of ―ontology-enabling‖ the system in this way can 
evaluate high-level queries over concepts that are not direct-
ly in the source databases and yet indirectly linked via an 
ontology. The task of the mediator is, to transform queries 
to the global schema into queries to the sources, to collect 
the results and to integrate and link them. The global 
scheme is based on a suitable data model, for which for ex-
ample, XML or RDF can be used as representation. Wrap-
pers are software components that represent the contents of 
a data source for the unification in another data model or 
schema. For example, XML wrappers are used to enable 
access to relational databases. The coupling between source 
and mediator via wrappers allows the mediator uniform ac-
cess to the sources, by creating a mapping between the data 
model of the mediator and the data model of the local 
source. Also, incoming requests of the mediator can be 
translated into requests into the local source system. 
C. Ontologies in Information Integration and Mediation 
In information integration systems, based on a mediator 
architecture as displayed in Figure 4, ontologies can be used 
to provide information at the level of conceptual models and 
terminologies. Thereby, facilitating conceptual-level queries 
against sources and resolving some of the semantic-level 
heterogeneities between them. In our original WPIM system, 
the process classification ontology and the innovation ontol-
ogy are used as a global view for registering process re-
sources and processing queries. When a resource is regis-
tered to an ontology, a mapping from the data set to the se-
lected ontology is generated. However, before such mapping 
can occur, the sources’ local data schemas have to be regis-
tered first. After these steps, wrappers are created for the 
registered resources. Each wrapper uses the mappings be-
tween the data source and ontology to translate queries from 
the global ontology to the local schema and also to translate 
content from the local schema to the global ontology.  
 
 
 
Figure 4. Extended Mediator Architecture [15] 
52
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

As explained above, the system can automatically use 
the subclass relation to expand concept queries when re-
quired. Note that although all system-registered ontologies 
can be considered as conceptual-level query mechanisms, 
the system can suggest suitable ontologies based on: first, 
the user’s choice of resources and second, the sources’ 
schema information. Database mediator systems can be used 
to provide uniform access to distributed heterogeneous data 
sets [15]. 
V. 
OVERALL CAPP KNOWLEDGE INTEGRATION AND 
MEDIATION CONCEPT 
Beyond integrating data from distributed data sources, 
our proposed CAPP knowledge integration and mediation 
approach also describes how to combine heterogeneous data, 
information, content and knowledge sources by a mediation 
approach. For that approach, DPP process knowledge sup-
porting CAPP activities need to be integrated by means of 
utilizing the WPIM semantic as well as need to be supported 
by mediation function, which allows integrated access 
through a global schema to the distributed CAPP knowledge 
resources in a DPP process. Over the course of the research 
on WPIM its field of application has been extended beyond 
just innovation management [21][22] and potentially can be 
applied as well in DPP and CAPP. This can be considered 
one of the phases of an innovation value chain. Furthermore, 
the web-based approach of the WPIM-Application-Tool 
suite supports working collaboratively in dispersed teams. In 
the domain of CAPP that means planning activities and con-
secutive manufacturing processes, which are handled by a 
network of many SMEs could benefit from such a common 
platform and therefore such use cases need further considera-
tion. 
A. Collaborative Planning Processes 
CAPP processes aim to combine and integrate distribut-
ed information and knowledge resources e.g., about ma-
chine and tool descriptions, machine features and process 
constraints in order to create an executable plan for a certain 
task. Such CAPP activities can happen within the boundary 
of one organization or even across organizational bounda-
ries. The CAPP-4-SMEs project [1] explicitly has defined 
the goal to research in the field of CAPP e.g., for the use 
case where Original Equipment Manufacturers (OEMs) 
work with global partners and suppliers, which are mainly 
SMEs, more collaboratively to achieve entire manufacturing 
value chain optimization [5].  This paragraph describes the 
concept of Collaborative Process Planning in CAPP-4-
SMEs and the challenge of turning the supervisory plan 
into an operational plan in an optimized manner. The plan-
ning process approach to be used in CAPP-4-SMEs is a 
form of DPP. Most process plans generated using existing 
CAPP systems are tied to specific resources (machines, fix-
tures, cutters, etc.) and therefore are inflexible and not re-
sponsive to unexpected changes. The plan must be severely 
revised every time when a resource becomes unavailable. 
Which might mean that similar planning tasks have to be 
accomplished repetitively [23, p. 5]. The goal of DPP is to 
improve flexibility and adaptability and ultimately allow 
real-time manufacturing intelligence. Therefore, a process 
plan consists of two parts: While generic data (machining 
method, machining sequence and machining strategy) is 
used to describe one or many alternative plans (which then 
is called Non-Linear Process Planning [3, p. 54]) machine-
specific data (tool, data, cutting conditions and tool paths) 
serves to choose from the actual resources available to pro-
duce the parts. This leads to a two-layer hierarchy, where 
the two different tasks can be accomplished at two different 
levels: shop-level SP and controller-level OP [23, p. 5ff].  
 
To represent the derived planning information, the con-
cepts of Machining Features (MFs) and FBs are used as 
enabling technologies. MFs typically represent shapes, 
which can be achieved by the available machining resources. 
As already described above, FBs are a concept provides con-
trol based on data flow and finite-state machine concept  
[23, p. 8ff]. The Decision Making for SP is non-trivial as 
there is not one single correct plan how to produce a part, as 
machining features applied in different sequences can be 
used to achieve the same result making non-linear process 
planning necessary. This task is covered in the steps machin-
ing sequence processing within the supervisory planning  
[23, p. 11ff]. In the following, and as a first step of semantic 
knowledge representation for the CAPP domain, this paper 
does focus on the semantic representation of SP and OP pro-
cesses. These processes include cutter selection, operation 
sequencing, cutting parameter assignment and tool path gen-
eration. They vary on the basis of chosen machining strategy 
and machining dynamics that affect tool life and surface fin-
ish quality. Improper decisions at this level may result in tool 
breakage, chatter vibration and even scrap. The knowledge 
about choosing the right resources is either covered in ven-
dor-specific handbooks or was gained through long-lasting 
experience of engineering experts who working for a specific 
company. That knowledge is either not extractable or there-
fore not representable in a standardized form (at least when 
looking at its informal encoding in handbooks) or even must 
be considered as implicit or tacit knowledge, when looking at 
the expert’s experience. While, the ultimate goal of DPP is to 
do operation planning in an automated fashion adapting to 
available scheduling and availability monitoring information.  
 
 
Figure 5. CAPP Ontology based on WPIM Models and DPP Process Types 
and Resources/Results 
 
The current reality is, that in many cases this planning 
step is still time and labor intensive and the required plan-
53
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

ning process themselves are not yet computer supported in 
terms of representing them in a machine readable semantic 
way. In the following, we will explain the representation, 
integration as well as mediation that can be achieved for 
representing CAPP activities based on DPP knowledge in an 
integrated way. 
That is accessible on a global level although the DPP 
knowledge resources are coming from distributed sources of 
the collaborating agents/processes. Figure 5 outlines our 
integration approach that will further be elaborated in the 
following. 
When combining, function blocks with WPIM we see 
strong advantages in both approaches. FBs are very plan-
ning oriented and focused on production domain. WPIM 
offers well described data structures for Processes, Activi-
ties and Tasks. In the following, we will now apply such 
WPIM process and resource representation structures, which 
are semantic-based and therefore give the possibility to rep-
resent data in an exchangeable, human-understandable and 
machine-readable format. For example, the created repre-
sentation structure allows navigation from Process level to 
Activity and Task level and vice versa. In this way, the se-
mantic representation structure will add value to distributing 
and at the same time sharing knowledge about production 
planning processes e.g., when exchanging single activities 
between processes and during allocation of tasks i.e., re-
sources/ results to a machine level. In the understanding of 
WPIM, the DPP planning process and resource knowledge 
is represented by planning activities consuming and produc-
ing planning knowledge resources. These can e.g., be FBs 
over all levels of CAPP activities from SP Process (SPP) 
activities through ECP Process (ECPP) activities to OP 
Process (OPP) activities (see Figure 5). Therefore, a pro-
duction of resulting planning results/resources from MFBs 
through EFBs to OFBs is possible. This process and re-
source knowledge can be brought into one integrated and 
well defined semantic schema with certain instances. In this 
way, the representation of the different types of planning 
activities producing and consuming FB resources by means 
of WPIM’s semantic process representation schemas allows 
to represent a top down planning process representation 
schema. As well as a top-down mediation of different types 
of knowledge-resource and planning-result representations 
from higher levels of planning abstraction to lower levels of 
operational planning representation. In this way, WPIM 
provides an integrated and well-structured schema to be 
filled during execution with instances of semantic data on 
each level of planning abstraction and corresponding pro-
cess and resource/result distribution. 
As displayed in  
Figure 6, a SPP can be represented by a WPIM Activity 
representation instance that transforms an input MFB on the 
basis of some additional planning resources produced by its 
tasks into an output MFB. Therefore, the EFB uses at least 
one EFB of an earlier iteration of a SPP activity. 
This means, that the MFBs produced by the SPP activity 
as displayed in Figure 6 are not only consumed by future 
iterations of such an SPP activity but also get consumed by 
the underlying ECPP activity. 
 
 
Figure 6. Supervisory Planning Process Activity 
 
Also an ECPP can be represented by an instance of a 
WPIM activity as shown in Figure 7. This process trans-
forms the incoming MFB provided by the SPP activity, the 
additional resource information (also MFBs) and the deliv-
ered OFB from the underlying OPP activity outgoing in an 
EFB. Therefore, an EFB uses at least one earlier iteration of 
a SPP activity and an OFB of the subsequent OPP activity. 
An ECPP activity (Figure 7) itself produces EFBs which get 
assigned to machines and consumed by them. In addition, 
the EFBs are used as inputs for the OCPP activities which 
are for producing and output of corresponding OFBs. 
 
 
Figure 7. Execution Control Planning Process Activity 
 
Analogously to the first two, an OPP can also be repre-
sented by an instance of WPIM activity representation. The 
OPP activity (Figure 8) transforms the already explained 
EFB that created apriori from the ECPP activity as well as 
several other information, like status and events (all MFBs) 
in an outbound OFB. Furthermore, in the DPP methodology 
OFBs have a direct link to the real execution of the process. 
That means, that OFBs are executed by a directly assigned 
resource e.g., a machine that at the same time produces a 
certain result in this way that can be re-used as a resources 
in the remainder of the planning process. 
 
 
Figure 8. Operation Planning Process Activity 
 
To achieve a representation of this, this kind of sub-
process structure on the basis of WPIM, the Process Plan-
54
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

ning levels ECPP and OPP have to be represented as addi-
tional underlying WPIM activities of the same MP. There-
fore, the resulting outputs of these processes (EFBs and 
OFBs) have been represented as planning results and there-
fore as knowledge resources that are handed over between 
these three planning activity levels of the same overall DPP 
MP. In summary, this means that the whole DPP methodol-
ogy as applied in CAPP application domains can be repre-
sented by WPIM as a three level integrated WPIM activity. 
That representation belongs to one overall DPP MP where 
the WPIM Activities represent SPPs, ECPPs and OPPs as 
well as their results/resources which are tasks for the activi-
ties itself. 
However, besides an integration on the level of the 
knowledge representation the WPIM system also needs to 
be extended to support access to distributed resources of 
such potentially distributed planning processes from a sys-
tem distribution point of view. Therefore we conclude our 
approach in the following with a corresponding design of a 
three level mediator architecture that can handle the above 
described process and resource representations. 
VI. 
EXTENDING WPIM TO INTEGRATE DPP KNOWLEDGE 
AND MEDIATE ITS ACCESS DURING CAPP 
Figure 9 displays a first level mediator architecture that 
integrates MFBs and other relevant and potentially distrib-
uted resources for the SPP activity from the different levels 
of the overall CAPP process that is implemented by means 
of the DPP method. The resulting mediator is called the SPP 
Mediator. 
 
 
Figure 9. First level Mediator Architecture using for SPP 
 
Therefore, a down-stream DPP mediation can be imple-
mented by means of two analogously derived additional 
mediators on the second and the third DPP level. 
On the second level of the mediator architecture follows 
then the deduced and so-called ECPP mediator which sup-
ports the above-mentioned ECPP activity. Figure 10 shows 
this second level of the mediator architecture. They assimi-
lated at least an earlier iteration of the SPP-mediator as 
MFB and a OFB of the subsequent OPP mediator (level 3) 
and various other relevant and potentially distributed re-
sources. 
Coming from the machining-data point of view, the cor-
responding up-stream Mediation Process starts from ma-
chines with a defined need of steering information which 
can be harmonized by using wrappers and offering a medi-
ated interface to clients. 
 
Figure 10. Second level Mediator Architecture using for ECPP 
 
The third and final level of the mediator architecture of 
the CAPP process forms the again derived OPP mediator. 
Figure 11 represents this level graphically and displays how 
the so-called OPP mediator completes the mediation pro-
cess. This integrates relevant and potentially distributed 
machine resources as MFBs and by the second level gener-
ated EFBs (ECPP-mediator) for the OPP activity. This 
three-tier architecture can support an Information Process 
by, providing data from distributed data repositories, com-
bining various data formats, in a single semantic enabled 
format, as well as a mediation process requesting, accessing 
and collecting/gathering/combining data from different dis-
tributed resources. 
 
Figure 11. Third level Mediator Architecture using for OPP 
 
The appendix contains a detailed illustration of the entire 
CAPP process of the mediator architecture (Figure 12) to 
get a good overall understanding and to clarify the relation-
ships and dependencies between the individual levels of 
mediation. 
In summary, this means that DPP i.e., deriving the Op-
erational Plan from the Supervisory Plan through the Execu-
tion Control Plan is therefore a three-level WPIM Process 
where the three levels can be modeled as interlinked WPIM 
activities. 
55
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

VII. CONCLUSION AND FUTURE WORK 
This paper has presented the relevant state-of-the-art and 
derived a method to support semantic knowledge manage-
ment of DPP knowledge in the CAPP application domain 
based on semantic process representations producing and 
consuming function blocks and other relevant planning re-
sources for distributed production planning. In this way, the 
challenges of planning resource distribution, sharing and 
mediation that are inherent to CAPP are addressed in a first 
initial step of modeling this domain. Besides this, require-
ments towards representing this knowledge in a machine 
readable way on the one hand and on the other hand design-
ing an implementation architecture that can deploy such a 
CAPP support into a cloud-based i.e., highly distributed or 
even fully virtualized system distribution are proposed.  
In this way, our approach will allow e.g., SMEs to par-
ticipate in a cloud based CAPP activity that is implemented 
on the basis of the DPP method. This is represented by the 
WPIM methodology in a machine readable way and where 
the distribution architecture within the cloud and beyond is 
achieved on basis of applying a three level mediator archi-
tecture. By extending the WPIM system with such a three 
level resource mediation architecture, users will be enabled 
to create process instances of the provided DPP master pro-
cesses representing all three levels of the DPP planning pro-
cess activities and all their resources and results from the 
highest level of product features down to the lowest level of 
machining features. By doing so, the individual SMEs can 
reflect, which resources they have available and can anno-
tate the DPP knowledge representation they have received 
and in this way documenting their potential competitive 
advantage. With this approach, we see the potential to ad-
dress several issues existing today.  
Firstly, on a general level - to capture DPP knowledge 
needed for process planning current tools are still rather 
complex to maintain and therefore not every SME has the 
capacity to run and maintain such a system. By delivering 
this functionality through a cloud-based repository approach 
building on semantic–web enabled knowledge representa-
tions and integration as well as mediation support. The us-
age of such tools can be provided at an affordable usage fee. 
Secondly, by the ability to provide knowledge not spe-
cific to a certain company or vendor of machines via e.g., a 
subscription model that is enabled through such an ap-
proach. SMEs, which do not have the manpower to build up 
that knowledge within their own research and engineering 
organization can source out this generic CAPP knowledge 
and start directly on enhancing their specific DPP 
knowledge increasing their competitive advantage in their 
respective production support niche. On a more specific 
level this approach fosters two aspects: From a knowledge 
management point of view the existence of explicit 
knowledge being available through handbooks etc. is made 
visible in a consistent and machine readable manner. The 
other fact is that tacit knowledge exists within the minds of 
long-standing employees is externalized by annotating these 
persons to specific process steps as expert. Referencing the 
SECI model [21, p. 20] this can be used for knowledge con-
version through socialization (based on the annotation in the 
WPIM process colleagues start asking questions to the ex-
perts about that matter and the tacit knowledge gets spread). 
From a collaboration aspect, this approach can support 
teams within a company and beyond the borders of an or-
ganization to collaboratively improve planning results. They 
can trigger knowledge conversion through socialization 
across the boundary of different sites of a company, which 
unlikely would happen if the fact that tacit knowledge exists 
(even though not the knowledge itself) would not be exter-
nalized. While supporting such a scenario within one com-
pany can be beneficial it would also be beneficial when sev-
eral companies do work together in a manufacturing net-
work. 
As a further development of this work, our next step is 
the practical implementation. For this purpose, we need 
more typical examples for the three step mediator architec-
ture and we want to reimplement and extend the WPIM tool 
suite. Thus, the theoretical preparatory work will be also 
practically applied and implemented. 
ACKNOWLEDGMENT AND DISCLAIMER 
This publication has been produced in the 
context of the CAPP-4-SMEs project. The 
CAPP-4-SMEs project has received fund-
ing from the European Union's Seventh 
Framework Programm for re-search, tech-
nological development and demonstration under grant 
agreement no 314024. 
However, this paper reflects only the author's view and the 
European Commission is not responsible for any use that 
may be made of the information it contains; 
REFERENCES 
[1]  F. Miltner, T. Vogel and M. Hemmje, "Towards 
Knowledge Based Process Planning Support for 
CAPP-4-SMEs: Problem Description, Relevant State 
of the Art and Proposed Approach", vol. 1, 
International Manufacturing Science and 
Engineering Conference (MSEC), 2014.  
[2]  T. Vogel, "Wissensbasiertes und Prozessorientiertes 
Innovationsmanagement WPIM - 
Innovationsszenarien, Anforderungen, Modell und 
Methode,Implementierung und Evaluierung anhand 
der Innovationsfähigkeit fertigender Unternehmen", 
Dissertation, Hagen, 2012.  
[3]  L. Wang, G. Adamson and M. H. a. P. Moore, "A 
Review of Function Blocks for Process Planning and 
Control of Manufacturing Equipment", Journal of 
Manufacturing Systems, Vol.31, No.3, pp.269-279, 
2012.  
[4]  L. Wang, W. Jin and H. Y. Feng, "Embedding 
machining features in function blocks for distributed 
process planning," International Journal of 
Computer Integrated Manufacturing, pp. 443-452, 
2006.  
56
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

[5]  L. Wang, H. Y. Feng and N. Cai, "Architecture 
design for distributed process planning," Journal of 
Manufacturing Systems, pp. 99-115, 2003.  
[6]  M. Helgoson, L. Wang, R. Karlsson, M. Givehchi 
and M. Tedeborg, "Concept for Function Block 
enabled Process Planning towards multi-site Cloud 
Collaboration", International Manufacturing Science 
and Engineering Conference (MSEC), Vol. 1, 2014.  
[7]  International Electrotechnical Commission, 
Switzerland: Function blocks – Part 1: Architecture, 
IEC 61499-1, 2005.  
[8]  R. Lewis, "Modelling control systems using IEC 
61499 – applying function blocks to distributed 
systems", ISBN: 0852976 796: The Institution of 
Electrical Engineers, 2001.  
[9]  International Electrotechnical Commission, 
Switzerland: Programmable controllers – Part 3: 
Programming languages, IEC 61131-3, 2003.  
[10]  T. Vogel and M. Hemmje, "Auf dem Weg zu einem 
Wissens-basierten und Prozess-orientierten 
Innovationsmanagement (WPIM) – Innovations-
szenarien, Anforderungen und Modellbildung," in 
KnowTech 2006, Poing, CMP-WEKA-Verlag, 2006.  
[11]  R. Cyganiak, D. Wood, M. Lanthaler, G. Klyne, J. 
Carroll and B. McBride, "RDF 1.1 Concepts and 
Abstract Syntax," W3C Recommendation 25 
February 2014, World Wide Web Consortium 
(W3C), http://www.w3.org/TR/rdf11-concepts/,, Feb 
2014, last accessed Nov 13, 2014. 
[12]  W3C OWL Working Group, "OWL 2 Web Ontology 
Language Document Overview (Second Edition)," 
W3C Recommendation 11 December 2012, World 
Wide Web Consortium (W3C), 
http://www.w3.org/TR/owl2-overview/, December 
2012, last accessed Nov 13, 2014. 
[13]  W3C, "OWL Web Ontology Language Overview,," 
World Wide Web Consortium,, 10 February 2004. 
[Online]. Available: http://www.w3.org/TR/owl-
features/. [Accessed 14 November 2013]. 
[14]  G. Wiederhold, "Mediators in the Architecture of 
Future Information Systems", The IEEE Computer 
Magazine, 1992.  
[15]  B. Ludäscher, K. Lin, B. Brodaric and C. Baru, 
"GEON: Toward a Cyberinfrastructure for the 
Geosciences—A Prototype for Geologic Map 
Integration via Domain Ontologies", Digital 
Mapping Techniques ’03 — Workshop Proceedings, 
U.S. Geological Survey Open-File Report 03–471, 
2003.  
[16]  T. Bray, J. Paoli, C. M. Sperberg-McQueen, E. 
Maler and F. Yergeau, "Extensible Markup 
Language (XML) 1.0 (Fifth Edition), W3C 
Recommendation 26 November 2008, World Wide 
Web Consortium (W3C)," 
http://www.w3.org/TR/REC-xml/, last accessed Nov 
2014, November 2008. 
[17]  S. Gao, C. M. Sperberg-McQueen, H. S. Thompson, 
N. Mendelsohn, D. Beech and M. Maloney, ""W3C 
XML Schema Definition Language (XSD) 1.1 Part 
1: Structures", W3C Recommendation 5 April 2012, 
World Wide Web Consortium (W3C), 
http://www.w3.org/TR/xmlschema11-1/," last 
accessed Nov 13, 2014, 5 April 2012. 
[18]  J. Melton, "ISO/IEC FDIS 9075-1 Information 
technology - Database languages - SQL - Part 1: 
Framework (SQL/Framework), ISO Draft 
International Standard, ISO/IEC JTC 1/SC 32 Data 
Management and Interchange," 
http://www.jtc1sc32.org/doc/N2151-
2200/32N2153T-text_for_ballot-FDIS_9075-1.pdf, 
last accessed Nov 13, 2014, August 2011. 
[19]  J. Robie, D. Chamberlin, M. Dyck and J. Snelson, 
"XQuery 3.0: An XML Query Language," W3C 
Recommendation 08 April 2014, World Wide Web 
Consortium (W3C), http://www.w3.org/TR/xquery-
30/, April 2014. 
[20]  B. Motik, B. Cuenca Grau, I. Horrocks, Z. Wu, A. 
Fokoue and C. Lutz, "OWL 2 Web Ontology 
Language Profiles (Second Edition)," W3C 
Recommendation 11 December 2012, World Wide 
Web Consortium (W3C), 
http://www.w3.org/TR/owl2-profiles/, last accessed 
Nov 13, 2014, December 2012. 
[21]  I. Nonaka and D. J. Teece, Managing Industrial 
Knowledge: Creation, Transfer and Utilization, 
London: SAGE Publications, 2001, pp. 13-28. 
[22]  F. Miltner, "Wissensbasiertes Prozessmanagement - 
Rollen, Kollaborationen und Schnittstellen - am 
Beispiel der Integration von SharePoint und WPIM," 
Hagen, 2013. 
[23]  L. Wang and W. Shen, Process planning and 
scheduling for distributed manufacturing, London: 
Springer, 2007.  
[24]  Environmental Systems Research Institute Inc., 
"Technical Description, An ESRI White Paper," 
http://www.esri.com/library/whitepapers/pdfs/shapef
ile.pdf, Redlands, CA, July 1998. 
[25]  ISO International Standard 10303-1:1994 Industrial 
automation systems and integration -- Product data 
representation and exchange -- Part 1: Overview and 
fundamental principles, International Organization 
for Standardization, Geneva, Switzerland (1994). 
[26]  ISO International Standard 10303-11:1994, 
Industrial automation systems and integration — 
Product data representation andexchange — Part 11: 
Description methods: The EXPRESS language 
57
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

reference manual, International Organization for 
Standardization, Geneva, Switzerland (1994). 
[27] ISO International Standard 14649-1:2003. Industrial 
automation systems and integration -- Physical 
device control -- Data model for computerized 
numerical controllers -- Part 1: Overview and 
fundamental principles. Geneva: International 
Organization for Standardization. Retrieved 2008-
10-27. 
[28] Vogel, Tobias. www.inKNOWvation.de. WPIM - 
Wissensbasiertes und Prozessorientiertes 
Innovationsmanagement. [Online] 2012. [Quote 
from: 1st May 2015.] 
http://www.inKNOWvation.de. 
 
58
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

APPENDIX
 
Figure 12. Entire CAPP process mediator architecture 
59
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

