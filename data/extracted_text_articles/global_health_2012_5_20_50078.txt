Detecting depression using a multidimensional model of emotional states
Imen Tayari Meftah1,2 and Nhan Le Thanh1
1INRIA Sophia Antipolis
CNRS and University of Nice Sophia Antipolis
Sophia Antipolis, France
Email: tayari@i3s.unice.fr, nhan.le-thanh@unice.fr
Chokri Ben Amar2
2University of Sfax and ENIS
REGIM laboratory
Sfax, Tunisia
Email: chokri.benamar@enis.rnu.tn
Abstract—Depression is a major problem in our society. It
causes great pain and suffering for patients and their families.
The purpose of this study is to detect persistent negative
emotions for early detection of depression using physiological
sensors. Therefore, we develop an automatic depression pre-
vention tool using an algebraic model of emotional states. This
algebraic model provides to represent emotions and provides
powerful mathematical tools for the analysis and the processing
of these emotions. It consists of representing and detecting
negative emotions. Experiments show the efﬁciency of the
proposed method in detecting negative emotions by giving high
recognition rate.
Keywords-depression; algebraic representation ; negative emo-
tions; physiological signal.
I. INTRODUCTION
Negative emotions (anxiety, fear, anger, and grief) may
affect physical health and the quality of life. Indeed, people
with depression experience severe and prolonged feelings
of negative emotions like sadness, anger, disgust and fear.
Depression is a common yet serious illness. It is a common
problem that carries a high burden of suffering. In fact, the
inability to diagnose clinical depression early, can have a
serious impact on suffers, including the risk for suicidal
ideation. Thus, Gotlib and Hammen [1] and Chynoweth et
al. [2] demonstrate that most suicides are linked to depres-
sive disorders and symptomatology. Depressed individuals
experience prolonged periods of hopelessness, anger, guilt,
desperation and a tendency to suicidal thoughts. Studies
suggest that effective treatments for depression which may
be aided by the detection of the problems in its early stages.
In this context, and as part of GERHOME project [3],
we aim to develop an automatic health care system that
would assist mental health professionals by providing early
warning-signs indicating whether a patient is likely to be
depressed through their emotional states. The objective of
GERHOME project is to create a research infrastructure that
will enable experiments with technologies for improving the
quality of life for the elderly. In fact, older adults generally
want to be treated at home and with as little pain and
discomfort as possible. Therefore our tool can be integrated
in smart home (SH) in order to prevent depression and detect
the mood disorders. For this, we use physiological signals
to detect speciﬁc emotions and then to prevent depression.
More physiological parameters can be measured directly by
wearable sensors or can be derived from the analysis and
correlation of different signals. For example, we can use a
watch or a bracelet to capture the heart rate, an earring for
Blood Volume Pulse and a shoe for the skin conductivity [4].
Therefore, our system permits to improve the quality and
efﬁciency of health care at home by preventing depression.
It is based on an algebraic model of emotional states [5]
and it consists of representing and detecting of persistent
negative emotional states.
The remainder of this paper is organized as follows.
In Section 2, we deﬁnes depression and then we give an
overview of related works on human emotion research. In
Section 3, we describe our model to represent emotions. In
Section 4, we describe our method of detection of negative
emotion based on physiological signal and we conclude in
Section 5.
II. DEPRESSION AND DESCRIPTIVE SCHEMES FOR
EMOTIONS
In order to detect depression, our method is based on
detecting negative emotions. In this section we deﬁnes
depression and then we give an overview of related works
on human emotion research.
A. Depression
Depression and anxiety disorders are highly prevalent
worldwide. Statistics demonstrate that approximately 150
million people suffer from a major depressive disorder at any
moment, and almost a million commit suicide each year [1]
[6]. Depression is deﬁned in medical dictionaries as a phys-
iological and metaphorical lowering of emotional function.
Someone with depression experiences extreme sadness or
despair that lasts for at least two weeks or longer. Indeed one
of the features of major depression is not that people have
negative reactions to negative situations, it is that they cannot
pull themselves out of those negative emotional moods [7].
Our goal is to detect persistent negative emotions in order
to prevent depression.
101
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-243-1
GLOBAL HEALTH 2012 : The First International Conference on Global Health Challenges

B. Descriptive Schemes for Emotions
An emotion is the consequence of a feeling or the grasping
of a situation and generates behavioral and physiological
changes. Emotion is a complex concept. Darwin [8] said
that emotional behavior originally served both as an aid to
survival and as a method of communicating intentions. He
thought emotions to be innate, universal and communicative
qualities. Ekman [9], Izard [10], Plutchik [11], Tomkins
[12] and MacLean [13] have developed the theory that
there is a small set of basic emotions out of which all
others are compounded. The most famous of these basic
emotions are the Big Six, used in Paul Ekman’s research
on multi-cultural recognition of emotional expressions [14].
The Big Six emotions are happiness, sadness, fear, surprise,
anger and disgust. According to research in psychology, two
major approaches to affect modeling can be distinguished:
dimensional and categorical approach. The dimensional ap-
proach models emotional properties in terms of emotion
dimensions. It decomposes emotions over two orthogonal
dimensions, namely arousal (from calm to excitement) and
valence (from positive to negative) [15]. The second ap-
proach posits a ﬁnite set of basic emotions which are
experienced universally across cultures (e.g., Plutchik [11],
Tomkins [12], Ekman [9], etc) . In our study, we opted for
Plutchik approach as the basis of our model and will thus
describe it in details.
1) Plutchik model:
Robert Plutchik proposed a three-
dimensional ”circumplex model” which describes the re-
lationships between emotions. He proposed eight primary
emotion dimensions arranged as four pairs of opposites [11]:
(Joy-Sadness, Fear-Anger, Surprise-Anticipation, Disgust-
Trust). The vertical dimension represents intensity or level
of arousal, and the circle represents degrees of similarity
among the emotions. He suggested that non-basic emotions
are obtained through the addition of basic emotions (color
analogy, Plutchik, 1962) [16]. In his model, for instance,
remorse = sadness + disgust and contempt = disgust +
anger. Plutchik deﬁned rules for building complex emotions
out of basic ones. In practice, combination of emotions
follows the method ”dyads and triads” [17]. He deﬁned the
primary dyads emotions as the mixtures of two adjacent
basic emotions. Secondary dyad includes emotions that are
one step apart on the ”emotion wheel”, for instance Fear
+ Sadness = Despair. A tertiary emotion is generated from
a mix of emotions that are two steps apart on the wheel
(Surprise + Anger = Outrage).
III. THE PROPOSED EMOTIONAL MODEL
In this section, we present our approach of modeling
emotional states. Indeed, the proposed model is different
from traditional approaches like ontological representation.
It is based on an algebraic representation using multidi-
mensional vectors. We represent every emotion as a vector
in a space of 8 dimensions where every axis represents a
basic emotion. This multidimensional model provides the
representation of an inﬁnity of emotions and provides also
a powerful mathematical tools for the analysis and the
processing of these emotions. The proposed model is similar
to the RGB colors representation model which is based on
three basic colors (Red, Green, Blue) to build all the others
ones. For example, blue and yellow paints mix together to
create a green pigment. In order to develop this analogy,
it’s necessary to deﬁne the basic emotions. For this, we
will adopt the Plutchik deﬁnition of basic emotions which
is a very intuitive and easy model including the idea that
complex emotions are obtained by mixing primary ones.
This last property is very important on our model because
it allows us to deﬁne an inﬁnity of combinations using the
eight basics emotions deﬁned by Plutchik.
A. Deﬁnition
The proposed model consists on the representation of
emotions using multidimensional vectors. We represent ev-
ery emotion as a vector in a space of 8 dimensions where
each axis represents a basic emotion. First, we deﬁne our
Base by (B) = (joy, sadness, trust, disgust, fear, anger,
surprise, anticipation). So, every emotion (e) can be ex-
pressed as a ﬁnite sum (called linear combination) of the
basic elements.
(e) =
8
∑
i=1
⟨E, ui⟩ui
(1)
thus, (e)
=
α1Joy + α2sadness + α3trust + .. +
α7Surprise + α8anticipation
where αi are scalars and ui(i = 1..8) elements of the basis
(B). Typically, the coordinates are represented as elements
of a column vector E
E =






α1
α2
.
.
α8






B
where αi ∈ [0, 1] represents the intensity of the respective
basic emotion. More the value of αi get nearer to 1, more
the emotion is felt.
In linear algebra, a basis is a set of vectors that, in a
linear combination, can represent every vector in a given
vector space or free module, and such that no element of
the set can be represented as a linear combination of the
others. We have demonstrate that (B) satisﬁes the spanning
property and the linear independence property [5]. Thus, we
proved that (B) = (joy, sadness, trust, disgust, fear, anger,
surprise, anticipation) is a linearly independent spanning set.
102
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-243-1
GLOBAL HEALTH 2012 : The First International Conference on Global Health Challenges

B. Representation of basic emotions
A vector represents a basic emotion if it veriﬁes the
following property:
∀i ∈ [1..8], ∃αi with
αi
8∑
i=1
αj
= 1
(2)
A basic emotion is described by a vector which contains a
single non-zero coefﬁcient. The following vectors represent
some basic emotions:
Edisgust =












0
0
0
α4
0
0
0
0












B
Esadness =












0
α2
0
0
0
0
0
0












B
where α4, α6 ̸= 0
The proposed model takes into account the property of
the intensity of the emotion. Indeed, each emotion can
exist in varying degrees of intensity. The coefﬁcients αi
determine the emotion intensity. According to the value of
the coefﬁcients αi we can make the difference between
annoyance, anger and rage or pleasure. So, rage is the basic
emotion anger with high intensity. The multidimensional
model provides the representation of an inﬁnity of emotions
and provides also a powerful mathematical tools for the
analysis and the processing of these emotions. Indeed, we
can apply the usual basic algebraic operations on vectors like
the addition, the scalar multiplication, the projection and the
distance in an Euclidean space. We are going to detail only
the addition. For more details, you can see [5].
C. Vector addition
We have seen in the previous paragraphs that the mixture
of pairs of basic emotions resulted of complex emotion.
fear and sadness for example produce the complex emotion
”despair”. ”envy” is a mixture of sadness and anger. In this
part we deﬁne the combination between emotions as the
sum of two emotion vectors. This addition is deﬁned as
the maximum value of coefﬁcients (term by term). Let E1u
and E2u be two emotional vectors expressed in the basis
(B) respectively by (λ1, λ2, .., λ8) and (λ
′
1, λ
′
2, .., λ
′
8). The
addition of these two vectors is deﬁned as:
E
′ = E1u
⊕
E2u = max(λi, λ
′
i)for0 ≤ i ≤ 8
(3)
In this sense, the vector representing the emotion despair,
which is mixture of fear and sadness, is deﬁned as:
Edespair = Efear
⊕ Esadness
Figure 1.
Combination and opposites on the Plutchik’s model
Edespair =










0
0
0
0
α5
0
0
0










B
⊕










0
α2
0
0
0
0
0
0










B
=










0
α2
0
0
α5
0
0
0










B
where α2 ̸= 0 et α5 ̸= 0
In the same way, we can obtain the ”vector form” of the
other complex emotions states deﬁned by Plutchik. These
emotions combinations are shown on (Figure 1).
IV. METHOD OF DETECTION OF NEGATIVE EMOTIONS
In our study, we explore the use of physiological signals
for detecting persistent negative affects. We elaborate an
emotion recognition method from Physiological Data based
on signal processing algorithm. Our method permits to rec-
ognize emotion composed of several aspects like simulated
and masked emotions. The data used for this study comes
from the data collected in the MIT Media Lab: Affective
Computing Group [18]. MIT’s data set comprised four
physiological signals, obtained from the masseter muscle
(EMG), blood volume pressure (BVP), skin conductance
(GSR) and respiration rate (RESP) collected over a period of
20 days, concerning eight emotions: the neutral state, anger,
hate, grief, platonic love, romantic love, joy and reverence.
Our approach is composed of two modules: training
module and the recognition module. In the training module,
feature vectors are extracted from emotion training patterns.
In the recognition module, classiﬁcation has been performed
by using the K-Nearest Neighbor algorithm. The result is a
8 component vector representing the detected emotion. This
103
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-243-1
GLOBAL HEALTH 2012 : The First International Conference on Global Health Challenges

Figure 2.
An example of a session data collected from four sensors [18]
 
Figure 3.
Segmentation of the signal by emotion
vector is transformed to XML data thanks to the three layer
model [19]. Let us here present the two modules of the
proposed emotion recognition method.
A. Training module and features extraction
This session explains the proposed method to collect
training data. Our newly developed method is based on
feature extraction using signal processing techniques. The
data consist of 25 minutes of recording time per day over
a period of 20 days. Each day includes 4 signals showing
8 states in the order: the neutral state, anger, hate, grief,
platonic love, romantic love, joy and reverence (Figure 2).
Healey’s original data was sampled at a rate of 20 samples
per second, creating a digital version of the signal [18].
The signal processing for each sensor, include isolation
of each emotion, smoothing, peak detection and features
extraction (c.f. Figure 2). The global scheme of the features
extraction is given by Figure 4. Firstly, we segmented the
data, according to the emotions elicited at corresponding
time frames (for example, although the recording time was
25 minutes, we only used the data from the time frame
when the appropriate emotion (e.g., anger) happened). Let
A designates the samples taken from any one of the eight
emotions and any one of the four sensor (e.g., emotion
anger, sensor: EMG). We process each appropriate emotion
data separately to extract 30 representative vectors for this
emotion. This is done by applying 3 major steps. First,
Figure 4.
The global scheme of the features extraction module
we smooth the signal to reduce its variance and facilitate
the detection of its maxima and minima. That is why we
apply Hanning window (smooth curve) [20]. Secondly, we
compute the gradient of the signal and we apply the zero-
crossings method to detect the peaks. Thirdly, we extract fea-
tures for each emotion by computing typical statistical values
related to peak, such as mean value, standard deviation, the
amplitude and the width of peak. These data will be stored
in a vector (the emotion feature vector) which corresponds to
the appropriate emotion. Thus, we built an emotion training
data base composed by 240 vectors representing the eight
affective states.
B. Recognition module
The recognition module consists of two steps: (i) features
extraction to have test data set and (ii) classiﬁcation. Test
data set was done by using similar steps to the training
data, except that it does not have the emotion information.
However, we used the K-Nearest Neighbor algorithm (KNN)
[21] to classify an instance of a test data into an emotion
classe. Infact, K-Nearest Neighbor (KNN) classiﬁcation is a
powerful classiﬁcation method. The key idea behind KNN
classiﬁcation is that similar observations belong to similar
classes. Thus, one simply has to look for the class designa-
tors of a certain number of the nearest neighbors and sum up
their class numbers to assign a class number to the unknown.
In practice, given an instance of a test data x, KNN
gives the k neighbors nearest to the unlabeled data from
the training data based on the selected distance measure and
labels the new instance by looking at its nearest neighbors. In
our case, the Euclidean distance is used. The KNN algorithm
ﬁnds the k closest training instances to the test instance.
Now, let the k neighbors nearest to x be Nk(x) and c(z) be
the class label of z. The cardinality of Nk(x) is equal to k.
Then the subset of nearest neighbors within class (e) ∈ the
neutral state, anger, hate, grief, platonic love, romantic love,
joy and reverence is
N e
k(x) = {z ∈ Nk(x), c(z) = e}
(4)
We then normalize each N e
k(x) by k so as to represent
probabilities of belonging to each emotion class as a value
between 0 and 1. Let the lower case ne
k(x) represent the
104
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-243-1
GLOBAL HEALTH 2012 : The First International Conference on Global Health Challenges

normalized value. The classiﬁcation result is deﬁned as
linear combination of the emotional class.
e∗ =
∑
< ne
k(x), e > e
(5)
Thus,
e∗ = nnoemotion
k
(x) noemotion + nanger
k
(x) anger
+... + njoy
k
(x) joy + nreverence
k
(x) reverence.
(6)
Thus, we build a probability model for each emotion class
where ne
k(x) represents the probability of the respective
emotion class. For example, if k = 10 and 8 of the nearest
neighbors are from emotion class anger and the other 2
are grief, then emotion class anger has an intensity value
of 0.8 (nanger
10
(x) =0,8) and emotion class grief has an
intensity value of 0.2 (ngrief
10
(x)=0.2). The classiﬁcation
result is deﬁned as: (e∗) = 0.8anger + 0.2grief. Thus,
our recognition method builds a probability model for each
class and permits to recognize emotion composed of several
aspects. Therefore, we get all the information on the emo-
tion. This representation can be transformed, therefore, to
the generic computational model of emotional states deﬁned
on Section 2 by applying the transformation matrix. Thus,
we obtained eight emotional vector expressed in the basis
(B). Then, we applied Plutchik’s rules (c.f. Figure 2) to
generate a data base of emotion for use at a later time.
For example, grief is the basic emotion sadness with high
intensity. Therefore, we can generate the emotion vector
sadness. Either, we can generate the emotion vector ”guilt”
by combining joy and fear and the emotion vector”despair”
by combining fear and sadness.
V. DETECTION OF DEPRESSION AND RESULTS
A. Detection of depression
We have already generated our data base of emotion, as
explained before. It consisting of emotion vectors classiﬁed
into 2 categories: negative and positive emotions. Negative
emotions are, for example: grief, sadness, despair, hate,
anger etc. Positive emotions are, for example: joy, romantic
love, platonic love, reverence etc. Our method consists on
detecting and classifying all the emotions felt throughout
the day and give a global report. However, to analyze a
given vector and determine the nearest emotion from the
known ones we need a tool to calculate the similitude from
the vector and the known emotions. For this, we propose
to use the Euclidean distance (2-norm distance). Therefore,
we have to compute for a given vector V1 the Euclidean
distance between it and all the vectors of the data base.
Then, we keep the vector of the data base minimizing
the Euclidean distance. This vector represents the nearest
emotion of V1 and the computed distance gives an idea
of the precision of this interpretation. For example, we can
found that the nearest emotion for the vector V1 is ”despair”
with a distance equals to zeros. We can afﬁrm without doubts
that V1 represents the emotion ”despair”. More the distance
from the nearest vector is important, less the interpretation
is accurate. So, the proposed method, using the Euclidean
distance, permits to analyze automatically a given vector and
provides the best interpretation of this vector.
Algorithm 1 Detection of depression
1: int negative day = 0
2: while negative day¡14 do
3:
while True do
4:
Wait for new day();
5:
Ed= Emotion Detection(); //gives all the emo-
tions felt throughout the day
6:
boolean day is negative=positive or negative(Ed);
//gives true if the new day is a negative day
7:
if day is negative then
8:
negative day + +;
9:
else
10:
negative day = 0;
11:
end if
12:
end while
13: end while
14: send alert();.
As previously stated, to detect depression we focus mainly
on negative emotions. Therefore, we propose a method to
classify all the emotions felt throughout the day and give
a health check. For example, a day with more negative
than positives emotions felt is considered as a negative day.
In fact, according to [7] [22], a person who experiences
negatives emotions for longer than a two-week period,
may be diagnosed with major depressive disorder. Thus,
the proposed algorithm calculates the number of successive
negative days in order to prevent depression. If the number
of successive negative days is greater than 14 (two weeks),
our system conclude that the person could be suffering from
depression and sends an alert message to the doctor (see
algorithm 1).
B. Results
As shown in Figure 5.1, the analysis of the EMG signal
using the proposed method, gives high accuracy percentage
of detection of negative emotions. Indeed, we obtained for
example 92% for anger and 62% for hate and 58% for
grief. Figure 5.2 shows the results of accuracy obtained
using the respiration (RESP) signal. Our method recognized
anger with more than 73%, hate with 66.66% and grief
with 50.58%. As know, it is hard to recognize emotions
very accurately only with one modality. For this reason, we
plan, for the future work, to conduct studies on multimodal
recognition. Indeed, by applying two modalities, results
could be improved up to 82%. Figure 6 gives an example
of report generated after applying the algorithm of detecting
depression along a period of 25 days. In the ﬁrst scenario,
105
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-243-1
GLOBAL HEALTH 2012 : The First International Conference on Global Health Challenges

Figure 5.
The classiﬁcation rates of the proposed method using EMG and
RESPIRATION signal
Figure 6.
Depression detection
our algorithm calculate the number of successive negative
days and conclude that the person could be suffering from
depression and sends an alert message to the doctor. How-
ever, in the second scenario, our algorithm conclude that the
person have a normal mood state.
VI. CONCLUSION AND FUTURE WORK
In this paper, we have presented a new approach for pre-
vention and early detection of depression using physiological
sensors. it consists of two main steps: the capture of phys-
iological features and analysis of emotional information.
The ﬁrst step permits to detect emotions felt throughout the
day. The second step consists on analyzing these emotional
information to prevent depression. For emotion detection, we
used signal processing algorithms to extract features and the
the K-Nearest Neighbor algorithm to classify the emotion.
Experiments show the efﬁciency of the proposed method in
detecting negative emotion by giving high recognition rate.
Finally, our system evaluate emotional information in order
to detect depression and send an alert to the doctor. For
the future work, we would extend our method to take into
account others information such as voice communications,
daily patterns of sleeping, eating, social interactions and
online behaviors to improve prevention of depression.
REFERENCES
[1] I.
Gotlib
and
C.
Hammen,
Handbook
of
De-
pression.
Guilford
Press,
2002.
[Online].
Available:
http://books.google.fr/books?id= ZS XP7d7ukC
[2] R. Chynoweth, J. I. Tonge, and J. Armstrong, “Suicide in
brisbane - a retrospective psychosocial study,” Australian and
New Zealand Journal of Psychiatry, pp. 37–45, 1980.
[3] CSTB,
“Gerhome
project,”
http://gerhome.cstb.fr/en/home/introduction.html, September
2009.
[4] R. Picard and J. Healey, “Affective wearables,” in ISWC ’97
In Proceedings of the 1st IEEE International Symposium on
Wearable Computers (1997), 1997, pp. 231 –240.
[5] I. Tayari Meftah, N. L. Thanh, and C. Ben Amar, “Towards an
algebraic modeling of emotional states,” in Fifth International
Conference on Internet and Web Applications and Services
ICIW’10, May 2010, pp. 513 –518.
[6] E. Van’t Hof, P. Cuijpers, W. Waheed, and D. J. Stein, “Psy-
chological treatments for depression and anxiety disorders in
low- and middle- income countries: a meta-analysis.” African
Journal of Psychiatry, pp. 200–207, 2011.
[7] T. Johnstone, C. M. V. Reekum, H. L. Urry, N. H. Kalin,
and R. J. Davidson, “Failure to regulate: counterproductive
recruitment of top-down prefrontal-subcortical circuitry in
major
depression,”
Journal
of
Neuroscience,
vol.
27,
no. 33, pp. 8877–8884, August 2007. [Online]. Available:
http://centaur.reading.ac.uk/4367/
[8] C. Darwin, The expression of the Emotions in Man and
Animals, 3rd ed.
Oxford University Press Inc, 1872.
[9] P. Ekman, Emotion in the human face. Cambridge University
Press, New York, 1982.
[10] C. E. Izard, Human emotions, S. Verlag, Ed.
Plenum Press,
New York, 1977.
[11] R. Plutchik, Emotion, a psychoevolutionary synthesis. Harper
and Row, New York, 1980.
[12] S. Tomkins, “Affect as ampliﬁcation: some modiﬁcations in
theory,” Theories of emotions, vol. 1, New York, Academic
Press., pp. 141–165, 1980.
[13] P. D. Maclean, Cerebral evolution of emotion, handbook of
emotions ed.
Guilford Press, New-York, 1993.
[14] P. Ekman and R. J. Davidson, The nature of emotion :
Fundamental questions. Oxford University Press, New York,
1994.
[15] J. Russell, “A circumplex model of affect,” Journal of Per-
sonality and Social Psychology, no. 39, pp. 1161–1178, 1980.
[16] R. Plutchik, The Emotions: Facts, Theory and a New Model,
ser. Studies in psychology. Random House, New York, 1962.
[17] M. de Bonis, Connaitre les ´emotions humaines, Mardaga, Ed.
Psychologie et sciences humaines, 1996, vol. 212.
[18] J. Healey, “Wearable and automotive systems for the recog-
nition of affect from physiology,” Ph.D. dissertation, Mas-
sachusetts Institute of Technology, 2000.
106
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-243-1
GLOBAL HEALTH 2012 : The First International Conference on Global Health Challenges

[19] I. Tayari and N. Le Thanh, “Sharing Emotional Information
Using A Three Layer Model,” in The Sixth International
Conference on Internet and Web Applications and Services
(ICIW 2011), IARIA.
Maarten, Netherlands Antilles: Xpert
Publishing Services, 2011.
[20] B. Julio and D. R. I., “On the use of the hanning window
for harmonic analysis in the standard framework,” IEEE
transactions on power delivery, vol. 21, no. 1, pp. 538– 539,
2006.
[21] P. Cunningham and S. J. Delany, “k-nearest neighbour clas-
siﬁers,” University College Dublin, Dublin Institute of Tech-
nology, Technical Report, 2007.
[22] “Mental health a report focusing on depression,” Common-
wealth Department of Health and Aged Care and Australian
Institute of Health and Welfare, National Health Priority
Areas Report, 1998.
107
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-243-1
GLOBAL HEALTH 2012 : The First International Conference on Global Health Challenges

