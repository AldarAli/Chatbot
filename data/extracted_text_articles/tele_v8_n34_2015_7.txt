189
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
A Hardware and Software System for Information Interchange in Multinational 
Disaster Relief Operations 
 
Peter Dorfinger, Ferdinand von Tüllenburg, Georg Panholzer, Thomas Pfeiffenberger 
Advanced Networking Center 
Salzburg Research Forschungsgesellschaft mbH 
Salzburg, Austria 
e-mail: {peter.dorfinger, ferdinand.tuellenburg, georg.panholzer, thomas.pfeiffenberger}@salzburgresearch.at 
 
 
Abstract—Information 
and 
communication 
technology 
becomes more and more important for large scale disaster 
work as it allows for sharing information between stakeholders 
in short times. However, the interchange of disaster related 
information is often affected by missing communication 
coverage and outages of pre-existing infrastructure. Further 
problems arise, if multiple organizations from different 
countries shall share all their disaster related information. 
Until now, there is no ICT-System available for disaster relief 
work, which provides an integrated solution of communication 
technology 
and 
information 
sharing 
and 
visualization 
applications helping for creating a common understanding 
across national and organizational borders of what is 
happening in the disaster operation. In this paper a flexible 
infrastructure for information interchange of disaster related 
information is presented. The first main building block of this 
infrastructure is the disaster information system consisting of 
various IT systems and software applications used to produce, 
share and manage disaster data. The second building block is a 
mobile, and easy to handle 802.11 driven communication 
hardware and software system. This system is capable to bring 
communication coverage to almost every arbitrary location 
within a disaster area by setting up a meshed wireless network. 
The wireless network is used to connect end devices used by 
field personnel to the disaster information system. The 
communication system can be operated independently of any 
pre-existing infrastructure such as Internet access or power 
supply. Several training events showed the usability of the 
proposed solution and the advantages of a comprehensive ICT 
system in international disaster work. 
Keywords—Emergency network; 802.11 communication; 
interoperability; information interchange; disaster relief. 
I. 
INTRODUCTION 
One central problem when coordinating relief units in 
large scale disaster relief operations is to provide the right 
information to the right people. Especially in the context of 
international relief operations new coordination problems 
arise 
from differing structures of the international 
associations. Different languages causing communication 
difficulties and making information distrustful if not properly 
formulated information is leaving room for interpretation. An 
example for the impact of this problem is the earthquake 
disaster in L’Aquila, Italy. Here, the local authorities 
declined offered international help as the effort to integrate 
foreign relief organizations in their own relief work was 
considered as too high, requiring too much manpower 
urgently needed in other places in the disaster area. 
Information technology can prove extremely useful in 
information gathering, storing and sharing. However, it must 
be kept in mind, that information should be shared according 
to the principle “as much as necessary, as little as possible” 
in a way easily and clearly to understand in order to protect 
helpers from information overload. With the help of 
broadband 
communication 
technology 
the 
narrow 
information channels of radio messages or telephone calls 
could be prized by enriching transported information with 
videos, photos or sensor data. Experiences from the usage of 
such a system by end users in multinational disaster 
operations are presented in [1]. Within this paper we present 
in detail the technical framework behind such a broadband 
communication solution. 
Following the principle of sharing precise and 
comprehensive information to the right person has multiple 
advantages to enhance efficiency of disaster relief work. 
First, it prevents helpers from becoming overwhelmed by the 
volume of information transmitted by e-mails, radio 
messages and telephone calls – a fact that is often claimed by 
relief workers nowadays [2]. Second, correct decisions can 
be made more quickly in order to provide urgent needed aid 
to affected people. For example, by bringing all meaningful 
information to a team leader working in the field, the team 
leader could take the right decision autonomously [2]. 
This is where the IDIRA (interoperability of data and 
procedures in large-scale multinational disaster response 
actions) project [3] comes into the picture. IDIRA’s target is 
to enhance interoperability of organizations and their 
systems in order to streamline the cooperation in relief work.  
IDIRA addresses this interoperability topic twofold. 
First, 
at 
an 
organizational 
level, 
IDIRA examines 
possibilities to reach administrative coordination of multi-
national disaster relief organizations, each with their own 
workflows and procedures. Second, on the technical side, 
IDIRA provides a complete solution consisting of 
information systems, communication protocols, software 
applications, and standard data formats. The developed 
systems accompany the topics stated above: Bringing all 
meaningful information to exactly the people needing it to 
make correct decisions and present information in an 
unambiguous manner. 

190
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
This solution allows exchanging disaster related 
information between administrative operators, executive 
personnel, and other disaster management systems connected 
to IDIRA. With IDIRA, information on incidents, resources, 
observations, and sensor data should be collected and shared 
to various other information systems like mobile devices and 
command and control systems (C&C). To reach the required 
level of interoperability and automatic information exchange, 
IDIRA has a strong focus on mobility of the developed 
systems. It is necessary to bring the systems directly to the 
scene of the disaster, because of severe infrastructural 
damage after the disaster. 
A prerequisite for an information exchange is a working 
broadband communication infrastructure within the disaster 
area. One of the major problems we address with our 
proposed communication infrastructure is that after a large 
scale disaster, the existing public broadband network is often 
partially destroyed, overloaded, or hit by power outages. 
Consequently, first responders cannot rely on any pre-
existing infrastructure which may fail as a consequence of 
the disaster. 
As the communication network is essential for a more 
efficient collaboration between first responders, there is a 
critical need for the fast setup of alternative communication 
means. However, first responders are not experts in setting 
up communication equipment. Thus, easy setup and 
maintenance is heavily required for such systems. 
This paper will present an easy to install adhoc 
communication infrastructure for first responders to be used 
for an enhanced collaboration in large scale disaster 
operations.  
This paper is structured as follows: Section II presents 
technologies and standards used within IDIRA and gives a 
brief overview on alternative communication solutions for 
disaster operations. Section III describes the IDIRA 
information system, as an example for an enhanced 
information system useable in multinational disaster 
operations. Section IV presents the details of our proposed 
mobile communication solution. Section V concludes the 
paper and outlines further steps and ideas to improve our 
solution.  
II. 
RELATED WORK 
Within the IDIRA applications, disaster information is 
represented using the Emergency Data Exchange Language 
(EDXL) [4]. This is an open XML-based messaging format 
and suite of standards aimed at the use of information 
exchange in emergency management systems. The EDXL-
CAP (Common Altering Protocol) [5] data format is applied 
to data about occurred incidents registered, for example 
automatically by a sensor system or manually by a human 
user. Information about resources such as availability of 
relief units, emergency vehicles or electrical generators, are 
exchanged by EDXL-RM (Resource Messaging) [5] 
standard. 
The 
EDXL-SitRep 
(Situation 
Report) 
[7] 
messaging standard is used within the IDIRA context for 
exchanging information on observations and situation reports 
sent by commanders in the field via their mobile devices. 
These standards are not bandwidth optimized and potentially 
use large headers and large data payloads. Large scale 
disasters may result in thousands of such messages. 
Consequently, to transport this information a broadband 
communication infrastructure is needed. 
Nowadays, 
a 
broad 
variety 
of 
communication 
technologies are used by first responder relief organizations 
and the most widespread technology used for many years 
was standard voice radio. However, with the advent of 
mobile communication standards such as 2G, 3G, and 4G 
these technologies are increasingly displaced. There also 
exists technology that is more tailor-made to disaster relief 
organizations regarding mobility and independence of pre-
existing infrastructure such as working backbone networks 
and power supply. This makes sense as, for instance, mobile 
phone networks are often heavily overloaded or partly out of 
order after a disaster occurred. One approach to overcome 
these problems was TETRA [8]. TETRA allows both, range 
limited direct device to device communication without usage 
of a fixed infrastructure and range unlimited indirect 
communication via a fixed infrastructure. To enhance 
reliability of TETRA, the fixed infrastructure system was 
designed in a highly redundant way and is not made 
accessible to the public. The downside of TETRA is the 
limited 
bandwidth 
(28.8 
kbit/s) 
available 
for 
data 
communication. 
Other communication solutions are based on satellite 
communication systems like BGAN [9], VSAT [10], or 
Emergency.lu [11]. Satellite communication is used for both 
data and voice communication and is operable also in remote 
areas. The disadvantage of this technology is the usually high 
operational costs and, in case of BGAN, the very limited 
bandwidth. With the exception of BGAN satellite 
communication seems as a central Internet uplink technology 
in the disaster area and less as a communication technology 
used by field personnel to communicate with each other.  
Especially the limited or expensive data communication 
capabilities are making these technologies only usable to a 
restricted degree. IDIRA heavily depends on data exchange 
with higher bandwidth demands and limited latency. One 
example is user interaction via IDIRAs web interface - the so 
called Common Operational Picture (COP). Here, data are 
exchanged between web clients of tactical personnel at the 
Command & Control Center and field commanders. To 
bootstrap a device using COP an initial data download of 
about 10 Mbyte of data is necessary and for a seamless 
operation a bandwidth of about 2 Mbit/s is recommended.  
Another problem arises from special international 
operating permissions and licenses needed for some 
communication 
technologies 
such 
as 
WiMAX 
[12] 
equipment. 
Moreover, for 
a 
communication 
system 
specifically designed for public protection and disaster relief 
(PPDR) called Highly Mobile Network Node (HiMoNN) 
[13] operating licenses are only available for a few countries 
worldwide. HiMoNN is designed in compliance with ECC 
Recommendation 
(08)04 
[14], 
and 
operates 
with 
transmission power of 8W in the 5GHz frequency band. It is 
able to transmit data over a distance of several kilometers 
with a bandwidth of 28Mbit/s. 

191
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
To overcome the problems of international operation 
permissions also other approaches were considered. For 
example, in the work of Raffelsberger and Hellwagner it is 
proposed to build up a mobile ad-hoc network (MANET) 
using the end user devices of first responders as 
communication hops [15]. These devices are using their 
802.11 wireless network interfaces to build up connections to 
other devices. This approach overcomes problems with 
missing operation permissions as 802.11 equipment can be 
operated all over the world without special license. During 
operation, first responders sending data via this MANET to a 
central host located in the Command and Control Center also 
employing special routing protocols. However, a quite dense 
concentration of devices is necessary making it difficult to 
use this technology to bridge distances of several kilometers 
to reach the central host. Another approach [16] overcomes 
the problem of low device density by placing mobile devices 
as stationary relays. It achieves this by using the mobile 
devices of disaster survivors to set up a disaster recovery 
network using 802.11 Wi-Fi. In contrast to other discussed 
approaches it focuses on connectivity for the survivors 
instead of the rescue teams, but can be used for both. Their 
approach and ours can be combined for greater range and 
flexibility. 
The communication system proposed in this paper also 
uses 802.11 [17], as this technology is widespread, cheap 
and can be used all over the world without special licenses. 
One of the main achievements of this work was to provide a 
solution for the problem of limited range between two 
802.11 end points.  
As routing protocol we use the Optimized Link State 
Routing Protocol (OLSR) [18], which is optimized for 
constrained wireless LANs. OLSR is based on multipoint 
relays in order to reduce the routing overhead on the 
network. 
III. 
IDIRA DISASTER INFORMATION SYSTEM 
In IDIRA, an information system is developed that 
improves information sharing and information presentation 
in disaster relief work. On the technical side, this information 
system consists of various software applications and specific 
hardware solutions allowing, for example, optimal resource 
planning 
and 
decision finding across 
national and 
organizational borders. This section gives an overview of 
applications and hardware infrastructure developed within 
IDIRA. 
Various software applications were developed to support 
information collection, data analysis, decision finding, and 
information sharing and presentation. 
One main building block of IDIRA’s information system 
is the disaster information data store, a central system used 
for storing all information related to the disaster. The data 
store comprises of information about incidents and 
observations or sensor data. Furthermore, information about 
available resources in the field - such as positions, tasks and 
utilization is stored as well as geographic information about 
infrastructural facilities like hospitals. Also, other important 
information such as weather data is contained within the data 
store. 
To store and transmit this information, standardized 
protocols and data formats are used, for example, the 
Emergency Data Exchange Language (EDXL) standardized 
by OASIS [4]. 
An example for automatic information collection and 
using EDXL is the sensor data integration. IDIRA supports 
automatically inducing data generated by different sensors 
using the OGC Sensor Observation Service (SOS) interface. 
IDIRA uses a generic Senor Fusion Engine (SFE) for sensor 
data aggregation. In case of a pre-defined behavior is 
recognized, the SFE generates an alarm messages in EDXL-
CAP format [19]. The EDXL-CAP is one specific message 
format defined by OASIS specifically for information 
interchange in disaster operations [5]. The standard CAP 
message contains information such as type of emergency, 
source of information, level of severity, location, and extent 
of disaster. A link to detailed information, such as state of 
damage and numbers of casualty for all settlements affected 
and, for example, coordinates of the nearest airports can be 
provided in the CAP message. Also, information related to 
availability and status of resources such as a fire fighting 
vehicle or some other technical equipment like water pumps 
is shared using EDXL. For this purpose, the EDXL-RM 
(Resource Messaging) [5] standard is used. The EDXL-
SitRep (Situation Report) [7] messaging standard is used 
within the IDIRA context for exchanging information on 
observations and situation reports, e.g., generated by 
commanders in the field. 
Several software applications were developed within 
IDIRA to insert, produce, share and process disaster data. To 
support optimal decision finding and risk management 
various simulation tools were integrated. For example, a fire 
simulation tool (FireSim) can be used to simulate the spread 
of forest fires [20] and a chemical accident simulation tool 
(ChemSim) is used to simulate the propagation of possibly 
toxic gases and chemicals. These simulators are mostly 
based on weather data such as wind strength and direction 
and several geographic parameters such as soil conditions 
and even more specific parameters such as dissolution rates 
of chemicals. An evacuation simulator can be used to 
calculate the safest way for evacuating people out of districts 
also considering geographic information and observations 
such as obstacles or dangerous areas. For improved resource 
allocation an optimal spatial partitioning algorithm was used 
[21]. 
Further decision support systems are integrated into 
IDIRA covering routing and load balancing capabilities. 
Using these applications feasible paths for vehicles or relief 
workers can be calculated. Also, questions can be answered 
such as which unit can reach a certain destination within a 
given amount of time, or which unit can be at the destination 
most quickly. Load balancing algorithms are supported, e.g., 
to distribute injured people optimally to medical facilities 
while preventing from overload. 
One further application of IDIRA is the integrated 
reporting system. Using the reporting application reports can 
be 
generated 
containing all meaningful information 
depending on the person the report is generated for. This 
helps protecting relief workers from information overload. 

192
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Another useful application developed within IDIRA is 
missing person tracing. This application helps to match data 
of missed persons with data of rescued persons across 
different tracing systems.  
Furthermore, a software interface exists in IDIRA, which 
allows creating connections to external applications like 
specialized management tools used by a certain unit or 
organization. Usually, for data exchange between IDIRA and 
the external application, a standardized message format such 
as EDXL is used. The IDIRA information system is designed 
to gather from and to provide information to local command 
and control infrastructures. For example, in case of 
earthquakes, the information of external agencies such as the 
German Geoforschungszentrum, the US Geological Survey 
or the European Mediterranean Seismological Center can be 
induced into the IDRIA information system. 
 
 
Figure 1: Disaster Information viewed by the COP. 
The centerpiece of information presentation is the so 
called Common Operational Picture (COP). The COP is a 
web based application having its main goal to present all 
information in the system in an understandable and tailor-
made way to the distinct users of the system, such as field 
commanders, tactical commanders, authoritative person or 
other stake holders within disaster relief work. Mainly, COP 
visualizes incidents, resources, tasks and other relevant 
information for disaster management on a map that can be 
seen in Figure 1. This map shows the epi center and affected 
regions of an earthquake, the position of resources or the 
location of incidents. Applying various filters and utilizing 
additional views on the available disaster information, COP 
helps to maintain an overview of the situation and protects 
from overlooking important details on a topic while 
simultaneously protecting the user from data overload. 
Furthermore, COP supports communication capabilities 
helping to get in touch with people involved in current relief 
work. Tasks can be assigned to field units, updates on tasks 
can be communicated by field units, text messages can be 
sent, or voice calls initiated. 
The COP and most of the applications introduced above 
are running on hardware infrastructures specifically designed 
for IDIRA. This includes the so-called Fixed Infrastructure 
and a transportable compound called Mobile Information and 
Communication System (MICS). 
The Fixed Infrastructure is a cloud computing 
infrastructure intended for high availability operation. It is 
located in a data center and reachable from the disaster area 
with permission as soon as there is access to the Internet. The 
Fixed Infrastructure together with the applications it is 
hosting acts as a central information hub where all disaster 
related information is stored and all persons and devices in 
disaster relief actions can access these data. The advantage of 
such a central data hub is that all users have the same view 
on the current state of a disaster. 
While the Fixed Infrastructure is only accessible when 
Internet uplink is available in the disaster area and the Fixed 
Infrastructure itself is not affected by the disaster, a 
transportable version of this central information hub was 
designed with the MICS. The MICS can be shipped directly 
on-site and hosts the same services applications as the Fixed 
Infrastructure and runs them locally at the disaster area. This 
makes the need of an Internet uplink optional and the system 
is fully functional in absence of it. Nevertheless, if an 
Internet uplink is present the MICS establishes a VPN 
connection to the Fixed Infrastructure that is running an 
OpenVPN 
server. 
For 
the 
uplink, 
any 
broadband 
communication technology existing at the MICS location can 
be used. Likewise the Fixed Infrastructure, the MICS 
provides access to external expert systems locally (or via 
Internet – if accessible). 
The IDIRA information system is the central information 
hub where disaster related information is accessible for relief 
workers and authoritative personnel. The second crucial part 
of the system is the communication system that grants access 
to the IDIRA information system and allows transmitting all 
meaningful information to mobile devices of field operators 
in action and will be presented in the next section. 
IV. 
IDIRA COMMUNICATION SYSTEM 
The IDIRA communication system is intended to connect 
devices at command and control centers as well as mobile 
devices to the IDIRA disaster information system. The 
IDIRA 
communication 
system 
fulfils 
a 
series 
of 
requirements, 
either 
brought 
in 
by 
first 
responder 
organizations or having its basis in the design principles of 
IDIRA itself.  
The following requirements are the results of end user 
surveys and a detailed requirement analysis done during the 
project: 
(1) The first requirement regards a largely unlimited and 
almost worldwide valid operation permission of the 
communication system. This is necessary as it would be a 
time-costly process to apply for operation permissions after a 
disaster has struck somewhere in the world. (2) Furthermore, 
the system should allow for integrating locally existing (and 
functional) broadband communication networks into the 

193
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
IDIRA communication system. (3) The usage of open 
standards should ensure that a broad variety of end devices 
can easily be integrated into the communication network 
being able to exchange data with the IDIRA disaster 
information system. (4) Usually, relief organizations only 
have a few IT experts. This entails the requirement that 
especially the field components of the communication 
system can be easily installed and handled (even by non IT 
experts). (5) One further requirement concerning especially 
end devices is basic offline functionality. When the 
connection to the information hub is interrupted, users of end 
devices must be able to work with the system without great 
limitations. (6) The last requirement regards the provided 
bandwidth of the communication system. The system must 
provide enough bandwidth to guarantee a seamless 
interaction with the information hub (i.e., at least 2 Mbit/s 
for operating the COP on a mobile device). These 
requirements are described in more detail in [1]. 
With regard to the requirements for international 
operating permissions and the usage of open standards, the 
mobile communication system has been designed to use 
802.11 based network technology. Additionally, 802.11 
technologies are widely spread nowadays, thus, does not 
require high acquisition and operating expenditures. On the 
other hand, two major drawbacks were needed to overcome: 
• 
Relief forces are not experienced in setting up a 
802.11 communication network and, 
• 
802.11 provides communication coverage for small 
areas only. 
This section presents a communication solution for a 
transportable 802.11 based communication network, which 
is intended to be installed right after a disaster strikes, 
bringing communication coverage to almost every place 
within a disaster area and, additionally, is fulfilling the 
requirements stated above. 
 
 
Figure 2: Schematic of the Wireless Gateway. 
A. Mobile Communication Equipment 
The central element of the proposed communication 
solution is a set of so called Wireless Gateway (WGW) 
devices. 
The central ideas behind the WGW are that (1) multiple 
Wireless 
Gateways 
(WGWs) 
get 
automatically 
interconnected using directional antennas and 802.11 
equipment. In comparison to omnidirectional antennas with 
directional antennas the signal quality between 2 WGWs can 
be improved. If two directional antennas are exactly aligned 
to each other the ratio between signal strength and noise 
level (SNR) increases and results in a higher possible 
throughput or larger distances between two WGWs. (2) After 
powering on, a WGW autonomously connects to other 
WGWs and starts building a meshed WLAN backbone 
network, which finally connects to the IDIRA disaster 
information system. (3) Additionally, each WGW provides 
communication coverage with a wireless hotspot and/or 
Ethernet LAN for end devices. (4) WGWs are designed as 
transportable devices and only need to be mounted on a pole 
and tripod before being powered on. 
Following these 4 ideas, a system was designed that 
finally provides a solution for the two major drawbacks and 
the imposed requirements. 
The main building blocks of the wireless gateway are 
presented as schematic in Figure 2. The system is mounted in 
a modular plastic housing consisting of four stacked layers.  
The top three layers (also referred to as modules) are equally 
built up. Each one is composed of a WLAN station, a 
directional antenna and a motor - all mounted on a turntable. 
The WLAN station supports wireless client mode and access 
point mode and is connected to a ~16 dBi directional 
antenna. The DC gear motor allows rotating the turntable by 
360° on the horizontal plane. Keeping WLAN station, 
antenna and motor altogether on the turntable simplifies 
cabling of the devices and reduces the risk of entanglements 
when the turntable is rotating.  
The bottom layer contains the control hardware and 
software of the WGW. A 5 port 100 Mbps Ethernet Switch 
connects the 3 top layer WLAN stations to a central router 
board containing the control logic, which is in charge of 
building the backbone connections to remote WGWs. 
Figure 3 shows a schematic overview of the prototypes, 
which were developed based on this concept. The Router-
board is an industrial grade embedded PC called Avila from 
manufacturer Gateworks. It is based on an Intel IXP425 CPU 
and features two 100 Mbit/s Ethernet ports and 4 MiniPCI 
slots. As operating system OpenWRT is running on the 
router board. 
Furthermore, two out of the four MiniPCI slots of the 
router-board are equipped with CM9 MiniPCI WLAN cards 
from manufacturer Wistron NeWeb. The cards are based on 
Atheros AR5213A chips, one is operating in the 5 GHz band 
used for establishing the backbone connection between 
WGWs and the other operates in the 2.4 GHz band and is 
used for connecting end devices in the environment operated 
in the wireless cloud around the WGW.  
 

194
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 3: Prototype schematic overview. 
The WLAN stations on the top three layers were 
implemented using a commercial product called Nanostation 
M5 from manufacturer Ubiquiti Networks [22]. For easier 
integration the plastic housing of the Nanostation M5 was 
removed and only the bare electronics were mounted on the 
turntables. To provide protection against physical influences 
the housing of the WGW covers all mechanical and 
electronic parts. The Nanostation M5 provides a built in 
100 Mbit/s Ethernet interface used as data-link between the 
Nanostation M5 and the Router-board. The antenna inside 
the Nanostation M5 has a non-symmetrical radiation pattern 
of about 42° azimuth angle and 15° elevation angle. The 
devices are mounted 90° rotated so that the relevant radiation 
angle for the mechanical antenna alignment process is now 
the narrow 15° angle. The directional antenna is dual-
polarized to support the MIMO feature of the 802.11n 
wireless interface. The installed MIMO antennas promise to 
enhance the signal quality and allow for higher bandwidth 
[23]. Figure 4 shows the radiation pattern of both 
polarization planes for the 15° beam width (green horizontal 
elevation, blue vertical elevation). 
The Nanostations are configured to operate as router and 
run a modified Ubiquiti firmware supporting the OLSR 
routing protocol that is also used on the Avila router board. 
The OLSR configuration has been modified such that 
Ethernet links are generally preferred over wireless links.  
 
 
Figure 4: Nanostation M5 radioation pattern [22]. 
Additionally, an Arduino Leonardo microcontroller is 
connected to the router-board, which itself interfaces the 
motors of the top three layers to perform their rotation. The 
microcontroller tracks the position of each turntable by a 
light barrier. The light barrier is attached to the turntable 
itself together with a reflector attached to the outer housing 
of each layer. As soon as the light-barrier reaches the 
reflector the turntable is in home position. 
The feedback signal of an incremental rotary controller 
(directly attached to the DC gear motor) is used to determine 
the exact position of the turntables. The rotary controller 
generates 2 signal patterns in order to determine both, the 
rotation direction of the turntable and to measure the 
turntable’s alignment by counting the number of rotation 
steps. 
The microcontroller is programmed to interpret text 
commands received over a serial interface. Furthermore, 
status information such as the current alignment can be 
requested from the microcontroller software. When the 
WGW is powered up, all turntables are aligned to their home 
position. During normal operation the microcontroller 
controls the DC motor and counts the pulses from the rotary 
encoders until the desired position is reached. 
The microcontroller is not aware of cardinal directions. 
Instead it is only aware of the angular displacement of each 
turntable compared to its home position. The software 
accepts additional commands to store the actual turntable 
positions in a non-volatile memory. This stored position is 
recovered when the device powers up and the homing 
procedure is finished. The microcontroller is connected to 
the prototypes main logic board via serial interface. 
The Switch on the base layer also provides power over 
Ethernet to the Nanostations on the 3 top layers. The 
microcontroller, the motors and the sensors are power 
supplied by a 5V DC/DC converter installed at the base 
layer. 
 
 

195
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
The second part belonging to the mobile communication 
equipment is the so called Communication Field Relay or, 
for short, COFR. COFR and WGW are intended to be 
installed as a compound that provides connectivity to the 
MICS or Fixed Infrastructure for relief workers at any 
arbitrary location in the disaster area. The Communication 
Field Relay is positioned at the foot of the pole the WGW is 
mounted on, and it is connected to the WGW by Ethernet 
LAN and, thus, connected to the backbone network spanned 
by the WGWs. A schematic diagram of the COFR is shown 
in Figure 5. 
The COFR is intended to provide several services for the 
IDIRA communication system. As a local communication 
hub for field commanders the COFR can provide a SIP 
service to allow for voice communication between field 
commanders without the need of a connection to the Fixed 
Infrastructure or the MICS – this grants more efficient 
bandwidth usage. Furthermore, the COFR can act as a 
communication proxy providing capabilities to cache data 
exchanged between end device applications and the IDIRA 
disaster information system. This guarantees a seamless 
operation even in cases the direct data exchange between an 
end device application and the central information system 
suffers from limited communication quality. The proxy 
service may also include a map server supplying geographic 
data to end devices. This has the advantage that potentially 
large map data are not needed to be transmitted multiple 
times for multiple end devices over a potentially constraint 
wireless backbone connection. 
From a networking perspective the COFR offers a DHCP 
server and DNS server capabilities granting simplified end 
device configuration. End devices automatically get a valid 
IP configuration (DNS, IP address, gateway address, etc.) 
after the device is attached to the network. These services are 
supplied to devices using the wireless connection to the 
802.11 hotspot (spanned by the WGW) or to devices directly 
wire-connected to the COFR via Ethernet. One Ethernet port 
of the COFR is especially considered for this case. A second 
Ethernet port is intended to be used as direct Internet uplink. 
Any arbitrary Internet uplink technology such as DSL, 
WiMAX, satellite-communication, UMTS, or LTE can be 
used. This Internet uplink can be shared by all clients 
connected to this COFR, to the local WGW or, to any remote 
COFR or WGW. The route is distributed by the OLSR 
dynamic gateway plugin. A third Ethernet port is used for the 
connection to the WGW and is providing - beneath 
communication capabilities - power supply to the WGW via 
Power over Ethernet (PoE). Therefore, the COFR can be 
connected to a power source either by a 230 V power socket 
or, if a power line or power generator is not available, to a 
battery via a 12 V cigarette lighter socket.  
A COFR is assembled of several embedded Linux boards 
(Raspberry PI) providing the software services mentioned 
above. As data storage a fast and energy efficient solid-state 
disk is included. Furthermore, a router allowing for 
connecting different hosts via cable and ensuring the 
connection to the Wireless Gateway (WGW) is part of the 
system. The router is also responsible for the Internet uplink. 
 
Figure 5: Building blocks of the Communication Field Relay. 

196
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
DSL/Cable
3G/4G
other
SAT
COFR
Fixed Infrastructure
COFR
COFR
COFR
3G/4G
DSL/Cable
3G/4G
other
COFR
MICS
COFR
 
Figure 6: IDIRA communication network. 
 
 
Figure 7: Local Alignment Algorithm 
Figure 6 shows a full-featured disaster communication 
network based on the proposed components. The depicted 
network consists of the MICS (installed at the Command and 
Control Center on-site), several mobile communication sites 
(WGW/COFR) and also the Fixed Infrastructure which is 
connected over Internet. The figure also shows that 
WGW/COFR compounds are using a variety of connection 
methods either to the MICS (via Wireless LAN or WIMAX) 
or to the Fixed Infrastructure (via various Internet uplink 
technologies). A fully operational mobile communication 
node consists of a WGW/COFR compound, a battery pack 
with capacity for about 12 hours, together with a tripod and a 
telescopic 6 m pole. 
 
Rotate the directional 
antenna to the maximum 
Scanresult
Free 
directional 
antenna
Reject Request
No
Requesting WGW 
found in 
Scanresults
Rotate to Startpositon
save ESSID, signal strength, 
noise, frequency for each 
WLAN found at the given 
position
Advance position by 5°
Scan for requesting WGW
Requesting WGW 
found
No
No
yes
Confirm request
Remote 
Request 
Received
Still connected
yes
Optimize position
Free the module
end
Stoppositon 
reached
no
Reject Request
 
Figure 8: Remote Alignment Algorithm 
B. Antenna Alignment and Networking Configuration 
After powered on, the WGWs try to connect to remote 
WGWs following an alignment algorithm. Figure 7 and 
Figure 8 show a simplified flow-diagram of the alignment 
algorithm performed by a requesting (local) WGW and a 
responding (remote) WGW. Figure 9 shows the state 
diagram the alignment algorithm is based on. The state 
diagram shows the individual states of each of the three top 
layers of the WGW. The alignment algorithm is executed on 
the router-board on the lowest level of the WGW. 
After supplying power to the WGW via PoE, the local 
adjustment sequence (see Figure 7) starts an initialization 
process. This initialization process identifies the home 

197
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
positions of the modules and performs a self-check of the 
system. After the initialization, all three modules start to scan 
for remote WGW signals radiated by their 5GHz omni-
directional antenna. For each module, individual start and 
stop positions are defined with an offset of 120° to each 
other. This allows for scanning the full 360° around the 
WGWs as fast as possible. During the scanning process, the 
antenna position is advanced by 5° in each step. One step 
lasts about 10 seconds, which is mainly determined by the 
time needed to execute the scan. The scan is stopped as soon 
as a module reaches its stop position or a remote WGW has 
been detected. When the stop position has been reached, the 
antenna is rotated to its starting position and the scanning 
process is restarted again. 
 
 
Figure 9: Alignment process state diagram. 
In case of the 5GHz remote signal has been detected with 
signal strength greater than -87 dbm, one directional antenna 
of the detecting WGW rotates to the position with the best 
strength of this signal. This antenna may not be the same as 
the one detecting the signal.  
During the scanning phase, the Nanostations M5 are 
configured to operate in access point (AP) mode as the 
firmware of the M5 only allows in AP mode to execute 
distinct scans for each scanning position. In station mode, in 
contrast, scan results are cached by the firmware over several 
scans. This, however, would make it impossible to map 
certain scan results to distinct positions.  
After the module has reached the best known position for 
this signal, the module is configured in station mode to 
connect to the omnidirectional antenna of the remote WGW. 
As IP based communication is needed for the following 
steps, also the IP configuration of the local WGW is done 
such that the local module configures itself with an IP 
address of the remote WGW. As for performance constraints 
no DHCP server is running at the remote WGW and a 
distinct mapping of IP addresses to WLAN SSIDs is used. 
Each WLAN spanned by the omnidirectional antenna of the 
WGWs is sending a distinct SSID. Based on this SSID, the 
alignment and configuration algorithm knows the IP address 
a connecting module needs to build up an IP based 
connection. 
An 
example 
for 
a 
connection 
to 
an 
omnidirectional antenna is shown in Figure 10. After a 
connection is established and the corresponding IP 
configuration is done, the local WGW sends a request to 
connect to a directional antenna at the remote WGW. 
At this time, the local WGW and the remote WGW are 
following distinct algorithm steps to establish the directional 
point-to-point connection. While the connecting WGW is 
following the remaining steps shown in Figure 7 (starting 
with checking if a request confirmation was received), the 
remote WGW will follow the sequence shown in Figure 8, as 
soon as a request has been received. 
When a connection request is received, one module is 
determined for the directional connection. If no module is 
available (because all are used for other connections) a reject 
is sent to the requesting WGW. Otherwise, the scan results 
will be searched for results of the requesting WGW. If such a 
result exists the determined module is rotated to the 
corresponding position with the best signal strength and a 
confirmation is sent to the requesting WGW. If such a scan 
result cannot be found, all available modules starting a 360° 
full scan beginning from their start positions. This scan is 
executed until the requesting WGW is found or the stop 
position is reached. If the signal of the requesting WGW has 
been found, a confirmation is sent and a module is rotated to 
the position with the best signal strength known. Otherwise, 
the request is rejected. 
When the requesting node receives the confirmation the 
connection to the remote WGW omnidirectional antenna is 
canceled, and the local WGW is configured to connect to the 
remote directional module. The local module is configured in 
station mode with the SSID of the remote module and the IP 
address is set according to the SSID of the remote module 
using a similar approach as when connecting to the omni-
directional antenna. Furthermore, also the IP address is set 
appropriately for the remote module (see Figure 10). If the 
request is rejected the module will continue scanning for 
remote WGWs. 
 

198
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
 
Figure 10: IP addressing scheme when connected to the omnidirectional antenna (above) and after successful connection between two WGW devices 
(below). 
The alignment sequence typically lasts between five and 
15 minutes. All established connections are monitored, and if 
one of them is lost the module will be reconfigured and starts 
to scan for remote WGWs again or connect to another 
previously located WGW. Not connected modules will 
continue to scan for remote WGWs. New scan results 
(coming from modules in scanning state) are used to adjust 
the position to ensure the best possible position to the remote 
WGWs based on the signal strength. 
Another view on the alignment procedure can be given 
by the state diagram shown in Figure 9. This diagram shows 
the states of each module and all transitions between them. 
State transitions are executed by a central control instance 
separately for each module. 
After powering up and during node initialization, the 
modules are in idle state. From the idle state, the control 
instance may trigger to perform a scan, trigger to connect to 
a remote WGW if a remote WGW is already known or being 
ready to be assigned to a remote WGW if a connection 
request is received from a remote WGW.  
When a module completes a scan (after reaching the end 
position) it returns into the idle state and is realigned and 
triggered to start another scan. If a remote WGW is 
identified, the control instance choses one scanning or idle 
module that should connect to the remote node and switches 
it to state “ready to connect”. 
If a remote request is received, the control instance also 
choses one scanning or idle module that is then used for 
establishing the directed point-to-point connection. The 
module is switched in state “ready for remote”. If the 
requesting WGW has been identified the module is rotated 
towards the remote node position and its state is changed to 
“remote assigned”. 
Once the connection is established, the module’s state is 
changed to “connected to module” and this connection is 
regularly checked. If the connection is lost it will change the 
state to “lost connection module” and try to re-establish the 
connection for y minutes. If it fails to re-establish the 
connection, it will change the state to “reset” and finally to 
“idle”. 

199
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
If a remote WGW has been identified in “scanning” state 
without receiving a request from it (i.e., the local WGW 
found the remote WGW first), one available local module 
will be reconfigured with an appropriate IP address to be 
able to connect to the 5GHz omni-directional antenna of the 
remote WGW. Also, the module is set to state “connected to 
omni” and the remote WGW is informed about the attempt 
to establish a point-to-point connection. If the connection to 
the remote WGW is lost, it is tried to re-establish the 
connection for x minutes, afterwards it will change the state 
to “reset” and finally to idle after all specific settings are 
reset. In case that the remote WGW node answers the request 
in a positive manner, the module is reconfigured and a 
connection to the remote module will be established. 
C. Node Positioning Support 
To install a field communication site is easy as it only 
requires mounting the WGW on a pole and connecting it to a 
COFR and a power source. But before a communication site 
can be established, one important question needs to be 
answered: Which location is particularly appropriate to setup 
a communication site where a WGW provide WLAN 
coverage for relief forces and is able to build up a backbone 
connection to other remote WGWs. 
This section describes the Reachability Optimized 
Positioning (ROP) application of IDIRA. ROP provides a 
Web based interface, which is fully integrated into COP and 
helps to find the best possible locations for setting up 
communication sites. Commanding personnel can run 
WLAN coverage simulations at arbitrary locations on the 
COP map in order to evaluate the WLAN coverage at this 
place regarding to range and signal quality of the directional 
antennas. This information is then used by early responder 
teams to identify the optimal location for a communication 
site where a direct line of sight is available between multiple 
WGWs. 
ROP calculates the radio signal propagation based on a 
digital earth surface model of the operational area. For this 
purpose, an extension of the open source tool SPLAT! [24] 
version 1.4 was developed, which uses a surface model with 
a resolution of 1/10th of an arc second. SPLAT! provides 
radio signal propagation based on a terrain analysis for the 
electromagnetic spectrum between 20 MHz and 20 GHz. The 
calculations are based on the Longley-Rice Irregular Terrain 
[25] as well as the new Irregular Terrain with Obstructions 
(ITWOM v3.0) [26] model. In its base version SPLAT! uses 
the elevation data from the U.S. Geological Survey and 
Space Shuttle Radar Topography Mission [27]. These data 
have a resolution of 1 arc second for some areas of the 
Earth’s surface and 3 arc seconds for the remaining areas.  
To achieve precise results in a radio wave propagation 
simulation this resolution is too coarse grained. To solve this 
issue an Earth surface data basis with a high resolution of 
1/10th of the Earth surface was chosen, which is available 
from some satellite remote sensing programs such as 
TerraSAR-X [28] or from local authorities for some specific 
regions. This is where an extension of SPLAT! was 
necessary, as higher resolved Earth surface data are not 
supported by SPLAT!. To make highly resolved elevation 
data usable in SPLAT!, the application had to be extended in 
order to allow SPLAT! to read, use and visualize this kind of 
elevation and surface data and also the algorithm to compute 
radio wave propagation was slightly adapted to the new data 
basis. With the increased resolution to 1/10th of an arc second 
the distance between points with available elevation data is 
approximately 3 m (for central Europe). This gives sufficient 
accurate 
propagation 
models 
to 
have 
guaranteed 
communication channels between WGWs. The coverage 
simulation also considers the operating height of the WGW 
of about 6 m and the results show if it is possible to establish 
line of sight communication between two WGWs absent of 
obstructions due to buildings, hills, or forests. 
To find the appropriate places and areas, the 
commanding staff starts a signal propagation simulation with 
a pole at the location of the MICS. The result of the 
calculation is a picture of the signal propagation simulation 
shown in Figure 11 as an overlay of the COP map. 
The white section in the circle indicates an area where it 
is possible to deploy the wireless gateways and to establish a 
communication channel to remote WGWs automatically. 
The red or dark grey area indicates that it is not possible to 
establish a communication infrastructure due to obstacles 
between the directional antennas. In the middle of the circle, 
the green or light grey area gives the commander the 
information that it is possible to support mobile equipment 
for communication in the incident area. These simulation 
results are presented within COP together with incident 
locations. Consequently, within one system tactical needs as 
well as communication needs can be taken into account 
when decisions for operational locations in the field of first 
responder field commanders have to be defined. 
 
 
Figure 11: Result of a radio signal propagation simulation. 
ROPs usability and correct way of working were proven 
in a validation test before it was used in multiple field trials 

200
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
of the IDIRA communication system. The result of the 
validation test is shown in Figure 12.  
Based on a simulation of the base area where the 
command and control center was located, ten places were 
defined 
to 
validate 
the 
possibility 
to 
establish 
a 
communication channel fully automatically (Point 1 - Point 
10). 
After the wireless gateways were deployed to the 
different places it was evaluated if a communication channel 
could be automatically established by the alignment 
algorithm: 
• 
Wireless gateways placed on areas indicating a good 
signal to noise ratio (green and yellow, respectively light 
grey areas), could successfully setup a communication 
channel: Yellow pins (Points 2, 4, 5, 9, and 10). 
• 
Wireless gateways placed in red or dark grey areas 
failed to setup a communication channel automatically: 
Red pins (Points 1, 3, 6, 7, and 8). 
These results show that the accuracy of the radio signal 
propagation simulation was sufficient to give a reliable 
answer to the question where communication sites should be 
established in order to build a backbone network allowing 
for a connection to the IDIRA information system. 
More detailed performance evaluation results of the 
IDIRA communication system can be found in [1][29] 
[30][31]. These papers contain results of several performance 
tests, end user training events, and large scale exercises held 
in context of the IDIRA project. 
 
 
Figure 12: Simulation validation. 
V. 
CONCLUSTION AND FUTURE WORK 
This paper presents the information and communication 
systems developed within the EU funded project IDIRA. The 
main goal of IDIRA was to develop a solution to enhance 
interoperability and cooperation of relief units part of 
multinational disaster response organizations working 
together after a large scale disaster. Such a solution considers 
two aspects of interoperability. Organizational aspects 
dealing with the administrative coordination of various 
disaster relief organizations, and technical aspects to find 
technological solutions to enhance information interchange. 
This paper focuses on the latter and presents various 
applications referred to as the IDIRA information system, 
which can help to find right decisions quickly and provide a 
common sight on what is happening within the disaster relief 
action. Furthermore, and with even more focus on details, a 
mobile communication system is presented providing 
wireless communication at almost any location within the 
disaster area. 
This communication system complies with several 
requirements that have been introduced by action forces of 
relief 
organizations, 
such 
as 
easy 
installation 
and 
transportation, interoperability with existing communication 
systems and, international operation permission. The core of 
this system is the WGW/COFR compound to be installed out 
in the field of a disaster area granting wireless 
communication capabilities to field personnel. The field 
personnel is able to access the central information system of 
IDIRA. To allow this, in the background the WGW 
establishes a wireless connection to the central information 
system potentially using multiple other WGWs as wireless 
communication hops. The COFR provides power supply and 
Internet uplink to the compound. An additional application 
was developed helping first responders to setup the 
WGW/COFR compound at the right location, where it is 
possible to build up a wireless backbone network and supply 
an area near an operation site with a 802.11 wireless hotspot. 
In several large scale exercises and user training events 
the usability of the IDIRA system has been proven. In these 
events, however, it was shown that several enhancements 
could improve the systems performance and should be 
considered in future. (1) Especially the WGWs mechanics 
should be built in a more robust way in order to make the 
system more capable for conditions in disaster operations. 
(2) The extension of the alignment algorithm with manual 
provided additional information could speed up the 
automatic alignment process. (3) Additional software 
interfaces to further existing disaster management tools and a 
broader variety of sensor sources will be provided.  
ACKNOWLEDGMENT 
This work was partially supported by the IDIRA 
European FP7 261726 research project. 
 
REFERENCES 
[1] Peter Dorfinger, Ferdinand von Tüllenburg, Georg Panholzer, 
and Thomas Pfeiffenberger, “A Flexible Self-Aligning 
Communication Solution for Multinational Large Scale 
Disaster Operations,” Proc. of the ICN 2015: The Fourteenth 
International Conference on Networks (ICN2015), April 19 - 
24, 2015 - Barcelona, Spain, pp. 230-236. 
[2] Nalini Suparamaniam and Sidney Dekker, “Paradoxes of 
power: the separation of knowledge and authority in 
international disaster relief work,“ Disaster Prevention and 
Management, vol. 12, no. 4, pp. 312–318, 2003. 

201
International Journal on Advances in Telecommunications, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/telecommunications/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[3] IDIRA Project. Interoperability of data and procedures in 
large-scale multinational disaster response actions, 2011-
2015 [Online]. Available from: http://idira.eu/. 2015.11.30. 
[4] OASIS Emergency Management TC. Emergency Data 
Exchange Language (EDXL) [Online]. Available from: 
https://www.oasis-
open.org/committees/tc_home.php?wg_abbrev=emergency 
2015.11.30. 
[5] OASIS Emergency Management TC. Common Alerting 
Protocol 
Version 
1.2, 
2010-07-01 
- 
CAP-v1.2-os 
[Online].Available 
from: 
https://www.oasis-
open.org/standards#capv1.2 2015.11.30. 
[6] OASIS Emergency Management TC. Emergency Data 
Exchange Language Resource Messaging, EDXL-RM-v1.0-
OS-errata-os, 22 Dec. 2009 [Online]. Available from: 
https://www.oasis-open.org/standards#edxlrm-v1.0 
2015.11.30. 
[7] OASIS Emergency Management TC. Emergency Data 
Exchange Language Situation Reporting, edxl-sitrep-v1.0-
wd19, Draft 02, 2012-08-07 [Online].Available from: 
http://docs.oasis-open.org/emergency/edxl-
sitrep/v1.0/cs01/edxl-sitrep-v1.0-cs01.zip 2015.11.30. 
[8] ETSI TR 103 269-1. TETRA and Critical Communications 
Evolution (TCCE); Critical Communications Architecture; 
Part 1: Critical Communications Architecture Reference 
Model 
[Online] 
Available 
from: 
http://www.etsi.org/deliver/etsi_tr/103200_103299/10326901/
01.01.01_60/tr_10326901v010101p.pdf 2015.09.14. 
[9] Immarsat BGAN. Broadband Global Area Network [Online]. 
Available 
from: 
http://www.inmarsat.com/service/bgan/ 
2015.11.30. 
[10] GVF VSAT. Global Very Small Aperture Terminal Forum 
[Online]. Available from: http://www.gvf.org 2015.09.14. 
[11] Emergency.lu. 
[Online]. 
Available 
from: 
http://www.emergency.lu 2015.09.14. 
[12] IEEE 802.16 WIMAX. IEEE Standard for Local and 
metropolitan area networks [Online]. Available from: 
http://standards.ieee.org/about/get/802/802.16.html 
2015.11.30. 
[13] IABG mbH. HiMoNN Higly Mobile Network Node [Online]. 
Available from: http://www.himonn.de 2015.08.31. 
[14] Electronic 
Communications 
Committee 
(ECC). 
The 
Identification of Frequency Bands for the Implementation of 
Broad Band Disaster Relief (BBDR) Radio Applications in the 
5 GHz Frequency Range [Online]. Available from: 
http://www.erodocdb.dk/docs/doc98/official/pdf/REC0804.pd
f 2015.11.30. 
[15] Christian 
Raffelsberger 
and 
Hermann 
Hellwagner, 
“Evaluation of MANET Routing Protocols in a Realistic 
Emergency Response Scenario,” Proc. of the 10th  Workshop 
of Intelligent Solutions in Embedded Systems (WISES’12). 
July 2012, pp. 88-92. 
[16] Matthias Herlich and Shigeki Yamada. "Motivation for a 
Step-by-Step Guide to Set up Wireless Disaster Recovery 
Networks," Proc. of the International Conference on 
Information and Communication Technologies for Disaster 
Management (ICT-DM 2015). 
[17] IEEE 802.11. IEEE Standard for Information Technology--
Telecommunications and Information Exchange Between 
Systems--Local and Metropolitan Area Networks--Specific 
Requirements Part 11: Wireless LAN Medium Access Control 
(MAC) and Physical Layer (PHY) [Online]. Available from: 
http://standards.ieee.org/about/get/802/802.11.html 
2015.11.30. 
[18] Thomas Clausen and Philippe Jacquet. (2003), “Optimized 
Link State Routing Protocol (OLSR),” Internet Engineering 
Task Force, IETF, RFC 3626. 
[19] Harald Rieser, Peter Dorfinger, Vangelis Nomikos, and 
Vassilis Papataxiarhis, “Sensor Interoperability for Disaster 
Management,” Proc. of the Sensor Applications Symposium 
(SAS2015) Zadar, Croatia; April 2015, pp. 389-395. 
[20] Satways, 
OptiFire 
[Online] 
Available 
from: 
, 
http://www.satways.net/index.php?option=com_content&view=articl
e&id=95:optifire-article&catid=53:simulation-a-
modelling&Itemid=91&lang= 2015.11.30. 
[21] Kostas 
Kolomvatsos, 
Kakia 
Panagidi, 
and 
Stathes 
Hadjiefthymiades, “Optimal Spatial Partitioning for Resource 
Allocation,“ Proc. of the 10th Int. ISCRAM Conference. May 
2013. 
[22] Ubiquiti networks. NanostationM & NanostationlocoM 
Datasheets 
[Online] 
Available 
from: 
http://dl.ubnt.com/datasheets/nanostationm/nsm_ds_web.pdf 
2015.11.30. 
[23] David Gesbert and Jabran Akhtar, “Breaking the barriers of 
Shannon’s capacity: An overview of MIMO wireless 
systems”, Telenor’s Journal: Telektronikk, vol. 98, no 1, pp. 
53-64, 2002. 
[24] John 
A. 
Magliacane. 
(2002) 
Splat! 
[Online]. 
Available from: http://www.qsl.net/kd2bd/splat.html 2015.11.30. 
[25] Anita Longley and Phill Rice, “Irregular terrain model,” 
Intstitute for Telecommunication Sciences, 1968. 
[26] Georgelpon Hufford, “The its irregular terrain model, ver 
1.2.2,” 
National 
Telecommunicatgions and Information Administration. 
[27] U.s. geological survey. U.S. Geological Survey. [Online]. 
Available from: http://srtm.usgs.gov/ 2015.08.31.. 
[28] Airbus Defence & Space. TerraSAR-X Radar Satellite 
Imagery. 
[Online] 
Available 
from: 
http://www.geo-
airbusds.com/terrasar-x/ 2015.11.30. 
[29] Thomas Pfeiffenberger, Peter Dorfinger, and Ferdinand von 
Tüllenburg “Communication Coverage Awareness for Self-
aligning Wireless Communication in Disaster Operations,” 
Pervasive Networks for Emergency Management March 2015 
St. Louis, Missouri, USA. 
[30] Peter Dorfinger, Ferdinand von Tüllenburg, Georg Panholzer, 
Massimo Cristaldi, Giovanni Tusa, and Franz Böhm” An 
Offline 
Capable 
Communication 
Framework 
for 
Multinational Disaster Operations based on Self-aligning 
Wireless Gateways,” 
Proceedings 
of 
International 
Conference on Digital Information Processing, Data Mining, 
and Wireless Communications (DIPDMWC2015) Dubai, 
UAE January 2015. 
[31] Peter Dorfinger, Georg Panholzer, Ferdinand von Tüllenburg, 
Massimo Christaldi, Giovanni Tusa, and Franz Böhm “Self-
aligning Wireless Communication for First Responder 
Organizations in Interoperable Emergency Scenarios,” In: 
Proc. of the 2014 International Conference on Wireless 
Networks, Las Vegas Nevada, USA. 
 

