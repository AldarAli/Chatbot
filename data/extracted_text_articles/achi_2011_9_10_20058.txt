An Augmented Reality Application for the Enhancement of Surgical Decisions 
 
 
Lucio T. De Paolis, Giovanni Aloisio 
Department of Innovation Engineering 
Salento University 
Lecce, Italy 
lucio.depaolis@unisalento.it 
giovanni.aloisio@unisalento.it 
Marco Pulimeno 
Engineering Faculty 
Salento University 
Lecce, Italy 
marco.pulimeno@unisalento.it 
 
 
Abstract— The practice of Minimally Invasive Surgery is 
becoming more and more widespread and is being adopted as 
an alternative to the classical procedure. This technique has 
some limitations and comes at a cost to the surgeons. In 
particular, the lack of depth in perception and the difficulty in 
estimating the distance of the specific structures in 
laparoscopic surgery can impose limits on delicate dissection or 
suturing. The availability of new systems for the pre-operative 
planning can be of great help to the surgeon. The developed 
application allows the surgeon to gather information about the 
patient and her/his pathology, visualizing and interacting with 
the 3D models of the organs built from the patient’s medical 
images, measuring the dimensions of the organs and deciding 
the best insertion points of the trocars in the patient’s body. 
This choice can be visualized on the real patient using the 
Augmented Reality technology. 
Keywords - user interface; Augmented Reality; medical 
image processing 
I. 
 INTRODUCTION 
One trend in surgery is the transition from open 
procedures to minimally invasive laparoscopic operations 
where visual feedback to the surgeon is only available 
through the laparoscope camera and direct palpation of 
organs is not possible.  
Minimally Invasive Surgery (MIS) has become very 
important and the research in this field is ever more widely 
accepted because these techniques provide surgeons with 
less invasive means of reaching the patient’s internal 
anatomy and allow entire procedures to be performed with 
only minimal trauma to the patient.  
The diseased area is reached by means of small incisions 
inside the body; specific instruments and a camera are 
inserted in the body and what is happening inside the body is 
shown in a monitor. The surgeon does not have a direct 
vision of the organs and he is thus guided by the camera 
images. This surgical approach is very different from the one 
of open surgery, where the organ can be fully visualized and 
handled. 
As a promising technique, the practice of MIS is 
becoming more and more widespread and is being adopted 
as an alternative to the classical procedure. The advantages 
of using this surgical method are evident for the patients 
because the possible trauma is reduced, the postoperative 
recovery is nearly always faster and scarring is reduced. 
Despite the improvement in outcomes, these techniques 
have their limitations and come at a cost to the surgeons. In 
particular, the lack of depth in perception and the difficulty 
in estimating the distance of the specific structures in 
laparoscopic surgery can impose limits on delicate dissection 
or suturing. 
Due to the great deal of difficulties involved in MIS 
related to perceptual disadvantages, many research groups, 
motivated by the benefits MIS can bring to patients, are now 
focusing on the development of surgical assistance systems.  
On the other hand, advances in technology are making 
possible to develop systems that can help surgeons to 
perform their tasks in ways that are both faster and safer.  
Latest developments in medical imaging acquisition and 
computer systems make possible the reconstruction of 3D 
models of the organs providing anatomical information 
barely detectable by CT and MRI slices or ultrasound scan as 
well as the safe guidance of instruments through the body 
without the direct sight of the physician. 
The emerging Augmented Reality (AR) technology has 
the potential to bring the advantage of direct visualization in 
open surgery back to minimally invasive surgery and can 
increase the physician's view of his/her surroundings with 
information gathered from patient medical images. 
In contrast with Virtual Reality technology where the 
user is completely immersed in a synthetic environment and 
cannot see the real world around him, AR technology, which 
consists of the addition of extra information to the real scene, 
allows the user to see virtual objects in addition to the real 
world. The user is under the impression that the virtual and 
real objects coexist in the same space.  
In medicine, Augmented Reality technology makes it 
possible to overlay virtual medical images onto the patient, 
allowing surgeons to have a sort of “X-ray" vision of the 
body and providing them with a view of the patient’s 
anatomy. The patient becomes transparent and this virtual 
transparency will therefore make it possible to find tumors or 
vessels not by locating them by touch, but simply by 
visualizing them through Augmented Reality.  
The virtual information could be directly displayed on 
the patient’s body or visualized on an AR surgical interface, 
showing where the operation should be performed. 
192
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

This paper presents an advanced platform for the 
visualization and the interaction with the 3D patient models 
of the organs built from CT images. 
The availability of a system for the pre-operative 
planning can be of great help to the surgeon and this support 
is even more important in pediatric laparoscopic surgery 
where a good understanding is needed of the exact 
conditions of the patient’s organs and the precise location of 
the operational site. 
In addition, the developed application allows the surgeon 
to choose the points for the insertion of the trocars on the 
virtual model and to overlap them on the real patient body 
using the Augmented Reality technology. 
This work is part of the ARPED Project (Augmented 
Reality Application in Pediatric Minimally Invasive Surgery) 
funded by the Fondazione Cassa di Risparmio di Puglia. The 
aim of the ARPED project is the design and development of 
an Augmented Reality system that can support the surgeon 
through the visualization of anatomical structures of interest 
during a laparoscopic surgical procedure. 
II. 
PREVIOUS WORKS 
In general, AR technology in minimally invasive surgery 
may be used for training purposes, pre-operative planning 
and advanced visualization during the real procedure. 
Several research groups are exploring the use of AR in 
surgery and many image-guided surgery systems have been 
developed. 
Devernay et al. propose the use of an endoscopic AR 
system for robotically assisted minimally invasive cardiac 
surgery [1].  
Samset et al. present tools based on novel concepts in 
visualization, robotics and haptics providing tailored 
solutions for a range of clinical applications [2].   
Bichlmeier et al. focus on handling the problem of 
misleading perception of depth and spatial layout in medical 
AR and present a new method for medical in-situ 
visualization [3].   
Navab et al. introduce the concept of a laparoscopic 
virtual mirror: a virtual reflection plane within the live 
laparoscopic video, which is able to visualize a reflected side 
view of the organ and its interior [4], [5].   
Kalkofen et al. carefully overlay synthetic data on top of 
the real world imagery by taking into account the 
information that is about to be occluded by augmentations as 
well as the visual complexity of the computer-generated 
augmentations added to the view [6]. 
De Paolis et al. present an Augmented Reality system 
that can guide the surgeon in the operating phase in order to 
prevent erroneous disruption of some organs during surgical 
procedures [7]. 
Soler et al. present the results of their research into the 
application of AR technology in laparoscopic. They have 
developed two kinds of AR software tools (Interactive 
Augmented Reality and Fully Automatic Augmented 
Reality) taking into account a predictive deformation of 
organs and tissues during the breathing cycle of the patient 
[8]. 
The collaboration between the MIT Artificial Intelligence 
Lab and the Surgical Planning Laboratory of Brigham led to 
the development of solutions that support the preoperative 
surgical planning and the intraoperative surgical guidance 
[9]. 
Papademetris et al. describe the integration of image 
analysis 
methods 
with 
a 
commercial 
image-guided 
navigation 
system 
for 
neurosurgery 
(the 
BrainLAB 
VectorVision Cranial System [10]. 
 
III. 
THE 3D MODELS OF PATIENT’S ORGANS 
In MIS, the use of images registered to the patient is a 
prerequisite for both the planning and guidance of such 
operations. From the medical image of a patient (MRI or 
CT), an efficient 3D reconstruction of his anatomy can be 
provided in order to improve the standard slice view by the 
visualization of the 3D models of the organs; colors 
associated to the different organs replace the grey levels in 
the medical images. 
In our case study the 3D models of the patient’s organs 
have 
been 
reconstructed 
using 
segmentation 
and 
classification algorithms provided by ITK-SNAP [11].  
ITK-SNAP provides semi-automatic segmentation using 
active contour methods, as well as manual delineation and 
image navigation; it also fills a specific set of biomedical 
research needs. 
In our case study, the slice thickness equal to 3 mm has 
caused some aliasing effects on the reconstructed 3D models 
that could lead to inaccuracies.  
Therefore we have paid special attention during the 
smoothing of the reconstructed models in order to maintain a 
good correspondence with the real organs.  
 
 
Figure 1.  3D model of the patient’s organs.  
193
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

By means of the user interface it is possible to display all 
the organs of the abdominal region or just some of these 
using the show/hide functionality; it is also possible to 
change the transparency of each organ. 
The clinical case is a two-year-old child with a benign 
tumor of the right kidney.  
Figure 1 shows the result of the image processing using 
ITK-SNAP; the skin and the muscles of the abdominal 
region are displayed in transparency and the tumor is shown 
in magenta. 
I. 
THE DEVELOPED APPLICATION 
The developed application is supplied with a specific user 
interface that allows the user to take advantage of the 
feature offered by the software.  
Starting from the models of the patient’s organs, the 
surgeon can notice data about the patient, collect 
information about the pathology and the diagnosis, choose 
the most appropriate positions for the insertion of the trocars 
and overlap these points on the patient’s body using the 
Augmented Reality technology.  
In this way it is possible to use this platform for the pre-
operative surgical planning and during the real surgical 
procedure too. 
In addition, it could be used in order to describe the 
pathology, the surgical procedure and the associated risks to 
the child’s parents, with the aim of obtaining informed 
consent for the surgical procedure [12]. 
In the developed application, as shown in Figure 2, all the 
patient’s information (personal details, diseases, specific 
pathologies, diagnosis, medical images, 3D models of the 
organs, notes of the surgeon, etc.) are structured in a XML 
file associated to each patient. 
A specific section for the pre-operative planning includes 
the visualization of the virtual organs and the physician can 
get some measurements on the organ or pathology and 
measure the distances.  
 
 
Figure 2.  Patient’s data collected in a XML file. 
 
Figure 3.  Section for the interaction with the organs. 
Figure 3 shows the specific section of the user interface 
for the interaction with the 3D models of the patient’s 
organs. 
By means of a detailed view of the 3D model, the surgeon 
can choose the trocar entry points and check if, with this 
choice, the organs involved in the surgical procedure can be 
reached and if this is the correct choice in order to carry out 
the procedure in the best way. 
Complications associated with initial abdominal entry are 
a prime concern for laparoscopic surgeons. In order to 
minimize first access-related complications in laparoscopy, 
several techniques and technologies have been introduced in 
the past years. The problem of blind access is that it may 
imply vascular injuries caused by the blind entry of 
instruments in the abdominal cavity.  
A possibility to solve this problem may be the direct 
visualization of under-layer viscera and vessels.  
Our application, by means of an Augmented Reality 
module, supports the placement of the trocars on the real 
patient during the surgery procedure and simulates the 
insertion of the trocars in the patient body in order to verify 
the correctness of the chosen insertion sites.  
The Augmented Reality surgery guidance aims to 
combine a real view of the patient on the operating table 
with virtual renderings of structures that are not visible to 
the surgeon. In this application we use the AR technology in 
order to visualize on the patient’s body the precise location 
of selected points on the virtual model of the patient. 
For the augmented visualization, in order to have a 
correct and accurate overlapping of the virtual organs on the 
real ones, a registration phase is carried out; this phase is 
based on fiducial points and an optical tracker is used. The 
tracker system consists of 2 IR cameras and uses a position 
sensor to detect infrared-emitting or retro-reflective markers 
affixed to a tool or object; based on the information received 
from the markers, the sensor is able to determine position 
and orientation of tools within a specific measurement 
volume.  
194
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

Usually an optical tracker is already in the modern 
operating rooms and provides an important help to enhance 
the performance during the real surgical procedures. 
Figure 4 shows the section for the accurate choice of the 
trocar insertion points. 
 
 
Figure 4.  Section for the choice of the trocar insertion.  
Using the augmented visualization, the chosen entry 
points for the trocars can be visualized on the patient’s body 
through the Augmented Reality technique in order to 
support the physician in the real trocar insertion phase.  
Figure 5 shows the augmented visualization with the 
trocar entry points overlapped on the patient’s body. 
 
 
Figure 5.  The augmented visualization. 
II. 
USABILITY TESTS 
In order to evaluate the validity and the usability of the 
developed application and to receive possible suggestions 
from the users, some tests have been carried out. The test 
phase has been realized in order to allow the users to check 
all the functionalities of the application. 
After a short period of training (5 minutes), the users 
have been tried to carry out different procedures and, 
subsequently, they have reported the impressions on a 
specific questionnaire. 15 subjects have been tested the 
application for an average time of 7 minutes and 43 seconds. 
The obtained results can be considered satisfactory and 
some annotations to improve the user interface and the 
usability of the application have been considered. 
III. 
CONCLUTIONS AND FUTURE WORK 
The developed application offers a tool to visualize the 
3D reconstructions of the patient’s organs, obtained by the 
segmentation of a CT scan, and to simulate the placement of 
the trocars in order to verify the correctness of the insertion 
sites.  
Furthermore the system retains patient and pathology 
information that the surgeon can insert and includes an 
Augmented Reality module that supports the placement of 
the trocars on the real patient during the surgery procedure.  
An accurate integration of the virtual organs in the real 
scene is obtained by means of an appropriate registration 
phase based on fiducial points fixed onto the patient. In 
addition, a complete user interface allows a simple and 
efficient utilization of the developed application. 
The platform can support the physician in the diagnosis 
step and in the preoperative planning when a laparoscopic 
approach will be followed. In addition, this support could 
lead to a better communication between physicians and 
patient’s parents in order to obtain their informed consent. 
The building of a complete Augmented Reality system 
that could help the surgeon during the other phases of the 
surgical procedure has been planned as future work; the 
acquisition in real time of a patient’s video and the 
dynamically overlapping of the virtual organs to the real 
patient’s body will be developed taking into account the 
surgeon point of view and the location of medical 
instrument. 
An accurate AR visualization modality will be developed 
in order to provide a realistic depth sensation of the virtual 
organs in the real body. 
Accuracy and usability tests will be also carried out. 
 
REFERENCES 
[1] 
F. Devernay, F. Mourgues, and E. Coste-Manière, “Towards 
Endoscopic Augmented Reality for Robotically Assisted Minimally 
Invasive Cardiac Surgery”, IEEE International Workshop on Medical 
Imaging and Augmented Reality, 2001, pp. 16-20. 
[2] 
E. Samset, D. Schmalstieg, J. Vander Sloten, A. Freudenthal, J. 
Declerck, S. Casciaro, Ø. Rideng, and B. Gersak, “Augmented 
Reality in Surgical Procedures”, SPIE Human Vision and Electronic 
Imaging XIII, 2008. 
[3] 
C. Bichlmeier, F. Wimmer, H.S. Michael, and N. Nassir, “Contextual 
Anatomic Mimesis: Hybrid In-Situ Visualization Method for 
Improving Multi-Sensory Depth Perception in Medical Augmented 
Reality”, Sixth IEEE and ACM International Symposium on Mixed 
and Augmented Reality (ISMAR '07), 2007, pp. 129-138. 
[4] 
N. Navab, M. Feuerstein, and C. Bichlmeier, “Laparoscopic Virtual 
Mirror - New Interaction Paradigm for Monitor Based Augmented 
195
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

Reality”, IEEE Virtual Reality Conference 2007 (VR 2007), 
Charlotte, North Carolina, USA, 2007, pp. 10-14. 
[5] 
C. Bichlmeier, S.M. Heining, M. Rustaee, and N. Navab, 
“Laparoscopic Virtual Mirror for Understanding Vessel Structure: 
Evaluation Study by Twelve Surgeons”, 6th IEEE International 
Symposium on Mixed and Augmented Reality (ISMAR'07), Nara, 
Japan, 2007. 
[6] 
D. Kalkofen, E. Mendez, and D. Schmalstieg, “Interactive Focus and 
Context Visualization in Augmented Reality”, 6th IEEE International 
Symposium on Mixed and Augmented Reality (ISMAR'07), Nara, 
Japan, 2007, pp. 191-200. 
[7] 
L.T. De Paolis, M. Pulimeno, M. Lapresa, A. Perrone, and G. Aloisio, 
“Advanced Visualization System Based on Distance Measurement for 
an Accurate Laparoscopy Surgery”, Joint Virtual Reality Conference 
of EGVE - ICAT - EuroVR, Lyon, France, 2009. 
[8] 
L. Soler, S. Nicolau, J-B. Fasquel, V. Agnus, A. Charnoz, A. 
Hostettler, J. Moreau, C. Forest, D. Mutter, and J. Marescaux, 
“Virtual Reality and Augmented Reality Applied to Laparoscopic and 
NOTES Procedures”, IEEE 5th International Symposium on 
Biomedical Imaging: from Nano to Macro, 2008, pp. 1399-1402. 
[9] 
W.E.L. Grimson, T. Lozano-Perez, W.M. Wells, G.J. Ettinger, S.J. 
White, and R. Kikinis, "An Automatic Registration Method for 
Frameless Stereotaxy, Image Guided Surgery, and Enhanced Reality 
Visualization" Transactions on Medical Imaging, 1996. 
[10] X. Papademetris, K.P. Vives, M. Di Stasio, L.H. Staib, M. Neff, 
S. Flossman, 
N. Frielinghaus, 
H. Zaveri, 
E.J. 
Novotny, 
H. Blumenfeld, R.T. Constable, H.P. Hetherington, R.B. Duckrow, 
S.S. Spencer, D.D. Spencer, and J.S. Duncan, “Development of a 
research interface for image guided intervention: Initial application to 
epilepsy neurosurgery”, International Symposium on Biomedical 
Imaging ISBI, 2006, pp. 490-493. 
[11] P.A. Yushkevich, J. Piven, H. Cody, S. Ho, J.C. Gee and G. Gerig, 
“User-Guided Level Set Segmentation of Anatomical Structures with 
ITK-SNAP”, Insight Journal, Special Issue on ISC/NA-MIC/MICCAI 
Workshop on Open-Source Software, Nov 2005. 
[12] E. Bollschweiler, J. Apitzsch., R. Obliers, A. Koerfer, S. P. Mönig, R. 
Metzger, and A. H. Hölscher, “Improving informed consent of 
surgical patients using a multimedia-based program? Results of a 
prospective randomized multicenter study of patients before 
cholecystectomy”, Ann Surg. 248, 2, Aug. 2008, pp. 205-211. 
 
 
196
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

