Emotion-Based Color Transfer of Images Using Adjustable Color Combinations 
Yuan-Yuan Su  
Department of Computer Science 
 National Tsing Hua University 
Hsinchu, Taiwan 
email:steven.nthu@gmail.com 
Hung-Min Sun  
Department of Computer Science 
 National Tsing Hua University 
Hsinchu, Taiwan 
email:hmsun@cs.nthu.edu.tw 
Abstract—This study developed a novel framework for the 
color-transfer between colored images, and that can further 
achieve emotion-transfer between colored images based on the 
human emotion (human feeling) and a predefined color-
emotion model. In this study, a new methodology is proposed. 
The main colors in an image can be adjusted based on the 
complexity of the content of images. The others contributions 
in the study are the algorithms of the Touch Four Sides (TFS) 
and the Touch Up Sides (TUS), which can improve the 
identification of the background and foreground and the other 
main colors that are extracted from the images.
Keywords-Emotion-Transfer; 
Color-Transfer; 
Color-
Emotion; Image Content Analysis. 
I.
INTRODUCTION
Images are the important media for conveying human 
emotions. Colors are also the main component of an image. 
In recent years, researchers have intensively studied the 
usage of images to convey emotions, opinions [1]-[5], and be 
used for one method to take single main color or a fixed 
number of main colors combinations to implement color-
transfer. Nevertheless, an unsolved problem is how to 
understand and describe the emotions caused by an image. 
Another problem is how to understand the inherent 
subjectivity of emotional responses by the user. This study 
develops a novel framework for the color-transfer focusing 
on color images and emotion-transfer implementation 
between color images based on human emotions and a 
predefined color-emotion model. 
II.
METHODS
The new emotion transfer method uses one scheme of 
dynamic and adjustable color combinations which is based 
on the complex content of a color image to determine which 
number of color combinations is used. Additionally, the 
proposed method can accurately identify the primary 
representative colors of the image, and also support both 
solutions, i.e., using relative images and semantics which 
come from a predefined color-emotion model for emotion 
transfer. The method follows five steps as below. 
1)
Color Emotion Model 
2)
Dynamic Extraction of the Main Colors 
a) Identification of the Main colors 
b) Determination of the amount of main colors 
3)
Identification of the Background and the Foreground 
4)
Emotion Transfer 
a) Matching for the Amount of Color Combinations 
b) Color Transfer 
c) Pixel Updates 
d) Gradient Preservation 
5)
Output Image Producing 
The flow chart of the proposed emotion-transfer framework 
is shown below. 
Figure 1. The flow chart of the proposed emotion-transfer framework 
The target emotion from source can be separated in two 
ways. The first approach adopted the Reference Image (RI) 
to get a target emotion, which is acquired by two steps: 
1)
Main colors extraction: extract the main colors for 
the input image and reference image. These main colors can 
be categorized as three kinds of color combination: two-
color, three-color, and five-color. Moreover, our method also 
supports other color-emotion model that may provide more 
than five-color combinations. Also, we combine two 
methods to identify the representative points from image-
pixels, which are Independent Scalar Quantization (ISQ) [6] 
and Linde-Buzo-Gray (LBG) algorithm [7], which is similar 
to a K-means clustering algorithm. In order to determine the 
amount of main colors, the proposed method is then used to 
determine the background and other main colors. 
2)
Emotion-matching: analyze the input image to 
compare with other reference images based on the number 
of main colors. Here, there are two cases. If the number of 
main colors is the same, the main colors of reference images 
will be adopted as the color combinations of target emotion 
7
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-707-8
CONTENT 2019 : The Eleventh International Conference on Creative Content Technologies

directly. One example of this way is shown in Figure 5. 
When the number of main colors are different, the target 
emotion will be assigned with same emotion and search the 
closest color combination from a predefined color-emotion 
model. Another way is to allow users to choose a desired 
emotion directly from a predefined color-emotion model 
which is the model developed by Chou [8] and contains 24 
emotions, each one includes 24 two-color combinations, 48 
three-color combinations and 32 five-color combinations. 
All of the colors in the Chou model are mapped to the RGB 
color space and the CMYK color space. However, this study 
uses the CIELab [9] color space, which is converted from 
the RGB color space. In this study, the number of color 
combinations is chosen according to the complexity of the 
contents of the input image or reference image. The main 
colors extracted from the input image are mapped to the 
target emotion with the same amount of color combinations. 
Therefore, the number of main colors must be controlled 
within this range. After the color-transfer algorithm is used 
to transfer the target emotion to the input image, the output 
image is obtained, and the procedures of the color- emotion 
transfer is completed. 
Fig. 5. When the input image and the reference image have the same 
number of main colors, the target emotion can adopt directly the main color 
from the reference image
III.
CONCLUSION AND FUTURE WORK
This study proposes a novel method and framework for 
performing emotion-transfer based on adjustable and 
dynamic color combinations for color images. The results 
for adjustable and dynamic color combinations have several 
advantages. They illustrate the emotions in images and 
enables color transfer to be performed separately in different 
regions of the images. The results show that the method 
improves the expression of color and emotion in images.  
Non-professionals can also use the proposed method to 
describe objectively and efficiently for the communication 
of human emotions. The experimental results show that the 
proposed approach can naturally alter the emotions between 
photo and painting. It also allows emotionally rich images 
for art and design. Since previous color transfer algorithms 
use only one color or a fixed color combination to obtain 
new images, the images are usually not rich or natural in 
terms of colors and emotions, and the clustering result 
sometimes does not recognize the dominant main color 
correctly.      
The proposed approach uses the methods of ISQ + LBG, 
which is more effective than LBG alone, and the quality of 
images are similar. Other new algorithms in the proposed 
approach, the Touch Four Slides (TFS) and Touch Up 
Slides (TUS) algorithms, can extract the background and 
dominant color correctly from the main colors for most 
images. Furthermore, the representative colors are obtained 
from the method of the adjustable and dynamic color 
combinations, which provides a closer link between human 
and emotion.  
In the future, diﬀerent color-emotion models could be 
used in this framework. For example, since the main colors 
extracted from color images are the most important 
representational colors, they can be used to identify specific 
images. In addition, it can also be used for the feature of the 
emotion. However, although the method always extracts the 
background color accurately, the dominant color may not be 
absolutely and correctly identified for all images. Therefore, 
the method may be still improved by additional elements to 
enhance the extraction of emotion from images, such as 
shape, texture, and so on. 
ACKNOWLEDGMENT
This research was partially supported by the Ministry of 
Science and Technology of the Republic of China under the 
Grants MOST 107-2218-E-007-046 and MOST-106-2221-E-
007 -026 -MY3. 
REFERENCES
[1]
C.-K. Yang and L.-K Peng, “Automatic mood-transferring 
between color images, ”  IEEE Computer Graphics and 
Applications 28, 52–61,March 2008. 
[2]
W. Fuzhang, D. Weiming, K. Yan, M. Xing, C. P. Jean and Z. 
Xiaopeng, “ Content-Based Color Transfer, ”  Computer 
Graphics Forum Volume 32, Issue1, pages 190–203, February 
2013. 
[3]
T Pouli and E Reinhard, “Progressive histogram reshaping 
for creative color transfer and tone reproduction, ”
Computers & Graphics 35 (1), 67-80, 2011. 40, 2011. 
[4]
Y. Chang, S. Saito, K. Uchikawa and M. Nakajima, “
Example based color stylization of images, ”  ACM 
Transactions on Applied Perception 2, 3 , 322–345, 2005. 
[5]
H. Li, Q. Hairong and Z. Russell, “Image color transfer to 
evoke different emotions based on color combinations”, 
Springer, SIViP, 9:1965–1973, 2015. 
[6]
J. D. Foley, A. V. Dam, S. k. Feiner, and J. F. Hughes, ”
Comput. Graphics: Principles and Practice,” Ma Addison 
Wesley, 1990. 
[7]
Y. Linde, A. Buzo, and R. M. Gray, “An Algorithm for 
Vector Quantizer Design, ”  IEEE Transactions on 
Communications, vol. 28, pp. 84-95, January 1980. 
[8]
C. Chien-Kuo, “Color Scheme Bible Compact Edition,”
Grandtech information Co., Ltd, 2011. 
[9]
CIELAB, “CIELab - Color Models - Technical Guides,” 
internet:ba.med.sc.edu/price/irf/Adobe_tg/models/cielab.html, 
accessed Feb 2019. 
8
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-707-8
CONTENT 2019 : The Eleventh International Conference on Creative Content Technologies

