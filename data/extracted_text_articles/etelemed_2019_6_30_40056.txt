Predicting If Older Adults Perform Cognitive Tasks Using Body Joint Movements From
RGB-D Videos
Jenna Ryan∗, Sarah Inzerillo∗, Jordan Helmick†, Ali Boolani‡, Natasaha Kholgade Banerjee∗ and Sean Banerjee∗
∗Department of Computer Science, Clarkson University, Potsdam, NY, USA
†MedExpress, Morgantown, WV, USA
‡Department of Physical Therapy, Clarkson University, Potsdam, NY, USA
Email: {ryanjc, inzeris, aboolani, nbanerje, sbanerje}@clarkson.edu, jordan.helmick@medexpress.com
Abstract—We present an approach that performs automated
detection of whether an older adult has performed cognitive tasks
such as form ﬁlling or problem solving using RGB-D video data
of older adults collected using the Microsoft Kinect v2 sensor. Our
approach uses the variances of 25 joint points on the 3D skeleton
obtained from the Kinect for training random forest classiﬁers
to detect if cognitive tasks are performed, based on deviations
in postural sway induced by cognitive tasks. We validate our
approach using a dataset of 10 subjects performing the test on
standing with eyes closed in the Berg Balance Scale (BBS) series
of diagnostic tests before and after cognitive tasks. Using leave-
one-subject-out cross-validation, we obtain an average detection
accuracy of 69.5%, with accuracies of 60% and 79% at detecting
that the test on standing with eyes closed was performed prior
to and after cognitive tasks respectively. Our approach can be
incorporated into intelligent health care systems to detect whether
older adults have performed cognitively demanding activities that
may induce stress or fatigue, and allow early intervention well
before the occurrence of adverse events such as falls.
Keywords–RGB-D; Kinect; cognitive; fatigue; random forest
I.
INTRODUCTION
The spread of low-cost sensors and computing in the
consumer space has enabled the rise of approaches to perform
automated health assessment in older adults. RGB-D sensors
such as the Microsoft Kinect have been used for detection of
falls [1], [2] and frailty [3], and encouragement of exercise [4].
Adverse events such as falls in older adults place high ﬁnancial
pressure on the health care system. The cost of fatal and non-
fatal falls in the US was $19.2 billion in 2000 [5] and $23.3
billion in 2008 [6]. Instead of detecting adverse events after
they have occurred, ﬁnancial burden on the health care system
can be signiﬁcantly reduced by monitoring older adult health
for signs of fatigue, which has been found to be correlated
with fall risk in older adults [7]. In this work, we use random
forests on RGB-D data from the Microsoft Kinect v2 sensor
to perform automated detection of whether an older adult has
performed cognitive tasks using variation in sway of standing
posture before and after cognitive tasks have been performed.
We deﬁne cognitive tasks in this work as activities involving
reasoning and decision making, that involve the use of working
memory [8]. The cognitive tasks used in our work include
problem solving and questionnaire ﬁlling. Cognitive tasks have
been found to be correlated to increase in postural sway [9],
[10] due to weakening of sensory systems related to balance in
older adults [11]. Increased sway has been found to be related
to rise in fatigue [12]. Using off-the-shelf sensors such as the
Kinect to detect the inﬂuence of cognitive tasks on balance
in older adults can enable intervention in the event of stress
induced by cognitive activities in daily living.
The primary challenge of our work is that cognitive tasks
show a subtle change in postural sway. Traditionally, physical
therapists detect deviation in postural sway by having subjects
perform balance tests such as tests under the Berg Balance
Scale (BBS) [13]. The BBS consists of 13 tests performed
in various postures with eyes open and one test performed
standing with eyes closed. The physical therapist provides
a numerical score between 0 and 56 on assessing all 14
tests, with a lower value indicating lesser balance ability.
However, due to variations between scores of multiple physical
therapists, several studies [14], [15] have been conducted to
determine the reliability of the BBS score in detecting a
change in postural sway. The minimum detectable changes at
an absolute reliability of 95% has been cited as 4 for scores
between 45 and 56 by Donoghue et al. [14] and between 2.8
to 6.6 for eleven studies reviewed by Downs et al. [15] with
BBS scores above 20. In the dataset used in our work where
10 subjects were evaluated doing BBS tests prior to and after
cognitive tasks, the BBS score after cognitive tasks was found
to be reduced by 1.6 points on average with scores ranging
from 49 to 56. Since the reduction is lower than the thresholds
discussed in Donoghue et al. [14] and Downs et al. [15], the
BBS score alone cannot be used to detect movement changes
induced by cognitive tasks.
While there exist approaches to detect changes in gait and
posture due to physical fatigue [16]–[18], these approaches
use body-mounted sensors that hinder natural motion and
may introduce noise that overpowers the subtle inﬂuence of
cognitive tasks. Additionally, these approaches use sensors
placed on a narrow range of locations, e.g., on the foot [16],
[17] or on the lower back [18], which may prove insufﬁcient
to detect the inﬂuence of cognitive tasks on full body postural
sway. Our work addresses the subtle inﬂuence of cognitive
tasks over sway in the head, shoulders, arms, hands, spine, legs,
and feet by using variances in the positions of 25 3D joints
from the Kinect, which being a non-contact sensor allows
natural unweighted motion. We use the 25 body joint variances
as input to the random forest classiﬁer, which provides a
binary output on whether the person performed cognitive tasks.
We enhance the contribution of sense of body joint location,
i.e., proprioception, toward balance by using the BBS test on
standing with eyes closed to eliminate the inﬂuence of visual
cues, which have been found to have the largest contribu-
tion toward balance amongst the visual, proprioceptive, and
vestibular balance mechanisms [19].
We use a linear mixed model with joint variances from
the 10 subjects analyzed in this work to demonstrate that
the 25 joint variances have a statistically signiﬁcant effect
in distinguishing the data prior to and after cognitive tasks.
102
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-688-0
eTELEMED 2019 : The Eleventh International Conference on eHealth, Telemedicine, and Social Medicine

We use a similar linear mixed model to demonstrate that in
a control dataset where the same 10 subjects perform two
rounds of the BBS tests on a different day with a break,
i.e., without cognitive tasks between the rounds, the 25 joint
variances do not have a statistically signiﬁcant contribution
in distinguishing between the pre- and post-break conditions.
Using a leave-one-out cross-validation approach for training
each random forest using 9 subjects and testing with the left
out subject, we obtain an overall average accuracy of 69.5%,
with average accuracies of 60% and 79.0% in detecting that
the test on standing with eyes closed was performed prior
to or after performing cognitive tasks respectively. We also
obtain an average accuracy of 44.5% on the control dataset in
distinguishing between pre- and post-break condition, which
being close to random chance indicates that postural sway
remains consistent in the absence of cognitive tasks.
The remainder of the paper is organized as follows. In
Section II, we discuss contact based approaches for detecting
fatigue, non-contact based approaches for detecting older adult
health, and fatigue detection in driving using non-contact
based sensors. In Section III, we describe the data collection
procedure during the experimental and control days for our
study. In Section IV, we describe our approach for detecting
deviations in balance using joint variance analysis. In Section
V, we describe the linear mixture model that we designed
to determine that joint variances are appropriate predictors
of whether older adults have performed cognitive tasks. In
Section VI, we provide details of the random forest classiﬁer
we trained to determine if an older adult had performed
cognitive tasks. In Section VII, we discuss the performance of
our classiﬁer and provide insights on where misclassiﬁcations
occur. We conclude the paper in Section VIII and provide
potential areas of future work.
II.
RELATED WORK
To the best of our knowledge, there exists no work on
detecting whether a subject performs cognitive tasks from
routine motions such as walking or standing. As cognitive
tasks are known to impact postural sway [9], [10] which
is related to fatigue [11], we discuss approaches to detect
physical fatigue using contact-based and non-contact sensors,
and fatigue during the cognitive task of driving.
Contact-Based Sensors for Detection of Fatigue. Tradi-
tional physiological approaches for automated fatigue detection
have focused on the use of surface electromyography (sEMG)
to measure muscle fatigue during physical exertion; a review
of these approaches may be found in Al-Mulla et al. [20].
While sEMG electrodes do not puncture the skin, they require
skin contact and use a signiﬁcant amount of hardware, thereby
being cumbersome for fatigue detection in everyday envi-
ronments. There also exist approaches to use body-mounted
sensors, such as pressure sensors at six points on the foot to
estimate fatigue during walking [17] or running [16] gait as a
function of maximum pressure. These gait-based approaches
have multiple cues from asymmetries and variations in rotation
or translation of the upper body, hips, legs, and feet during
walking or running gait. Our work on detecting changes in
standing body posture handles the challenge of working with
a smaller set of cues restricted to body sway.
In the area of detection of posture balance, Wall et al. [21]
provide a balance prosthesis that measures head tilt using iner-
tial sensors mounted on the shoulders and trunk, and displays
the tilt to the user for user-driven balance re-adjustment. Their
approach does not perform detection of differences in sway.
Shahzad et al. [18] estimate balance impairment for fall risk
by predicting the score of the BBS for older adults using
acceleration data obtained from a triaxial accelerometer po-
sitioned at the lower back. Their approach shows a separation
between the mean BBS scores of non-fallers at 53.3±2.9 and
fallers at 45.5±7.2. The mean separation is greater than the
thresholds discussed in Donoghue et al. [14] and Downs et
al. [15]. This enables Shahzad et al. to use linear least squares
and LASSO for regression of the BBS score. In our work, the
average separation of 1.6 between BBS scores before and after
cognitive tasks is much smaller than the Donoghue et al. or
Downs et al. thresholds for change detection, preventing the
use of the BBS score as a predictor of cognitive tasks. Our
approach overcomes this issue by using the skeleton obtained
with the Kinect sensor to detect whether cognitive tasks are
performed from the effect they have in the increasing the sway
of 25 body joints.
Physical fatigue or aging handled by the above approaches
show gross changes in movement which can be picked up
by body-mounted sensors. However, body-mounted sensors
hinder natural user motions, and due to their added weight
may prevent separation of data prior to and after cognitive
tasks that have a subtle inﬂuence on motion. Our approach of
using non-contact sensors retains natural motions, enabling us
to detect the weak inﬂuence of cognitive tasks.
Non-contact RGB-D Sensors to Assess Older Adult Health.
Despite the popularity of cameras and RGB-D sensors such
as the Kinect in the consumer space, approaches to perform
automated detection of anomalous health patterns in older
adults using non-contact at-a-distance sensors have been lim-
ited. There exist approaches to perform detection of falls by
tracking the vertical state of a subject [1] or the acceleration
and distance of the center of mass [2]. However, these ap-
proaches enable intervention only after a fall has occurred.
In contrast, our work evaluates postural instabilities to enable
early intervention well before a high-risk incident such as a
fall arises. Gianara et al. [3] use the Kinect to perform frailty
assessment on subjects performing the Timed Up and Go
(TUG) [22] test. They determine that gait parameters such as
walking time and speed, distance covered, and swing correlate
well with the Tillburg Frailty Indicator (TFI) score, while
postural parameters such as torso inclination do not show a
strong correlation with the TFI score. Unlike our work, they
do not perform prediction of frailty in a novel individual.
Fatigue Detection During Driving. The body of work that
resembles ours in using non-contact sensors to detect fatigue
due to cognitive tasks is work on driving fatigue detection,
surveyed extensively in Wang et al. [23]. Here, the cognitive
tasks involved include paying attention to roads, signs, lanes,
pedestrians, intersections, and other drivers. These approaches
use a camera to analyze the user’s face, whereas our work
analyzes the body and assumes that the face may not be
visible, an issue that can occur when the user looks away
from the sensor, has their back toward the sensor, or is at a
distance where the resolution is insufﬁcient for face analysis.
103
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-688-0
eTELEMED 2019 : The Eleventh International Conference on eHealth, Telemedicine, and Social Medicine

Additionally, these approaches detect gross observable changes
such as eyelid open versus closed [24]–[30], head tilt due to
nodding versus upright head [24], [28], eye-gaze narrowed
versus wide [24], and yawning versus not yawning [24], [28],
[30], [31]. Our work detects the presence of subtle changes in
body sway when cognitive tasks such as questionnaire ﬁlling
and problem solving are performed by elderly individuals
in whom body posture prior to induced fatigue shows low
stability due to age [32].
III.
DATA COLLECTION PROCEDURE
Our dataset consists of 10 older adults with 6 female and 4
male subjects. The subjects in our dataset range in age from 57
to 68 years with a mean age of 63.50 ± 4.28 years. To reduce
the effect of confounding factors, we ensure that all subjects
have not been diagnosed with any neurological conditions,
have no pre-existing balance disorders or recent orthopedic
surgery, have visual acuity, and do not require assistive devices
to stand or walk. We collect data from the subjects on two
separate days—an experimental day when the subjects perform
cognitive tasks and a control day when the subjects do not
perform cognitive tasks and instead have a rest break. The
time in between the two collection days ranges from 1 to 9
days, with an average of 2.4 ± 2.5 days, and with the order
of experimental and control day randomized across subjects.
On both the control and experimental day we measure
the subject’s vitals, i.e. height, weight, body composition,
and radial pulse heart rate/blood pressure, and administer
three questionnaires on current feelings of fatigue, mood and
motivation. We then administer three standard diagnostic tests
to measure static and dynamic balance. The tests include
14 assessments under the BBS [13], the Timed Up and Go
(TUG) [22] test, and the 30 Second Chair Stand test [33]. On
the control day, we give the subject a 1 hour break. On the
experimental day, we have the subject perform cognitive tasks
by asking them to ﬁll out questionnaires on demographics,
medical history, physical activity, sleep, grit, hope, satisfaction
with life, interest, self management, and food frequency, and
to perform problem solving activities such as Serial Subtract
3, Serial Subtract 7, Continuous Performance Test, Rapid
Visual Information Processing Test, Trails B Test, and 8
minute Tapping Test [34]–[36]. The subject performs cognitive
tasks on a tablet. After the break on the control day or
cognitive tasks on the experimental day, we ask the subject
to repeat the 30 Second Chair Stand, TUG, and BBS tests.
We record the subject’s vitals, and ask the subject to re-ﬁll
the three questionnaires on current feelings of fatigue, mood
and motivation. The control day activities range from 64.7
to 71.6 minutes, with an average of 68.5 ± 2.0 minutes. The
experimental day activities range from 93.6 and 120.4 minutes,
with an average of 107.5 ± 8.5 minutes.
We developed a custom C# based application using the
Kinect SDK to collect RGB-D video, face, and joint data for
each subject. The RGB-D video data consists of both color
and depth frames captured at 30 frames per second. The face
data consists of 1347 3D face points for each frame of the
video. The joint data consists of 25 3D joint points along
with corresponding x and y coordinate points in color and
depth space for each frame of the video. In Figure 1, we show
color images and corresponding 3D skeletons for 4 different
Subject 4
Experimental
After
Subject 1:
Experimental
Before
Subject 5
Control
After
Subject 7
Control
Before
0 Seconds
2.5 Seconds
5 Seconds
7.5 Seconds
10 Seconds
Figure 1.
Left: Color and skeleton data from four subjects for various
captures. Right: Kinect skeleton labeled with medial axis and left side joints.
subjects. The right side of Figure 1 shows the 3D Kinect
skeleton from a frontal view with labels for joints along the
medial axis and on the left side of the subject.
IV.
REPRESENTING BALANCE DEVIATION USING JOINT
VARIANCES
To eliminate the inﬂuence of visual stimuli which show the
largest contribution to balance [19], we use RGB-D videos
representing the ‘Standing with Eyes Closed’ test from the
BBS assessments for each subject. The ‘Standing with Eyes
Closed’ test involves a subject standing upright with eyes
closed for 10 seconds. Due to the short period of the test,
it provides the added advantage of avoiding noise in the
data due to motions such as straightening clothes, speaking
to the experimenter for clariﬁcation, or accidental gesturing.
The longer duration eyes open tests contain such motions,
which while natural in everyday settings, overpower changes
in motion due to the subtle impact of cognitive tasks. Our
recognition of deviation in balance is based on the premise
that increased movement in the balance tests is related to an
increase in fatigue [12]. To evaluate amount of movement,
we provide an algorithm in MATLAB that estimates the net
variance in each body joint by computing the sum of the
variances in the X, Y , and Z dimensions from the 3D joint
data collected by the Kinect. The variances in the spread of
3D joint points represents the deviation of the subject from a
mean standing position.
Figure 2 shows 3D plots for the Kinect joints data obtained
for a sample subject performing the ‘Standing with Eyes
Closed’ test on the control day prior to and after the break,
and on the experimental day prior to and after the performance
of cognitive tasks. Each plot shows the 3D skeleton from
the ﬁrst frame of the data, together with clusters of 3D
points at each joint representing the locations of the joints
throughout the capture. As each cluster indicates, deviations
in balance inherent to the human body introduce variations in
the locations of the joints. The cluster of points from the left
shoulder is magniﬁed at the bottom of each plot. Note that
on the experimental day after cognitive tasks, the shoulder
points trace a more spread out trajectory in comparison to
the experimental day prior to cognitive tasks and the control
day after the break. The joint variance captures this spread.
Also, while there is a high spread of points on the control
day prior to the break, the bulk of the points are concentrated
104
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-688-0
eTELEMED 2019 : The Eleventh International Conference on eHealth, Telemedicine, and Social Medicine

Control Day:
Before Break
Control Day:
After Break
Experimental Day:
Before Cognitive Tasks
Experimental Day:
After Cognitive Tasks
Figure 2.
Positions of 3D joints for control and experimental day before and
after. Each inset shows the left shoulder points zoomed in.
around the shoulder, and the trailing points are largely outliers.
The joint variance in this case is weighted toward the higher
concentration of points near the mean.
V.
HYPOTHESIS TESTING ON DIAGNOSTIC TESTS AND
JOINT VARIANCES
The three diagnostic tests—30 Second Chair Stand, TUG
and BBS—provide a holistic understanding of changes in
static and dynamic balance. To determine if cognitive tasks
have an observable impact on the diagnostic test scores, we
perform a two-sided paired Wilcoxon Sign Rank Test to test
the following sets of hypotheses on both the control and
experimental day:
Null: Difference between [diagnostic test] scores before and after is 0.
Alt.: Difference between [diagnostic test] scores before and after is not 0.
Here [diagnostic test] refers to the 30 Second Chair Stand
test, the TUG test, and the BBS tests. Since the three diagnostic
tests are performed sequentially, and a subject’s performance
may be impacted by a prior test we apply a Bonferroni
correction and reject the null hypothesis if p < 0.05/3, i.e., if
p < 0.016. On both the control and experimental day we fail to
reject the null hypothesis for all three balance tests, indicating
that cognitive tasks do not create a statistically signiﬁcant
difference in the diagnostic test scores. For the 30 Second
Chair Stand test, we obtain a p-value of 0.76 for the control
day, and 0.34 for the experimental day. For the TUG test we
obtain a p-value of 0.68 for the control day, and 0.37 for the
experimental day. For the BBS, we obtain a p-value of 0.11 for
the control day, and 0.06 for the experimental day. By failing
to reject all three null hypotheses on the diagnostic tests, we
show that cognitive tasks do not show a gross change in static
and dynamic balance tests, indicating that the test scores are
poor predictors of whether cognitive tasks are performed.
The 25 joint variances computed in Section IV provide
a ﬁne-grained understanding of how cognitive tasks affect
movement. We construct a linear mixed model on both the
experimental and control days to determine whether cognitive
tasks impact the joint variances in the ‘Standing with Eyes
Closed’ test before and after cognitive tasks are performed.
Using a log-linear transformation, in the experimental day we
obtain a conﬁdence interval bound of [30.80%, 98.59%] for
the percent difference between the joint variances before and
after cognitive tasks. The percentages indicate a statistically
TABLE I.
ACCURACY OF PREDICTING WHETHER COGNITIVE TASKS
HAVE BEEN PERFORMED ON THE EXPERIMENTAL DAY AND ON THE
CONTROL DAY (PRED. = PREDICTED).
Experimental Day
Control Day
Pred. Before
Pred. After
Pred. Before
Pred. After
Before
60.0%
40.0%
42.0%
58.0%
After
21.0%
79.0%
53.0%
47.0%
signiﬁcant increase of 30.80% to 98.59% in joint variance after
cognitive tasks. On the control day, we obtain a conﬁdence
interval bound of [−34.31%, 3.76%] for the difference between
the joint variances before and after the rest break. In this case,
since 0 lies within the conﬁdence interval, we show no statis-
tically signiﬁcant difference in joint variance before and after
the rest break. The statistically signiﬁcant percent increase in
joint variances after cognitive tasks on the experimental day
substantiates the need for ﬁne-grained joint-based analysis.
VI.
PREDICTING IF COGNITIVE TASKS ARE PERFORMED
USING RANDOM FORESTS
As determined by the linear mixed model, joint variances
on the experimental day have strong discriminative power to
distinguish whether the ‘Standing with Eyes Closed’ test was
performed before or after cognitive tasks. We use the joint
variances as input features in a random forest classiﬁer, with
the output being 0 prior to cognitive tasks and 1 after cognitive
tasks. We use the treebagger function in MATLAB to train
a random forest with 500 decision trees and √n predictors for
each decision split as recommended in Breiman [37], where n
is the number of features, i.e., n = 25. We use a leave-one-
out cross-validation approach for testing our model on data
from the experimental day, where in each fold, 9 of the 10
subjects are used for training, while the left-out subject in
that fold is used for testing. The joint variances from the data
captured before and after cognitive tasks are removed from the
training data for the left-out subject, enabling our approach to
perform prediction of cognitively induced fatigue without prior
knowledge of the subject. The randomness in formation of
decision of trees induces slight differences in the classiﬁcation
at each run of the random forest algorithm. To account for
the randomness, we aggregate the results of the random forest
classiﬁcation for each leave-one-out fold over 10 re-runs of
the random forest algorithm. To determine if the random forest
classiﬁer substantiates the control hypothesis in Section V by
detecting close to chance, we similarly use leave-one-out cross-
validation to train and test the random forest classiﬁer on data
from the control day, where the joint variances are calculated
prior to and after the rest break.
VII.
RESULTS
We show overall results of classiﬁcation using random
forests in Table I. Results of classifying whether the subject
performed the ‘Standing with Eyes Closed’ test before and
after cognitive tasks on the experimental day are shown on
left. We obtain an overall classiﬁcation accuracy of 69.5% on
the experimental day, where the average and standard deviation
are computed over 10 runs of the random forest classiﬁer. We
obtain a classiﬁcation accuracy of 60.0% for the ‘Standing
with Eyes Closed’ test being performed before cognitive tasks,
105
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-688-0
eTELEMED 2019 : The Eleventh International Conference on eHealth, Telemedicine, and Social Medicine

TABLE II.
PER-SUBJECT EXPERIMENTAL DAY CLASSIFICATION
BEFORE AND AFTER COGNITIVE TASKS.
Subject
1
2
3
4
5
6
7
8
9
10
Before
100%
0%
100% 100% 100%
0%
0%
0%
100% 100%
After
100% 80% 100% 100% 100% 100% 20% 100%
0%
90%
and an accuracy of 79.0% for the test being performed after
cognitive tasks. The false positive rate is 40.0%, while the
false negative rate is 21.0%. The lower false negative rate
using the standard random forest algorithm with √n split
predictors proves advantageous to our work, as it is essential
to accurately detect stress induced by cognitively demanding
tasks for intervention. Higher false positives, while inconve-
nient, do not adversely affect the health of the monitored
individual. The right side of Table I shows results of classifying
whether the subject performed the test prior to or after the
break on the control day. The overall classiﬁcation accuracy is
44.5% which being close to chance at 50% substantiates the
hypothesis test in Section V that in the absence of cognitive
tasks, discernible changes in movement may not be produced.
Table II shows per-subject classiﬁcations on the experimental
day averaged over all classiﬁer runs. The classiﬁer correctly
classiﬁes subjects 1, 3, 4, and 5; 6 and 8 after cognitive
tasks; and 10 before cognitive tasks. It generally shows correct
classiﬁcation for 2 and 10 after cognitive tasks.
Incorrect classiﬁcations for data prior to cognitive tasks
occur due to clothing adjustment for subject 2 as seen in
Figure 3(a), and inﬂuence of hand motions toward the center
and experimenter hand support for subject 7 as seen at the top
of Figure 3(b), all of which cause the joint points to show large
deviations from the mean posture. Incorrect classiﬁcation for
data after cognitive tasks may occur due to directed motions
corresponding to a downward shrug observed at the bottom of
Figure 3(b), and due to a steady movement of the shoulders
along the camera axis as observed for the skeleton of the
upper body for subject 6 on the left of Figure 3(c) which
is larger than the motion after cognitive tasks on the right.
The motions in both subjects may resemble the hand motions
of subject 2 adjusting clothing prior to cognitive tasks. These
steady, largely uni-directional, movements may not be related
to balance which tends to show movements with spread along
multiple dimensions as in the shoulder points in Figure 2.
As shown by Figure 3(d), subject 9 shows dense clusters
of points both prior to and after cognitive tasks in the upper
body, causing the data obtained after cognitive tasks to be
classiﬁed as being prior to cognitive tasks. One reason for
the misclassiﬁcation may be that the subject had a higher
amount of physical and mental energy in comparison to the
average physical and mental energy across all subjects on
the experimental day. According to the summarization of the
physical and mental energy for each subject obtained from
self-reported responses to the three questionnaires for fatigue,
mood, and motivation discussed in Section III, the average
physical and mental energy of all 10 subjects prior to cognitive
tasks was 184.7±55.0 and 193.8±64.9 respectively, while the
average physical and mental energy after cognitive tasks was
155.1 ± 71.1 and 150.2 ± 81.0 respectively. Subject 9 showed
higher values of physical and mental fatigue prior to cognitive
tasks at 266 and 263, and after cognitive tasks at 259 and 243.
(a) Subject 2 Prior to 
Cognitive Tasks
(c) Subject 6 Before (Left) and After 
(Right) Cognitive Tasks
(d) Subject 9 Before (Left) and After 
(Right) Cognitive Tasks
(b) Subject 7 Prior to (Top) and After 
(Bottom) Cognitive Tasks
Figure 3.
Frames demonstrating reasons for incorrect classiﬁcation.
VIII.
DISCUSSION
In this paper, we have presented an approach to predict
if cognitive tasks have been performed by an older adult by
analyzing deviations in the standing posture of subjects using
the Kinect. Even though the Kinect has been discontinued,
our approach for movement analysis can be performed using
third party skeleton tracking [38] with other depth sensors
such as the Asus Xtion Pro or Intel RealSense. Our approach
provides an average accuracy of 69.5%, with 79% accuracy
in detecting that cognitive tasks have been performed. By
using low-cost non-contact sensors, our approach enables
detection of the subtle effect of cognitive tasks on motion, and
enables implementation of monitoring technologies in homes
and health care facilities without body-mounted equipment. In
this work, we focus our analysis on subjects performing the
‘Stand with Eyes Closed’ test on the BBS scale to eliminate
the effect of visual cues. In future work, we will analyze eye
gaze patterns from video data to account for the contribution
of the visual system in re-adjusting for balance after cognitive
tasks are performed in the open eyes tests. To account for po-
tential subject-dependency on balance as indicated by subject
9 in Section VII, we will build subject-speciﬁc models for
detection of the effect of cognitive tasks by using data on the
control day to learn regular subject behavior. Such a system
may be propagated to everyday environments for older adult
health monitoring by using occasional input from health-care
providers to update movement models. We will also analyze
the performance of classiﬁers such as linear regression, logistic
regression, and support vector machines to determine optimal
classiﬁers prior to propagation in the ﬁeld.
While our approach on joint variances enables detection
of balance based on increase in deviation from upright pos-
ture, extraneous motions such as clothing adjustments, hand
gestures, and body motions while speaking can overpower the
subtle effect of cognitive tasks. However, such motions are
natural in everyday interactions, and must be accounted for in
a health monitoring system deployed in average user spaces.
The signature of extraneous motions unrelated to balance
may show a higher directional dependence, e.g., downward
movement of a cluster of points belonging to the hand during
clothing adjustment, whereas joint motions related to balance
may have a higher degree of isotropy. In future work, we will
perform principal components analysis to use the magnitude of
movement along various directions at each joint in predicting
the performance of cognitive tasks based on balance ability.
We will also perform an extended data collection on movement
patterns of subjects in everyday environments.
106
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-688-0
eTELEMED 2019 : The Eleventh International Conference on eHealth, Telemedicine, and Social Medicine

ACKNOWLEDGEMENTS
This work was partially supported by the National Science
Foundation (NSF) grant #1730183.
REFERENCES
[1]
E. E. Stone and M. Skubic, “Fall detection in homes of older adults
using the microsoft kinect.” IEEE J. Biomedical and Health Informatics,
vol. 19, no. 1, 2015, pp. 290–301.
[2]
T. Xu, Y. Zhou, and Z. Ma, “Athocare: An intelligent elder care at
home system,” in International Conference on Digital Human Modeling
and Applications in Health, Safety, Ergonomics and Risk Management.
Springer, 2016, pp. 298–305.
[3]
E. Gianaria, M. Grangetto, M. Roppolo, A. Mulasso, and E. Rabaglietti,
“Kinect-based gait analysis for automatic frailty syndrome assessment,”
in International Conference on Image Processing.
IEEE, 2016, pp.
1314–1318.
[4]
S. Ganesan and L. Anthony, “Using the kinect to encourage older adults
to exercise: a prototype,” in CHI’12 Extended Abstracts on Human
Factors in Computing Systems.
ACM, 2012, pp. 2297–2302.
[5]
J. A. Stevens, P. S. Corso, E. A. Finkelstein, and T. R. Miller, “The
costs of fatal and non-fatal falls among older adults,” Injury prevention,
vol. 12, no. 5, 2006, pp. 290–295.
[6]
J. Davis, M. Robertson, M. Ashe, T. Liu-Ambrose, K. Khan, and
C. Marra, “International comparison of cost of falls in older adults living
in the community: a systematic review,” Osteoporosis international,
vol. 21, no. 8, 2010, pp. 1295–1306.
[7]
S. Morrison, S. R. Colberg, H. K. Parson, S. Neumann, R. Handel, E. J.
Vinik, J. Paulson, and A. I. Vinik, “Walking-induced fatigue leads to
increased falls risk in older adults,” Journal of the American Medical
Directors Association, vol. 17, no. 5, 2016, pp. 402–409.
[8]
A. Diamond, “Executive functions,” Annual review of psychology,
vol. 64, 2013, pp. 135–168.
[9]
C. Smolders, M. Doumas, and R. T. Krampe, “Posture and cognition in-
terfere in later adulthood even without concurrent response production,”
Human Movement Science, vol. 29, no. 5, 2010, pp. 809–819.
[10]
U. Granacher, S. A. Bridenbaugh, T. Muehlbauer, A. Wehrle, and
R. W. Kressig, “Age-related effects on postural control under multi-
task conditions,” Gerontology, vol. 57, no. 3, 2011, pp. 247–255.
[11]
E. V. Sullivan, J. Rose, T. Rohlﬁng, and A. Pfefferbaum, “Postural sway
reduction in aging men and women: relation to brain structure, cognitive
status, and stabilizing factors,” Neurobiology of aging, vol. 30, no. 5,
2009, pp. 793–807.
[12]
A. Nardone, J. Tarantola, A. Giordano, and M. Schieppati, “Fatigue
effects on body balance,” Electroencephalography and Clinical Neuro-
physiology/Electromyography and Motor Control, vol. 105, no. 4, 1997,
pp. 309–320.
[13]
K. Berg, S. Wood-Dauphine, J. Williams, and D. Gayton, “Measuring
balance in the elderly: preliminary development of an instrument,”
Physiotherapy Canada, vol. 41, no. 6, 1989, pp. 304–311.
[14]
D. Donoghue and E. K. Stokes, “How much change is true change?
the minimum detectable change of the berg balance scale in elderly
people,” Journal of Rehabilitation Medicine, vol. 41, no. 5, 2009, pp.
343–346.
[15]
S. Downs, J. Marquez, and P. Chiarelli, “The berg balance scale has
high intra-and inter-rater reliability but absolute reliability varies across
the scale: a systematic review,” Journal of physiotherapy, vol. 59, no. 2,
2013, pp. 93–99.
[16]
K. Yonekawa, T. Yonezawa, J. Nakazawa, and H. Tokuda, “Fash:
Detecting tiredness of walking people using pressure sensors,” in Mobile
and Ubiquitous Systems: Networking & Services, MobiQuitous, 2009.
MobiQuitous’ 09. 6th Annual International.
IEEE, 2009, pp. 1–6.
[17]
I. Tanaka, S. Terada, R. Tsuchiya, D. Hanawa, and K. Oguchi, “Fatigue
estimation using foot pressure sensors,” in International Conference on
Telecommunications and Signal Processing. IEEE, 2013, pp. 600–602.
[18]
A. Shahzad, S. Ko, S. Lee, J.-A. Lee, and K. Kim, “Quantitative as-
sessment of balance impairment for fall-risk estimation using wearable
triaxial accelerometer,” IEEE Sensors Journal, vol. 17, no. 20, 2017,
pp. 6743–6751.
[19]
E. E. Hansson, A. Beckman, and A. H˚akansson, “Effect of vision,
proprioception, and the position of the vestibular organ on postural
sway,” Acta oto-laryngologica, vol. 130, no. 12, 2010, pp. 1358–1363.
[20]
M. R. Al-Mulla, F. Sepulveda, and M. Colley, “A review of non-invasive
techniques to detect and predict localised muscle fatigue,” Sensors,
vol. 11, no. 4, 2011, pp. 3545–3594.
[21]
C. Wall, M. S. Weinberg, P. B. Schmidt, and D. E. Krebs, “Balance
prosthesis based on micromechanical sensors using vibrotactile feed-
back of tilt,” IEEE Transactions on Biomedical Engineering, vol. 48,
no. 10, 2001, pp. 1153–1161.
[22]
D. Podsiadlo and S. Richardson, “The timed up & go: a test of basic
functional mobility for frail elderly persons,” Journal of the American
geriatrics Society, vol. 39, no. 2, 1991, pp. 142–148.
[23]
Q. Wang, J. Yang, M. Ren, and Y. Zheng, “Driver fatigue detection:
a survey,” in Intelligent Control and Automation, 2006. WCICA 2006.
The Sixth World Congress on, vol. 2.
IEEE, 2006, pp. 8587–8591.
[24]
Q. Ji, Z. Zhu, and P. Lan, “Real-time nonintrusive monitoring and
prediction of driver fatigue,” IEEE transactions on vehicular technology,
vol. 53, no. 4, 2004, pp. 1052–1068.
[25]
W. Dong and X. Wu, “Fatigue detection based on the distance of eyelid,”
in Proceedings of the IEEE International Workshop on VLSI Design and
Video Technology.
IEEE, 2005, pp. 365–368.
[26]
M. S. Devi and P. R. Bajaj, “Driver fatigue detection based on eye track-
ing,” in International Conference on Emerging Trends in Engineering
and Technology.
IEEE, 2008, pp. 649–652.
[27]
R. C. Coetzer and G. P. Hancke, “Eye detection for a real-time vehicle
driver fatigue monitoring system,” in Intelligent Vehicles Symposium.
IEEE, 2011, pp. 66–71.
[28]
R. Jim´enez, F. Prieto, and V. H. Grisales, “Detection of the tiredness
level of drivers using machine vision techniques,” in Electronics,
Robotics and Automotive Mechanics Conference.
IEEE, 2011, pp.
97–102.
[29]
J. He, S. Roberson, B. Fields, J. Peng, S. Cielocha, and J. Coltea,
“Fatigue detection using smartphones,” Journal of Ergonomics, vol. 3,
no. 03, 2013, pp. 1–7.
[30]
T. Azim, M. A. Jaffar, and A. M. Mirza, “Fully automated real time
fatigue detection of drivers through fuzzy expert systems,” Applied Soft
Computing, vol. 18, 2014, pp. 25–38.
[31]
Y. Cao and B.-L. Lu, “Real-time head detection with kinect for driving
fatigue detection,” in International Conference on Neural Information
Processing.
Springer, 2013, pp. 600–607.
[32]
D. L. Sturnieks, R. St George, and S. R. Lord, “Balance disorders in the
elderly,” Neurophysiologie Clinique/Clinical Neurophysiology, vol. 38,
no. 6, 2008, pp. 467–478.
[33]
C. J. Jones, R. E. Rikli, and W. C. Beam, “A 30-s chair-stand test as
a measure of lower body strength in community-residing older adults,”
Research quarterly for exercise and sport, vol. 70, no. 2, 1999, pp.
113–119.
[34]
A. B. Scholey, S. J. French, P. J. Morris, D. O. Kennedy, A. L. Milne,
and C. F. Haskell, “Consumption of cocoa ﬂavanols results in acute
improvements in mood and cognitive performance during sustained
mental effort,” Journal of Psychopharmacology, vol. 24, no. 10, 2010,
pp. 1505–1514.
[35]
T. N. Tombaugh, “Trail making test a and b: normative data stratiﬁed
by age and education,” Archives of clinical neuropsychology, vol. 19,
no. 2, 2004, pp. 203–214.
[36]
H. Nagasaki, H. Itoh, K. Hashizume, T. Furuna, H. Maruyama, and
T. Kinugasa, “Walking patterns and ﬁnger rhythm of older adults,”
Perceptual and motor skills, vol. 82, no. 2, 1996, pp. 435–447.
[37]
L. Breiman, “Random forests,” Machine learning, vol. 45, no. 1, 2001,
pp. 5–32.
[38]
“Nuitrack full body skeletal tracking software,” https://nuitrack.com/.
107
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-688-0
eTELEMED 2019 : The Eleventh International Conference on eHealth, Telemedicine, and Social Medicine

