An Empirical Investigation of Usability
Measurement in Canvas Educational Applications
A Case Study at the University of North Texas
1st Shabbab Algamdi
Computer Science Department
University of North Texas
Denton, Texas
shabbab.algamdi@unt.edu
2nd Stephanie Ludi
Computer Science Department
University of North Texas
Denton, Texas
stephanie.ludi@unt.edu
Abstract—A Learning Management System (LMS) is a com-
puter software that enables teachers and students to become more
actively involved in their studies and learn more effectively. The
Canvas LMS is one of the best examples in this field as it is
a widely adopted LMS. It is extensively utilized throughout a
range of educational institutions, involving K-12 schools as well as
universities. The platform has received recognition for its intuitive
user interface and comprehensive selection of impacts educational
resources.This study is conducted on computer science students
at the University of North Texas because this sample of students
is more familiar with the terminologies used in the study
regarding gauging usability in Canvas applications. This is done
in accordance with the Jacob Nielsen usability factors study. The
goal of this study is to identify the most significant problems with
the usability of the Canvas application. This study simultaneously
examines and classifies them according to several aspects, and
then determines how to address and improve the responses
for each of these factors. This methodologies adopted in this
study serve as a tool for the main investigation, and the 104
students successfully completed it. The overall scale in the study
had a Cronbach’s alpha rating of 0.969, which shows that the
reliability and consistency of the questionnaire in this study are
quite high.The survey’s framework was built upon the principles
outlined by Jacob Nielsen for mobile usability. During the pilot
testing phase of the survey, the results revealed a substantial
percentage of reliability and validity. Despite minor fluctuations,
the findings consistently demonstrated a commendable level of
reliability. These results open the door for further investigations.
Keywords—Usability; Human-Computer Interaction; Learning
Management Systems; User Reviews; Mobile Application Platform.
I. INTRODUCTION
During the COVID-19 pandemic, the evolution and en-
hancement of Learning Management Systems (LMS) have
been notably pronounced, with Canvas emerging as a promi-
nent example. Canvas LMS boosts a comprehensive set of
features that benefit both students and instructors, contributing
to the positive development of online education during this
challenging period [1]. The Canvas app is one of the most
significant LMS applications [2]. These platforms offer a
variety of functions and resources to help in managing courses,
distributing content, and grading students. The ease of use and
steep learning curves of these platforms greatly influence their
efficiency. A LMS is highly useful when it is simple for users
to use, efficient, and requires minimal effort on their part to
fulfill tasks. The value of the Canvas app has been examined
in a few of studies [1][3] when compared to other educational
apps, the usefulness of the Canvas application is proven to be
high. It is discovered that students using Canvas scored higher
on its navigation easiness and friendly layout.
Mobile learning has a lot of educational potential. The most
recent iteration of mobile technology makes it simple to pro-
vide digital material using portable wireless mobile devices.
Because of the inherent limitations of mobile devices, such
as their small screens, lack of input capabilities, and low
computing capacity, creating mobile learning applications is
not an easy task [4].
In a separate investigation, Hossain [5] conducted a survey
involving college students, revealing a paradox in their percep-
tions of Canvas. While they granted Canvas high marks for its
usability, their assessment of the platform’s search features
and mobile usability was notably unfavorable. In addition
to these studies, a collection of articles and blog posts also
underscores the apparent simplicity of using Canvas. Similarly,
within the domain of educational technology, a blog post
emphasized Canvas’s adaptability and functionality compared
to Blackboard (another widely used LMS), further affirming
the significance of customization and usability within different
LMS platforms [6].
One notable tool that contributes to enhancing the user
experience of educational apps, such as Canvas, is the utiliza-
tion of app reviews. As the usage of smartphones and tablets
by students surges, mobile usability becomes an increasingly
crucial aspect determining the performance of mobile apps.
The usability of an app on mobile devices pertains to its ease of
use and its efficient functionality. A mobile application is con-
sidered user-friendly when it is intuitive, performs seamlessly,
and minimizes user effort. In 2023, the task of identifying
high-quality educational apps appears to be a challenging
endeavor, particularly considering the staggering number of
over 567,000 educational apps available [7]. Thus, instead of
95
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

relying solely on app reviews, this study opted for a more
empirical approach by conducting a usability survey for the
Canvas app. The rest of this paper is organized as follows.
Section II highlights the recent research endeavors related to
the scope of this study. Section III presents the main core
of the methodology adopted. Section IV presents the results
and discussions achieved. Section V discusses the correlation
between the variables, and finally Section VI concludes this
paper and presents recommendations for future work.
II. RELATED WORK
Related work is investigated on two levels. One is address-
ing the mobile application usability in general, while the other
is focusing on education apps usability specifically.
A.
Mobile Application Usability
Building upon Shackel’s model, Nielsen [4] in 1993 pre-
sented his own conceptualization of usability. Initially en-
compassing four attributes (Learnability, Effectiveness, Effi-
ciency, and Satisfaction). Nielsen subsequently revised this
by eliminating ’Effectiveness’ and introducing ’Memorability’
and ’Errors’, culminating in a five-attribute framework. This
conceptualization garnered substantial recognition within the
Human-Computer Interaction (HCI) community, particularly
due to its emphasis on users’ perceptions of the system
and aspects of recall, as highlighted by the inclusion of
’Satisfaction’ and ’Memorability’[8] [9].
Usability in mobile applications is delineated based on the
International Standards Organization’s (ISO) definition, char-
acterizing it as the degree to which a designated user can
employ such an application to realize predetermined objectives
with accuracy, proficiency, and contentment within a given
usage context [10] [11]. Usability studies focus on how system
features and user interactions interact when placed within
particular activities and expected results. Due to the fact that
many software products have been found to be less than ideal
in meeting user needs, a variety of thorough study projects that
go under the general heading of ”usability” have been started.
These efforts aim to promote more profound understanding
and relevant measurement, with the goal of capturing all
relevant phenomena in a single framework or model [12].
B. Education Apps usability
Several academic studies have been conducted to evaluate
the effectiveness of educational applications. A recent inves-
tigation employed deep learning models to discern usability
issues within mobile applications in the education applications
[13]. This research has focused alot on how application
functionality and design affect student learning results [14].
Mobile learning offers a paradigm wherein educational ac-
quisition is untethered from traditional spatial and temporal
constraints. Instead of being confined to established settings
like classrooms or predefined schedules, it facilitates peda-
gogical engagement across diverse locales and at any chosen
moment[15].
This literature review delves into pertinent insights extracted
from recent research concerning the usability of educational
applications. Earlier investigations have primarily focused on
appraising the efficacy of employing educational apps for
instructing young children [16] [17]. Their analysis culmi-
nated in the observation that the efficacy of educational apps
predominantly hinged on factors such as the quality of the
user interface, the ease of navigation, and the capacity to
engage with content. In a similar vein, Perera and Yacef’s
investigation underscored that student motivation and engage-
ment were profoundly impacted by the visual and experiential
aspects inherent in educational app design [18]. Tailoring
learning experiences to individual students stands as another
pivotal attribute of educational apps, contributing to their
user-friendliness. In this context, Lee et al. examined the
influence of personalized learning approaches on the ease
of utilizing educational apps[19]. Their findings underscored
students’ inclination toward personalized learning features,
particularly adaptive content and feedback mechanisms. These
attributes emerged as effective tools for sustaining student
interest and motivation [20]. The usability of educational apps
presents a multifaceted and intricate challenge, encompassing
numerous elements that influence student engagement, moti-
vation, and learning achievements. Through the adoption of
a comprehensive perspective encompassing app design and
functionality, coupled with the integration of attributes that
foster personalization and usability, developers can elevate the
overall usability of educational apps and thereby elevate the
quality of student learning experience [21].
Based on the Jakob Nielsen factors, the scope of this
study can be formulated as follows: For the Canvas LMS
application, and as outlined by Nielsen’s study, to what extent
are the interrelationships between the different usability factors
observable, and what are their effects?
III. METHODOLOGY
To comprehensively understand the usability factors of the
Canvas LMS application in light of Nielsen’s criteria, we
adopted a structured approach. This section delineates the
methods we used, starting with a foundation in the informa-
tion background, followed by an exploration of the general
challenges users encounter.
A. Information Background and General Challenge
In Table 1 valuable insights into the Information Back-
ground and General Challenges encountered by users of
Canvas within the study. The breakdown of users by educa-
tional level indicates a majority of Graduate students (72.1%),
followed by Undergraduate (23.1%) and Doctoral (4.8%)
students. This diversity of academic levels engaging with the
LMS is noteworthy.
The duration of usage of the Canvas mobile app displays an
even distribution, with a significant portion of respondents
(30.8%) using it for 6 months to 1 year and 19.2% for 1 year
to 2 years. This result suggests a moderate level of familiarity
with the platform. Interestingly, fewer users have used the app
96
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

for longer durations, implying that turnover among users could
impact the interpretation their experiences and challenges.
Within the Computer Science Engineering (CSE) department,
a considerable number of respondents (92.3%) are enrolled in
various programs, with Computer Science (62.5%) emerging
as the predominant academic department. This concentration
highlights the potential for tailoring Canvas features to address
this department’s specific needs and requirements. Notable
representation is also seen from other departments, such as
Computer Engineering (13.5%), AI (16.3%), and Cybersecu-
rity (4.8%), underscoring the platform’s adaptability across
diverse fields of study. These findings emphasize the impor-
tance of comprehending the CSE department’s educational
backgrounds, usage patterns, and program enrollments. Such
understanding can guide the enhancement of Canvas to better
serve the distinct needs and challenges faced by users at
different academic stages and within various fields of study.
These demographics are visually represented in Figure 1.
Fig. 1. Information Background for Canvas Users in the Study
TABLE I
INFORMATION BACKGROUND FOR CANVAS USERS IN THE STUDY
Items
N
%
What is the current level of education?
Undergraduate
24
23.1%
Graduate
75
72.1%
Doctoral
5
7.8%
How long have you been using the LMS
Canvas app on mobile?
Less than 6 months
20
19.2%
6 months to 1 year
32
30.8%
1 year to 2 years
20
19.2%
2 years to 3 years
15
14.4%
More than 3 years
17
16.3%
Are you enrolled in any program at the
CSE department?
Yes
96
92.3%
No
8
7.7%
Academic departement
Computer Science
65
62.5%
Computer Engineering
14
13.5%
Cybersecurity
5
4.8%
AI
17
16.3%
other
3
2.9%
B.
Reliability analysis
In Table 2 the Cronbach alpha levels of the study variables
concerning the Canvas users is presented. The conducted
reliability analysis on the Canvas user study variables offers
a comprehensive evaluation of the key factors influencing
user satisfaction and experience. The Cronbach’s alpha values
assigned to each variable serve as internal consistency and
measurement reliability indicators, thus shedding light on the
robustness of the study’s conclusions. Remarkably, the notably
high Cronbach’s alpha values for several variables such as
Visibility of System Status (0.920), Aesthetic and Minimalistic
Design (0.900), and User Control and Intuitiveness (0.911)
underline the robust reliability and interconnectedness of these
aspects. While certain variables exhibit somewhat lower Cron-
bach’s alpha values, such as Recognition Over Recall (0.737)
and Realistic Error Management (0.667), they still indicate a
reasonable level of reliability.
Furthermore, Consistency and Standards, Efficiency of Use
and Performance, and Alignment Between System and Real-
World Context display satisfactory Cronbach’s alpha values of
0.772, 0.798 and 0.777, respectively. Finally, Cronbach’s alpha
level for the total scale in the study was 0.958, indicating that
this questionnaire has excellent reliability and consistency.
TABLE II
THE RELIABILITY ANALYSIS OF THE FACTORS IN THE STUDY
Variable
No.
of
items
Cronbach
alpha
Visibility of System Status
2
0.920
Match Between System and Real World
2
0.777
Aesthetic and Minimalistic Design
2
0.900
Recognition Rather than Recall
2
0.737
Effective Design to Lesson User’s Workload
2
0.870
Flexibility and Efficiency of use
2
0.680
User control and obviousness
2
0.911
Realistic error management
2
0.667
Consistency and standards
3
0.772
Efficiency of use and performance
2
0.798
Total scale
21
0.958
C. Validity Analysis
Table 2 exhibits the outcomes of the validity analysis
conducted on the factors within the Canvas user division.
The validity of the factors was determined via a Pearson
correlation analysis. To establish their construct validity, each
item of the scale was correlated with the entire scale. All
items showcased an immensely significant positive correlation
with the entirety of the scale they are associated with. Thus,
the essential items sufficiently established the concept of the
factors and effectively expressed their significance in assessing
the impressions of Canvas users.
IV. DESCRIPTIVE STATISTICS ANALYSIS
Table 3 and Figure 2 show the descriptive statistics, includ-
ing mean, standard deviation, and the agreement levels of the
Canvas users factors in the study. The ”Visibility of System
Status” factor reflects a positive user sentiment. The users
97
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

TABLE III
USABILITY MEASUREMENT SCORES
Factor
Mean
Std.
Dev.
Level
Visibility of System Status
The status of icons is clearly indicated in the
application.
4.36
1.153
Agree
Graphical user interface menus make obvious
whether deselection is possible.
4.11
1.187
Agree
Visibility of System Status mean score
4.23
1.126
Agree
Match Between System and Real World
The selected colors correspond to common ex-
pectations about the color codes.
4.22
0.996
Agree
Function keys labeled clearly and distinctively,
even if this means breaking consistency rules.
4.06
1.153
Agree
Match Between System and Real World mean
score
4.14
0.974
Agree
Aesthetic and Minimalistic Design
Field labels are brief, familiar, and descriptive.
4.32
1.138
Agree
The large objects, bold lines, and simple areas
have been used to distinguish icons.
4.32
1.193
Agree
Aesthetic and Minimalistic Design mean score
4.32
1.112
Agree
Recognition Rather than Recall
The system provides mapping: do the relation-
ships between controls and actions appear to the
user?
4.19
1.176
Agree
There is a good color and brightness contrast
between image and background colors.
4.32
1.099
Agree
Recognition Rather than Recall mean score
4.26
1.013
Agree
Effective Design to Lesson User’s Workload
A simple design canvas is easy to navigate and
understand and it can significantly reduce the
amount of cognitive load required to complete a
task.
4.40
1.030
Agree
Feedback and error messages can help users
quickly identify and correct mistakes, reducing
the time and effort needed to complete a task.
4.27
1.193
Agree
Effective Design to Lesson User’s Workload
mean score
4.34
1.048
Agree
Flexibility and Efficiency of use
The canvas supports both beginner and expert
users, are multiple levels of error message detail
available.
4.34
1.151
Agree
Canvas offer ”find next” and ”find previous”
shortcuts for database searches.
3.99
1.364
Agree
Flexibility and Efficiency of use mean score
4.16
1.098
Agree
User control and obviousness
Canvas has design and services which make it
customizable and easy to use
4.28
1.177
Agree
Canvas is customizable and simple to use be-
cause to its design and service features.
4.21
1.163
Agree
Realistic error management
Canvas is providing clear and concise error
messages that communicate what went wrong
and how the user can fix it.
3.72
1.282
Agree
Realistic error management mean score
3.93
1.059
Agree
Consistency and standards
Canvas symbols, icons, and symbolism should
be consistent.
4.38
0.818
Agree
When users interact with content on Canvas cat-
egories, they should expect a clear and familiar
experience
4.54
0.743
Agree
Consistency and standards mean score
4.45
0.706
Agree
Efficiency of use and performance
The Canvas application offers specific features
and tools that can help users to quickly locate
the information they need, potentially making it
more efficient than other learning management
systems.
4.22
1.109
Agree
Efficiency of use and performance mean score
4.18
1.026
Agree
Other Considerations
Users may be accessing the device in a variety
of settings, such as while walking, standing in a
crowded area, or sitting in a quiet space.
4.40
1.091
Agree
Fig. 2. All Canvas Users’ Factors Mean in The Study
agree that icons are clearly indicated (M= 4.36, SD = 1.153),
and the graphical user interface menus clarify deselection (M=
4.11, SD = 1.187). The whole mean score factor was 4.23,
indicating a high agreement of the Canvas users toward its
Visibility of System Status. Similarly, the factor ”Match Be-
tween System and Real World” garners agreement, with users
finding that selected colors align with common expectations
(M= 4.22, SD= 0.996) and function keys are distinctly labeled
(M= 4.06, SD= 1.153). Also, the overall mean score of this
factor was 4.14, reflecting the higher matching between the
Canvas system and the real world.
In terms of ”Aesthetic and Minimalistic Design,” users ap-
preciate the use of brief, familiar, and descriptive field la-
bels (M= 4.32, sd= 1.138) and the incorporation of large
objects and bold lines to distinguish icons (M= 4.32, SD=
1.193). Likewise, the overall mean score of this factor was
also 4.32. Furthermore, the ”Recognition Rather than Recall”
factor emphasizes user-friendly design, with users recognizing
the presence of mapping between controls and actions (M=
4.19, SD= 1.176) and appreciating good color and brightness
contrast (M= 4.32, SD= 1.099). The overall mean score of this
factor was 4.26, indicating the increased agreement from the
Canvas users toward this factor.
In addition, the ”Effective Design to Lessen User’s Workload”
factor suggests that a simple design reduces cognitive load
(M= 4.40, SD= 1.030), and users find feedback and error
messages helpful (m= 4.27, SD= 1.193) in streamlining tasks.
The overall mean score showed a high agreement degree with a
mean score of 4.34. similarly, the ”Flexibility and Efficiency of
Use” factor demonstrates Canvas’s support for both beginner
and expert users (M= 4.34, SD= 1.151), although the ”find
next” and ”find previous” shortcuts receive slightly lower
agreement (M= 3.99, SD= 1.364). However, the overall mean
score of this factor was high (4.16), indicating the flexibility
and efficiency of the Canvas use by the participants in the
study.
Moreover, the ”User control and obviousness” factor un-
derscores Canvas’s customizability and ease of use (M= 4.28,
SD= 1.177), aligning with users’ positive perceptions of its
design and services (M= 4.21, SD= 1.163). In this context,
98
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

the User control and obviousness mean score was 4.24. In
terms of ”Realistic error management,” users agree that Canvas
provides clear error messages (M= 3.72, SD= 1.282) and
emphasizes plain language over technical jargon (M= 4.14,
SD= 1.160). Although this factor has the lowest overall mean
score (3.93) among other factors, it still has an agreement level
of response.
On the other hand, The ”Consistency and standards” factor
reflects users’ positive reactions to consistent symbols and
icons (M= 4.38, SD= 0.818), familiar interaction experiences
(M= 4.54, SD= 0.743), and a navigational design standard on
the homepage (M= 4.41, SD= 4.41). The overall mean score
was consistent with these variable scores, with 4.45. Lastly, the
”Efficiency of use and performance” factor highlights Canvas’s
potential efficiency in locating information (M= 4.22, SD=
1.109) and the potential workflow improvements brought by
shortcuts (M= 4.14, SD= 1.142). The overall mean score of
this factor was 4.18, suggesting a highly effective use and good
performance of the Canvas application.
Overall, these results indicate a generally positive percep-
tion of Canvas, with users agreeing on its effectiveness in
delivering a user-friendly, efficient, and consistent experience.
The findings offer actionable insights for further enhancing
the platform’s usability and addressing specific areas for
improvement.
V. CORRELATIONS BETWEEN VARIABLES
Figure 3 show the correlation analysis among the variables
within the Canvas user scale. It yields valuable insights into
the connections between different facets of user experience
and system functionality. The matrix of correlation coefficients
presents a glimpse into the interrelationships of these variables,
illuminating potential patterns and interdependences.
All the variables in the scale show a positive significant
correlation with each other, indicating a high interconnection
between these factors. Where, X1= Visibility of System Status
mean score, X2= Match Between System and Real World, X3=
Aesthetic and Minimalistic Design, X4= Recognition Rather
than Recall, X5= Effective Design to Lessen User’s Workload,
X6= Flexibility and Efficiency of use, X7= Handling varied
contexts of use in mobile environments, X8= User control and
obviousness, X9= Realistic error management, X10= Consis-
tency and standards, X11= Efficiency of use and performance.
Also, P-value calculated by a Pearson correlation test.
VI. CONCLUSION AND RECOMMENDATIONS FOR FUTURE
WORK
As for the research question addressed in this study, and
following the discussion of the significance of The validity
analysis of the factors pertaining to Canvas user division is pre-
sented herein. A questionnaire was implemented on 104 CSE
students to evaluate the different usability factors. To ascertain
the validity of each factor, a Pearson correlation analysis was
employed. Construct validity was gauged by correlating each
item on the scale with the totality of the scale. Notably, all
items exhibited a robust and statistically significant positive
Fig. 3. The Heat Correlation Map of the Variables within the Canvas User
Scale
correlation with their respective scales. Consequently, these
items are deemed competent in representing the conceptual
underpinnings of the factors and are pivotal in assessing the
perceptions of Canvas users. An explanation of the interactions
between the elements is made possible by Figure 3, which
clearly shows the correlations among them.
The achieved results open the door for further comparative ex-
amination between the components in the investigated Canvas
LMS and other apps such as the Blackboard application.
REFERENCES
[1]
M. J. J. Gumasing, A. B. Vasquez, A. L. S. Doctora, and
W. D. D. Perez, “Usability evaluation of online learning
management system: Comparison between blackboard
and canvas,” in 2022 the 9th international conference on
industrial engineering and applications (europe), 2022,
pp. 25–31.
[2]
K. Haan, Best Learning Management Systems (LMS)
Of 2023, https://www.forbes.com/advisor/business/best-
learning-management-systems/, Jul. 2021.
[3]
M. N. Yakubu and S. I. Dasuki, “Factors affecting the
adoption of e-learning technologies among higher edu-
cation students in nigeria: A structural equation mod-
elling approach,” Information Development, vol. 35,
no. 3, pp. 492–502, 2019.
[4]
A. A. Arain, Z. Hussain, W. H. Rizvi, and M. S.
Vighio, “Evaluating usability of m-learning application
in the context of higher education institute,” in Learning
and Collaboration Technologies: Third International
Conference, LCT 2016, Held as Part of HCI Interna-
tional 2016, Toronto, ON, Canada, July 17-22, 2016,
Proceedings 3, Springer, 2016, pp. 259–268.
99
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

[5]
A. A. M. S. Hossain, “Evaluating and testing user
interfaces for e-learning system: Blackboard usability
testing,” J. Inf. Eng. Appl, vol. 5, no. 1, p. 23, 2015.
[6]
J. Kaliski, J. Kalinowski, P. Schumann, T. Scott, D.
Shin, et al., “Competition in the elearning industry: A
case study,” Journal of Business Case Studies (JBCS),
vol. 4, no. 2, pp. 106–122, 2008.
[7]
G. A. Store, Educational Applications on Store, https:
//www.educationalappstore.com/app- lists/apps- for-
education/, [Online; accessed 02-October-2023], 2023.
[8]
J. Nielsen, Usability engineering. Morgan Kaufmann,
1994.
[9]
W. Ali, O. Riaz, S. Mumtaz, A. R. Khan, T. Saba, and
S. A. Bahaj, “Mobile application usability evaluation:
A study based on demography,” IEEE Access, vol. 10,
pp. 41 512–41 524, 2022.
[10]
N. A. N. Ahmad and M. Hussaini, “A usability testing
of a higher education mobile application among post-
graduate and undergraduate students.,” International
Journal of Interactive Mobile Technologies, vol. 15,
no. 9, 2021.
[11]
H. Hoehle and V. Venkatesh, “Mobile application us-
ability,” MIS quarterly, vol. 39, no. 2, pp. 435–472,
2015.
[12]
P. Weichbroth, “Usability of mobile applications: A sys-
tematic literature study,” Ieee Access, vol. 8, pp. 55 563–
55 577, 2020.
[13]
S. Alagmdi, A. Albanyan, and S. Ludi, “Investigating
the usability issues in mobile applications reviews using
a deep learning model,” in 2023 IEEE 13th Annual
Computing and Communication Workshop and Confer-
ence (CCWC), IEEE, 2023, pp. 0108–0113.
[14]
A. H. Safar, A. A. Al-Jafar, and Z. H. Al-Yousefi,
“The effectiveness of using augmented reality apps in
teaching the english alphabet to kindergarten children:
A case study in the state of kuwait,” EURASIA Journal
of Mathematics, Science and Technology Education,
vol. 13, no. 2, pp. 417–440, 2016.
[15]
B. A. Kumar and P. Mohite, “Usability of mobile
learning applications: A systematic literature review,”
Journal of Computers in Education, vol. 5, pp. 1–17,
2018.
[16]
D. O’Brien, K. A. Lawless, and P. Schrader, “A taxon-
omy of educational games,” in Gaming for classroom-
based learning: Digital role playing as a motivator of
study, IGI Global, 2010, pp. 1–23.
[17]
P. G. Schrader and K. A. Lawless, “The knowledge,
attitudes, & behaviors approach how to evaluate perfor-
mance and learning in complex environments,” Perfor-
mance Improvement, vol. 43, no. 9, pp. 8–15, 2004.
[18]
T. Hidayati and S. Diana, “Students’ motivation to learn
english using mobile applications: The case of duolingo
and hello english,” JEELS (Journal of English Educa-
tion and Linguistics Studies), vol. 6, no. 2, pp. 189–213,
2019.
[19]
Y.-C. Hsu and Y.-H. Ching, “Mobile app design for
teaching and learning: Educators’ experiences in an
online graduate course,” International Review of Re-
search in Open and Distributed Learning, vol. 14, no. 4,
pp. 117–139, 2013.
[20]
D. Zhang, “Delivery of personalized and adaptive con-
tent to mobile devices: A framework and enabling
technology,” Communications of the Association for
Information Systems, vol. 12, no. 1, p. 13, 2003.
[21]
N. S. A. Rashid, X. W. Chen, M. F. Mohamad Marzuki,
et al., “Development and usability assessment of a mo-
bile app (demensia kita) to support dementia caregivers
in malaysia: A study protocol,” International Journal
of Environmental Research and Public Health, vol. 19,
no. 19, p. 11 880, 2022.
100
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

