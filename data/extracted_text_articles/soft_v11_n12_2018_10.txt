A Process-Oriented Evaluation Framework for In-Memory Technology Applications
Stephan Ulbricht∗, Marek Opuszko∗, Johannes Ruhland∗
∗Friedrich Schiller University Jena
Department of Business Informations, Jena, Germany
Email: stephan.ulbricht@uni-jena.de, marek.opuszko@uni-jena.de, johannes.ruhland@uni-jena.de
Abstract—For several years, it has been predicted that In-memory
based IT-systems will become a key technology in addressing the
challenges of increasing data volumes and computational speed
requirements. Nevertheless, many companies seem reluctant to
switch to this technology. Missing application scenarios are often
cited as the main cause of the slow spreading. To adress this
research gap, this work will introduce a framework for the
analysis and evaluation of potential applications of In-memory
IT-Systems. The developed framework offers researchers as well
as the corporate sector the opportunity to evaluate the suitability
of such IT systems for existing as well as future use cases. The
development process follows the approach of the design science
research. In the ﬁrst phase relevant inﬂuencing factors for the
use of In-memory systems are identiﬁed conducting a literature
review. In the second phase an expert survey is carried out for
the evaluation and the identiﬁcation of further inﬂuencing factors.
The results show that an acceleration of IT processing does not
generate substantial added value. In particular, business-related
factors have been neglected in the past. Therefore, a structured
analysis framework is introduced considering both, data and
analysis factors as well as economical factors. In the last step the
introduced framework is applied based on selected cross-industry
uses cases to underline the evaluation capabilities.
Keywords–In-Memory
IT-Systems;
Case Study; In-Memory
Computing; In-Memory Database.
I.
INTRODUCTION
In this work, we introduce a design science based system,
able to identify and evaluate inﬂuential factors for potential
application scenarios of In-memory IT-systems [1]. The aim of
this approach is to examine existing as well as potential future
scenarios. Based on an analysis framework, the requirements
and their feasibility of use cases are examined. In order to
identify possible inﬂuence factors of In-memory application
scenarios, case studies and scientiﬁc literature are analyzed.
Subsequently, the inﬂuence factors found are evaluated with
the help of ﬁeld experts who participated in an expert survey,
also identifying yet unknown and additional factors.
In December 2014, Amazon introduced the ”Prime Now”
service, which guarantees the delivery of several thousands of
products within an hour [2]. In the ﬁeld of high frequency
trading, fractions of a second can determine proﬁt or loss
[3]. Sociologists have been talking about this subject as the
”age of acceleration” for quite some time [4]. Never before in
history were decision makers forced to make entrepreneurial
decisions under greater time pressure than today. Furthermore,
increasingly huge and heterogeneous data sets are challenging
companies. Due to the increasing computational demands,
conventional IT solutions reach their performance limits more
and more frequently. One of the most promising technologies
for solving these challenges are In-memory-based IT systems
(IMIS). Although the technology was subject to high expecta-
tions in the past, the predicted boom has not yet begun. In this
context, many companies complain about the lack of useful
and economical application scenarios [5][6]. In a study by the
American SAP user group, this point is mentioned as one of the
main causes for the delayed distribution [7]. The reasons for
this is, among others, the previous focus on technical aspects
[8]. A study by the market research company PAC [9], on the
other hand, shows that the In-memory technology is of great
interest to many companies and can play an important role in
the future. 36% of the surveyed company representatives see
this technology as an important building block in future IT
landscapes. In this ﬁeld of tension, it becomes clear that the
In-memory technology has great potential that has not yet been
exploited. Our contribution starts at this point. With the aid of
our framework practitioners are able to assess the potential of
IMIS.
The paper is organized as follows. Section II introduces
the technical background and the related work in the ﬁeld of
IMIS. In Section III the research methodology is presented.
Afterwards the results of the literature review and the expert
survey are presented in Section III. Section IV comprises the
conception and structuring of the framework. The application
of the developed framework is shown based on selected use
cases in Section V. The ﬁnal section summarizes the contribu-
tions to practice and research.
II.
RESEARCH BACKGROUND
The idea of using main memory to store data is not
new. These concepts were introduced in the 1980s and 1990s
[10][11]. At that time, the main focus was a very fast response
times which were realized by main memory databases. The
speed advantage in comparison to conventional hard disk data
access is illustrated in Table I. Due to high costs and low
memory sizes, the interest regarding In-memory databases
decreased and the technology almost fell into oblivion. With
the introduction of the HANA platform [12], the IT-software
provider SAP has once again placed the focus on IMIS.
TABLE I. Data Access Overview (cited from [13]).
Action 
Time 
Main memory access  
100ns 
Read 1MB sequentially from memory  
250 000ns 
Disk seek  
5 000 000ns 
Read 1MB sequentially from disk  
30 000 000ns 
 
A. Problem Context
The previous concerns about the durability of the stored
data could be eliminated by the use of non-volatile RAM [14].
The concept of IMIS includes more than a pure data storage
97
International Journal on Advances in Software, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/software/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

in the main memory. In contrast to conventional relational
databases, the data is no longer stored row-based, but most
often column-based [15]. The concept of a column-based data
storage is illustrated in Figure 1. The advantage of a column-
based storage is on the one side a better data compression and
on the other side a better suitability for analytical tasks.
col1
col2
col3
row1
A
B
C
row2
A
B
C
row3
A
B
C
row4
A
B
C
A
B
C
A
B
C
A
B
C
A
B
C
A
A
A
A
B
B
B
B
C
C
C
C
Row-Oriented Database
Column-Oriented Database
Row
Row
Row
Row
Column
Column
Column
Contiguous
memory array
Contiguous
memory array
Figure 1. Row- and Column-oriented data layout (adapted according to [13])
Originally, the main application area of IMIS were fast and
ﬂexible analysis of large amounts of data in data warehouses.
In the meantime, the application areas were extended to
transaction systems. The goal here is to dissolve the histor-
ically grown separation between online analytical processing
(OLAP) and online transaction processing (OLTP) systems
[16][17][18]. These hybrid systems are referred to as Online
Mixed Workload Processing (OLXP) [19] and Hybrid Trans-
actional/Analytical Processing (HTAP) [20].
The advantage of a common data storage is the elimination
of extract, transform, load (ETL) processes from the OLTP
into the OLAP system. In addition, transactional data can be
used for analytical and planning tasks. Furthermore, there is a
potential for savings through the elimination of an additional
system [13]. However, it is important to note that analysis and
transaction systems have fundamentally different characteris-
tics and requirements [21]. Analytical systems are generally
used for the support of specialists and executives. Decisions at
these company levels are, in most cases, characterized as strate-
gically or tactically, that means for a longer period. The data
access during the execution of analysis are almost exclusively
read-only [21][22]. On the other hand, transaction systems are
used to solve everyday business tasks of a company. In most
cases, the time horizon only covers a relatively short period
[23]. The typical transactional workload is also largely read
access, but compared with analyzes, with a signiﬁcantly higher
proportion of write accesses [21]. The merging of OLAP
and OLTP systems to an OLXP / HTAP system leads not
only to the advantages mentioned, but also to problems and
difﬁculties. From a technical point of view, hybrid workloads
(line / column-based & read / write) must be simultaneously
processed [24][25][26]. The merging to a common information
system also leads to a stronger dependency on the respective
system provider. In order to be able to exploit the entire beneﬁt
of an IMIS, a large number of applications and processes have
to be adapted.
B. Related Work
IT providers, such as SAP have predominantly driven the
hype surrounding the In-memory technology in the past years.
The focus of recent developments was mostly technology-
oriented. Similar tendencies can be found in early scientiﬁc
contributions. Mainly technical features, such as the column-
based storage of data [15], data compression [27] or the
persistence of volatile storage media [28] were investigated.
An alternative approach for the analysis of possible In-memory
applications tries to assess the advantages and potentials on the
basis of business requirements. In the ﬁrst publications in this
area [29][30][31] Piller and Hagedorn are investigating factors
for evaluating In-memory applications. The authors examine
the potential of IMIS in the retail sector. Despite the early stage
of this technology at the time of the investigation, initial appli-
cation patterns have already been identiﬁed. Similar results are
also reported by Cundius et al. in their work [32][33]. They
developed a model for evaluating real-time IT systems. The
focus of this work was on the workﬂow-speciﬁc properties of
real-time IT systems. In [34] the characteristics of In-memory
systems were described. Based on the identiﬁed attributes
application capabilities were derived. As mentioned in the
previous section, the starting point of the IMIS developments is
the acceleration of analytical applications. In the ﬁeld of real-
time analytics Nadj and Schieder [35] evolved a taxonomy for
the characterization of real-time business intelligence.
The use of IMIS not only has an impact on data processing,
but also on the downstream decision-making and implemen-
tation processes. Vom Brocke et al. examine the connection
between the In-memory technology and the resulting business
use in their contributions [36][37][38]. They conclude that a
value-creation for companies is strongly related to the adaption
of processes. Vom Brocke et al. as well as B¨arenf¨anger et al.
[39] conclude that the introduction of In-memory technology
not only leads to a direct beneﬁt, but to a large extent to
downstream improvements in the process ﬂow. Meier et al.
further pursue the aim of an economic evaluation in [40].
They also divided the economic effects into direct and indirect
attributable effects.
One of the most important innovations of IMIS is the
combination of analysis and transaction systems. Winter et
al. analyze the properties of IMIS in one of the ﬁrst case
studies [41]. In addition to the volume of data, the integration
of the analysis and transaction system is identiﬁed as the most
important indicator for the assessment of IMIS. This point is
also highlighted in several other scientiﬁc papers in this ﬁeld
[19][29][30][42]. From a solely technical perspective, IMIS
offers huge potential. However, the question arises which com-
panies or application areas can exploit this potential in practice.
For many companies predeﬁned reports and evaluations on a
daily basis will still be sufﬁcient. For others, the use of real-
time data can become a decisive competitive advantage.
Another circumstance that inﬂuences the valuation and
therefore also the decision concerning the use of IMIS is the
uncertainty about the possible performance beneﬁts. Research
in this area has shown that In-memory databases do not
always perform better than traditional relational databases. A
prerequisite for a real performance advantage, for example, is
a certain amount of data volume and the number of users [43].
Previous application examples often refer to very speciﬁc
or exotic tasks. A popular example of the application of IMIS
is the analysis of sports data, e.g., in Formula 1 [44] or soccer
[45]. Although these examples are quite illustrative, they are
not suitable to provide insights into the solution of ”everyday”
business problems. The lack of economic use cases is regarded
as one of the main obstacles to the adoption of IMIS. This is
98
International Journal on Advances in Software, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/software/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

mentioned in scientiﬁc literature [29][42][46] as well as from
a company point of view [5][8].
III.
RESEARCH METHODOLGY
The goal of this research work is to examine and struc-
ture IMIS use cases with regard to their success factors.
The methodology of Design Science Research [47] was used
to develop the framework. The aim of this approach is
to make comprehensible, scientiﬁcally sound and practice-
relevant statements in the context of information systems.
The design process is not static, it allows changes to be
incorporated into the existing model. In the so-called design
science research cycle, the results repeatedly iterate through
the various stages of the model development [48]. The whole
design science research cycle as adapted from [48] is shown
in Figure 2. The approach comprised three pillars, eviron-
ment, design science research core and knowledge base. The
environment pillar is where the object of interest and the
application domain reside [47]. This includes organizations,
people and technologies. The knowledge base is comprised by
foundations and methodologies. Hevner et. al [47] state that
this includes foundational theories, frameworks, instruments,
constructs, models and methods. The approach further contains
three cycles within and between the pillars to ensure that both
the relevance and a rigor methodology are ensured during the
design phase. The advantage is that the dynamic characteristics
of business needs can be directly taken into account. The
detailed elaboration of the three phases is described in the
following section:
Evaluate
Build 
Framework
 
Rigor Cycle
- Grounding
- Additions to 
Knowledgebase
Relevance 
Cycle
- Requirements
- Field Testing
Application Domain
 - In-Memory Systems
   -  Aspects:
      - Organizational
      - Technical
      - Human
Foundations
- Scientific Theories 
  & Methods:
     - Model Structure 
 
 Theory
        - Literature 
          Review
        - Expert Survey
 
- Experience & 
    Expertise:
- Science
- Corporate
    - System 
      Vendors
Design 
Cycle
Environment
Design Science 
Research
Knowledge Base
Figure 2. Design Science Research Cycle (adapted according to [48])
Relevance Cycle: The goal of each research is the develop-
ment of an idea or model which is relevant for the application
domain and improves its environment. To reach this goal we
validated the relevance of our model multiple times. Starting
point and motivation of this research project was the already
mentioned demand from business as well as science. During
the development the relevance was ensured by the inclusion
of experts from science, companies and system providers.
Rigor Cycle: Performing scientiﬁc work requires the
consideration of thoroughly and established methods with
regard to the problem context. To address these requirements
we have evaluated and selected appropriate methods for the
construction of our framework. The methodology described
by Klein and Scholl [49] was used to deﬁne the overall
structure of the framework. The main advantage of the used
methodology is the avoidance of structural defects during the
modeling phase. Hereby, it was possible to develop a well-
designed and feasible decision model. For this purpose, the
scope of the model was ﬁrst restricted in order to consider
only the aspects, which are relevant for the problem solving.
After the relevant inﬂuential factors were identiﬁed, they were
subdivided through a structural analysis. As a result of this
structuring process, an operationalizable target system for
assessing and analyzing In-memory use cases has been created.
Literature Review: 
Libraries: AIS Electronic Library, 
EmeraldInsight, IEEEXplore, 
ScienceDirect, SpringerLink and 
Google Scholar
Total Results: ~2400
Relevant: ~30
Keywords: In-Memory Computing, In-
Memory Technology, In-Memory Database, In-
Memory IT System and In-Memory Data 
Management
Phase 1
Expert Survey: 
Total: 25 Experts
Scientific Experts: 8
Corporate Experts: 9
System Vendors: 8
Phase 2
Phase 3
Framework Development
1. influence factors selection
2. structuring of the framework
3. evaluation
Framework Development
Influence Factors 
Selection
Structuring of the 
Framework
Evaluation of the 
Framework
Figure 3. Illustration of the research methodology
Design Cycle: In order to gather the basic factors in-
ﬂuencing the framework, scientiﬁc work and previous case
studies in the ﬁeld of IMIS were analyzed and evaluated
during the ﬁrst design phase. In terms of research method,
this was accomplished according to Webster and Watson
[51]. In the literature review, established literature databases
(AIS Electronic Library, EmeraldInsight, IEEEXplore, Sci-
enceDirect, SpringerLink and Google Scholar) were inves-
tigated. The search included the following key words: ”In-
Memory Computing”, ”In-Memory Technology”, ”In-Memory
Database”, ”In-Memory IT System” and ”In-Memory Data
Management”. Subsequently, a backward search was carried
out. Therefore, only papers dealing with the application and
the business perspective of IMIS were used. The study of
the literature databases revealed that around 2400 scientiﬁc
publications have so far dealt with IMIS. During the litertaure
review phase we conducted a backward as well as a forward
search as suggested by Webster and Watson [51]. In the
backward search, the quoted sources of the keyword search
were analyzed to determine the results of prior research. Based
on these results we used Google Scholar to identify the citing
articles. Due to the context of this paper only publications with
an business perspective were considered. Hence, 30 relevant
papers remained. The detailed results are explained in the
next section. During the second design phase a qualitative
expert survey [52] was carried out to evaluate the results
and identify further factors. In particular, the expert survey
was carried out to reveal further ﬁndings on challenges from
an economic point of view. In order to cover a broad range
of opinions and experiences, the experts were composed of
representatives from different ﬁelds. In total 25 experts in
the ﬁeld of IMIS were interviewed. These included scientists,
company representatives as well as representatives of leading
99
International Journal on Advances in Software, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/software/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Data
Latency
Reaction Time
Value lost 
through 
latency
Analysis
Latency
Decision
Latency
Implementation
Latency
Infrastructure
Latency
Business 
Value
Time
Business-relevant 
Event occurs
Event data 
stored
Analysis 
information 
delivered
Action 
initiated
Action 
completed
Additional Business 
Value through faster 
Data & Analysis 
Processing
Chart legend
Old Event
Improved Event
Time Improvement
Figure 4. Correlation between time and business value (adapted according to [50])
IMIS providers. To ensure a comprehensive knowledge base
we only included experts with a proven experience with In-
memory systems. The scientiﬁc experts were selected based on
publications in the area of IMIS as well as knowledge in the
ﬁeld of databases and information systems. The interviewed
representatives of the system providers and the companies were
also selected on the basis of their experience in this area. Be-
cause of the relative high aquistion costs of IMIS systems only
corporate representatives from medium and large companies
have been included. In semi-structured interviews the experts
were asked about the potential and the obstacles of the In-
memory technology. In addition, the experts were asked to
evaluate possible application scenarios and their characteristics
in detail. An overview of the research methodologies is shown
in Figure 3.
IV.
RESULTS FROM THE LITERATURE REVIEW AND
EXPERT SURVEY
This section outlines the steps of the design cycle process.
The results of the literature review are presented in the ﬁrst
part. The ﬁndings from this part form the foundation of the
created artifact. In the second part, the results of the expert
survey are presented. In the context of the design science cycle,
the expert survey is used to evaluate the previous results as well
as to reveal new inﬂuence factors.
A. Results of the literature and case study review
The examined contributions used different approaches to
deal with the analysis and assessment of the scenarios. The
work [29] by Piller and Hagedorn has proven to be a suitable
basis for the model presented in this work. Starting from the
business process characteristics described in this study, further
inﬂuencing factors were identiﬁed and classiﬁed.
Main memory-based databases are often mentioned to
solve the challenges which are associated with so called
Big Data applications. Due to the availability of larger main
memory and advanced compression by the column orientation,
IMIS is able to process large amounts of data [13][53].
Therefore, it is appropriate to include the data volume of a
use case into the consideration. Apart from the data volume,
a number of other factors play a decisive role. These include,
for example, the urgency of the results [29][30][38][50] or the
dynamics of the data [29][30][32]. Hence, high-performance
systems have a strong positive effect if the data changes
frequently. If the underlying data changes only rarely and to
a small extent, the potential additional value of a real-time
result is very limited. An example for this are purchase pro-
posals in large online shops based on customer segmentation,
which change in general only rarely or marginally. A further
inﬂuencing parameter is the number and type of source systems
[54][55]. In order to cover a broad range of information, it may
be advantageous to integrate several different source systems.
However, from a critical point of view, problems emerge.
The transmission from external sources can lead to delays. A
further and currently very often-discussed topic is the veracity
of information [56].
As already mentioned in Section II, business processes
must be adapted with regard to the newly gained ﬂexibility
and speed of data analysis in order to exploit the full poten-
tial [32][36][37]. The need for process adaptation has to be
clariﬁed on the base of the time business-value relationship
concept from Hackathorn [50]. Figure 4 visualizes this concept
100
International Journal on Advances in Software, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/software/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

and shows that the information-processing latency caused by
IMIS can be reduced, but the additional business proﬁt is
relatively low. In order to generate a higher added value, it
is also necessary to modify and accelerate the downstream
decision-making and implementation processes.
B. Results of the expert survey
In order to evaluate the results and identify further inﬂu-
ential factors, a semistructured expert study was conducted.
One of the most frequent points mentioned in the interviews
was the high uncertainty regarding the economic beneﬁt.
Despite the decline in hardware costs, the purchase of a main
memory-based information system is associated with both high
investment costs and a signiﬁcant total cost of ownership [40].
As with any other investment decision, sufﬁcient value must be
generated to cover the cost of acquisition. A large proportion
of the interviewed company representatives have criticized the
poor cost-beneﬁt ratio concerning IMIS and mentioned several
causes. In most business applications, mainly ”conventional”
analysis and evaluations are carried out in the information
system. These are already deﬁned in advance or can be
well predicted and scheduled. Due to the tactical or strategic
character of the decisions, there is no exceptional urgency to
obtain the results in most cases.
Out of traditional OLAP tasks, the In-memory technology
is perceived more positively. This includes, for example, the
areas of predictive maintenance or the integration and analysis
of social media. To implement a predictive maintenance, a
large number of sensors must be integrated into the analytical
system. The continuous measurement results in a high volume
of data. Ideally, these data should be analysed as quickly
as possible. Another example is the processing of social
media, where large quantities of unstructured texts have to be
processed. These two examples already conﬁrm a signiﬁcant
proportion of the inﬂuencing factors from the ﬁrst design
phase. Another important criterion frequently mentioned were
implementation conditions. According to the experts, not only
the speed of decision-making is a relevant factor, but also the
technical effort and legal obstacles that have to be considered.
These factors were not taken into account in the previous lit-
erature. Efforts for the indoor localization or digital price tags
were cited as examples for technical obstacles. An example
for legal obstacles are the data privacy laws regarding the
analysis of personal data, especially in european countries like
Germany, Spain or the Netherlands.
V.
CONCEPT AND STRUCTURE OF THE EVALUATION
FRAMEWORK
The literature review as well as the results from the expert
study make clear that a variety of factors inﬂuence the assess-
ment of IMIS scenarios. To support the IMIS decision process
it is necessary to structure the inﬂuence factors. According
to Klein and Scholl [49] the decision factors were divided
into a goal hierarchy. This enables a better unterstanding and
usability of the model. Based on the results of the literature
review, the factors can be clustered into two main categories:
data and analysis factors. In the category analysis factors, a
large part of the investigations dealt with questions of urgency,
complexity or ﬂexibility of analysis. Another segment of
research focuses on data-driven factors. These include, among
other issues, the volume, the topicality and the dynamics of
data. As the hesitant spread of IMIS shows, the technical
advantages alone are not enough to generate a substantial
beneﬁt. In the past research of IMIS, this fact was rarely taken
into account. To consider aspects which are related to, e.g.,
real-time decisions and to take the results of the expert study
into account, the framework was extended by the category of
economic factors. This category contains factors with regard to
internal as well as external implementation conditions, which
are particularly important in the corporate context. This part
of the goal hierarchy comprises, e.g., the legal framework or
the target group acceptance. The resulting decision model is
summarized in Figure 5.
Another issue to be considered is the distinct impact of the
inﬂuence factors. The different characteristics of the factors
show that some have a positive effect on the use of IMIS, while
others have a negative impact. To take this into account, we
have extended the IMIS evaluation framework by an additional
inﬂuence indicator. The positive inﬂuences are quite obvious
on the basis of the technical characteristics. In case of, e.g., a
high urgency or a strong data dynamic, the In-memory technol-
ogy can point out its advantages. An example for factors which
are limitating the beneﬁt of IMIS is the amount and kind of
source systems. The integration of numerous external source
systems can lead to latencies regarding the data provision.
Another example are limitations caused by legal regulations.
In several countries privacy policies prohibit the analysis of
personal data. For a better understanding the decision criterias
of our framework are explained in the following part:
A. Analysis factors
Urgency: How fast are the results of the evaluations
needed? These factor focuses on the required response time
for results of the IT-system, for instance, if deadlines have to
be met or subsequent process depend on the results of upstream
processes along a critical path. Another example are ad hoc
reports requested by high management level [29][30][36][53].
Complexity of the evaluations: How complex is the calcu-
lation of the results? The complexity of the calculation depends
on the algorithms used and the underlying data [19][29][30].
Flexibility of analysis: Is it more common for new analysis
to be performed spontaneously? So far, reports have often been
pre-aggregated. The creation of spontaneous evaluations may
take a signiﬁcant amount of time [19][29][41][66].
Degree of detail of the evaluations: In previous informa-
tion systems, the analyzed data is mostly pre-aggregated. With
the help of modern IT systems, evaluations of every level of
detail can be implemented [29][46][55].
Integration of Analysis and Transaction System - hybrid
workload: This involves the processing of hybrid workloads,
here both transactional and analytical data are used for the
tasks to be accomplished. These hybrid systems are called
OLXP or HTAP. The advantage of shared data management
is the elimination of extraction, transformation and loading
(ETL) processes from the OLTP system to the OLAP system.
In addition, real-time data can be used for analyzes, evaluations
or planning [19][29][30][41][42].
Number and type of data sources: From how many
sources and from which types the data is obtained. Internal
sources are easier to implement and faster to retrieve in most
101
International Journal on Advances in Software, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/software/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

+ effects of data changes [29], [30], [32]
+ flexibility of analysis [19], [23], [30], [41]
+ complexity of analysis [19], [29], [30]
+ hybrid workload [19], [29], [30], [41], [42]
- source systems [35], [55]
+ data volume [19], [30], [41]
+ data complexity [53], [54], [70]
- internal realization conditions 
[23], [32], [36], [37], [39], [53]
+ target group acceptance [63]
- technical realization conditions [64]
- legal realization conditions [65] 
+ potential added value [61], [62]
+ degree of detail [30], [46], [55]
data 
dynamic
In-Memory-
System decision 
factors
data factors
analysis factors
economic 
factors
+ frequency of change [19], [30], [53]
+ range of variation [29], [30], [32]
+ urgency [29], [30], [38], [62]
Legend
+ positive impact
-  negative impact
Figure 5. Overview of the analysis and evaluation framework
cases. They further offer a higher predictability for changes in
the interface, e.g., changes in the API. For external sources,
such as social media or cloud services, however, delays may
occur and interfaces have to be updated on a regular basis
[55][54].
B. Characteristics of the underlying data - data factors
Data volume: How big is the underlying dataset. In general
the use of In-memory systems is economically more reasonable
with large data volumes. Smaller amounts of data can be
usually processed by conventional means [19][29][41].
Data Complexity: In addition to volume and the rate of
change, the complexity of data plays a crucial role in big data.
The complexity depends on the one hand on the format and on
the other hand on the data structure. Data can be categorised
as structured in a table like manner, semi-structured like XML,
JSON, text ﬁles or unstructered data, such as images and
video. Especially the processing of unstructered data usually
requires additional methods, such as text-mining and ﬁltering
and enhancing images in order to perform image recognition
techniques [57][58][60].
Characteristics of the underlying data - data dynamics
Frequency of change - topicality of the data: Which
requirements are made in terms of timeliness? Decisive here is
how much added value can be generated by the second-precise
data in comparison to data that is updated in a minutely, hourly
or daily manner. If the requirements on the topicality of the
data s lower, techniques such as caching and temporal data
storage may be used [19][29][53][67].
Effects of the data changes: The inﬂucence factor focus
on the implications of data variations regarding the business
success [29][30][32]. This factor can be interpreted as the
sensitivity of economical effects if data changes. For instance,
even small irregularities during the paint work in the automo-
bile assembly lead to elaborate amendments in the subsequent
production process.
Range of variation: To what extend does the performance
measures change and what is the potential impact of data
variations on the business [29][30][32]?
C. Characteristics of industry - economic factors
Internal realization conditions and implementation pe-
riod: How quickly can the results and decisions from the IT
system be implemented. The use of real-time data has no
added value if, despite a rapid calculation, several days are
required for the implementation of the results. The availability
of real-time information makes it necessary to react quickly to
changes. For the use of the entire potential, it is often necessary
to comprehensively adapt the affected business processes in a
company [23][32][36][38][39][63][53].
Potential (economic) added value: The acquisition of a
new IT system entails high investment costs. This raises the
question of whether the target market has enough potential to
generate the necessary added value [61][62].
Target group acceptance: Are customers ready and will-
ing to deliver all necessary data (e.g., GPS data)? On the other
hand, it is also important to know if a customer is constantly
accepting ﬂuctuating prices in the supermarket [63].
Technical realization conditions: Is it actually possible
to collect and transfer the desired data in due time under
difﬁcult conditions? For example, the transmission of sensor
data from a Brazilian silvermine (or other remote locations) to
the company’s IT system [64].
Legal realization conditions: To what extent may data
be evaluated at all or is the system applicable worldwide.
In Germany, for example, there are very strict requirements
regarding the data privacy and the processing of personal data.
Legal issues in terms of data privacy may occur across borders
or make once legal practices illegal in terms of the General
Data Protection Regulation (GDPR) [68]. Another example is
the decision against the permission of so called geoblocking
and discrimination of EU online shop users [69].
102
International Journal on Advances in Software, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/software/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

VI.
APPLICATION EXAMPLE OF THE FRAMEWORK
In this section the functionality of the framework will be
shown based on selected application examples from different
sectors. The examples were discussed during the expert inter-
views and in initial case studies. Based on the selected use
cases, the advantages of our IMIS evaluation framework are
clariﬁed.
1) Case study ”Analysis of Sales and Inventory Data”: The
analysis of sales and inventory data is one of the core tasks in
the retail sector. One goal is the reduction of storage and deliv-
ery costs. At the same time out-of-stock situations should be
avoided. Thereby, it is necessary to take current sales ﬁgures,
ﬂuctuations due to promotions as well as external inﬂuences
into account. The main characteristics of this business process
are described below:
Data characteristics: Due to the large number of sales
transactions the underlying data volume is quite high. Sales
documents in the retail sector are well-structured and can
therefore be easily processed. A complex transformation is not
necessary. The sales ﬁgures are subject to extensive and quite
frequent variations. In practice, ﬂuctuations can occur up to
500% [70]. This can lead to out-of-stock situations within a
very short time. This in turn leads to a decreasing customer
satisfaction and the loss of potential sales [71].
Analysis characteristics: Caused by the already men-
tioned variations of the sales ﬁgures it is necessary to recognize
anomalies as fast as possible. Therefore, high requirements
regarding the urgency of the analysis are formulated in this
case. The analysis of the information is mostly based on
recurring standard reports. The complexity of the evaluation
as well as the complexity of the underlying data in this case
study is typically low. To detect the anomalies it is sufﬁcient to
evaluate the current inventory information which is typically
stored in transactional systems.
Economic characteristics: Due to the high range of ﬂuc-
tuations in sales ﬁgures, the fast detection of corresponding
anomalies and the avoidance of out-of-stock situations leads
to a better customer satisfaction and a economic beneﬁt.
At this point, the question arises which measures can be
taken to minimize the ﬂuctuations. In the work of Piller
and Hagedorn [29], only non-price measures are proposed
to reduce sales ﬂuctuation. In this case, there are no legal
or technical obstacles to the realization of the measures. As
shown in Figure 4, not only the improved data availability
and faster data processing play a role to generate business
value, but also the downstream decision and implementation
processes. In the example, ”Analysis of Sales and Inventory
Data,” this issue represents the main weakness. Even with
multiple daily supplies, deliveries may take several hours. This
long implementation latency diminishes the advantages of an
accelerated data and analysis processing.
Evaluation of the case study: Evaluating the presented
characteristics, it becomes clear that in overall the data re-
quirements are on a high level. This is caused in partic-
ular by the high data volume and high frequency of data
changes. The analyses requirements can be summarized as
low up to medium. Although the results need to be quickly
processed they include only transactional tasks, the analysis
are predictable and not particularly complex. From a technical
perspective the use of an IMIS System is not essential. In com-
bination with the economic limitations, traditional enterprise
resource planing system are still able to monitor and control
of stock levels.
2) Case study ”Spatial Analytics in Soccer”: As already
mentioned in Section II-B the analysis of soccer was one of the
ﬁrst IMIS application scenarios and one of the most popular
showcases. In this case, video and sensor data from soccer
matches are evaluated and recommendations are given to the
coaches. With the help of the evaluation model presented in
this work, the potential for the use of spatial analysis in soccer
should be assessed.
Figure 6. Example of a spatial analysis in soccer
Data characteristics: The processing of spatial data places
very high demands on IT systems. In the case of spatial
analysis in soccer this involves very large amounts of data
with a complex structure [72]. The constant movement of the
players on the ﬁeld leads to a high frequency of data changes.
A sample spatial analysis in soccer is visualized in a movement
heatmap diagram in Figure 6. This example illustrates well the
high demands on the data processing.
Analysis characteristics: The ﬁxed time horizon of a
soccer game demands, that the results of the analysis have
to be provided within at least 90 minutes. Furthermore, the
continuous changes in a game lead to a very fast decrease
of the competitive advantage of the information. Most added
value is therefore achieved by the provisioning in real-time.
Another challenge is the processing of video recordings in
conjunction with pattern recognition. This requires the use of
advanced algorithms. The demanded degree of detail varies be-
tween individual and team analysis. All these points highlight
the high requirements regarding the analysis capabilities.
Economic characteristics: From an economic point of
view, competitive advantages through better and faster in-
formation promise a tremendous added value. The imple-
mentation of this case has shown that the required technical
capabilities are available. It can be assumed that the players
are able to realize the suggestions from the IT system. So
far there are no limitations which interfere the use of spatial
analysis in soccer. The limiting factors in this scenario are the
legal reglementations. An extraction from the FIFA Statutes
shows that such aids are not allowed during a soccer match:
”information and data transmitted from the devices/systems
is not permitted to be received or used in the technical area
103
International Journal on Advances in Software, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/software/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

during the match” cited from [73]. The technical area depicts a
designated space on the soccer ﬁeld restricted to the technical
staff, coaches and substitute players. This restriction severely
limits the potential added value. As a result, the analysis can
only be used for the post-processing and the preparation of
games.
Evaluation of the case study: The evaluation of the
attributes from a technical point of view implies the suitability
of an IMIS. The data as well as the analysis characteristics
require a sophisticated IT system. Due to the permanent
recording of the spatial information, very large amounts of
data accumulate. Conventional information systems can not
complete these tasks in sufﬁcient time. The beneﬁt of the
presented framework becomes especially clear when the eco-
nomic factors are considered. Basically, a faster and more
ﬂexible processing would lead to a high economic beneﬁt.
The major beneﬁt in this use case is limited through legal
reglementations. These reglementations result in an forced
implementation latency of several hours. Within this time
horizon also conventional IT systems are able to perform the
calculations. An IMIS system is therefore not mandatory.
3) Case study ”Management of Renewable Energy”: The
energy revolution and the closely related use of renewable
energy resources is one of the greatest challenges facing states,
companies and individuals today. The scenario to be analyzed
comprise a holistic ”energy cycle” - from the generation to the
transmission up to the consumer. The concept of a connected
intelligent energy network is often called ’smart grid’. The
efﬁcient execution of this holistic energy process requires the
consideration of numerous factors such as the weather, the
energy grid utilization or the current consumption. The process
characteristics are described below analogously to the previous
examples:
Data characteristics: In the energy sector very large
amounts of data accrue every day. These data is generated
e.g., by smart meter devices, weather stations or the continous
application of sensors. This variety of data sources leads to
an increasing of the data complexity. The data processing
increasingly requires the consideration of complex data struc-
tures [74]. Another challenging characteristic is the high data
dynamic. The amount of the produced energy, the energy
demand, etc. are frequently changing. In addition to the high
frequency of changes the impact of data changes is substantial.
All in all the demands placed on data processing can be
assessed as high in the examined criteria.
Analysis characteristics: The efﬁcient control of measures
requires, that the analysis results have to be available in real-
time. In this use case, current data from a variety of source
systems must be taken into account. Analogous to the previous
case this results in an interaction of transactional and analytical
tasks. An important part of the management of renewable
energy is the prediction of the produced energy. Thereby
complex procedures are used, considering for example weather
conditions [75]. Similar to the data requirements there are high
analysis requirements.
Economic characteristics: As already described in the
introduction of this use case, this scenario offers comprehen-
sive possibilities for improvements. The potential added value
comprises beside monetary savings also positive ecological
aspects. Through the use of smart meter devices, controllable
energy networks and improved weather forecasts the technical
requirements for smart grids are already in place. The only
weak point in the economic evaluation of this scenario is the
inconsistent user acceptance. Studies in this ﬁeld have revealed
a differing acceptance to adopt to this technology [76].
Evaluation of the case study: The technical requirements
in this case are very high in all areas. The large data volume,
the data volatility, recently changing data, the need for quick
responses and the combination of analytical and transactional
tasks are strong indicators for the suitability of an IMIS.
The economic analysis of this example also shows a high
added value through faster data processing. Furthermore, the
realization conditions indicates no basic obstacles. The model
therefore indicates the suitability of the In-memory technology
in all examined categories.
VII.
CONCLUSION
The aim of this work was to create a framework for
analyzing and evaluating application scenarios in the context
of IMIS. As current research as well as statements from
industry experts show, such a framework was missing. To
cover all relevant factors for the application of an IMIS, not
only theoretical work was included in this work. Through the
inclusion of corporate experts, also practical aspects have been
considered. Based on the ﬁrst case studies in this area and
scientiﬁc work, a large part of the inﬂuencing factors could
be identiﬁed. Results show that the inﬂuence factors found
through literature review and expert study could be divided
into three main categories: analysis factors, data-driven factors
and economic factors. Based on the expert survey, it was
also possible to conﬁrm the factors from the literature and to
uncover other previously unconsidered factors. In order to take
account of all aspects relevant to the companies, the model was
expanded by features with regard to the proﬁtability and the
feasibility of possible ﬁelds of application. These include, for
instance, the implementation conditions, legal obstacles or the
acceptance of target groups. The capabilities of the framework
were emphasized through the presented cross-industry use
cases. It became clear that the evaluation of possible IMIS
application scenarios requires a holistic view of all aspects.
The presented model can be used as an additional assessment
instrument for corporate decision makers.
In a next step, it will be necessary to evaluate the suit-
ability of the framework based on quantitative investigations
in different industry sectors. The use cases presented in this
work indicate a relevance variation in terms of the assessment
of the inﬂuence factors. It is supposed that the relevance of
the inﬂucence factors varies between branches and companies.
Another question not considered in this work is the implicit
and explicit nature of the inﬂuence factors in terms of value
creation. Some factors like urgency have a very direct explicit
impact on the value creation whereas other factors such as data
complexity or data volume have a more indirect and implicit
impact. Consequently, this fact should be taken into account
in future work.
REFERENCES
[1]
S. Ulbricht, M. Opuszko, J. Ruhland, and M. Thrum, “Towards an
analysis and evaluation framework for in-memory-based use cases,”
in The Twelfth International Multi-Conference on Computing in the
Global Information Technology, 2017, pp. 22–27.
104
International Journal on Advances in Software, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/software/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[2]
“Amazon
Introduces
Prime
Now,”
2014,
URL:
http://www.
businesswire.com/multimedia/home/20141218005363/en/
[accessed:
2017-03-14].
[3]
“The
Wall
Street
Journal
-
High-Speed
Stock
Traders
Turn
to
Laser
Beams,”
2014,
URL:
http://www.wsj.com/articles/
SB10001424052702303947904579340711\\424615716
[accessed:
2017-03-14].
[4]
H. Rosa, Beschleunigung: die Ver¨anderung der Zeitstrukturen in der
Moderne, ser. Suhrkamp Taschenbuch Wissenschaft.
Suhrkamp, 2005.
[5]
“SAP
fehlen
echte
HANA-Business-Cases,”
2015,
URL:
http://www.cio.de/a/sap-fehlen-echte-hana-business-cases,2940526
[accessed: 2017-03-14].
[6]
“Lack
of
SAP
HANA
use
cases
stiﬂing
demand
among
ASUG
members,”
2014,
URL:
http://diginomica.com/2014/08/08/
lack-sap-hana-use-cases-stiﬂing-demand-among-asug-members/
[accessed: 2017-03-14].
[7]
“ASUG Member Survey Reveals Successes, Challenges of SAP
HANA
Adoption,”
2014,
URL:
http://www.asugnews.com/article/
asug-member-survey-reveals-successes-challenges-of-sap-hana-adoption
[accessed: 2017-03-14].
[8]
“Hunting happy HANA customers,” 2014, URL: http://diginomica.com/
2014/10/27/hunting-happy-hana-customers/ [accessed: 2017-03-14].
[9]
“SAP Business Suite powered by SAP HANA,” 2014, URL: https://
www.pac-online.com/download/9757/125462 [accessed: 2017-03-09].
[10]
H. Garcia-Molina and K. Salem, “Main memory database systems:
An overview,” IEEE Transactions on knowledge and data engineering,
vol. 4, no. 6, 1992, pp. 509–516.
[11]
D. J. DeWitt, R. H. Katz, F. Olken, L. D. Shapiro, M. R. Stonebraker,
and D. A. Wood, Implementation techniques for main memory database
systems.
ACM, 1984, vol. 14, no. 2.
[12]
F. F¨arber, S. K. Cha, J. Primsch, C. Bornh¨ovd, S. Sigg, and W. Lehner,
“Sap hana database: data management for modern business applica-
tions,” ACM Sigmod Record, vol. 40, no. 4, 2012, pp. 45–51.
[13]
H. Plattner and A. Zeier, In-memory data management: technology and
applications.
Springer Science & Business Media, 2012.
[14]
M. K. Gupta, V. Verma, and M. S. Verma, “In-memory database
systems-a paradigm shift,” 2014, pp. 333–336.
[15]
D. J. Abadi, P. A. Boncz, and S. Harizopoulos, “Column-oriented
database systems,” Proceedings of the VLDB Endowment, vol. 2, no. 2,
2009, pp. 1664–1665.
[16]
A. Kemper and T. Neumann, “Hyper: A hybrid oltp&olap main memory
database system based on virtual memory snapshots,” in Data Engineer-
ing (ICDE), 2011 IEEE 27th International Conference on. IEEE, 2011,
pp. 195–206.
[17]
H. Plattner, “A common database approach for oltp and olap using an
in-memory column database,” 2009, pp. 1–2.
[18]
N. May, A. B¨ohm, and W. Lehner, “Sap hana–the evolution of an in-
memory dbms from pure olap processing towards mixed workloads,”
Datenbanksysteme f¨ur Business, Technologie und Web (BTW 2017),
2017.
[19]
P. Loos, J. Lechtenb¨orger, G. Vossen, A. Zeier, J. Kr¨uger, J. M¨uller,
W. Lehner, D. Kossmann, B. Fabian, O. G¨unther et al., “In-memory
databases in business information systems,” Business & Information
Systems Engineering, vol. 3, no. 6, 2011, pp. 389–395.
[20]
M.
Pezzini,
D.
Feinberg,
N.
Rayner,
and
R.
Edjlali,
“Hybrid
transaction/analytical processing will foster opportunities for dra-
matic business innovation,” Gartner (2014, January 28) Available
at https://www. gartner. com/doc/2657815/hybrid-transactionanalytical-
processing-foster-opportunities, 2014.
[21]
J. Krueger, M. Grund, C. Tinnefeld, B. Eckart, A. Zeier, and
H. Plattner, “Hauptspeicherdatenbanken f¨ur unternehmensanwendun-
gen,” Datenbank-Spektrum, vol. 10, no. 3, 2010, pp. 143–158.
[22]
P. Loos, S. Strohmeier, G. Piller, and R. Sch¨utte, “Comments on
in-memory databases in business information systems,” Business &
Information Systems Engineering, vol. 4, no. 4, 2012, pp. 213–223.
[23]
S.
Strohmeier,
“Hauptspeicherdatenbanken
in
der
betrieblichen
informationsversorgung–technische innovation und fachliche stagna-
tion,” Wirtschaftsinformatik, vol. 54, no. 4, 2012, pp. 209–210.
[24]
J. Krueger, M. Grund, C. Tinnefeld, H. Plattner, A. Zeier, and F. Faer-
ber, “Optimizing write performance for read optimized databases,” in
Database Systems for Advanced Applications.
Springer, 2010, pp.
291–305.
[25]
J. Wust, J.-H. Boese, F. Renkes, S. Blessing, J. Krueger, and H. Plattner,
“Efﬁcient logging for enterprise workloads on column-oriented in-
memory databases,” in Proceedings of the 21st ACM international
conference on Information and knowledge management.
ACM, 2012,
pp. 2085–2089.
[26]
A. K. Goel, J. Pound, N. Auch, P. Bumbulis, S. MacLean, F. F¨arber,
F. Gropengiesser, C. Mathis, T. Bodner, and W. Lehner, “Towards
scalable real-time analytics: an architecture for scale-out of olxp work-
loads,” Proceedings of the VLDB Endowment, vol. 8, no. 12, 2015, pp.
1716–1727.
[27]
D. Abadi, S. Madden, and M. Ferreira, “Integrating compression and
execution in column-oriented database systems,” in Proceedings of the
2006 ACM SIGMOD international conference on Management of data.
ACM, 2006, pp. 671–682.
[28]
T. Winsemann and V. K¨oppen, “Kriterien f¨ur datenpersistenz bei
enterprise data warehouse systemen auf in-memory datenbanken.” in
Grundlagen von Datenbanken, 2011, pp. 97–102.
[29]
G.
Piller
and
J.
Hagedorn,
“In-memory
data
management
im
einzelhandel: Einsatzbereiche und nutzenpotentiale,” Multikonferenz
Wirtschaftsinformatik 2012 : Tagungsband der MKWI 2012 / Hrsg.:
Dirk Christian Mattfeld; Susanne Robra-Bissantz.
[30]
——, “Business beneﬁts and application capabilities enabled by in-
memory data management,” in Innovative Unternehmensanwendungen
mit In-Memory Data Management, IMDM 2011, 2. Dec 2011, Mainz,
ser. LNI, W. Lehner and G. Piller, Eds., vol. 193. GI, 2011, pp. 45–56.
[31]
——, “Einsatzpotenziale f¨ur in-memory data management in be-
trieblichen anwendungssystemen,” Wirtschaftsinformatik & Manage-
ment, vol. 3, no. 5, 2011, pp. 18–25.
[32]
C. Cundius and R. Alt, “Real-time or near real-time?-towards a real-
time assessment model,” Thirty Fourth International Conference on
Information Systems, 2013, pp. 1–18.
[33]
——, “A process-oriented model to business value–the case of real-
time it infrastructures,” in Proceedings of the 50th Hawaii International
Conference on System Sciences, 2017.
[34]
B. Otto and R. B¨arenf¨anger, “Potentiale und risiken von in-memory-
technologie: Eine business engineering-perspektive,” in Wirtschaftsin-
formatik in Wissenschaft und Praxis.
Springer, 2014, pp. 153–163.
[35]
M. Nadj and C. Schieder, “Towards a taxonomy of real-time business
intelligence systems,” 2017.
[36]
J. vom Brocke, S. Debortoli, and O. M¨uller, “In-memory database
business value,” 360 - The Business Transformation Journal, vol. 3,
no. 7, 2013, pp. 16–26.
[37]
J. vom Brocke, “In-memory value creation, or now that we found love,
what are we gonna do with it?” BPTrends, vol. 10, 2013, pp. 1–8.
[38]
J. vom Brocke, S. Debortoli, O. M¨uller, and N. Reuter, “How in-memory
technology can create business value: insights from the hilti case,”
Communications of the Association for Information Systems, vol. 34,
no. 1, 2014, pp. 151–167.
[39]
R. B¨arenf¨anger, B. Otto, and H. ¨Osterle, “Business value of in-memory
technology–multiple-case study insights,” Industrial Management &
Data Systems, vol. 114, no. 9, 2014, pp. 1396–1414.
[40]
M. C. Meier, A. Schefﬂer, and K. Finanz, “ ¨Okonomisch sinnhafte be-
wertung von in-memory-basierten betrieblichen informationssystemen.”
in IMDM.
Citeseer, 2011, pp. 115–124.
[41]
R. Winter, S. Bischoff, and F. Wortmann, “Revolution or evolution?
reﬂections on in-memory appliances from an enterprise information
logistics perspective.” in IMDM, 2011, pp. 23–34.
[42]
R. Sch¨utte, “Analyse des einsatzpotenzials von in-memory-technologien
in handelsinformationssystemen.” in IMDM, 2011, pp. 1–12.
[43]
R. Meyer, V. Banova, A. Danciu, D. Prutscher, and H. Krcmar, “As-
sessing the suitability of in-memory databases in an enterprise context,”
in Enterprise Systems (ES), 2015 International Conference on.
IEEE,
2015, pp. 78–89.
[44]
“McLaren Formula 1 - Partners - SAP,” 2015, URL: http://www.
mclaren.com/formula1/partners/SAP [accessed: 2017-03-14].
105
International Journal on Advances in Software, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/software/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[45]
“Big Data & Spatial Analytics Help Germany Score the World Cup,”
2014,
URL:
http://www.saphana.com/community/blogs/blog/2014/
07/15/how-big-data-helped-germany-score-the-world-cup
[accessed:
2017-03-14].
[46]
G. Koleva, “Fields of usage for in-memory databases in enterprises,” in
11th Workshop on Information Systems and Services Sciences, 2011,
pp. 19–33.
[47]
A. R. Hevner, S. T. March, J. Park, and S. Ram, “Design science in
information systems research,” MIS quarterly, vol. 28, no. 1, 2004, pp.
75–105.
[48]
A. R. Hevner, “A three cycle view of design science research,” Scan-
dinavian journal of information systems, vol. 19, no. 2, 2007, p. 4.
[49]
R. Klein and A. Scholl, Planung und Entscheidung. Vahlen, M¨unchen,
2004.
[50]
R. Hackathorn, “Minimizing action distance,” DM REVIEW, vol. 12,
2002, pp. 22–23.
[51]
J. Webster and R. T. Watson, “Analyzing the past to prepare for the
future: Writing a literature review,” MIS quarterly, 2002, pp. xiii–xxiii.
[52]
H. O. Mayer, Interview und schriftliche Befragung: Grundlagen und
Methoden empirischer Sozialforschung.
Walter de Gruyter, 2013.
[53]
H. Zhang, G. Chen, B. C. Ooi, K.-L. Tan, and M. Zhang, “In-memory
big data management and processing: A survey,” IEEE Transactions on
Knowledge and Data Engineering, vol. 27, no. 7, 2015, pp. 1920–1948.
[54]
M. Nadj and C. Schieder, “Quo vadis real-time business intelligence?
a descriptive literature review and future directions,” 24th European
Conference on Information Systems, 2016, pp. 1–20.
[55]
W. H. Inmon, Building the data warehouse.
John wiley & sons, 2005.
[56]
L. Berti-Equille and J. Borge-Holthoefer, “Veracity of data: From
truth discovery computation algorithms to models of misinformation
dynamics,” Synthesis Lectures on Data Management, vol. 7, no. 3, 2015,
pp. 1–155.
[57]
H. Baars and H.-G. Kemper, “Management support with structured
and unstructured data an integrated business intelligence framework,”
Information Systems Management, vol. 25, no. 2, 2008, pp. 132–148.
[58]
B. Inmon and K. Krishnan, Building the Unstructured Data Warehouse:
Architecture, Analysis, and Design.
Technics Publications, 2011.
[59]
T. Knabke and S. Olbrich, “Grundlagen und einsatzpotentiale von in-
memory-datenbanken,” in Analytische Informationssysteme.
Springer,
2016, pp. 187–203.
[60]
S. Sarawagi, “Queries over unstructured data: Probabilistic methods to
the rescue,” in International Workshop on Business Intelligence for the
Real-Time Enterprise.
Springer, 2009, pp. 1–13.
[61]
L. Olsson and C. Janiesch, “Real-time business intelligence und action
distance: Ein konzeptionelles framework zur auswahl von bi-software.”
in Wirtschaftsinformatik, 2015, pp. 691–705.
[62]
R. Hackathorn, “Real-time to real-value,” Information Management,
vol. 14, no. 1, 2004, p. 24.
[63]
M. Bauer, Kundenzufriedenheit in industriellen Gesch¨aftsbeziehungen:
kritische Ereignisse, nichtlineare Zufriedenheitsbildung und Zufrieden-
heitsdynamik.
Springer-Verlag, 2013.
[64]
S. King, Big Data: Potential und Barrieren der Nutzung im Un-
ternehmenskontext.
Springer-Verlag, 2014.
[65]
S. Ciriani, “The economic impact of the european reform of data
protection,” Digiworld Economic Journal, vol. 97, 2015, pp. 41–58.
[66]
W. Sinzig and K. R. Sharma, “In-memory-technologie: Verbesserungen
bei
planung,
simulation
und
entscheidungsunterst¨utzung,”
Wirtschaftsinformatik & Management, vol. 3, no. 2, 2011, pp.
18–23.
[67]
J. Lee, Y. S. Kwon, F. Frber, M. Muehle, C. Lee, C. Bensberg, J.-Y.
Lee, A. H. Lee, and W. Lehner, “Sap hana distributed in-memory
database system: Transaction, session, and metadata management.”
in ICDE, C. S. Jensen, C. M. Jermaine, and X. Zhou, Eds.
IEEE Computer Society, 2013, pp. 1165–1173. [Online]. Available:
http://dblp.uni-trier.de/db/conf/icde/icde2013.html#LeeKFMLBLLL13
[68]
M. K¨orner, “Die reform des eu-datenschutzes: Der entwurf einer eu-
datenschutz-grundverordnung (ds-gvo)–teil ii,” 2018.
[69]
J. Borer, “Spruchpraxis zum eu-wettbewerbsrecht (2016/2017),” Swiss.
Rev. Int’l & Eur. L., vol. 27, 2017, p. 251.
[70]
C. Narasimhan, S. A. Neslin, and S. K. Sen, “Promotional elasticities
and category characteristics,” The Journal of Marketing, 1996, pp. 17–
30.
[71]
P. Verhoef and L. Sloot, “Out-of-stock: reactions, antecedents, manage-
ment solutions, and a future perspective,” Retailing in the 21st Century,
2006, pp. 239–253.
[72]
A. Bialkowski, P. Lucey, P. Carr, Y. Yue, S. Sridharan, and I. Matthews,
“Large-scale analysis of soccer matches using spatiotemporal tracking
data,” in Data Mining (ICDM), 2014 IEEE International Conference on.
IEEE, 2014, pp. 725–730.
[73]
“Laws of the Game 2017-18,” 2017, URL: http://resources.ﬁfa.
com/mm/document/footballdevelopment/refereeing/02/90/11/67/
lawsofthegame2017-2018-en neutral.pdf [accessed: 2018-02-09].
[74]
K. Zhou, C. Fu, and S. Yang, “Big data driven smart energy manage-
ment: From big data to big insights,” Renewable and Sustainable Energy
Reviews, vol. 56, 2016, pp. 215–225.
[75]
P. D. Diamantoulakis, V. M. Kapinas, and G. K. Karagiannidis, “Big
data analytics for dynamic energy management in smart grids,” Big
Data Research, vol. 2, no. 3, 2015, pp. 94–101.
[76]
M. Broman Toft and J. Thøgersen, “Exploring private consumers
willingness to adopt smart grid technology,” International journal of
consumer studies, vol. 39, no. 6, 2015, pp. 648–660.
106
International Journal on Advances in Software, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/software/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

