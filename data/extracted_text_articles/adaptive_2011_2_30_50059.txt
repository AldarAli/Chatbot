A Case Study on Self-Sufﬁciency of Individual Robotic Modules in
an Arena With Limited Energy Resources
Raja Humza
Department of Biomedical Microsystems
Fraunhofer Institute for Biomedical Engineering (IBMT)
St. Ingbert, Germany
humza.raja@ibmt.fraunhofer.de
Oliver Scholz
School of Engineering
University of Applied Sciences (HTW)
Saarbr¨ucken, Germany
oliver.scholz@htw-saarland.de
Abstract—From self-sufﬁciency perspective, in an artiﬁcial
robotic swarm, the critical parameter that inﬂuences the
collective and individual’s behavior is not the time required
to locate and successfully dock to a recharge station in the
arena, rather it is the time a robot occupies a recharge station
to fully recharge its on-board batteries. It becomes critical
because during recharging of a robot, the recharge station is
no longer available for the rest of the modules in the arena.
In a bigger swarm, it becomes impractical due to several
reasons to deploy an equivalent number of recharge stations
in the arena. Therefore, it is of great interest for the system
designers to know the appropriate ratio between the number
of recharge stations and the number of robotic modules. To
test the behavior of an autonomous robotic swarm we have
employed traditional bio-inspired techniques with a simple
threshold based mechanism that uses the on-board state of
charge of a robot to govern and adapt a robot’s behavior in
different scenarios. The paper concludes with the validation of
initial work in Player/Stage simulator and a future work plan.
Keywords-Autonomous robotic systems; trophallaxis; power
management; self-sufﬁciency; charger to robot ratio; CRR.
I. INTRODUCTION
Long term survivability and autonomy of an autonomous
system (living and artiﬁcial) are governed by energy re-
sources available in the environment and its ability to adapt
itself to changing conditions. From the energy autonomy
perspective, foraging as in nature, provides an ability to
a mobile robotic system to be aware of its dynamically
changing energy requirements in order to autonomously
search and regain its replenished energy from the environ-
ment. Where as, the adaptiveness empowers a system to
tune its behavior/operations with the internal and external
system dynamics. The foraging principle has been applied
in a variety of ways, to develop the control and behavior
of a robotic swarm – both individually and collectively,
e.g., collection of objects scattered around the arena and to
assemble them in some random or a predeﬁned location [1],
[2], [3], and to investigate the collective behavior of a multi-
robotic system [4], [5].
According to McFarland, to be energetically autonomous,
the self-sufﬁciency is an ability of an autonomous system
to maintain itself in a viable state for a longer period of
time [6]. A self-sufﬁcient robot therefore has the ability to
perform the “basic cycle of work”, i.e., ﬁnd fuel and refuel
itself [7].
In literature, to prolong the operational time and improve
the energy autonomy of individual autonomous modules in
a robotic swarm different techniques have been applied that
use either, threshold mechanisms which are based on the
battery voltage level [8], activation variables [9], [10], or
time [11] to determine an appropriate action for a robot.
Another approach that has been applied to prolong the
activity time of autonomous robotic systems in a constraint
environment includes “charge station sharing”, as in [11],
[12]. In the said approach, Michaud and Robichaud high-
lighted the potential issues that arise in an arena with limited
energy resources, e.g., “when is it appropriate for a robot
to recharge”, “how long should the robot recharge itself”,
“what can be done to preserve energy”. In their approach, the
operational time estimated from the battery voltage is used
to determine the appropriate “time” to recharge a robot.
This paper is organized as follows: Section II brieﬂy
presents the related work. Section III describes the addressed
problem. Section IV then describes the proposed ﬁnite state
machine that controls the behavior of a robot in different
scenarios. Section V presents the strategies used to measure
the overall system performance by varying swarm population
and number of recharge stations. Section VI describes the
experimental setup, and later presents and discusses the sim-
ulation results. At the end, Section VII draws a conclusion
and presents future work plans.
II. RELATED WORK
In an approach of collective energy distribution to achieve
long term survivability, Kubo and Melhuish [13] explored
the idea of robot trophallaxis. Trophallaxis, which is a food
sharing phenomenon found in nature, enables a robot to
donate an amount of its internal energy reserve to its weaker
(having less energy) fellow robots in the swarm. In their
model, the robots that are engaged in a cleaning task share
their energy between each other using a simple collision
29
ADAPTIVE 2011 : The Third International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-156-4

based mechanism in which after a simple arbitration mech-
anism, one becomes energy “donor” and the other becomes
the energy “recipient”. The system performance was then
measured using three energy transfer rules and by varying
the number of robots with a static recharge station in the
arena.
Recently, Kernbach et. al. in [14] presented a kinetic
model of swarm foraging to maintain energy homeostasis
in an arena with ﬁxed recharge stations. As deﬁned, en-
ergy homeostasis is a means of keeping the energy ﬂow
balance/equivalent among the individuals in a robotic swarm.
Their model uses the time spent by the robots during
working, searching, waiting, and recharging, to measure
the energetic efﬁciency of the swarm. The model then
assumes the charging and discharging time of the robotic
modules to be approx. equal to the same charging and
discharging currents of the Jasmine robot [15]. This means,
while operating in the environment, one half of the swarm
population keeps itself busy in performing the assigned task
and the other half is docked to the recharge stations. The
assumption in other words, sets the number of recharge
stations to half the number of robots in the arena. To increase
the energetic efﬁciency of the swarm in their work, they
mainly focused on the time spent by the robots during
“searching” and “waiting” for a recharge station rather than
the “charging” and “discharging”(working) time periods.
III. PROBLEM STATEMENT
In an artiﬁcial robotic swarm, the parameters that control
or effect the self-sufﬁciency of robotic modules include the
energy availability in the environment, energy required to
regain replenished energy, and the recharging time especially
in case the energy resources are fewer than the number
of robotic modules in the arena. From the system design
perspective, the recharging time of an on-board battery pack,
which is a critical parameter, usually depends on the bat-
tery chemistry. For example, the lead-acid battery requires
roughly between 12–16 hours [16], whereas, the lithium-
ion polymer cells require about 1–2 hours to fully recharge.
Other parameters that depend on the battery chemistry and
are relevant to the robot electronic and mechanical design
include, charge/energy density, supply voltage and the size
of the cells.
In an autonomous robotic swarm, the foremost objective is
the long term survival of a maximum number of modules in
a swarm, as in the case of the SYMBRION/REPLICATOR1
project, which sets a grand challenge, namely 100 robots
surviving 100 days. The fundamental questions that we have
found unanswered in the literature includes: what type and
what level of cooperation is beneﬁcial for the group that
maximizes the number of active modules in the arena? What
is the effect of longer recharging time on the behavior and
1www.replicators.eu
SOC of competing robots? In a real environment with a large
number of robotic individuals, e.g. > 50 robotic modules, it
is quite impractical to deploy a recharge station for every
single robot in the arena, mainly, due to the cost factor
involved in the production of the large number of recharge
stations and the space requirement in the arena. Therefore,
it is important to know how many recharge stations are
minimally required to keep a sufﬁcient number of robots
alive for a longer period of time in a given environment. In
other words, what should be a sensible charger to robot ratio
(CRR), i.e.,
CRR = Number of recharge stations
Total number of robots
.
(1)
As already mentioned, Kernbach et. al. in [14] have proposed
the ratio CRR to be 0.5 – the number of recharge stations
equals half the number of robotic modules, to optimize
the number of active modules in the arena. But with the
assumption that the charging and discharging time of the
robots are equal. Whereas, we want to ﬁnd out the CRR
value in a scenario where the recharging time is less than
the average discharging/operational time of a robot – roughly
half.
IV. FINITE STATE MACHINE FOR COLLECTIVE
FORAGING
To survive in an arena with fewer energy resources
for a longer period of time, we have developed a ﬁnite
state machine to control an individual’s behavior in the
swarm. Figure 1 shows the ﬁnite state machine (FSM) of
an autonomous foraging robot. A robot in its life cycle
goes through the following states: “nesting”, “trophallaxis”,
“searching”, “approach and dock to a recharge station”,
“recharging”, “avoidance”, “waiting”, “faint”, and ﬁnally,
“dead”. The transition between the states is triggered either
on external stimuli (from sensor values), e.g. obstacles, or
on internal stimuli, i.e. state of charge (SOC) of a robot. The
state transitions that are triggered on internal stimuli use two
variables: “current state of charge” (SOCcurr) and the “state
of charge reserved” (SOCres), which is considered to be the
maximum amount of charge a robotic module can reserve in
order to search and successfully dock to a recharge station
in the arena. The current state of charge of a robot’s battery
pack in percentage is obtained as,
SOCcurr =
remaining charge
maximum charge capacity ×100.
(2)
A. Nesting
It is the healthiest state of a robot in its life cycle. A
robot in nesting state has enough energy to explore the
environment, perform the assigned task and if required can
donate its excess charge to any other distressed robot in
the arena. A robot remains in nesting state until it has just
30
ADAPTIVE 2011 : The Third International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-156-4

Searching 
Approach  
& dock -- CHG 
Faint 
Recharging 
Nesting 
Trophallaxis 
Avoidance 
Avoidance 
Avoidance 
Waiting 
Avoidance 
Dead 
SOCcurr > SOCres  
&& distressedrobot 
SOCcurr < SOCres 
SOCcurr ! SOCres 
SOCcurr " 99% 
SOCcurr < 0.25 x SOCres 
SOCcurr < 0.1 x SOCres 
!Stop&wait  
&& !CHGavailable 
CHGavailable 
CHGavailable 
dockedCHG 
SOCcurr > SOCres  
&& !distressedrobot 
dockedbyRobot 
obstacle 
!obstacle 
!obstacle 
obstacle 
obstacle 
obstacle 
!obstacle 
!obstacle 
SOCcurr < 0.25 x SOCres 
Figure 1: Finite state machine that controls the behavior of an autonomous robot
enough energy left to autonomously reach and dock to a
recharge station without any external assistance, i.e.,
SOCcurr > SOCres.
B. Searching
It is the state in which the highest priority task for a robot
is to search/locate a recharge station in the arena to regain its
replenished energy before it completely runs out of energy.
A robot enters “searching” mode either from the “nesting”
or “trophallaxis” state, when SOCcurr becomes less than or
equals SOCres. This means, when the condition
SOCcurr ≤ SOCres
becomes true, a robot spends its remaining energy for its
survival. For further clarity, the variable SOCres is just a
threshold that assigns the foraging task as the highest priority
task for a robot, when the above condition becomes true.
C. Avoidance
An obstacle can either be a robot, a recharge station or a
boundary wall in the arena, within the detection range of a
robot, which forces it to enter the “avoidance” state for the
period of time the obstacle remains in its detection range.
D. Trophallaxis
This is a bio-inspired phenomenon employed here to
increase the survival time of individual modules in a robotic
swarm. Upon receiving distress messages from a faint robot
a healthy, “nesting” robot in the vicinity automatically aligns
and docks itself to it for the purpose of energy donation. Af-
ter successfully docking, the “healthy/donor” robot donates
its excess energy, i.e., SOCcurr −SOCres, to the faint robot.
After energy exchange, the robot in “faint” state remains in
this state if its SOCcurr remains insufﬁcient to start searching
the recharge station in the arena again, i.e.,
SOCcurr < 0.25×SOCres.
E. Approach and Dock
Upon detecting either a recharge station or a distressed
robot in the arena, a robot “searching” or “nesting” auto-
matically aligns itself towards its target for the purpose of
docking. In case multiple robots approach the same target,
a recharge station or a distressed robot, those that succumb
return back to their previous state. On successfully docking
with the recharge station, a robot enters “recharging” state.
F. Recharging
As mentioned earlier, in an arena with limited energy
resources the recharging time of a robot becomes critical as
the recharge station becomes unavailable to the rest of the
competing robots in the arena. In case of a REPLICATOR
robotic module, that uses a 6 cells lithium polymer battery
pack, the recharging time is roughly between 1–1.5 hours at
a continuous current corresponding to 1C, i.e., 1400 mA.
Likewise, in simulation, ignoring the time required for
cell balancing, a robot in the state of “recharging” occu-
pies the recharge station no longer than for a duration of
approximately 1 hour, depending on its battery SOCcurr.
G. Waiting
A robot enters the “waiting” state, if it stops receiving
beacon signals from the recharge station while in the “ap-
proach and dock” state. This happens in two scenarios: either
when a competing robot in the arena successfully docks to
31
ADAPTIVE 2011 : The Third International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-156-4

the recharge station prior to it, or the robot itself moves
away from the recharge station, so that it misses the line
of sight. A robot remains in waiting state until it starts
receiving charger signals again, or on the expiry of a waiting
timer – Tw. The length of Tw is in fact the amount of time
required to fully recharge a depleted battery pack at 1C. In
our implementation, we set it to 10 minutes to compensate
the frequent/erroneous triggering into “waiting” state, e.g.,
moving away form the line of sight.
H. Fainting
It is the state in which the robot’s remaining SOC is
considered as not enough to search and successfully dock to
a recharge station in the arena. A robot in this state therefore
stops moving and starts broadcasting “distress messages” on
its IR communication channels. In the current framework, a
robot remains in faint state until
0.1×SOCres < SOCcurr < 0.25×SOCres.
I. Dead
It is considered to be the end of the life cycle of an
autonomous robot. It is reached from the “faint” state in
case the distressed robot does not receive any aid from the
fellow robots in the arena. It is reached when the condition
SOCcurr ≤ 0.1×SOCres
becomes true.
V. FORAGING STRATEGIES
To estimate a tradeoff between the number of recharge
stations and robotic modules, we have devised some simple
strategies to measure and compare the performance of a
robotic swarm in different scenarios.
A. Simple
This scenario was in fact devised to compare and evaluate
the results obtained from other techniques. In the simple
scenario, the individual autonomous robots lack the ability
of dynamic collaboration, i.e., trophallaxis. In fact, they are
selﬁsh in the respect that each module is concerned with its
own survival in the arena. In this approach, 70% of the max.
SOC is considered as SOCres.
B. Trophallaxis
Trophallaxis provides an individual the ability to sense
and dynamically cooperate with fellow robots in the arena.
With this ability, a healthy, “nesting” robot becomes a donor
by sharing its excess energy as soon as it docks to a
distressed robot that resides in the “faint” state. Upon a
successful docking it starts donating its excess charge to
it, where the excess amount of charge “E” is calculated as
the difference between SOCcurr and SOCres, i.e.
E
=
SOCcurr −SOCres.
(3)
C. Learn and Adapt with Trophallaxis
In the above two foraging strategies, i.e., “simple” and
“trophallaxis”, the variable SOCres uses a ﬁxed value, i.e.
70% of max. SOC, for the transition between the FSM states.
In the case described here, with the ability to learn and
adapt, each robot in the swarm learns from the environment
an appropriate value of SOCres each time it successfully
docks to a recharge station from the time it started its
search, to update its previous estimate. Let SOCres(n − 1)
be the value learned at docking instance (n − 1) with a
recharge station, and SOCres(n) be the reserved SOC learned
at current docking instance (n), i.e. the new value. Where,
n = 0,1,2,... The SOCres for the next run was then updated
by taking the average of the two estimates, as,
SOCres(n)
=
SOCres(n−1)+SOCres(n)
2
,
(4)
and, by scaling it,
SOCres(n)
=
SOCres(n)×1.5,
(5)
with a factor of “1.5”. The scaling was done to reduce
the effect of the low value of SOCres learned in the two
estimates. Otherwise, an abrupt decrease in the SOCres that
reﬂects the energy abundance in the environment, may lead
to a false prediction.
D. Stop and Wait
It’s a simple technique that is based on the idea of energy
conservation. With the “stop and wait” ability, if a robot
stops receiving “charger” signals when in the “approach and
dock” state, instead of switching back to “searching” state
again, it enters the “waiting” state with the assumption that
the charger is occupied by some other robot. A robot remains
in “waiting” state until it starts receiving “charger” signals
again or the waiting timer (Tw) expires. During waiting state,
a robot stops its locomotion to save its energy while the rest
of the on-board electronics remain active. Further, in the
“stop and wait” topology, a robot disables its trophallaxis
ability and strives only for its own survival.
E. Stop and Wait with Trophallaxis:
It is meant to see the combined effect of two simple
techniques on energy distribution in the swarm. In this
topology, the robots in the swarm on one side preserve their
energy by actively choosing the “wait” state and on the other
side donate their excess energy to fellow robots to increase
the number of active robots in the arena.
VI. EXPERIMENTAL SETUP AND RESULTS
At this stage of development, to explore the dynamic
behavior of robotic modules with limited sensing abilities in
the arena, we implemented a simple robot model and the test
scenarios in Stage simulator [17]. For this purpose, we were
provided with an abstract model of a REPLICATOR robot
32
ADAPTIVE 2011 : The Third International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-156-4

in the “Stage” simulator by Wenguo Liu from the Bristol
robotic laboratory (BRL), University of the West of England,
Bristol, UK.
Figure 2: A screen shot of an example scenario in Stage simu-
lator: 6 robots with 2 recharge stations in a simulation arena of
dimensions 4m × 4m
A. Robot Model
The dimensions of the simulated robot model are
80 mm × 80 mm × 80 mm. It has four infra-red (IR)
sensors (one on each side) for communication in the arena,
four status LEDs (one on each side), eight light sensors (two
on each side), four docking units (one on each side), a loco-
motion drive, a battery pack, and a robot controller. The IR
and light sensors help the robot to perform beacon detection
in order to align itself towards the target. The on-board
partially simulated battery pack as in the original robot,
provides the nominal voltage of 22.2 V with maximum
1400 mAh of charge capacity. Considering 75 % efﬁciency
of the LiPo battery pack, it ﬁnally provides a max. capacity
of 1050 mAh. The battery management module uses a
coulombs counting approach for the estimation of battery ca-
pacity and the absolute state of charge. The simulated robot
current consumption values are also taken from empirical
values recorded with real robot hardware. On every time
instant “t”, the on-board electronics current consumption
was taken randomly between 25 mA to 50 mA at nominal
voltage. During random walk the robot’s locomotion drive
consumed a continuous current of 250 mA, whereas the
docking unit that becomes active only during docking and
undocking with a recharge station or to a robot for a period
of 5 seconds as in the original system, drew a current of
55 mA per second.
B. Simulation Results
To explore the foraging behavior of a robotic swarm,
collectively and individually, with limited energy resources
we have varied the number of robots with ﬁxed number
of recharge stations in a simulation arena of 4m × 4m.
Figure 2 shows a screen shot of an example scenario in
Stage simulator [17] with 6 robotic modules and 2 ﬁxed
recharge stations.
In our experiments we are focusing on the average state of
charge of robotic modules as it provides a rough estimate of
ﬂow of energy and number of dead robots in the arena. The
higher the energy level of the robotic individuals the longer
they can survive on their own which in turn enables them to
perform a variety of tasks collectively and individually in the
arena. Therefore, to get a reliable estimate of average SOC
of a robot and the average number of dead robots in a given
condition, we ran each strategy, as mentioned in section V,
10 times with each robot having an initial SOC of 80 %
of the max. battery capacity. Each time the simulation was
then recorded for a period of 10 hours.
Figure 3 shows the simulation results in three cases
recorded by varying the number of robots in the arena with
a ﬁxed number of recharge stations. In ﬁgure 3, the hori-
zontal axis shows the applied “strategies”, and the vertical
axis shows the “average SOC of a robot” in percentage –
averaged over 10 simulation runs. The error bars show the
standard deviation of 10 simulation runs. Figure (3a) shows
the average SOC of a robot, to compare the effect of limited
energy resources in two scenarios: 3 robots with 1 recharge
station (3r1c) and 6 robots with 2 recharge stations (6r2c),
thus keeping the ratio CRR constant, i.e. 0.333. Figure (3b)
shows the average SOC of a robot with CRR = 0.25 in
two scenarios: 4 robots with 1 recharge station (4r1c) and
8 robots with 2 recharge stations (8r2c). And lastly, ﬁg. (3c)
shows the average SOC of a robot with CRR = 0.166 again
in two scenarios: 6 robots with 1 recharge station (6r1c)
and 12 robots with 2 recharge stations (12r2c). Before
discussing the results shown in ﬁgure 3, to get an idea of
the applied strategy on the swarm it is important to see the
average number of dead robots at the end of simulation
runs. Figure 4 shows the average number of dead robots
in different scenarios with CRR = 0.333, 0.25, and 0.166.
The horizontal axis shows the applied “strategies”, and the
vertical axis shows the “average number of dead robots”.
The error bars again show the standard deviation of 10
simulation runs.
In the case CRR = 0.33, the trophallaxis feature in a
smaller swarm size neither contributed in increasing the avg.
SOC of robots nor in decreasing the average number of
dead robots. But on the contrary, in the bigger swarm it
improves the avg. SOC of robots and slightly decreases the
avg. dead robots. The “learn and adapt” strategy is barely
able to produce the same results as with the simple strategy.
The “stop and wait” has shown its effect only in the bigger
swarm. In the case CRR = 0.25, the trophallaxis feature
likewise in the smaller swarm fails to show it presence on the
avg. SOC of robots. But the stop and wait strategy together
with trophallaxis feature in the bigger swarm decreases the
avg. no. of dead robots by increasing the avg. SOC of the
33
ADAPTIVE 2011 : The Third International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-156-4

Stop&Wait
with Troph.
Learn&Adapt Stop&Wait
  with Troph.
Trophallaxis
Simple
Strategies
0
10
20
30
40
50
60
70
 3r1c
 6r2c
Avg. SOC of a robot in percentage
(a) CRR = 0.33
Strategies
Stop&Wait
with Troph.
Learn&Adapt Stop&Wait
  with Troph.
Trophallaxis
Simple
0
10
20
30
40
50
60
70
 4r1c
 8r2c
Avg. SOC of a robot in percentage
(b) CRR = 0.25
Strategies
Stop&Wait
with Troph.
Learn&Adapt Stop&Wait
  with Troph.
Trophallaxis
Simple
0
10
20
30
40
50
60
70
 6r1c
 12r2c
Avg. SOC of a robot in percentage
(c) CRR = 0.166
Figure 3: Average state of charge (SOC) of a robot in different
scenarios with CRR = 0.33, 0.25, and 0.166. The error bars show
the standard deviation of 10 simulation runs.
robots in the swarm. At the end, in the case CRR = 0.166,
we have seen nearly the similar trend in avg. SOC of robotic
modules and the avg. number of dead robots as we have in
case of CRR = 0.25.
Concerning the active number of robots, it is evident from
ﬁgure 4, that the “trophallaxis” feature alone especially in
the bigger swarm decreases the avg. number of dead robots
in the arena and its effect is also comparable with the “stop
0
2
4
6
8
10
 
Avg. number of dead robots
 3r1c
 6r2c
Strategies
Stop&Wait
with Troph.
Stop&Wait
Learn&Adapt
  with Troph.
Trophallaxis
Simple
(a) CRR = 0.33
0
2
4
6
8
10
Avg. number of dead robots
 4r1c
 8r2c
Strategies
Stop&Wait
with Troph.
Stop&Wait
Learn&Adapt
  with Troph.
Trophallaxis
Simple
(b) CRR = 0.25
0
2
4
6
8
10
 
Avg. number of dead robots
 6r1c
 12r2c
Strategies
Stop&Wait
with Troph.
Stop&Wait
Learn&Adapt
  with Troph.
Trophallaxis
Simple
(c) CRR = 0.166
Figure 4: Average number of dead robots in different scenarios
with CRR = 0.33, 0.25, and 0.166. The error bars show the standard
deviation of 10 simulation runs.
and wait” strategy. Therefore, the combination of the two
strategies showed a signiﬁcant decrease in the avg. number
of dead robots, especially in case of CRR = 0.25 and 0.16.
VII. CONCLUSION AND FUTURE WORKS
A. Conclusions
In this paper, we have explored the effect of few potential
issues in a simulated environment that may become critical
34
ADAPTIVE 2011 : The Third International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-156-4

for a robot swarm operating in a real environment with
limited energy resources. For this purpose in our preliminary
work, we have implemented a basic robot model and the
test scenarios in Player/Stage simulator. The performance
of the system is then evaluated from the avg. SOC of
robotic modules and the avg. number of dead robots in the
arena. Considering the two measures, we have seen that the
CRR = 0.25 provides us a fair trade off between the number
of recharge stations and the number of robotic modules in
a closed environment. As in a bigger swarm, the robotic
individuals are able to achieve nearly the same avg. SOC
as in case of CRR = 0.33. This in fact provides us the
motivation to test the system behavior with a bigger swarm
size with the ratio CRR = 0.25.
B. Future Works
In the current framework, a critical parameter that is left
and requires the attention of the system designer is the
system energy loss especially during energy trophallaxis. In
future, along with the simulation work we plan to implement
and test such simple strategies on a real robot swarm, i.e.,
REPLICATOR robotic modules, to compare it with simula-
tion results. The testing on the real hardware also involves
the measurement of energy losses during trophallaxis and
power sharing between the robots.
ACKNOWLEDGMENT
We are very thankful to “Wenguo Liu” from Bristol
robotic laboratory (BRL), University of the West of England,
Bristol, UK, and “Lachlan Murray” from University of
York for providing their assistance in Stage simulator. This
work is part of a European Union funded project named
“REPLICATOR”. The “REPLICATOR” project is funded
within the work program Cognitive Systems, Interaction,
Robotics under the grant agreement no. 216240.
REFERENCES
[1] M. J. Matari´c, “Minimizing complexity in controlling a
mobile robot population,” in Proceedings of the 1992 IEEE
International Conference on Robotics and Automation, (Nice,
France), pp. 830–835, 1992.
[2] E. Nitz, R. C. Arking, and T. Balch, “Communication of
behavioral state in multi-agent retrieval tasks,” in Proceedings
of the 1993 IEEE International Conference on Robotics and
Automation (L. W. Robert and O. Conner, eds.), vol. 3,
(Atlanta, GE), pp. 588–594, IEEE Computer Society Press,
May 1993.
[3] D. Goldberg and M. J. Matari´c, “Robust behavior-based
control for distributed multi-robot collection tasks,” CiteSeerX
- Scientiﬁc Literature Digital Library (United States), 2000.
[4] L. Parker, “The effect of action recognition and robot aware-
ness in cooperative robotic teams,” IEEE/RSJ International
Conference on Intelligent Robots and Systems, vol. 1, p. 212,
1995.
[5] K. Sugawara and T. Watanabe, “A study on foraging behavior
of simple multi-robot system,” in IECON 02: IEEE 2002
28th Annual Conference of the Industrial Electronics Society,
vol. 4, pp. 3085 – 3090, Nov. 2002.
[6] D. McFarland, “Autonomy and self-sufﬁciency in robots,” in
The Artiﬁcial Life Route To Artiﬁcial Intelligence: Building
Embodied Situated Agents (L. Steels and R. Brooks, eds.),
(Lawrence Erlbaum, USA), pp. 187–213, 1994.
[7] D. McFarland and E. Spier, “Basic cycles, utility and oppor-
tunism in self-sufﬁcient robots,” Robotics and Autonomous
Systems, vol. 20, no. 2-4, pp. 179 – 190, 1997. Practice and
Future of Autonomous Agents.
[8] S. Oh and A. Zelinsky, “Autonomous battery recharging for
indoor mobile robots,” in Australian Conference on Robotics
and Automation, 2000.
[9] F. Michaud and j. Audet, “Using motives and artiﬁcial emo-
tions for long-term activity of an autonomous robot,” in Pro-
ceedings of the ﬁfth international conference on Autonomous
agents, AGENTS ’01, (New York, NY, USA), pp. 188–189,
ACM, 2001.
[10] F. Michaud, E. Robichaud, and J. Audet, “Using motives
and artiﬁcial emotions for prolonged activity of a group of
autonomous robots,” in Emotional and Intelligent II: The
Tangled Knot of Social Cognition - AAAI Fall Symposium,
Cape Code Massachussetts, pp. 85–90, 2001.
[11] F. Michaud and E. Robichaud, “Sharing charging stations
for long-term activity of autonomous robots,” in Proc. of the
International Conference on Interlligent Robots and Systems,
IEEE/RSJ, (EPFL, Lausanne, Switzerland), pp. 2746–2751,
Oct. 2002.
[12] F. Sempe,
A. Munoz,
and A.
Drogoul, “Autonomous
robots sharing a charging station with no communication:
a case study,” in Distributed Autonomous Robotic Systems
(H. Asama, ed.), vol. 5, (Tokyo), pp. 91–100, Springer-Verlag,
2002.
[13] C. Melhuish and M. Kubo, “Collective energy distribution:
Maintaining the energy balance in distributed autonomous
robots using trophallaxis,” in Distributed Autonomous Robotic
Systems 6 (R. Alami, R. Chatila, and H. Asama, eds.),
pp. 275–284, Springer Japan, 2007.
[14] S. Kernbach, Handbook of Collective Robotics, ch. Improving
the Scalability of Collective Systems, pp. 225–256. Springer-
Verlag Berlin, 2010.
[15] S. Kornienko, O. Kornienko, C. Constantinescu, M. Pradier,
and P. Levi, “Cognitive micro-agents: individual and collec-
tive perception in microcorob swarm,” in IJCAI-05 Workshop
on Agents in Real-Time and Dynamic Environment, pp. 33–
42, 2005.
[16] “Charging the lead acid battery.” http://batteryuniversity.com/
learn/article/charging the lead acid battery/, [Last accessed:
1 Apr. 2011].
[17] B. Gerkey, R. Vaughan, and A. Howard, “The player/stage
project: Tools for multi-robot and distributed sensor systems,”
in 11th International Conference on Advanced Robotics
(ICAR 2003), (Coimbra, Portugal), pp. 317–323, June 2003.
35
ADAPTIVE 2011 : The Third International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-156-4

