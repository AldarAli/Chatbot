A Tangible Directional-View Display for Interaction
Youngmin Kim, Byoungha Park, Kwang-Soon Choi, and Kwang-Mo Jung
Realistic Media Platform Research Center
Korea Electronics Technology Institute
Seoul, Korea
E-mail: rainmaker@keti.re.kr, bhpark@keti.re.kr, lenon@keti.re.kr, jungkm@keti.re.kr
Abstract—A tangible directional-view display system that can
provide different perspective views without any special glasses
is introduced. The proposed system can display perspective
floating five images in the space in front of the system with the
help of concave mirrors. In addition, the proposed system
adopted an ultrasonic focusing technology in order to provide
immersive experiences and deliver the sense of touch. We will
explain our proposed method and provide theoretical analysis
that supports it.
Keywords-Interaction, Directional-View, Ultrasonicsound
I.
INTRODUCTION
Since the successful development of a stereoscopic three-
dimensional (3D) film, studies on autostereoscopic 3D
display have been actively conducted recently. The ultimate
goal of such a 3D display is to provide multiple viewers with
a tangible 3D display. However, it is hard to implement such
a 3D display because of several constraints, such as a lack of
display panels that are usable commercially for ultimate 3D
display [1-6]. Also, there are several reasons why some
people are still against stereoscopic 3D displays; one of the
reasons is the discomfort of wearing glasses.
For the ultimate tangible 3D display, there are several
requirements. First, it is necessary to display different
perspective images according to the users even though it is
not necessary to provide such volumetric 3D display. Second,
it should detect a hand gesture to identify the user’s
movements. Finally, a proper sense of touch should be
provided to the viewer’s fingertip in order to deliver
immersive experiences [7].
In this paper, we propose a tangible directional viewable
display for interaction using floating displays and ultrasound
transducers. For providing high-definition directional-view
images that can be viewed without any special gadgets by
plural viewers, we integrated three lenticular lens displays
and five floating displays into the proposed system. The
proposed system has two attached infrared (IR) cameras as
detectors. In addition, a number of ultrasound transducers are
designed to feel tactile stimulation at a specific point. The
paper is structured as follows. In Section II, we explain the
proposed method by using floating displays and IR camera.
In Section III, the experimental results that support the
proposed method are provided, and, in Section IV, we
conclude the paper.
II.
PROPOSED METHOD
Figure 1 shows a schematic representation of our
proposed system. The system consists of a display system in
which three lenticular lens displays and five floating displays
are combined, a hand gesture recognition system for
interaction (IR camera), and a spatial tactile system that
provides tactile expression. Various types of 3D displays,
such as a holographic display and volumetric displays, can
be considered to construct a tangible 3D display. However,
each candidate has limitations, such as a massive amount of
information to be processed and difficulty to interact with
rotating screen. A floating display is a method of projecting
clear two-dimensional (2D) images, which has been applied
as a “Pseudo hologram” recently. Among the various
abovementioned display methods, a floating display that
provides vivid images and is suitable for interaction as a
tangible display was selected.
Figure 1.
Schematic diagram of the tangible directional-view display
system
Three lenticular lens displays were adopted for delivering
immersive experiences to the viewers. They located in an
upper position for a number of viewers to observe images.
These three lenticular lens displays were used for the
selection of image contents, as shown in Figure 2. In the
display system, viewers selected contents using a lenticular
132
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

Lenticular lens display
Floating display
24inch Lenticular
display
PC1
(Gesture S/W
Sound S/W)
PC2
PC3
PC4
(Content S/W
Gesture S/W)
DVI
DVI
DVI
LAN
5ch Speaker
Vision camera
(TOF)
15inch
floating
display
Tactile control
USB
USB
Aud.
Aud.
USB
PC
LAN
24inch Lenticular
display
24inch Lenticular
display
5ch Speaker
Vision camera
(TOF)
15inch
floating
display
PC
15inch
floating
display
PC
15inch
floating
display
PC
15inch
floating
display
PC
(a)
(b)
(a)
(b)
(c)
lens display, followed by touching the image contents
directly. A floating display can be constructed by a concave
mirror. This mirror is optically equivalent to the floating lens,
so the location and the size of the floating image can be
mathematically by the mirrors. For simplicity, a Jones
transfer matrix of the floating display along the light
propagation paths is expressed as follows:
(1)
where x1, x2, x3, and x4 denote the location of the original
image, the lens, the floating image, and the viewer’s eye,
respectively [8]. θ1, θ2, θ3, and θ4 denote the angle of each
optical component, and r represents the radius of the concave
mirror. H1, H2, H3, and H4 denote the size of the original
image, the floating lens, the floating image, and the distance
from the viewers’ eye, respectively. According to the
equation, the location and the size of the floating image can
be calculated. Because the horizontal viewing angle of each
floating display is 45 degree, we choose five floating
displays for covering five viewers simultaneously. This
floating display is varied at the lower part for viewers to see
only the floating images.
Figure 2.
(a) a photo of our proposed system and (b) a system block
diagram of our proposed system.
For the tactile impression, we developed a technology
that can focus stimulation on a specific location using an
ultrasound transducer technology [9]. The focus where a
floating image is projected over a space is set up followed by
obtaining a distance difference from the focus to the
corresponding ultrasound transducers as shown in Figure 3.
Since the distance is different according to the corresponding
ultrasound transducers, a phase difference is generated per
ultrasound transducer. Therefore, we should adjust this
difference by using phase differences. We use 5 by 10
transducers per module and 8 ultrasound transducer modules
in total were used for increasing the tactile pressure.
Figure 3.
Focusing of ultransound wave by ultrasound transducers: (a) a
schematic of ultrasound transducer system, (b) distance estimation between
focal point (x, y, z) and each transducer, and (c) phase alignment of
ultrasound wave by considering phase difference among transducers.
Lastly, a detecting system using IR emission units was
used for applying tactile stimulation by the location of the
fingertip of users. The system was designed to find out user’s
fingertip using general time-of-flight (TOF) mode. Four of
predefined hand gesture (left, right, enter, and backward)
were selected according to the user’s gesture.
133
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

(a)
(b)
III.
EXPERIMENTAL RESULTS
To verify our proposed system, we integrated three
lenticular lens displays, detecting camera systems, floating
displays, and tactile devices using ultrasound transducers, as
shown in Figure 4. Figure 4 (a) depicts the configuration of
the proposed system, and Figure 4 (b) depicts the mounted
ultrasound transducers in the system. A 24 inch lenticular
lens display with 9 views was used as the frontal display
device. Each unit was connected with a 5-channel speaker
and a TOF camera. For floating displays, 15 inch high
brightness LCD monitors were used as a display panel,
whose
images
were
viewed
by
viewers
through
the
polarization glass located in the center of the system. A 37
inch parabolic mirror a focal length of 9.3 inch and diameter
of 35 cm in the central area was cut, and five 15 inch LCD
monitors were used. Each floating display had a 45 degree
field of view, and the diameter of the lower system was 90
cm, while that of the polarization glass was 30 cm. Five 10
inch tablet PCs (Samsung Galaxy note) were used and three
types of scenarios were displayed by the system.
Figure 4.
(a) a photo of experimental setup and (b) ten sets of ultrasound
transducer module.
IV.
CONCLUSION
We proposed a tangible directional-view display system
for providing a user interaction experiences. The system was
constructed by three sets of lenticular lens displays, five sets
of floating displays, a designed ultrasound transducer system,
and two TOF cameras using IR units. Integrated systems are
presented to verify the validity of the proposed method, and
the experimental results show that the proposed system
provides different perspective view images and tactile
expressions according to the predefined positions. We expect
our system to have a number of applications, such as
advertisement, game, e-training, and immersive digital
signage industries.
ACKNOWLEDGEMENT
This research was supported by a grant from the R&D
Program funded by the Ministry of Trade, Industry and
Energy (MOTIE), Republic of Korea. Also, the authors are
deeply thankful to all interested persons of MOTIE and
NIPA (National IT Industry Promotion Agency).
REFERENCES
[1]
B. Lee, “Three-dimensional displays, past and present,” Phys.
Today, vol. 66, pp. 36-41, 2013, dot:10.1063/PT.3.1947.
[2]
Y. Kim, et al., “A frontal projection-type three-dimensional
display,” Opt. Express, vol. 20, 2012, pp.20130-20138.
[3]
S. A. Benton, “Survey of holographic stereograms,” Proc.
SPIE, vol. 367, 1983, pp 15-19.
[4]
M. Yamaguchi, N. Ohyama, and T. Honda, “Holographic 3-D
printer,” in Practical Holography IV, S. A. Benton, ed., Proc.
SPIE, vol. 1212, 1990, pp. 84-92.
[5]
N. Peyghambarian, S. Tay, P.-A. Blanche, R. Norwood, and
M. Yamatomo, “Rewritable holographic 3D displays,” Opt.
Photon. News, vol. 19, 2008, pp. 22-27.
[6]
D. Lanman, M. Hirsch, Y. Kim, and R. Raskar, “Content-
adaptive parallax barriers: optimizing dual-layer 3D displays
using low-rank light field factorization,” ACM Trans. Graph.
vol. 29, 2010, pp. 163-172 .
[7]
Y. Kim, “Tangible 3D display for interaction,” The 13th
International Meeting on Information Display (IMID 2013),
2013, pp. 27-1.
[8]
P. Yeh, “Extended Jones matrix method,” J. Opt. Soc. Am.,
vol. 72, pp. 507-513, 1982.
[9]
T. Iwamoto, M. tatezono, T. Hoshi, and H. Shinoda,
“Airborne ultrasound tactile display,: ACM SIGGRAPH 2008,
2008, p. 1.
134
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

