A First Look at AMI Traffic Patterns and Traffic
Surge for Future Large Scale Smart Grid
Deployments
Yaling Nie, Yanchen Ma
Hitachi (China) Research & Development Corporation Beijing, China
ylnie@hitachi.cn; ycma@hitachi.cn
Abstract—IoT (Internet of Things) applications are deployed in
China with strong market requirements. To research the key
technologies for future large scale IoT deployment, especially the
impacts of IoT traffic to traditional IP network and Data Center,
in this paper, we analyzed IoT traffic patterns and verified them
through evaluation. IoT traffic patterns with layered system
architecture and parameters affecting traffic are discussed. The
evaluation
results
show
that
traffic
surge
generated
by
synchronous IoT application traffic cause network congestion for
network and outage of Data Center resources. The transport
protocols and data encapsulation format affect the application
performance.
These
potential
problems
should
be
further
research on.
Keywords-AMI; large scale; traffic pattern; traffic surge.
I.
INTRODUCTION
Several types of IoT services are provided to industry and
human life, such as smart metering, point of sale, fleet
management,
telemedicine,
environment
monitoring
and
control, home automation, and so on.
Compared to traditional ways of using IP network of
human-centric web applications, IoT services are different. The
services have less randomness. The sessions are triggered by
predefined time or events; the packet series inside a session is
also predefined by the program. Usually, the number of IoT
devices is very large. Parallel data transmission puts extreme
amount of load on individual nodes of networks. The number
of IoT devices is changeable. The data might be transmitted
synchronously or with a random time schedule.
From the session level point of view, there are 3 cases [1]:
The first case is periodical sessions. This is the case in
environments monitoring service; the device reports the
monitoring data every hundreds of seconds. In the second case,
the session initiation times are random. This can be found in a
point of sale service; a session is initiated once when people
come to trigger a new transaction, not at predefined time. In the
third case, the session is usually initiated periodically but may
also be triggered by random events. This is the case in
telemedicine services, when the physical characteristics data
are sent every few minutes and an alarm is sent to the server
once a monitored indicator is over or under threshold.
In the near future, massive IoT devices will be distributed
everywhere with large scale deployment. Different types of
sensors are used for different kinds of applications. IoT service
will converge with human centric web applications. It will
make a great impact on network and Data Center. New IoT
service features generate new IoT traffic features. New IoT
traffic patterns are also emerging.
In this paper, we determine three important IoT traffic
patterns and analyze their potential problems. The following
sections of this paper are organized as follows. In Section II,
we analyze the IoT traffic patterns. Section III describes the
study of IoT traffic surge, and perspective analysis for use case
deployment. Section IV exposes the experimental process and
the results. Finally, Section V gives the conclusion.
II.
TRAFFIC PATTERNS ANALYSIS
A.
IoT Service Model
Figure 1 shows the typical architecture of IoT system and
the corresponding traffic. Data from sensor/meter is gathered
through IP network, and transported to servers in data center.
The accumulated traffic in data center can reach GB/TB level
for computing, storage and networking process.
Figure 1.
Architecture of IoT system and traffic.
120
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-226-4
INFOCOMP 2012 : The Second International Conference on Advanced Communications and Computation

B.
IoT Numerical Model
We have several assumptions in the dedicated IoT service:
sensors’ gateways perform data aggregation and processing of
sensor data before forwarding it to remote users. Data delivery
models, event-driven, query-driven and periodic are assumed to
be used by the gateways to transfer data.
We found the IoT traffic gathered in the Data Center server
can be formulated as shown in Figure 2. The assumption is on
base of IoT application parameters [2][3]. F is the frequency of
meter data in sensor/meter. P is the packet sizes of the meter
data. F’(t) is the time schedule of concentrator. S is the
deployment
scale
level:
like
building
deployment,
site
deployment or city level deployment.
Figure 2.
IoT Traffic model.
The IoT traffic has a hybrid traffic patterns. The following
three models are selected for further research:

Traffic pattern 1: Periodical traffic. Frequency: Real-
time/Periodical: 15min, 30min, 45min. And Packet
length: 50-300B/meter, MB/sensor, Use case: control
and
automation,
transportation,
environmental
monitoring for emergency services and healthcare.

Traffic pattern 2: Sessional traffic surge/burst, event-
driven, query-driven, Frequency: 1h~1d~1M/Packet
length: KB~MB, Use case: emergency report, booting

Traffic pattern 3: Periodical traffic surge. In large scale
deployment, the traffic load rises to the system
resource capacity (threshold), or even over the system
resource capacity (threshold). The hybrid traffic of
Traffic pattern 1 and Traffic pattern 2 can generate
periodical
traffic
surge,
Use
case:
interactive,
conversational, streaming.
C.
IoT Traffic patterns with Layered Structure
Hybrid IoT traffic gathered in the Data Center, with the
key parameters of: F, P, T, S. The total system has a layered
structure. Layer 1 is the sensor/meter network layer, where
real-time traffic is generated. Most of the traffic from layer 1
will go through GW/concentrator layer for a further time
schedule. Some IoT traffic will go directly to layer 3. Layer 3
is the IP network, connecting large scale geography area. The
hybrid IoT traffic finally reaches servers in Data Center: layer
4.
Figure 3.
Layered structure.
Data collection frequency F and system scale S are
parameters affecting total data volume. In a critical scenario, if
the data collection frequency F is high, and the system scale S
increases to a large value, the total data volume will be large.
The collection period (T1) and the collection time (T2) are
parameters affecting the traffic shape. As shown in Figure 4
below, the predefined IoT traffic is periodically reporting data
with T1 slot. The real transmission of the data in T1 slot is in
T2 period. With different ratio of T1 and T2, the IoT traffic
will be deferent.
Figure 4.
Collection period T1 and collection time T2.
III.
TRAFFIC SURGES ANALYSIS
Periodical load surge from IoT application or special events
(e.g., emergency alerting) will conflict with Data Center
resource capacity, even inducing break down of Data Center
systems.
A.
Use Case Study
Mobile data traffic surge is expected to be 40 Exabyte by
2014 [4]. Mobile connections are expanding globally, along
with other mobile connections, due to the growing hardware
and software components for smart meters, business and
consumer
surveillance,
inventory
management,
and
fleet
management, all of which are designed for operational
excellence. Machine-to-Machine Traffic is expected to increase
40-Fold between 2010 and 2015.
Mobile carriers such as NTT DoCoMo, Verizon met mobile
traffic burst, conflict with system resource. ISP like TAOBAO
met traffic surge also. Its SecKill service, which is a kind of
time-limited sales promotions, one web has requirements of
1billion in 10mins. The first system break down happened in
2009.
Chinese
carriers/vendors
are
considering
traffic/flow
control. In carrier network, the real time large traffic is out of
control. A possible solution might be an intelligent pipe:
121
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-226-4
INFOCOMP 2012 : The Second International Conference on Advanced Communications and Computation

broadband rapid respond for bandwidth requirements, resource
allocation, optimization, and so on.
B.
Beijng City Perspective AMI deployments
City level deployment of Advanced Metering Infrastructure
(AMI) services is very popular in China. Table 1 shows the
deployments in three cities.
TABLE I.
AMI DEPLOYMENT BY 2011
City
L2 devices
(GW/Concentrator)
User
Number
TaCheng,
XINJIANG
36000smart meter, 185
collector
19,200
LuCheng, Wenzhou,
ZHEJIANG
14,485 cellular collector
190,405
HuZhou, ZHEJIANG
487.1 thousand
cellular/microwave collector
HV 12690，
LV 1187,700
Refer to the AMI deployment of HUZHOU in 2011 [5],
with the population result of 2010; we can get the forecast AMI
numbers of BeiJing for city level deployment shown in Table 2.
TABLE II.
PREDICTIVE NUMBER FOR BEIJING DEPLOYMENT
BeiJing
HuZhou
Population
19.612 million
19,200
People/House density
2.45
2.65
House Users
8,000,000 users
1200,000 users
L2 devices
3,600,000 collector
487,100 collector
Table 3 is the comparison of China railway public ticket
ordering system ‘www.12306.cn’ [6] and AMI service. The
ticketing system met heavy traffic surges especially at spring
festival ticket release time. At 8, 10, 12, 15 everyday the traffic
surges happened. As the deployment reaches a large scale, and
the interactive requirements increase, AMI applications have a
high possibility to have traffic surges periodically as well.
TABLE III.
TRAFFIC SURGE POSSIBILITY
12306
AMI
Parallel traffic
1GB
< 1GB
Server load
1GB
MB level
User number (peak)
5 million, KB/user
5 million,
KB/user
mode
interactive
Light interactive
The common solution is to increase the system capacity.
But, there are some solutions considering IoT traffic surge
[7][8][9][10]. Like [11], in M2M communication: terminal
self-test and determine communication gap to avoid traffic
congestion. Or, some vendor has a hardware solution of DC
network IF with huge size buffer.
IV.
EVALUATION RESULTS
We use AMI as the example for evaluation of IoT traffic
patterns, its impacts and problems. The AMI system will be
deployed in large scale [12]. Thus, the application will generate
massive AMI data [13]. This massive AMI data will be
transported through IP network and processed in the data
center.
A.
Platform Implementation
We select AMI Beijing city level deployment as the
application scenario as shown in Figure 5. Sensors’ data is
collected every 15min 60Byte/meter, periodical data delivery
(transmission finished within) in network. Traffic Generator
send IoT traffic: historical AMI data repeating, predicted AMI
data, AMI data through mathematics model. Multiple Traffic
Generators simulated massive IoT traffic to IoT server in Data
Center virtualization platform. Evaluation parameters: traffic
model to Data Center, capacity, jitter, traffic/time model for
different AMI scenarios.
Figure 5.
Logical System Structure.
In Figure 6, the Traffic Generator (TG) is used to generate
massive AMI data. Multiple TGs are used to simulate
distributed AMI systems. Data from TG will be transmitted to
IP network, through local or public network. The AMI server
and database are in the data center, with virtualization platform.
Figure 6.
Evaluation System structure.
B.
Problem Analysis
a) Traffic Paterenss via Evaluation
Traffic patterns are monitored through evaluation.
122
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-226-4
INFOCOMP 2012 : The Second International Conference on Advanced Communications and Computation

Data from sensors, through the public IP network, is
gathered in the AMI server. The traffic is shown in Figure 7
below. It is periodical traffic. In Figure 7(a), it is around 6000
sensor’s metadata, through 24 concentrators, sending data to
servers in data center. The data frequency is set to 5 minutes,
for it is easier to get the test result than 15 minutes used in the
commercial system.
.
(a)
(b)
Figure 7.
Layered structure.
In Figure 7(b), we increased the number of the sensors to
18000, through 72 concentrators. The total traffic arriving at
the server in data center is shown in Figure 7(b). Compared to
the result in Figure 7(a), the traffic in one period is affected
with jitters. However, the periodical feature is still not changed.
And the traffic in every period has similar traffic model
features from statistics points.
b) Traffic Impacts to Data Center
Corresponding to the traffic patterns in Figure 7(a) and 7(b),
the CPU and memory utilization in data center servers is
pushed to have the same periodical load model feature.
Potential problems:
(1)
Low
efficiency:
in
the
time
slots
between
the
transmission periods, IoT dedicated resources like computing,
storage and network are in low efficiency status.
(2) Resource Bottleneck: For large scale massive data
generated traffic surge, during the session, the allocated
resource will be bottleneck to the load.
c) Traffic Impacts to network
Network resource occupation competition:
In the concentrator, there are long packets series transmitted
in a short period; it occupied the network I/O buffer. In the
server, packets from concentrators have competitions for the
network resources. Especially in wireless network, the wireless
buffer and channel resource are limited. Figure 8 shows a delay
burst in the wireless channel while the wireless channel is
rather congested.
Figure 8.
Delay in wireless channel competetion.
Potential problem:
(1) Long packets series, with synchronized feature for real-
time applications, will generate network congestion. Then the
application quality will be affected.
d) Traffic Impacts to applications QoS
The traffic model has an impact on application QoS
parameters.
As Figure 9 shows, the TG sends 6000 sensor’s data. These
sensor’s data are encapsulated in XML format and transported
over TCP/IP. In one sending period, one stream, around 4KB,
are divided into packet series to the TCP receiver in the server,
and the server will buffer these packets, until the last packet
comes. Then these 4KB data will decapsulated together. So the
delay of the data in the first packet is increased with the longest
buffering time: the delay of the data in the last packet is the
shortest one. If the number of the packets increases together
with sensor number, this factor will affect the application QoS
more deeply.
Figure 9.
TG + Server schedule.
Figure 10 is result of the application QoS. They are sensor
meta data delay average in 20 seconds (a), sensor meta data
delay in 5 minutes (b), and sensor meta data reach ratio(c). In
123
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-226-4
INFOCOMP 2012 : The Second International Conference on Advanced Communications and Computation

Figure 10, 6000 sensor’s data cross fixed public IP network,
has average delay in seconds level.
(a)
(b)
(c)
Figure 10. Application QoS Parameters.
Potential problems:
(1) How to decrease the delay in the application layer and
assure the QoS of IoT services for this traffic model?
(2) Transportation protocols and data encapsulation format
(packet length, format) are important parameters of the traffic
model. For TCP transportation, with long packets series,
uniform packets encapsulation, the application QoS will be
decreased.
In the test bed, TCP was the protocol used for assuring
packet transmission. However, depending on the network status,
TCP windows update mechanism will result in delay and even
packet loss. On the other hand, if we use UDP protocol, the
delay of above problem can be solved to some extent. However,
in channel or network congestion, there will definitely be
packet loss of the sensor data.
We use XML format for the meta data in the test bed. This
format is easier for encapsulation and decapsulation. However,
the efficiency for transmission and server processing is not
enough, especially for massive data from sensors. There also
should be an efficient and standard meta data format.
V.
CONCLUSION
Large scale IoT deployments generate a new class of
traffic. It is important to know the large scale IoT deployments
impact on Data Center and the network. Potential problems
should
be
further
studied.
These
include:
traffic
surge
generated by synchronous IoT application, in which traffic may
cause network congestion and outage of DC resources. In this
report, we discussed the IoT traffic modeling and evaluation in
order to clarify the impact of future large scale IoT server on
network and data center. Through the IoT traffic modeling
analysis and the evaluation work, we found the potential
impacts and problems of IoT massive data to datacenter,
network and application QoS.
Traffic surge generated by synchronous IoT application
traffic may cause network congestion for cellular network and
outage of DC resources. The transport protocols and data
encapsulation format will affect the application processing
performance greatly and should be carefully selected. It is
important to find solutions to these issues.
REFERENCES
[1]
Huawei, “Traffic model for M2M services,” 3GPP TSG-RAN WG2
Meeting #69 R2-101184, 2010
[2]
Jasmina Krnic and Srdjan Krco, “Impact of WSN Applications'
Generated Traffic on WCDMAAccess Networks,” 19th International
Symposium on Personal Indoor and Mobile Radio Communications
(2008) IEEE
[3]
Rongduo Liu, Wei Wu, Hao Zhu, and Dacheng Yang, “M2M-Oriented
QoS Categorization in Cellular Network,” 7th International Conference
on Wireless Communications, Networking and Mobile Computing
(WiCOM), 2011 IEEE
[4]
Cisco White Paper, “Cisco Visual Networking Index: Global Mobile
DataTraffic Forecast Update,” 2010–2015, VNI Mobile 2011
[5]
http://www.huzhou.gov.cn/art/2011/12/19/art_24_84435.html , accessed
August 2012
[6]
www.12306.cn , accessed August 2012
[7]
CHEN Yun-sheng, FU Tun, “Application of wireless broadband access
technology
in
power
distribution
and
utilization
network,”
Telecommunications for Electric Power System, Vol 31 No. 212, Jun.
10，2010, pp. 10-13
[8]
Jae Yoo Lee and Soo Dong Kim, “Software Approaches to Assuring
High
Scalability
in
Cloud
Computing,”
7th
IEEE
International
Conference on E-Business Engineering, 2010, pp. 300-306
[9]
Jasmina Krnic and Srdjan Krco, “Impact of WSN Applications'
Generated Traffic on WCDMA Access Networks,” PIMRC 2008: 1-5
[10] M.T.S. Jonckheere, R. N´u˜nez-Queija, and B.J. Prabhu, “Performance
Analysis of Traffic Surges in Multi-class Communication Networks,”
Proceedings of International Teletraffic Congress 2010
[11] News:http://itpro.nikkeibp.co.jp/article/NEWS/20110527/360767/
,
accessed August 2012
[12] M. Zubair Shafiq, Lusheng Ji, Alex X., Liu Jeffrey, and Pang Jia Wang,
“A First Look at Cellular Machine-to-Machine Traffic –Large Scale
Measurement
and
Characterization,”
Joint
ACM
International
Conference on Measurement and Modeling of Computer Systems
(SIGMETRICS) and IFIP International Symposium on Computer
Performance, Modeling, Measurements and Evaluation (Performance),
London, UK, June, 2012.
[13] Sandra
C´espedes,
Alvaro
A.
C´ardenas,
and
Tadashige
Iwao,
“Comparison of Data Forwarding Mechanisms for AMI Networks,”
Innovative
Smart
Grid
Technologies
(ISGT),
2012
IEEE
PES,
Publication Year: 2012 , Page(s): 1 - 8
124
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-226-4
INFOCOMP 2012 : The Second International Conference on Advanced Communications and Computation

