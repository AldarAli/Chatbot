A Multilayer Architecture for Cognitive Systems
Supporting well-deﬁned processes that are partially executed manually in technical work places
Veronika Thurner
Munich University of Applied Sciences
Department of Computer Science and Mathematics
Munich, Germany
Email: veronika.thurner@hm.edu
Thorsten Gressling
ARS Computer und Consulting GmbH
Munich, Germany
Email: thorsten.gressling@ars.de
Abstract—Many technical work places, such as laboratories or
test beds, are the setting for well-deﬁned processes requiring both
high precision and extensive documentation, to ensure accuracy
and support accountability that often is required by law, science,
or both. In this type of scenario, it is desirable to delegate certain
routine tasks, such as documentation or preparatory next steps, to
some sort of automated assistant, in order to increase precision
and reduce the required amount of manual labor in one fell
swoop. At the same time, this automated assistant should be
able to interact adequately with the human worker, to ensure
that the human worker receives exactly the kind of support that
is required in a certain context. To achieve this, we introduce a
multilayer architecture for cognitive systems that structures the
system’s computation and reasoning across well-deﬁned levels
of abstraction, from mass signal processing up to organization-
wide, intention-driven reasoning. By partitioning the architecture
into well-deﬁned, distinct layers, we reduce complexity and
thus facilitate both the implementation and the training of the
cognitive system. On this basis, we outline the functional modules
of a cognitive system supporting the execution of partially manual
processes in technical work places.
Index Terms—Cognitive system; Multilayer architecture; Tech-
nical work place; Machine learning; Context sensitive; Neural
network.
I. MOTIVATION
Many technical work places, such as laboratories or test
beds, are the setting for series of well-deﬁned, repetitive
actions requiring high precision in their execution, as well
as extensive documentation of every process step. Both are
necessary to ensure accuracy on the one hand, and on the
other hand to support accountability that often is required by
law, science, or both. Typical examples are laboratories for
micro-biological analysis or chemical experiments, premises
of optometrists or hearing aid acousticians, or test beds for
the quality inspection of produced goods, such as measuring
vehicle exhaust fumes or assessing nutritional values of food.
All these settings share a number of commonalities. For one
thing, within each of these working settings a human being
interacts extensively with technical devices, such as measuring
instruments or sensors. For another thing, processing follows
a well-deﬁned routine, or even precisely speciﬁed interaction
protocols. Finally, to ensure that results are reproducible,
the different steps and achieved results usually have to be
documented extensively and in a precise way.
Especially in scenarios that execute a well-deﬁned series of
actions, it is desirable to delegate certain routine tasks, such
as documentation or preparatory next steps, to some sort of
automated assistant, in order to increase precision and reduce
the required amount of manual labor in one fell swoop. At the
same time, this automated assistant should be able to interact
adequately with the human worker, to ensure that the human
worker receives exactly the kind of support that is required
in a certain context. To achieve this, the assistant needs to be
context aware, i.e., equipped with cognitive input channels. As
well, the assistant is expected to learn new behavioral patterns
from previous experience.
Traditional software systems for process control or work-
ﬂow management are well able to support a set of well-
deﬁned processes that has been explicitly speciﬁed in advance.
However, in situations that were not foreseen initially, or that
were not explicitly speciﬁed because they were deemed to be
highly unlikely to happen, these systems quickly meet their
limits, requiring human take-over and problem solving abilities
in expert mode.
The increasing capabilities of cognitive systems imply the
potential for a new generation of systems that offer context
sensitive reasoning on a scale hitherto unknown in machines
and software systems. We exploit these possibilities by devis-
ing a cognitive hardware-software-system for supporting the
execution of hybrid (i.e., partly manual and partly automated)
processes in technical environments, in a manner that com-
bines the respective strengths of human-expert-like cognition
and reasoning with machine-like processing power, to improve
performance, efﬁciency, accuracy and security issues.
By cognitive system, we denote a system that is capable
of sensory perception and of expressing itself via techni-
cal devices, analogously to corresponding abilities found in
biological organisms. Furthermore, it comprises an internal
representation that is comparable to emotions. However, as
system boundaries and internal states of an artiﬁcial intelli-
gence differ greatly from those of humans beings and animals,
its underlying system of values and beliefs in general differs
from that of biological organisms.
After this initial motivation, we review related literature and
brieﬂy sketch the goals of our research in section 2. In sec-
63
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

tion 3, we introduce the physical architecture of our cognitive
system, followed by a logical architecture in section 4. The
core element of the logical architeture are building blocks,
whose structure is presented in section 5. To illustrate the
processing of our cognitive system and the interaction of the
building blocks on the different layers, we present an example
execution in section 6. Section 7 sketches the prototypical
implementation that we realized as a proof of concept. Finally,
we critically discuss our work in section 8, before summarizing
it in section 9.
II. STATE OF THE ART AND GOALS
Research has already elicited several aspects that are rele-
vant in this context. An overview of existing approaches to
computation and information architecture is provided by [1],
distinguishing among others the different types of information
that are processed, from subsymbolic computation focusing
on data and signal processing to symbolic computation that
processes data structures, thus reﬂecting different levels of ab-
straction. In [2], patterns for cognitive systems are investigated
into, focusing on systems that process textual information, yet
indicating that other kind of information, such as cognitively
interpreted sensory data, will be addressed by cognitive sys-
tems in the near future, thus entering into new dimensions of
machine cognition.
Approaches for systematic process support through Context
Aware Assistive Systems (CAAS) are discusses in [3], [4]
and [5], in the context of manufacturing on the shop ﬂoor
and human interaction with the production line. Identifying
human actions observed via cameras and relating them to the
manufacturing process are a crucial issue in these Context
Aware Assistive Systems.
The research from [6], [7] and [8] focusses on the usage of
augmented reality in intelligent assistant systems, discussing
among others digital projections into the current working
situation, to guide the human workers through their share of
the working process.
Anderson et al. [9] introduce the cognitive architecture ACT-
R, which implements artiﬁcial intelligence in a symbolic way.
In contrast to this, in our approach we combine symbolic and
connectionistic aspects.
So far, existing supportive systems for processes that are
partially executed manually in technical work places are
realized mainly in a rule oriented way and implemented by
algorithms. As a consequence, they cover only those situations,
states and actions that have been anticipated in advance. How-
ever, they only have limited ability to learn from experience.
Recently, research on context awareness signiﬁcantly pro-
gressed towards identifying a speciﬁc situation from a prede-
ﬁned set of possibilities in a given context and well-deﬁned
surroundings, incorporating cognition and artiﬁcial reasoning
on a single level of abstraction. This single level of abstraction
is then realized as a monolithic block of neural networks.
However, this monolithic block needs to deal with the entire
complexity by itself, which would require an extreme amount
of training that exceeds what can be handled even by modern
hardware.
Therefore, as a next step, we introduce an architecture for
cognitive systems that expands cognition and reasoning across
several levels of abstraction, to support a wide range of assis-
tant services ranging from small actions to strategic processes.
By partitioning the systems’s cognition and reasoning into
separate levels of abstraction (rather than implementing them
as a single monolithic block), we reduce both implementation
complexity and training effort. Thus, it is possible to tackle
even very complex problems, which would exceed the capacity
of a monolithic approach.
We discuss the applicability of our approach in the context
of a cognitive system that supports hybrid processes involving
manual tasks within technical surroundings.
III. PHYSICAL ARCHITECTURE
Physically, a technical work place comprises a variety of
technical devices, as a relevant tool set to execute, or support
the execution of, actions involved in the processes at the work
place. Typical examples for, e.g., a chemical laboratory are
electronic high precision scales, a centrifuge, a power supply
or a fume hood. Some of these devices are connected to
computational hardware (e.g., a remote server), either directly
or via a data network. In contrast to this, other devices such
as a traditional heater, operate in an isolated way, without
any direct data exchange with the computational hardware.
Furthermore, the work place comprises a variety of tools and
devices for manual tasks, such as pipettes or glassware, as well
as other materials, e.g., chemical or biological substances to
be processed or analyzed.
In addition, to evolve from a technology interspersed work
place towards an intelligent assistant, the work place must
be equipped with devices that enable the system’s cogni-
tion, as well as its interaction with the human user that
executes the manual process steps. Traditionally, cognitively
exploitable input devices are, for example, a microphone (with
subsequent speech analysis) or a camera (with subsequent
image processing). In addition to this traditional notion of
audio-visual cognition, sensors and other technical measuring
devices provide additional cognitive channels that supply the
system with information on the current situation at the work
place.
Communication from the system towards the human user
is realized, e.g., via a monitor, a loudspeaker or a projec-
tor that focusses its beam of light on the tool to be used
next, or that displays instructions on the process step that
should be executed next. Other, more sophisticated devices
arise continuously, such as mixed reality smart glasses for
displaying instructions directly into the ﬁeld of vision, activity
tracking bracelets that combine skin and body sensors with
functionality for alerting its wearer, or even EEGs for inte-
grating information on the human user’s brain activity into
the system’s data pool.
64
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

Level of 
Abstraction
     (Mn) Processing
Work Place 1
Work
Place
k
Work
Place
2
     (Mj) Processing
(M(j-1)) Processing
(M1) Processing
Technical Devices
Device m
Device 2
Device 1
(M0.2)
(M0.1)
. . .
I(n+1)
S(n+1)
I(n)
S(n)
. . .
I1.m
S1.m
I1.1
S1.1
I2
S2
I(j-1)
S(j-1)
Ij
Sj
I(j+1)
S(j+1)
. . .
. . .
Fig. 1. Multilayer architecture of cognitive systems for supporting hybrid processes in technical work places.
Note that some of these technical devices may include
their own data storage, as well as computational hardware,
thus being able to directly aggregate and process the data
they collected, before passing it on to more sophisticated
computational hardware for integration with the data from
other devices and subsequent further processing.
IV. LOGICAL ARCHITECTURE
The cognitive system that we devise to support process
execution is embedded into this technical work place.
Logically, we design a multilayer architecture that structures
the cognitive system into different levels of abstraction (see
Figure 1), rising from concrete at the bottom towards more
and more abstract as we move upwards on the processing
level stack. Thus, each layer Mj encapsulates processing on a
speciﬁc level of abstraction, and focuses on different tasks. By
structuring the overall system into logical processing layers,
it is possible to train each layer individually for its respective
tasks. Furthermore, modularizing the overall system improves
performance by reducing processing time, as the different
layers can be run in parallel.
65
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

(Mi) Building Block for Layer i
Knowledge
Database
Evaluator
Composer
Processing
Logbook
Storage for Situations
Storage for Instructions
Neural
Network
Algorithmic
Logic
Feedback on
Network
Parameters
E3
A3
A4
Generated Situations
Generated Instructions
A2Training
A2
E2Training
E2
Ii
Si
E1Training
E1
A1
A1Training
I(i+1)
S(i+1)
Fig. 2. Pattern of building block that implements each layer.
Processing involves the analysis of incoming data, which
is synthesized and analyzed to identify the situation that the
work place is in, corresponding to an overall system state
in the context of the executed processes. From the identiﬁed
situation, processing derives which actions should be taken as
next steps, and passes these on as instructions to other layers,
systems, technical devices or – via output devices – to the
human user. Thus, the cognitive system is able to effectively
support the human user in a context sensitive way. Note
that these suggested actions are determined by aggregated
conclusions that the system draws from its analysis.
Layers are interconnected by communication channels. Note
that the information on situations ﬂows upwards in the process-
ing layer stack via channels S (white block arrows in Figure 1),
whereas instructions are passed down from layer to layer via
channels I (black block arrows).
The processing layer stack is based on a layer of technical
devices D1, . . . , Dm as described above. These devices collect
data on the work place and enter these into the cognitive
system as situation information via channels S1.i, with 1 <=
i <= m. Some of these devices (such as Dm in Figure 1)
merely collect data, e.g., by simple measuring, and pass them
straight on to the ﬁrst processing layer M1. Other devices
(such as D1 and D2 in Figure 1) comprise an independent
processing component (M0.1 or M0.2, respectively), which
preprocesses the data before entering it into the ﬁrst processing
layer.
Moving upwards on the processing layer stack, situation
information is aggregated from separate small snippets of
measured data into larger contexts, such as actions, sequences
of actions or even entire processes. Analogously, abstract
instructions that are passed from top to bottom are made more
and more speciﬁc from layer to layer, down to signals that
operate a speciﬁc technical device in the bottom layer.
On each layer, processing takes into account the situation
information that is entered into the layer from below, as
well as the instruction information that is passed to the layer
from above. Thus, situations are interpreted in the light of
instructions that reﬂect the larger context of the overall system,
as identiﬁed on the higher levels of abstraction.
As depicted for layer Mj in Figure 1, a processing layer
can merge several process layer stacks, each representing a
different work place. Thus, their information ﬂows are inte-
grated and consolidated, allowing for integrated information
processing on a cross-organizational level of abstraction.
V. BUILDING BLOCKS
Each layer in Figure 1 is implemented by a building block
that follows the architectural pattern depicted in Figure 2 for
a building block i, with 0 <= i <= n, in a cognitive system
that comprises n >= 1 processing layers stacked on top of
one layer of technical devices.
66
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

Building block i is linked with the building blocks of its
surrounding processing levels i−1 and i+1 via communication
channels, depicted as block arrows in Figure 2. Thus, the
situation information perceived by building block i − 1 is
passed on via channel Si to building block i, which stores
the information in its storage for situations. Analogously,
instructions issued by building block i + 1 are passed on
via channel I(i + 1) to building block i, which stores the
information in its storage for instructions.
The central part of each building block is its processing
unit, which comprises both aspects of algorithmic logic and
of artiﬁcial intelligence (implemented via one or more neural
networks), in varying proportions (see Figure 3). On the
lower levels of abstraction, the major part of processing is
accomplished by algorithmic logic, whereas on the higher
levels of abstraction, aspects of artiﬁcial intelligence dominate
the processing.
Level of 
Abstraction
i=n
i=0
Algorithmic
Logic
Artificial
Intelligence
Fig. 3. Varying proportions of algorithmic logic and artiﬁcial intelligence.
The processing unit works on three different kinds of input:
• E1: Information on situations
• E2: Information on instructions
• E3: Relevant general factual knowledge, stored as rules
in the knowledge database
Based on these inputs, the processing unit analyses the
incoming information, interprets it and synthesizes it into
its interpretation of the situation, thus lifting the previous
information on the situation onto a higher level of abstraction.
For example, on layer M1, short snippets of data that were
measured by the technical devices (e.g., an electronic scale
and a heater) in the underlying physical layer are gathered,
consolidated and then passed on to layer M2. On layer M2,
this consolidated data is then merged and interpreted to build
a larger semantic context, e.g., a certain step in a chemical
experiment where a certain amount of substance must be
added to an existing mixture, and then heated to a speciﬁc
temperature. In order to properly identify the semantic context
correctly, the processing unit in layer M2 incorporates known
“recipes” of chemical experiments that are stored within the
knowledge database of layer M2.
Thus, the processing unit generates four different kinds of
output:
• A1: Information on the synthesized, interpreted situation,
passed on as input to the next higher layer (i + 1), if
present
• A2: Set of instructions that is passed down to the next
lower layer (i−1), if present, or that is addressed directly
to the technical devices, if i = 0
• A3: Newly gathered knowledge rules for the knowledge
database
• A4: Information on all inputs, processing steps and
generated outputs, as well as on all modiﬁcations that
were induced in the parameters of the neural network, to
be documented in the logbook
Within the processing unit, algorithmic logic and neural
networks can be combined in many different topologies to
build the processing unit. In particular, they can be connected
in series or in parallel, or in a combination of both, involving
one or more instances of both algorithmic logic and neural
network.
For example, a modern thermometer which includes both a
temperature sensor and some form of algorithmic logic could
monitor whether the current temperature exceeds a previously
deﬁned threshold. If the threshold value is exceeded, the
algorithmic logic passes the history of measured values on to
the neural network, which synthesizes and analyses this data
in order to identify the current situation.
Another example for a neural network connected in-series to
a subsequent algorithmic logic (i.e., the other way round from
the above example), would be to enter a variety of measured
data from different devices into the neural network, which
derives from this data the overall situation of the work place.
After the neural network classiﬁed and identiﬁed the situation,
this information on the situation is passed on to an algorithmic
logic that executes the predeﬁned process that deals with this
type of situation.
An example for running algorithmic logic and neural net-
work in parallel, followed by a second algorithmic logic
that is connected in series, would be some sort of security
mechanism, where both algorithmic logic and neural network
process the same input data individually and independently of
each other. After both components reached their classiﬁcation
result, a subsequent algorithmic logic compares the individual
results and decides on further processing steps.
For training purposes, the building block provides another
two components: a composer and an evaluator, depicted in
Figure 2 by dashed lines. The composer generates instructions
and situations and inserts them into the respective storages as
training data. To achieve this, the composer can either generate
this new data from scratch, or cut and paste snippets of “real”
data from the storages into new sequences.
During training mode, the processing unit works on this
training data E1Training and E2Training and processes
it into the resulting answers A1Training and A2Training,
67
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

which are then passed on to the evaluator. The evaluator’s
resulting verdict is re-entered into the neural network, to adapt
the parameters within the neural network, as necessary. The
criteria that form the basis for the evaluator’s assessment are
speciﬁed by a set of rules, reﬂecting goals and basic values.
For example, they can postulate the maximization of security,
or the minimization of costs.
Note that composer and evaluator are active only during
training of the neural network, but not during operations.
VI. EXAMPLE EXECUTION
To illustrate which kinds of tasks are dealt with on the
different layers and what kind of information is processed,
Figure 4 visualizes the information ﬂow over time for an
example system and a speciﬁc exemplary situation.
The physical layer of our example work place contains
seven devices, six of which are directly connected to the
cognitive system: a thermometer D1, three cameras D2, D3
and D4, a loudspeaker D5 and an e-mail system D6. In
addition, the work place comprises a traditional heater D7,
which is not data connected to the cognitive system, but
observed by thermometer D1 and the three cameras.
Adhering to the generalized architecture in Figure 1, our
exemplary cognitive system is structured into four processing
layers: M1 for signal processing close to the technical devices,
M2 for reactions which combines short signal snippets into
larger situation contexts, M3 for drawing conclusions and M4
for overall organization. Note that layer M4 merges several
work places (WP2 and WP3), in addition to the work place
in focus.
In the diagram, time is discretized into time steps, pro-
gressing from top to bottom for reasons of readability. (As
a consequence, processing layers are arranged vertically, with
abstraction increasing from left to right.) Within each time
step, all processing actions are executed in parallel. Note that
the diagram in Figure 4 abstracts from the processing time that
is required in each processing layer. Consider processing to
take place at the transition from each time step to its successor,
in parallel for each processing layer.
In time step 1, the technical devices pass the data they
observed on to layer M1 for signal processing, as situation
information. More precisely, thermometer D1 communicates
a series of measured temperature values, each labeled with
a time stamp. All three cameras continuously gather images
from their respective sections of the work place. Each camera
contains basic image processing facilities, which allow for
identiﬁcation of previously registered work place personnel.
Thus, cameras D2 and D3 communicate that they identiﬁed
person “Klaus” at a certain position in the work place. In
contrast to this, camera D4 did not identify any persons in
the section of the work place that it observes.
Layer M1 receives this situation information from the tech-
nical devices and stores it in its storage for situations. On this
basis, it aggregates the gathered information and synthesizes
it into a more complex understanding and larger context of a
situation, thus increasing the level of abstraction. Here, layer
M1 realizes that both cameras D2 and D3 identiﬁed the same
person, Klaus, and calculates the position of Klaus in the
work place. Furthermore, layer M1 analyzes the sequence of
temperature information measured by the thermometer. Here,
layer M1 realizes that the temperature rises really quickly.
This aggregated information is then passed on to layer M2 for
reactions in time step 2. Information is organized according
to the syntactic pattern of type of device, time stamp and
two more items of structured information, whose syntax and
semantics are relative to the type of the device.
The knowledge database of layer M2 contains information
on the experiments that are carried out within the work
place, referenced as DoE (i.e., design of experiments) in
Figure 4. From previous context information, layer M2 is
aware that DoE 89 is currently processed. M2 realizes that
the measured temperature rises both faster and higher than
speciﬁed in the “recipe” that is deﬁned in DoE 89, and that the
thermometer T is correlated with the heater D7. As well, M2
identiﬁes that the thermometer T is merely a sensor and thus
cannot be regulated, whereas the heater D7 can be regulated.
Furthermore, M2 identiﬁes that person Klaus is located close
to the heater D7. All this synthesized situation information is
passed on to layer M3 for conclusions in time step 3, and
stored there in M3’s storage for situations. In addition, the
technical devices keep sending situation information towards
level M1 continuously. In Figure 4, this information ﬂow is
indicated as well for time step 3.
As a next step, layer M3 deduces from the situation
information that device D7 is about to overheat and that
Klaus is still present and able to act. Furthermore, experience
gathered from previous situations indicates that in experiments
that are executed according to DoE 89, temperature problems
arise rather frequently, independently of the current human
operator. In addition, M3 realizes that heater and thermometer
work ﬁne in other experiments, and thus seem to be in order
technically. As a result, in time step 4 layer M3 communicates
as instructions to level M2 that the heater D7 must be
regulated, and that Klaus should act to regulate the heater.
In addition, M3 communicates to level M4 for organization
that temperature problems occur frequently when executing
DoE 89. In addition, during time step 4 layer M1 passes on
its newly aggregated situation information on to level M2,
indicating that the temperature is still rising and that Klaus has
moved towards the heater. As layer M4 for organization joins
the information of several work places, additional information
arrives as input from other work places during time step 4.
Based on all this situation information, layer M4 for orga-
nization deduces that there might exist a systematic problem
in the documentation of DoE 89, such as wrong instructions.
As well, M4 identiﬁes that the situation in work place 1 is
highly critical. Therefore, M4 speciﬁes suitable instructions
and passes them down to level M3 during time step 5.
In parallel, layer M2 processes the newly arrived situation
68
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

time
step
8
time
step
7
time
step
6
time
step
5
time
step
4
time
step
3
time
step
2
time
step
1
Technical Devices
(D6)
E-Mail
(D5)
Speaker
(D4)
Camera
(D3)
Camera
(D2)
Camera
(D1)
Therm.
(M4)
Organization
(M3)
Conclusions
(M2)
Reactions
(M1)
Signal
Processing
CAM, 20171029-1244-5602, 
Klaus, [92, 47]
T, 20171029-1244-7352, 
58.5241, extreme rise
identified person "Klaus", position [92,45]
identified person "Klaus", position [92,49]
measured value, time stamp
answers to other WPs,
irrelevant here
"Klaus, please be careful"
peter@chemistry.org,
"temperature always
too high in DoE 89"
E-Mail, to author of DoE 89,
"temperature always
too high in DoE 89"
LSP, "Klaus, please be careful"
warn Klaus
problem detected in recipe
abnormal situation detected,
highly critical
Systematic error exists in DoE 89
"Klaus, please reduce 
temperatur of heater D7"
LSP, "Klaus, please reduce 
temperature of heater D7"
from WP 3:
[11 experiments] [today],
[material shortage expected]
for [DoE 122]
from WP 2:
[9 experiments] [today],
[everything ok]]
from WP 2:
[operator] [dropped out]
[temperature] at [DoE 89] [frequently]
[too high] [independent of user],
[thermometer] [ok] [at other DoEs]
"Klaus" should act
to regulate the heater
device D7 must be regulated
reduce heat
current DoE is 89
Person "Klaus" present,
close to device D7
according to DoE,
D1 is related to device D7
Device D7 is a heater,
can be regulated
Device for T is just sensor,
cannot be regulated
T has value 53°C, should be 45°C 
according to DoE, rising too fast
CAM, 20171029-1244-5602, 
Klaus, [80, 47]
T, 20171029-1244-3122, 
53.1211, rise
T, 20171029-1245-0144, 
53.7888, fast rise
no person identified, position n/a
identified person "Klaus", position [80,45]
identified person "Klaus", position [80,49]
measured value, time stamp
Fig. 4. Information ﬂows between processing layers, for an exemplary execution of the system.
69
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

information in the light of the instructions that were handed
down towards layer M2 during time step 4. As the temperature
is still rising rapidly, M2 passes down to layer M1 the
instruction that the loud speaker D5 should instruct Klaus to
reduce the temperature of heater D7.
This instruction is translated by layer M1 into appropriate
signals for the loud speaker D5, which are transferred to D5
during time step 6. In addition, layer M3 for conclusions de-
rives from the instructions received from M4, in combination
with the information on the ongoing situation, that a problem
was detected in the recipe of DoE 89 and that Klaus has to be
warned about the critical situation. Corresponding instructions
are passed from M3 to M2 during time step 6.
M2 translates these abstract instructions into device speciﬁc
instructions and passes them down to signal processing M1
during time step 7.
Finally, M1 generates the appropriate, device speciﬁc sig-
nals for the loud speaker D5 and for the e-mail system
D6, respectively, and passes them down to their respective
recipients, which execute them appropriately.
VII. PROTOTYPICAL PROOF OF CONCEPT
A prototypical proof of concept addressing the lower layers
of the example presented here was realized as a show case,
using IBM Watson as well as Tensorﬂow for the neural
network processing.
In this prototypical realization, the layer M0 comprises
a variety of cognitive channels implemented via IoT hard-
ware: three cameras, one projector, one microfone, speakers
addressed via ﬁve Raspberry PI (based on Python), one ph-
Meter, one scale, and temperature sensors addressed via three
ESP8266 (based on Lua). A selection of IBM Watson services
is used to realize cognitive abilities on this layer (STT speech
to text, TTS text to speech, and visual recognition via REST).
Both layers M1 and M2 are realized in the cloud. Process-
ing is based on IBM Bluemix Services that are implemented
in TypeScript. In addition, more complex cognitive abilities
from the IBM Watson portolio are included on layer M2, e.g.,
NLC natural language classiﬁer, which is addressed via REST
as well. Furthermore, the storage for situations on layer M2
is realized via a NoSQL Couch database.
Layer M3 runs on local hardware. Processing logic is
implemented in Python. Situation information is retrieved
from M2 by download. Within the prototype, test cases were
classiﬁed by hand and are processed by a convolutional neural
network (based on MNIST implementation) in Tensorﬂow,
using two convolutional / pooling layers and the dense layer
with ten cases. Classiﬁcation results are uploaded manually to
layer M2.
In spite of the rather small numer of test cases, the system
achieves good classiﬁcation results. Note that for layer M3
to deliver more comprehensive classiﬁcation results, a much
larger amount of data would have to be collected on level M2,
comprising at least 1000 laboratory days. Nonetheless, by this
prototypical realization and the test cases under consideration,
it was possible to validate the feasibility of our architecture.
VIII. CRITICAL DISCUSSION
In principle, it would be possible to implement a cognitive
assistant system with matching abilities as a monolithic block
of neural networks, rather than using our multilayer architec-
ture. However, this monolithic block would have to handle the
entire complexity by itself, thus requiring an extreme amount
of training that greatly exceeds what can be handled even by
modern hardware. This complexity can be handled only by
partitioning the system into smaller parts that are implemented
and trained separately.
All in all, the structure of the building blocks ensures that
the system corresponds to a sequence of symbolic components
(for persistently storing information on situations and instruc-
tions) and subsymbolic, algorithmic components that process
this information. Thus, the overall processing is clearly struc-
tured into distinct layers, which facilitates the implementation
of processing units and allows for their individual training, as
well as for the analysis of the resulting information.
Note that the layering we suggest does not replicate the
layers of the human brain. Rather, it creates levels of abstrac-
tion that are tailored to meet the speciﬁc requirements of the
technical system. As a consequence, the system’s cognition
and thus its awareness will differ from that of a human being.
As any artiﬁcial intelligence, the system has an error mar-
gin that depends, e.g., on the noisy environment, changing
illumination, the possible novelty of input sequences, as well
as on the imperfection of the decision system itself. Thus, it
is possible that the system misinterprets a situation.
If, for example, the system’s task is to identify a person
“Klaus” based on data gathered by cameras and microphones,
it can indeed happen that Klaus is not recognized, or that a
wrong person is recognized as “Klaus” (although it is, in fact,
“Peter”). In the ﬁrst case, the system is aware that something
did not work properly; in the second case, it is not.
Strategies for dealing with the ﬁrst error case range from
retry (i.e., issuing instructions to present oneself to the camera
again) to comment, thus informing the user as comprehensively
as necessary that something unexpected has happened. The
second case, where the system is unaware of its error, is more
severe. Although it cannot be entirely avoided, its possibility
can be signiﬁcantly reduced by sufﬁcient training.
IX. CONCLUSIONS AND FUTURE WORK
We introduced a multilayer architecture for cognitive sys-
tems that support the operation of technical work places,
in which hybrid processes (partially executed manually, and
partially using technical devices) are executed. To ensure
efﬁciency and adaptability, we structured this architecture
into separate layers on different levels of abstraction. Each
layer deals with speciﬁc kinds of tasks and processes the
70
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

corresponding kind of information, which again is organized
into different levels of abstraction.
Each layer of the conceptual architecture is realized by a
building block, which incorporates aspects of both algorith-
mic logic and artiﬁcial intelligence. We provided a template
deﬁning the glass box view of these building blocks. Based
on this template and the conceptual architecture, it is possible
to develop cognitive systems that scale appropriately, to meet
the demands of the application context under consideration.
As a next step, we demonstrated the interaction and cooper-
ation of the different layers for a concrete example, speciﬁed
from the context of a chemical laboratory. Furthermore, we
sketched a prototypical proof of concept that addresses the
lower layers of the presented example. This prototype was
run on a small number of test cases, to validate the feasibility
of our architecture.
For extending the prototypical system towards a more com-
prehensive classiﬁcation of situations and recommendations
of instructions, extensive laboratory data will have to be
collected, as a basis for properly training the cognitive system.
Parts of this work are closely related to an innovation that is
covered by the German patent application 10 2017 126 457.4.
REFERENCES
[1] M. Burgin and G. Dodig-Crnkovic, “A Taxonomy of Computation and
Information Architecture,” in ECSAW, Dubrovnik, Croatia.
ACM, 2015,
pp. 7:1–7:8, DOI: 10.1145/2797433.2797440.
[2] C. Leibold and M. Spies, “Towards a Pattern Language for Cognitive
Systems Integration,” in EuroPLoP, Irsee, Germany.
ACM, 2014, pp.
17:1–17:9, DOI: 10.1145/2721956.2721968.
[3] M. Aehnelt and B. Urban, “The knowledge gap: Providing situation-aware
information assistance on the shop ﬂoor,” in HCI, Los Angeles, USA.
Springer, 2015, pp. 232–243, DOI: 10.1007/978-3-319-20895-4 22.
[4] O. Korn, M. Funk, and A. Schmidt, Assistive systems for the workplace.
IGI Global, 2015, pp. 121–135, DOI: 10.4018/978-1-4666-8200-9.ch097.
[5] T. Kosch, Y. Abdelrahman, M. Funk, and A. Schmidt, “One size does not
ﬁt all – Challenges of providing interactive worker assistance in industrial
settings,” in UbiComp/ISWC, Maui, USA.
ACM, 2017, pp. 1006–1011,
DOI: 10.1145/3123024.3124395.
[6] A. Srivastava and P. Yammiyavar, “Design of multimodal instruc-
tional tutoring agents using augmented reality and smart learning ob-
jects,” in ICMI, Tokyo, Japan.
ACM, 2016, pp. 421–422, DOI:
10.1145/2993148.2998531.
[7] M. Funk, T. Kosch, and A. Schmidt, “Interactive worker assistance:
Comparing the effects of in-situ projection, head-mounted displays, tablet,
and paper instructions,” in UbiComp.
ACM, 2016, pp. 934–939, DOI:
10.1145/2971648.2971706.
[8] S. B¨uttner, O. Sand, and C. Rocker, “Exploring design opportunities for
intelligent worker assistance: a new approach using projetion-based AR
and a novel hand-tracking algorithm,” in AmI, Malaga, Spain.
Springer,
2017, pp. 33–45, DOI: 10.1007/978-3-319-56997-0 3.
[9] J. Anderson, M. Matessa, and C. Lebiere, “ACT-R: A Theory of Higher
Level Cognition and its Relation to Visual Attention,” Human–Computer
Interaction, 1997.
71
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

