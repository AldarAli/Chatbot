Dependency of SAR Image Structure Descriptors with Incidence Angle 
 
Corneliu Octavian Dumitru 
Remote Sensing Technology Institute (IMF) 
German Aerospace Center (DLR) 
Oberpfaffenhofen - Wessling, Germany 
corneliu.dumitru@dlr.de 
Mihai Datcu 
Remote Sensing Technology Institute (IMF) 
German Aerospace Center (DLR) 
Oberpfaffenhofen - Wessling, Germany 
mihai.datcu@dlr.de 
 
 
Abstract— The interpretation of the structure in Synthetic 
Aperture Radar images depends by the used parameters and 
incidence angle. The evaluation is done on the high resolution 
SAR data and the interpretation is realized automatically.                                                                                
In this paper, we propose to study and asses the behavior of the 
primitive feature extracted methods for images of the same 
scene with 2-3 look angles covering the min-max range of the 
sensor. The tests are done on TerraSAR-X products High 
Resolution Spotlight mode at 3 m resolution and two sites were 
found that are appropriate for this. To identify the best 
features and appropriate incidence angle for them the Support 
Vector Machine and as a measure of the classification accuracy 
the precision –recall were considered. The precision-recall was 
computed first for all investigated features and after that the 
best were taken into account for the incidence angle evaluation. 
Keywords - TerraSAR-X products; inicidence angle; patch; 
features; semantic; classification; precision-recall.  
I. 
 INTRODUCTION  
The specific information in High Resolution (HR) SAR 
(Synthetic Aperture Radar) images acquired in single 
polarization is mainly in the "structure", e.g. textures, 
objects, or scattering signatures. The "spatial context" 
becomes very important rather then the "pixel based" 
descriptors which are less informational. The adopted 
solution is to analyze image patches corresponding to ground 
areas of ca. 200x200m. Experiments and tests carried 
recently confirmed the usefulness of the concept, however 
further analysis is needed to asses the behavior of the method 
for the indexing of very large SAR data sets as the case in 
Image Information Mining (IIM). 
There are few publications available [1] ÷ [5] where the 
images are tile into patches. In [1], the patch size is 256x256 
m in order to ensure that the extracted information capture 
the local characteristics within a patch rather the global 
features across the entire image. 
In [2], the TerraSAR-X (TSX) HR Spotlight products 
(resolution of ~1 m) were tiled into patches of 200x200m in 
order to characterize the large and relatively small structures 
available in the urban scene. The images covered different 
region: Las Vegas, Venice, Gizah, and Gauting.  
In [3], the original images are tiled into patches of 16x16 
pixels or 128x128 pixels. The results of the classification 
(city, forest, and sea) were better for the patch size of 
128x128 pixels. The same authors propose in [4] a patch 
contextual approach for HR satellite images (resolution of 
0.6 m) where the patch size is 200x200 pixels. 
In our previous work [5], a pyramid with different 
resolutions (1m, 2m, 2.9m, 4m, and 8m) was considered for 
TSX HR Spotlight where each image was tiled into patches 
at different size in order to have the same area cover on the 
ground. The patch sizes vary from 400x400m (for 1m 
resolution) to 25x25m (for 8m resolution). 
The paper structure is the following. Section 2 presents 
the TSX products used for tests, while Section 3 explains the 
actual state-of-the-art of the feature extraction methods and 
shortly describe the applied methods. Section 4 provides the 
details about the experiments and points the conclusion. The 
references end the paper. 
II. 
TERRASAR-X PRODUCTS 
TerraSAR-X is the German radar satellite launched on 
June 2007. It operates in the X-band and is a side-looking 
SAR based on active phased array antenna technology. It 
does supply high quality radar data for purposes of scientific 
observation of the Earth [6]. 
The basic products are available in a huge diversity of 
modes (Stripmap, Spotlight, ScanSAR), types (complex, 
detected, geocoded), and configurations (Spatially Enhanced 
Products or Radiometrically Enhanced Products) [6]. 
For our investigation, we considered TSX products, 
geocoded product, high resolution spotlight mode, and 
radiometrically enhanced. Two sites are downloaded from 
the TSX EOWEB portal [7], one covering the Berlin area 
and the second one the Ottawa area. For these two sites the 
parameters extracted from the metadata of each product are: 
Berlin-the ground range resolution is about 2.9m, the orbit 
direction with ascending looking, and the incidence angles 
are 30° and 42°, and Ottawa-the ground range resolution is 
similar, but the orbit direction is descending and the 
incidence angles are 27°, respectively 41°. 
The number of looks depends by the incidence angle and 
varies from 5 for an incidence angle of 20° to 9 for an 
incidence angle of 55°. 
III. 
FEATURES EXTRACTION METHODS  
Many feature extraction methods have been proposed in 
the past several decades but few authors are compare these 
feature for satellite images. 
On a conceptual level we decide which features can be 
extracted in general and on a practical level, we apply the: 
gray level co-occurrence feature extraction [33] for texture 
92
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-194-6
SPACOMM 2012 : The Fourth International Conference on Advances in Satellite and Space Communications

analysis, Gabor filtering [18] to extract any geometrical or 
neighbourhood relationships, quadrature mirror filters [30] 
for texture analysis, and non-linear short time Fourier 
transform [32] for spectral characteristics of the image. 
We can divide the features in two categories: statistical 
and spectral. 
A. Statistical 
1) Gray level co-occurrence matrix 
a) State of the art 
The gray level co-occurrence matrix (GLCM) is a second 
order statics of how often different combinations of pixel 
brightness values (gray levels) occur in an image [13]. 
Haralick et al. [8] compute gray level co-occurrence 
matrix for a distance of one with four directions (0°, 45°, 
90°, and 135°). For a seven-class classification problem, they 
obtained approximately 80% classification accuracy using 
texture features in remote sensing images application. 
Rignot and Kwok [9] have analysed SAR images using 
texture features computed from GLCM. However, they 
supplement these features with knowledge about the 
properties of SAR images. For example, image restoration 
algorithms were used to eliminate the specular noise present 
in SAR images in order to improve classification results.  
Schistad and Jain [10] compare different methods for 
texture computation in ERS SAR imagery. One of the used 
and computed methods was GLCM with four directions like 
in [8]. The angular second moment, contrast, entropy, 
cluster shade, inertia, and inverse difference moment [13] 
were computed as texture features from the GLCM. A five 
class classification problem was considered and 29% (an 
average) classification error using GLCM was obtained. 
Randen and Husoy [11] consider GLCM as a reference 
method and they compared this with other filtering methods 
(like: QMF, Gabor, discrete cosine transform, etc) for texture 
extraction. The size of the gray levels in the image is 8 x 8 
(also chosen by Ohanian and Dubes [12]). On the one hand, 
if the value is large, the number of pixel pairs contributing to 
each element in image will be low, and the statistical 
significance poor. On the other hand, if the gray levels are 
low, much of the texture information may be lost in the 
image quantization. The angular second moment, contrast, 
correlation, and entropy were computed as texture features 
for each orientation. The average of the classification error 
was 32%. 
b) Appplied method 
The GLCM is created from a gray scale image by 
selecting either horizontal (0°), vertical (90°), or diagonal 
(45° or 135°) orientation. 
The size of GLCM depends on the number of gray values 
available in the image. For example, in [29], they obtain for 
an input image of 8 bits, i.e., 256 values, a GLCM of 
256x256 elements.  
In our case, we scale the radiometric range of the input 
images to 16 steps and obtain a GLCM size of 16x16 
elements.  
The texture parameters [33] computed from the GLCM 
are: mean, variance, entropy, contrast, energy, correlation, 
homogeneity, autocorrelation, dissimilarity, cluster shade, 
cluster prominence, and maximum probability. 
 
B. Spectral 
1) Gabor filters 
a) State of the art 
A Gabor filter (GAFS) is a linear filter used in image 
processing. 
Randen and Husoy [11] review the major filtering 
approaches to texture feature extraction and performed a 
comparative study by comparing with two classical non-
filtering approaches (GLCM which is a statistical method 
and autoregressive which is model based method). The 
dyadic Gabor filter bank (i.e. Gaussian shaped band-pass 
filters, with dyadic coverage of the radial spatial frequency 
range and multiple orientations) proposed by Jain and 
Farrokhnia [14] was considered for the experiments in [11]. 
Five radial frequency were used (proposed by [14] for 
images of size 256 x 256 pixels) and four orientations (0°, 
45°, 90°, and 135°). The average error on the classification 
was 31%. 
Du [15] used texture features derived from Gabor filters 
to segment SAR images. He successfully segmented the 
SAR images into categories of water, new forming ice, older 
ice, and multi-year ice. Lee and Philpot [16] also used 
spectral texture features to segment SAR images. 
Shu et al. [17] extract the information at four directions 
(0°, 45°, 90°, and 135°) by using Gabor filters and then 
computing the mutual information of each corresponding 
image pair. The experiments show that the method can work 
very well even if the SAR image is not filtered; this indicates 
that the method is robust to speckle noise. 
In Manjunath and Ma [18] a Gabor wavelet based texture 
analysis method is proposed and its application to image 
databases is demonstrated on Brodatz texture database but 
also considering the current work related to the idea of 
browsing large satellite images database. The experiments 
results demonstrate that these Gabor features are robust. 
Rotation and scale invariance are important in many 
applications and the preliminary results obtained by [18] 
using Gabor features are very promising. 
In [19] ÷ [22], the Gabor filters are applied to Brodatz 
texture database with very good results. 
b) Appplied method 
Frequency and orientation representations of a Gabor 
filter are similar to those of the human visual system, and it 
has been found to be particularly appropriate for texture 
representation and discrimination. In the spatial domain, a 
2D Gabor filter is a Gaussian kernel function modulated by a 
sinusoidal plane wave [18]. The Gabor filters are self-similar 
- all filters can be generated from one mother wavelet by 
dilation and rotation. 
We have chosen the Gabor filters designed by Manjunath 
and Ma at Vision Research Lab, University of California. 
The texture parameter results computed from the Gabor 
filter are mean and variance for different scales and 
orientations. 
 
93
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-194-6
SPACOMM 2012 : The Fourth International Conference on Advances in Satellite and Space Communications

2) Quadrature mirror filters 
a) State of the art 
Quadrature Mirror Filter (QMF) banks are multirate (i.e. 
with variable sampling rate throughout the system) digital 
filter banks, introduced by Croisier, [23], Esteban and 
Galand [24]. During the last two decades since the inception 
of QMF banks, they have been extensively used in speech 
signal 
processing, 
image 
processing 
and 
digital 
transmultiplexers [25]. QMF banks are used to split a 
discrete-time signal into a number of bands in the frequency 
domain to process each sub-band in independent manner. 
QMF was used for texture analysis by Randen and Husoy 
[11] as extended classes of filters which include among 
others Gabor filters, discrete cosine transform, etc. This is a 
large class of filters which incorporate both infinite impulse 
response (IIR) and finite impulse response (FIR) filters. In 
their experiments the average of the classification error was 
between 26% and 33%. 
b) Appplied method 
As proposed in [30], statistical features obtained from the 
filtered images using QMF banks in synergy with some other 
features can be used for image (satellite image) indexing. 
The number of features which can be obtained from the 
presented algorithm depends upon the level selected for the 
QMF sub-band decomposition like a wavelet. Features are 
nothing but the mean and variance of the four filtered and 
sub-sampled images in the QMF sub-band pyramid.  
There are many techniques available to design QMF 
banks. We have chosen the QMF banks designed by 
Simoncelli and Adelson at the Vision Science Group, The 
Media Laboratory, MIT [34]. 
The parameters computed from the QMF banks (QMFS) 
are mean and variance of the low pass sub-band, horizontal 
sub-band, vertical sub-band, and diagonal sub-band. 
3) Non-linear short time Fourier transform 
a) State of the at 
Much work on extraction of features based on short time 
Fourier transform is done in speech and audio processing. 
The method proposed in [26] was investigated by Li and 
Ogihara [32] for music information retrieval. They are using 
short time Fourier transform feature extraction method to 
extract the timbral texture witch is not capture by the popular 
method in speech and music processing, the Mel-frequency 
cepstral coefficients. The derived features computed from 
STFT are: spectral centroid, spectral Rolloff, spectral flux, 
low energy, and zero crossings. 
The goal of Popescu et al. paper [26] is to define an 
analysis model for High Resolution Spotlight SAR imagery, 
which is able to integrate the radiometric, as well as 
geometric and texture properties of the SAR data, in order to 
facilitate large data-base queries by informational content 
indexing of the images. The proposed model use the 
information contained in the spectra of the SAR signal.  
The Short Time Fourier Transform (STFT) was 
considered in order to extract the features necessary for the 
Bayesian Support Vector Machine classifier. The features 
are: spectral centroid, spectral flux, cepstral coefficients, and 
first and second statistic measures. Using this method a 
number of 30 classes were recognized from the 9,000 
patches of SAR images acquired with TerraSAR-X satellite. 
b) Appplied method 
This method of SAR image feature extraction and 
complex image information retrieval was first proposed in 
[31]. This non-parametric analysis is a form of time 
frequency analysis where the cutting of a spectrum allows 
the study of the phase responses of scatterers seen from 
different viewing angles.  
The STFT extracts six non-linear features: the first two 
features are based on statistical properties of the spectrum 
and the next four features are timbre features used for music 
genre classification [32]. 
Non-linear STFT (NLFT) features were initially 
proposed mainly for feature extraction from complex-valued 
SAR images, but experiments showed that they give very 
encouraging results also for real-valued images.  
Our proposed algorithm is an implementation of the non-
linear STFT feature extraction. The features parameters 
computed from the STFT are: mean of the STFT 
coefficients, variance of the STFT coefficients, spectral 
centroid in range, spectral centroid in azimuth, spectral flux 
in range, and spectral flux in azimuth. 
IV. 
PERFORMANCE EVALUATION 
Presently Earth Observation (EO) satellites acquire huge 
volumes of high resolution images, very much over-passing 
the capacity of the users to access the information content of 
the acquired data. In addition to the existing methods for EO, 
data and information extraction are needed new methods and 
tools to explore and help to discover the information hidden 
in large EO image repositories. 
For our investigation two sites were considered: Berlin- 
Germany and Ottawa – Canada. For the evaluation of the 
best features the Berlin site was considered in order to 
compute the precision-recall of GLCM, GAFS, QMFS and 
NLFT features. After the best features were identified these 
are used for answering to the question “Which is the best 
incidence angle”. In this case both sites, Berlin and Ottawa 
were process. 
To evaluate the feature extraction methods and the best 
incidence angle a tool based on Support Vector Machine 
with relevance feedback (SVM – RF) was built. 
The SVM – RF tool supports users to search images 
(patches) of interest in a large repository. The Graphical User 
Interface of this tool allows Human-Machine Interaction to 
rank the automatically suggested images which are expected 
to be grouped in the class of relevance. Visual supported 
ranking allows enhancing the quality of search results by 
giving positive and negative examples as right and left click 
respectively. 
The size of the images covering the area of: Berlin is 
5549x3368 pixels and Ottawa the size is 4783x3381 pixels. 
In our case, the product-image is tile in patches with the 
size of 220x220m, and after that, sub-sampled to 110x110m 
for better performances (see in [5] the comparison results). 
The feature vector for GLCM has a fix number of 
features for each orientation equal to 12 features, but in our 
94
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-194-6
SPACOMM 2012 : The Fourth International Conference on Advances in Satellite and Space Communications

experiments all the orientations (from 1 to 4) were 
considered obtaining a feature vector of 48 features (denoted 
by GLCM_1_2_3_4). In the case of Gabor filters, 4 scales 
and 6 orientations (48 features denoted by GAFS 4_6) were 
considered. For QMFS, the number of levels of wavelet 
decomposition was equal to 1 this means a vector of 8 
features was obtained (denoted by QMFS 1), while for 
NLFT the number of features was fixed to 6.  
All the features are normalised before being used in the 
SVM-RF tool. For normalisation the Z-score normalisation 
method was selected from the many available and used [33]. 
We define a number of semantic classes and group the 
patches accordingly, using the SVM-RF tool and the human 
expertise. In our approach, for assigning the patches into 
classes, one patch was assigned only to one class based on 
the dominant content of the patch. 
During the evaluation, the number of classes retrieved for 
Berlin area is 11 classes and for Ottawa area the number of 
classes is 6 (some examples are shown in Figure 1). 
 
Figure 1.  Typical classes extracted from the Berlin image (first line) and 
from Ottawa (second line). 
For each feature extraction method, we tried to detect the 
classes among the number of identified patches of our 
database. For each class, we give 20% of the patches of each 
class for the training as positive examples and one patch 
from the rest of the classes as a negative example and we 
tray to detect the similar patches during 7-10 training 
iterations. The evaluations stop when the classified patches 
which are displayed by the Search Engine (SVM - RF tool) 
remain in a stable result. The procedure is repeated two times 
for the same class, giving the same positive and negative 
examples in the same order. 
For the quantitative assessment, we compared the 
classification results with the annotated database. We 
purpose for our evaluation the Precision-Recall that will be 
computed for each class, feature, and incidence angle.  
The precision is defined as the fraction of the retrieved 
images which are relevant, while the recall is defined as the 
fraction of relevant images which have been retrieved.  
For the evaluation of the best feature that are intend to be 
used for the evaluation of the incidence angles, in Table I 
and Table II are displayed (for Berlin site with 30° of the 
incidence angle) the precision-recall for all four features, 
each class separately. With red colour is marked the best 
result obtained for each class, with blue colour is represented 
the average of the precision or recall for each class or feature 
algorithm, and with green colour is represented the global 
average of the precision or recall for entire product-mode-
patch (this means for all investigated classes and feature 
algorithms). 
After the investigation and comparison between the 
features is done the following observation arise:  
a) The Gabor filters perform better than the other 
features especially when the precision is computed.  
b) Regarding the recall, the best performance is 
obtained for quadrature mirror filters. 
c) The quadrature mirror filters has the advantage of 
being faster (in required run time for feature computation) 
than the Gabor filters. 
Based on the previous remarks, for evaluating the best 
incidence angle the GAFS and QMFS are taking into 
account. The two selected feature extraction methods were 
applied for this investigation to our dataset (Berlin and 
Ottawa).  
On the TerraSAR-X archive [6], we identified two sites 
with different incidence angles and orbit direction: Berlin 
30° and 42° with ascending looking and Ottawa 27° and 41° 
with descending looking. 
In the next tables (Table III –IV), for these two sites the 
precision-recall was computed and the results are displayed. 
With blue color is represented the average of the precision or 
recall for each class or feature algorithm and with green 
color is represented the global average of the precision or 
recall for entire mode-incidence angle. The best incidence 
angle was obtained for both sites in the case of bigger value 
of the incidence angle. 
We are focus only to recall because is more relevant than 
the precision for our investigation. 
TABLE I.  
THE PRECISION- COMPARISON BETWEEN ALL PF ALGORITHMS (GEC-RE PRODUCT, SPOTLIGHT MODE AND PATCH SIZE 110X110) - BERLIN 
Semantics 
Class No 
GAFS 4_6 
GLCM 1_2_3_4 
NLFT 
QMFS 1
Average features - class 
Forest 
class00 
100.00% 
100.00% 
73.33% 
81.25% 
88.65% 
Forest + other objects 
class01 
84.62% 
75.76% 
76.79% 
79.69% 
79.22% 
Channel 
class02 
100.00% 
92.59% 
70.73% 
63.16% 
81.62% 
Train lines type 1 
class03 
100.00% 
100.00% 
100.00% 
100.00%
100.00% 
Urban type 1 
class04 
86.37% 
86.67% 
90.91% 
68.97% 
83.23% 
Train lines type 2 
class05 
100.00% 
100.00% 
100.00% 
100.00%
100.00% 
Building reflection 
class06 
80.10% 
65.45% 
53.09% 
61.25% 
64.97% 
Urban type 2 
class07 
100.00% 
60.00% 
36.84% 
65.22% 
65.52% 
Street plus building 
class08 
58.33% 
75.00% 
20.00% 
55.00% 
52.08% 
Urban type 3 
class09 
81.82% 
71.43% 
68.75% 
90.00% 
78.00% 
Sport  fields 
class10 
100.00% 
100.00% 
100.00% 
100.00%
100.00% 
Average all class / features 
 
90.11% 
84.26% 
71.86% 
78.59% 
Total: all classes and features: 81.21% 
95
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-194-6
SPACOMM 2012 : The Fourth International Conference on Advances in Satellite and Space Communications

 
TABLE II.  
THE RECALL - COMPARISON BETWEEN ALL PF ALGORITHMS (GEC-RE PRODUCT, SPOTLIGHT MODE AND PATCH SIZE 110X110) - BERLIN 
Semantics 
Class No 
GAFS 4_6 
GLCM 1_2_3_4 
NLFT 
QMFS 1 
Average features - class 
Forest 
class00 
71.43% 
71.43% 
78.57% 
92.86% 
78.57% 
Forest + other objects 
class01 
66.67% 
75.76% 
65.16% 
77.27% 
71.22% 
Channel 
class02 
51.35% 
67.57% 
78.38% 
64.86% 
65.54% 
Train lines type 1 
class03 
58.33% 
66.67% 
66.67% 
58.33% 
62.50% 
Urban type 1 
class04 
63.33% 
50.00% 
66.67% 
66.67% 
61.67% 
Train lines type 2 
class05 
27.27% 
27.27% 
63.64% 
63.64% 
45.46% 
Building reflection 
class06 
68.06% 
50.00% 
59.72% 
68.06% 
61.46% 
Urban type 2 
class07 
32.35% 
26.47% 
20.59% 
44.12% 
30.88% 
Street plus building 
class08 
14.58% 
31.25% 
25.00% 
22.92% 
23.44% 
Urban type 3 
class09 
32.15% 
35.71% 
39.29% 
32.15% 
34.83% 
Sport  fields 
class10 
55.56% 
55.56% 
44.44% 
55.56% 
52.78% 
Average all class / features 
 
49.19% 
50.70% 
55.28% 
58.77% 
Total: all classes and features: 53.49%
 
TABLE III.  
THE PRECISION / RECALL - COMPARISON BETWEEN DIFFERENT INCIDENCE ANGLES (GEC-RE PRODUCT WITH SPOTLIGHT MODE) - BERLIN 
Precision 
Recall 
Incidence angle = 30° 
Incidence angle = 42°
Incidence angle = 30° 
Incidence angle = 42°
Semantics 
Class No 
Average features - class 
Average features - class 
Forest 
class00 
100.00% 
90.63% 
64.29% 
82.15% 
Forest + other objects 
class01 
95.17% 
82.16% 
81.82% 
71.97% 
Channel 
class02 
98.08% 
81.58% 
60.81% 
58.11% 
Train lines type 1 
class03 
100.00% 
100.00% 
41.67% 
58.33% 
Urban type 1 
class04 
88.46% 
77.67% 
58.34% 
65.00% 
Train lines type 2 
class05 
100.00% 
100.00% 
41.67% 
45.46% 
Building reflection 
class06 
83.09% 
70.68% 
42.36% 
68.06% 
Urban type 2 
class07 
82.36% 
82.61% 
32.35% 
38.24% 
Street plus building 
class08 
66.59% 
56.67% 
29.17% 
18.75% 
Urban type 3 
class09 
89.59% 
85.91% 
32.15% 
32.15% 
Sport  and other fields 
class10 
100.00% 
100.00% 
44.45% 
55.56% 
Total all classes and features 
91.21% 
84.35% 
48.10% 
53.98% 
 
TABLE IV.  
THE PRECISION/RECALL - COMPARISON BETWEEN DIFFERENT INCIDENCE ANGLES (GEC-RE PRODUCT WITH SPOTLIGHT MODE) - OTTAWA 
Precision 
Recall 
Incidence angle = 27° 
Incidence angle = 41° 
Incidence angle = 27° 
Incidence angle = 41° 
Semantics 
Class No 
Average features - class 
Average features - class 
Water 
class00 
100.00% 
92.19% 
70.97% 
79.04% 
Channel 
class01 
97.62% 
89.58% 
65.63% 
67.19% 
Building reflection 
class02 
87.97% 
79.79% 
59.53% 
80.96% 
Urban type 1 
class03 
98.17% 
96.24% 
66.67% 
76.07% 
Urban type 2 
class04 
100.00% 
68.00% 
59.38% 
62.50% 
Field 
class05 
88.10% 
85.16% 
88.10% 
66.67% 
Total all classes and features 
95.31% 
95.31% 
68.38% 
72.07% 
 
V. 
CONCLUSION 
Based on the presented results and the parameters of the 
TSX products extracted from the XML file, a general 
conclusion can be drawn that, for value of the incidence 
angle closer to the upper bound of the sensor range (for 
TerraSAR-X High Resolution Spotlight mode products the 
bounds are around 20° for lower value and 55° for upper 
value) combined with orbit orientation (ascending or 
descending looking) give better results that in the case when 
the value of the incidence angle is closer to the lower bound 
of the sensor range.  
96
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-194-6
SPACOMM 2012 : The Fourth International Conference on Advances in Satellite and Space Communications

For Berlin this is 42° and for Ottawa is 41°. For these 
two sites the number of retrieved classes is equal to 11 for 
Berlin area and to 6 for Ottawa area.  
The good classes in recall are: for Berlin – forest, forest 
plus other objects, building reflection and urban; for Ottawa 
– water, channel, building reflection, urban, field. (2) The 
bad classes in recall are only for Berlin - street plus building 
class. 
ACKNOWLEDGMENT 
This work was partially funded by ESA (European 
Satellite Agency) under the KLAUS project (contract 
no. 22823/09/I-AM). 
REFERENCES 
[1] C.-R. Shyu, M. Klaric, G. Scott, A. Barb, C. Davis, and K. 
Palaniappan, “GeoIRIS: Geospatial Information Retrieval and 
Indexing System – Content Mining, Semantics Modeling, and 
Complex Queries”, IEEE Trans. Geoscience and Remote 
Sensing, vol. 45, Issue 4, pp. 839-852, 2007. 
[2] A. Popescu, I. Gavat, and M. Datcu, “Image Patch Contextual 
Descriptors for Very High Resolution SAR data: A Short 
Time Fourier Transform Non-Linear Approach”, “in press”. 
[3] P. Birjandi and M. Datcu, “ICA based visual words for 
describing under meter high resolution satellite images”, Proc. 
of. IGARSS 2009, Cape Town, 2009. 
[4] P. Birjandi and M. Datcu, “Patch Contextual Descriptors for 
Very High Resolution Satellite Images: A Topographic ICA 
Approach”, “in press”. 
[5] C.O. Dumitru, J. Singh, and M. Datcu, “Selection of relevant 
features and TerraSAR-X products for classification of high 
resolution SAR images“, EUSAR 2012, May 2012. 
[6] TerraSAR-X: “Basic Products Specification Document”, 
Issue: 1.6 (TX-GS-DD-3302), April 2012. 
[7] https://centaurus.caf.dlr.de:8443/eoweb-
ng/template/default/welcome/entryPage.vm, April 2012. 
[8] R. M. Haralick, K. Shanmugam, and I. Dinstein, “Textural 
features for image classification”, IEEE Trans. Systems, Man, 
and Cybernetics, SMC-3, pp. 610-621, 1973. 
[9] E. Rignot and R. Kwok, “Extraction of Textural Features in 
SAR Images: Statistical Model and Sensitivity”, Proc. 
International Geoscience and Remote Sensing Symposium, 
Washington, DC, pp. 1979-1982, 1990. 
[10] A.S. Solberg and A. Jain, “Texture Fusion and Feature 
Selection Applied to SAR Imagery”, IEEE Trans. Geoscience 
and Remote Sensing, vol. 35, no. 2, pp. 475-478, 1990. 
[11] T. Randen and J.H. Husoy, “Filtering for Texture 
Classification: A Comparative Study”, IEEE Trans.Pattern 
Analysis and Machine Intelligence, vol. 21 no.4, pp. 291-310, 
1990. 
[12] P.P. Ohanian and R.C. Dubes, "Performance Evaluation for 
Four Classes of Textural Features", Pattern Recognition, vol. 
25, no. 8, pp. 819-833, 1992. 
[13] http://www.fp.ucalgary.ca/mhallbey/orderliness_group.htm, 
April 2012 
[14] A.K. Jain and F. Farrokhnia, “Unsupervised Texture 
Segmentation Using Gabor Filters”, Pattern Recognition, vol. 
24, no. 12, pp. 1167-1186, 1991. 
[15] L. J. Du, “Texture Segmentation of SAR Images Using 
Localized Spatial Filtering”, Proc. International Geoscience 
and Remote Sensing Symposium, Washington, pp.1983-1986, 
1990. 
[16] J. H. Lee and W. D. Philpot, “A Spectral-Textural Classifier 
for Digital Imagery”, Proc. International Geoscience and 
Remote Sensing Symposium, Washington, pp. 2005-2008, 
1990. 
[17] L. Shu, T. Tan, M. Tang, and C. Pan, “A Novel Registration 
Method for SAR and SPOT Images”, Proc. IEEE 
International Conference on Image, pp. II.213-II.216, 2005. 
[18] B. S. Manjunath and W. Y. Ma, “Texture Features for 
Browsing and Retrieval of Image Data”. IEEE Trans. Pattern 
Analysis and Machine Intelligence, vol.18, pp.837–842, 1996. 
[19] P. Porter and N. Canagarajah, “Robust Rotation-Invariant 
Texture Classification: Wavelet, Gabor filter and GMRF 
based Schemes”, Proc. Visual Image Processing, vol. 144, 
no. 3, pp. 180-188, 1997. 
[20] S.E. Grigorescu, N. Petkov, and P. Kruizinga, “Comparison 
of Texture Features based on Gabor Filters”, IEEE Trans. 
Image Processing, vol. 10, no. 11, pp. 1160-1167, 2002. 
[21] D. Zhang, A. Wong, M. Indrawan, and G. Lu, “Content-based 
Image Retrieval Using Gabor Texture Features”, IEEE Trans. 
Pattern Analysis and Machine Intelligence, pp. 13-15, 2000. 
[22] M. Torres-Torriti and A. Jouan, “Gabor vs. GMRF Features 
for SAR Imagery Classification”, Proc. Int. Conference on 
Image Processing, Thessaloniki, vol. 3, pp. 1043 – 1046, 
2001. 
[23] A. Croisier, D. Esteban, and C. Galand, “Perfect Channel 
Splitting 
by 
use 
of 
Interpolation/Decimation/Tree 
Decomposition Techniques”, Proc. International Conference 
on Information Science and Systems, Patras Greece, 1976. 
[24] D. Esteban and C. Galand, “Application of quadrature mirror 
filters to split-band voice coding schemes”, Proc. IEEE Int. 
Conf. ASSP, Hartford, Connecticut, pp. 191-195, 1977.  
[25] P. Vaidyanathan, “Quadrature Mirror Filter Banks, M-band 
Extensions and Perfect-Reconstruction Techniques”, IEEE 
ASSP Magazine, vol. 4, no. 3, pp. 4-20, 1987. 
[26] A. Popescu, C. Patrascu, I. Gavat, J. Singh, and M. Datcu, 
“Spotlight TerraSAR-X Data Modeling using Spectral Space-
Variant Measures, for scene Targets and Structure Indexing”, 
Proc. The 8th European Conference on Synthetic Aperture 
Radar, Aachen, Germany, 2010. 
[27] T. Zou, W. Yang, D. Dai, and H. Sun, “Polarimetric SAR 
Image Classification Using Multifeatures Combination and 
Extremely Randomized Clustering Forests”, EURASIP 
Journal on Advances in Signal Processing vol. 2010, 
ID 465612, 9 pages, 2010. 
[28] M. Fauvel, J. Chanussot, J.A. Benediktsson, and J.R. 
Sveinsson, 
“Spectral 
and 
Spatial 
Classification 
of 
Hyperspectral Data using SVMs and Morphological Profiles”, 
IEEE 
International 
Geoscience 
and 
Remote 
Sensing 
Symposium, Barcelona, Spain, pp. 4834-4837, 2002.  
[29] R. Haralick, K. Shanmugam, and I. Dinstein, "Textural 
Features for Image Classification", IEEE Trans. Systems, 
Man, and Cybernetics, vol. 3, no. 6, pp. 610–621, 1973. 
[30] M. Campedel, E. Moulines, and M. Datcu, “Feature Selection 
for 
Satellite 
Image 
Indexing”, 
ESA-EUSC: 
Image 
Information Mining – Theory and Application to EO, 2005. 
[31] A. Popescu, I. Gavat, and M. Datcu, "Complex SAR image 
characterization using space variant spectral analysis", Proc. 
IEEE Radar Conference, pp. 1-4, 2008. 
[32] Z. Li and M. Ogihara, “Towards Intelligent Music 
Information Retrieval”, IEEE Trans. Multimedia, vol. 8, no. 
3, pp. 564-574, 2006. 
[33] N. Karthikeyani Visalakshi and K. Thangavel, “Impact of 
Normalization in Distributed K-Means Clustering”. Int. 
Journal of Soft Computing, vol. 4, no. 4, pp. 168-172, 2009. 
[34] http://persci.mit.edu/pub_pdfs/simoncelli_subband.pdf, April 
2012.
97
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-194-6
SPACOMM 2012 : The Fourth International Conference on Advances in Satellite and Space Communications

