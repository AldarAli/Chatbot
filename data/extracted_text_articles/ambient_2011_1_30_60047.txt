A Model for Activity Recognition and Emergency Detection in Smart Environments 
 
Irina Mocanu and Adina Magda Florea 
Computer Science Department 
University ”Politehnica” of Bucharest 
Bucharest, Romania 
 e-mail: irina.mocanu@cs.pub.ro, adina.florea@cs.pub.ro
 
 
Abstract—Activity recognition has become an important 
feature in smart environments designed for helping old people 
living alone and independently in their homes. This paper 
presents a model for detecting emergencies in case of human 
activity recognition in such a smart environment. The 
emergencies detection is performed using a stochastic context-
free grammar with attributes together with a domain activity 
ontology for modeling the daily programme of the supervised 
person. 
Keywords-activity recognition; smart environments; context-
free grammar with attributes; emergency detection. 
I. 
 INTRODUCTION 
The percentage of elderly people in today’s societies 
keeps on growing. As a consequence we are faced with the 
problem of supporting older adults in loss of cognitive 
autonomy who wish to continue living independently in their 
home as opposed to being forced to live in a hospital. Smart 
environments have been developed in order to provide 
support to the elderly people or people with risk factors who 
wish to continue living independently in their homes, as 
opposed to live in an institutional care. 
In order to be a smart environment, the house should be 
able to detect what the occupant is doing in terms of one’s 
daily activities. It should also be able to detect possible 
emergency situations. Furthermore, once such a system is 
completed and fully operational, it should be able to detect 
anomalies or deviations in the occupant’s routine, which 
could indicate a decline in his abilities.  
Our goal is to develop an integrated ambient intelligent 
system for elderly people or people with risk factors, called 
AmIHomCare, which includes several modalities of 
surveillance and assistance of people with special needs. One 
component of the system is the human activity recognition 
module, which is dedicated to recognizing human activities 
as part of daily living. Identification of daily activities is 
done using ontologies [1], vision-based models [2], sensor-
based models [3] or different algorithms such as Hidden 
Markov Models [4]. Also the module is responsible with the 
detection of emergency situations during the daily activities. 
The paper presents a model for emergency detection for a set 
of human activities known to take place in the living room. 
The rules used for activities recognition are modeled with a 
stochastic 
context-free 
grammar. 
Different 
types 
of 
emergencies are detected during the activity parsing using a 
set of data: (i) an attribute for modeling the duration of 
activity added in the activity grammar and (ii) a domain 
ontology for represented activities’ properties (e.g., normal 
duration, usual place of performing an activity, time of the 
day or usual sequence of some activities). 
The rest of the paper is organized as follows: Section II 
presents existing methods for activity recognition and 
Section III describes the general structure of the 
AmIHomCare system in which the component responsible 
for activity recognition will be integrated. Section IV 
introduces the model for emergencies detection in activity 
recognition. Experimental results are presented in Section V 
and the paper is concluded in Section VI.  
II. 
RELATED WORK 
Activity recognition became an important research issue 
related to the successful realization of intelligent pervasive 
environments. It is the process by which an actor’s behavior 
and his or her environment are monitored and analyzed to 
infer the activities. Activity recognition consists of: (a) 
activity modeling, (b) behavior and environment monitoring, 
(c) data processing and (d) pattern recognition. There are 
several approaches for activity recognition as described in 
[1]: 
 
Vision-based activity recognition which uses visual 
sensing facilities: camera-based surveillance systems 
to monitor an actor’s behavior and the changes in its 
environment. It is composed of four steps: human 
detection, behavior tracking, activity recognition and 
high-level activity evaluation. Various other research 
approaches used different methods such as: single 
camera or stereo and infra red to capture activity 
context. For example, in [2], a system for 
recognizing activities in three steps is presented: (i) 
track pedestrians across a scene and recognize a set 
of human activities; (ii) use multiple cameras to 
observe the scene and (iii) use an active dual camera 
for task recognition at multiple resolutions.  
 
Sensor-based activity recognition uses sensor 
network technologies to monitor an actor’s behavior 
along with its environment. In this case there are 
sensors attached to humans. Data from the sensors 
are collected and analyzed using data mining or 
machine learning algorithms to build activity models 
and perform activity recognition. In this case, there 
recognized activities included human physical 
13
AMBIENT 2011 : The First International Conference on Ambient Computing, Applications, Services and Technologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-170-0

movements: walking, running, sitting down/up as in 
[3]. Most of wearable sensors are not very suitable 
for real applications due to their size or battery life. 
 
Activity recognition algorithms can be divided in 
three categories: machine learning techniques, 
grammar 
based 
techniques 
and 
ontological 
reasoning. Many types of machine algorithms for 
activity recognition were developed, including 
Hidden Markov Models, Bayesian Networks or 
Support Vector Machine techniques. Among them 
Hidden Markov Models and Bayesian Networks are 
the most commonly used methods in activity 
recognition. Standard Hidden Markov Models 
(HMM) are employed for simple activity recognition 
as described in [4][5]. They are not suitable for 
modeling complex activities that have large state and 
observation spaces. Parallel HMM [6] are proposed 
for recognizing group activities by factorizing the 
state space into several temporal processes. Another 
approach for activity recognition based on HMM is 
semi-Markov models as described in [7]. Other 
models are represented by conditional random fields. 
Conditional random fields are discriminative models 
for labeling sequences [8]. They condition on the 
entire observation sequence, which avoids the need 
for the assumption of independence between 
observations. The Conditional Random fields 
method performs as well as or better than the HMM 
even when the model features do not violate the 
independence assumptions of the HMM as described 
in [8]. Other type of methods for human activity 
recognition is based on hierarchical Bayesian 
networks [9] or dynamic Bayesian networks [10], 
which can model the duration of an activity. Another 
method for activity recognition uses context-free 
grammar. 
A 
context-free 
grammar 
for 
the 
description of continued and recursive human 
activities is presented in [11]. Other types of 
grammars are used for activity recognition. An 
example is stochastic context-free grammars. 
Detection and recognition of temporally extended 
activities and interactions between multiple agents 
are modeled using a probabilistic syntactic approach 
(stochastic context- free grammar), as described in 
[12]. Stochastic context-free grammars are also used 
for recognizing kitchen-specific activities as in [13]. 
In [14], an attribute grammar which is capable of 
describing features that are not easily represented by 
finite symbols is proposed. This grammar is used for 
representing multiple concurrent events which 
involve multiple entities by associating unique object 
identification labels with multiple event threads. The 
ontological reasoning models activities in an 
ontology and the reasoning is realized based on the 
properties of the compound entities as described in 
[1]. 
III. 
ACTIVITY RECOGNITION IN AMIHOMCARE SYSTEM  
The general structure of an ambient intelligent system (an 
intelligent house) for home medical assistance of elderly or 
disabled people, called AmIHomCare is presented in [15]. 
The paper describes the main components of the system, the 
purpose of each component and the links between them. 
The main objective of this system is to develop an 
intelligent environment for ambient assisted living, which 
achieves home monitoring and assistance for elderly people 
or patients with risk factors, controls the environment, and 
detects medical emergencies.   
The system has four main components: 
 
A component to monitor and control ambient 
factors such as light, temperature, humidity, as well 
as home security; 
 
A component to monitor patient health status by 
using non-intrusive and intrusive sensors, and send 
alerts in case of  risk values; 
 
A component to achieve patient gesture recognition 
and gesture-based interaction with a “robot like” 
personal assistant; 
 
A component to achieve human activity monitoring 
(the supervising system), offers to the patient 
pervasive access and retrieval to medical products 
information (the retrieval system). Both the 
supervising system and the retrieval system work 
based on captured images and patient specific 
context.  
AmIHomCare also includes a connection to a call center 
and a home assistance center. The AmIHomCare system 
proactively assists people in their daily activities or medical 
needs, detects medical emergencies, and sends information 
to a call center.  
The supervising system analyses the images captured by 
the supervision cameras. For each image, the context of the 
detected person together with its pose are determined. The 
context together with the pose form a sub-activity. An 
activity is composed by a set of successive sub-activities. 
The process for human activity recognition is described in 
Figure 1 as it is presented in [16].  
 
Figure 1.  Human activity recognition 
NO 
image 
Person 
detection 
Next 
supervising 
YES 
Context 
identification
Context 
Ontology 
context 
Human pose 
identification 
Pose 
Sub-activity 
identification 
Activity 
Parsing  
activity 
Grammar 
for human 
poses 
Grammar 
for human 
activities 
14
AMBIENT 2011 : The First International Conference on Ambient Computing, Applications, Services and Technologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-170-0

A supervising camera is installed in each room of the 
house. It takes snapshots at a predefined interval. Each image 
is analyzed in order to perform human activity recognition. 
The main steps of the human activity identification, as 
described in [16] are: (i) Person detection in the image; (ii) 
Identification of the detected person’s context (iii) Person’s 
pose identification in the recognized context and (iv) Sub-
activity identification based on the obtained context and on 
the person’s pose. The context of a person refers to the zone 
from the room in which the person was detected, together 
with the surrounding objects (furniture objects) from the 
room. Thus, each room is divided in zones of interest. For 
example, the living room from Figure 2 is divided in three 
zones: R1 (the resting zone), R2 (the reading zone) and R3 
(the dining zone). For example, if we consider a person in 
the living room from Figure 2 in zone R2, near the armchair, 
his context will be (zone:R2, furniture object: armchair).  
 
Figure 2.  Areas from the living room. 
The image from the supervising camera is analyzed in 
two steps in order to detect the person’s context. First the 
image is annotated so that image objects will get associated 
keywords. Image annotation is performed with a parallel 
genetic algorithm, described in [17], which determines the 
best 
match 
between 
each 
image 
region 
and 
the 
corresponding objects in the room. Secondly, the image is 
analyzed for person detection. The bounding boxes of the 
objects from the image (the detected person and the furniture 
objects) are compared. Thus the objects close to the 
supervised person will be identified. Then these objects will 
be used to determine the zone of the room in which the 
person is located. This assumes a model of the house is 
available. The house model is a domain ontology – the 
context ontology, which consists of the rooms in the house, 
the zones inside each room and the furniture objects. Each 
room has its component zones and each zone consists of the 
component furniture objects. For a better person’s context 
identification, each furniture object from the house and the 
supervising person have associated a depth using a distance 
sensor (sonar).  Thus each furniture object from the ontology 
will have an associated list of one or more depth values. 
Each depth value in the list will be measured considering a 
known angle of the distance sensor. Next the ontology is 
queried with the objects close to the supervised person. The 
query result is zone R which contains the majority of objects 
close to the detected person (under a predefined threshold). 
The zone R together with the nearest furniture object(s) from 
R forms the person’s context. 
The position of the detected person is obtained using its 
depth (from the distance sensor) combined with a movement 
sensor. In case of movement detection, the human pose is 
identified. The human pose identification is described in 
[16]. The human body is modeled by its body components. A 
list of known poses stored in an and-or graph is used for this 
purpose. The pose is obtained using a set of rules modeled as 
a stochastic context-free grammar, which is transformed into 
the equivalent and-or graph. The human pose identification 
is performed probabilistically, by bottom-up constructing a 
list of parse trees in the grammar. The parse tree with the 
biggest probability is chosen from the result list. 
Each activity is decomposed into a sequence of sub- 
activities. Each sub-activity consists of the human pose and 
its context. For the human activities, in [16] there are 
considered three possible activities: 
 
Watch TV: walk through the living room and sit 
down on the armchair (from R1) or on the sofa; 
 
Have a snack: walk through the living room and sit 
down on a chair near the dining table; 
 
Read a book: walk through the room, go to the 
bookshelf and sit down on the armchair (from R2). 
A set of successive sub-activities are assembled in an 
activity using a stochastic context-free grammar.  
IV. 
EMERGENCIES DETECTION  IN HUMAN ACTIVITY 
RECOGNITION 
Activities of Daily Living (ADL) have some general 
characteristics: (i) they are composed of component sub-
activities (for example for preparing a meal somebody takes 
the ingredients and then will cook it); (ii) they are performed 
in specific circumstances (in a specific environment with 
specific objects for specific purposes) (for example people 
go to bed in a bedroom at a specific time or meals are made 
in a kitchen with a cooker) and (iii) people have different 
lifestyles. Thus activity recognition must be used together 
with an emergency detection technique. For this purpose the 
activity recognition technique must be used together with the 
daily programme of the supervised person which will be 
inferred with an emergency detection mechanism. 
Emergencies detection in activity recognition implies (i) 
activity recognition based on a model for activities and 
second (ii) emergency detection inferring the detected 
activity together with the general daily programme of the 
supervised person. Thus it is necessary to have a model for 
activities such that it can be easy to detect some 
abnormalities in the daily programme of the supervised 
person. 
In this paper, four types of daily activities abnormalities 
are considered:  
 
Activities with a longer duration than usual, which 
will generate a duration emergency; 
 
Activities which are performed in a wrong place, 
which will generate a context emergency; 
 
Activities which are performed at an unusual time of 
the day, which will generate an unusual time 
emergency. 
sofa 
table 
door 
table 
TV set 
chair 
armchair 
chair 
bookshelf 
armchair 
R2 
R1 
R3 
 
15
AMBIENT 2011 : The First International Conference on Ambient Computing, Applications, Services and Technologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-170-0

 
Activities which are performed in an unnatural order, 
which will generate an unnatural order emergency. 
In all the above cases, we can have a high or a low 
emergency. 
The majority of the methods for human activity 
recognition are based on a set of rules for discovering 
activities. These rules are modeled as Bayesian networks or 
stochastic context-free grammars, as described in Section II. 
In these cases the time of the day, the place or the order of 
the activities are ignored. In [10], the duration of an activity 
is also taken into account, leading to an activity model based 
on dynamic Bayesian networks. In this case, the modeling of 
the four abnormalities described above: (duration, place, 
time of the day and order of activities) is done with a 
stochastic context-free grammar with an attribute for activity 
recognition, plus an activity ontology. The attribute from the 
grammar will keep the duration for the recognized sub-
activity/activity. The normal duration, the time of the day, 
place and activity order are modeled by the activity ontology 
(the daily programme ontology). 
The use cases described in [18] are used for 
abnormalities modeling. Mary is an old woman who is living 
alone in the smart environment. The following examples are 
considered: 
a) Reading a book: Mary is going to the bookshelf. 
She is taking a book, then she is walking to the armchair. 
But after that she will be walking through the room for a 
long time. This situation is a low emergency and the smart 
environment will alert Mary that she wants to read a book 
and she will go to the armchair which is near the bookshelf 
and sit down.  
b) Resting on the sofa: Mary is resting on a sofa for a 
period which is longer than usual. In this situation for the 
beginning it is a low emergency and the smart environment 
will alert Mary to stand up. If Mary doesn’t stand up, the 
emergency will become a high emergency and the smart 
environment will send a message to the call center to 
intervene.  
c) Lying down on the floor: Mary is lying down on the 
floor in the middle of R2 zone. In this situation it is a low 
emergency and the smart environment will alert Mary that 
she must wake up. If she will remain lying down on the 
floor the emergency will became high and the smart 
environment will send a message to the call center. 
d) Having a nap after the breakfast in the morning: 
Mary just finished her breakfast and she went to the 
bedroom and fell asleep. This is unusual, because after she 
finished her breakfast she made a phone call with her friend. 
In this situation, initially  a low emergency is triggered and 
the smart environment will alert Mary that she must wake 
up. If she will remain falling asleep the emergency will 
became high and the smart environment will send a message 
to the call center. 
For doing this it is necessary to modify the model for 
activity recognition so that the duration of a sub-activity/an 
activity can be determined. Thus the stochastic context-free 
grammar used for activity recognition in [16] will be 
modified in a stochastic context-free grammar with an 
attribute. The attribute associated with the grammar will 
model the duration of each sub-activity / activity. The normal 
duration of a sub-activity, the place in which an activity is 
performed, time of the day at which each activity is realized 
and the acceptable sequence of activities form the daily 
programme of the supervised person. The daily programme 
of each supervised person is modeled in a domain activity 
ontology. A domain activity ontology for some activities of 
daily living was created. The daily programme of each 
supervised person will be an instance from this ontology. 
The conceptual activity model of the ontology is described in 
Figure 3. 
 
Figure 3.  The conceptual activity model from the daily programme 
ontology 
Each activity is described by a number of properties: (a) Sub-
activity: some activities are composed of a set of component 
sub-activities (for example the reading activity is composed 
of: walking – going to the bookshelf, taking the book and 
then walking again – to sit on the armchair); (b) Super-
activity: each activity may be part of other activity (for 
example walking is part of the reading activity or of the 
resting activity); (c) Context: each activity is performed at a 
specific location (context) (for example the resting activity is 
performed on the sofa in the living room or on the bed in the 
bedroom); (d) Duration: each activity has a normal duration; 
(e) Time: each activity is performed at a specific time of the 
day; (f) Goal: each activity has a specific goal; (g) 
Resources: some activities need a set of resources (for 
example the reading activity requires a book taken from the 
bookshelf); (h) Dependence: each activity is made after 
another activity or after a set of activities (for example 
resting takes place after lunch). 
The activity recognition and emergency detection can be 
described as in Figure 4. As described in Section III, first the 
context of the supervised person has been identified using 
the context domain ontology; then the human pose is 
estimated using a stochastic context-free grammar (SCFG) 
combined with an and-or graph which describes a set of 
known human poses. The identified context and the human 
pose form a sub-activity. Successive sub-activities will be 
assembled in a known activity by parsing in a stochastic 
context-free-grammar with an attribute (ASCFG). The 
ASCFG is obtained from the stochastic context-free 
last
Activity 
sub  
activity 
Duration 
Activity 
super  
activity 
Activity 
require 
Resources 
Time 
at time 
location 
Context 
Goal 
achieve 
Activity 
depend on 
16
AMBIENT 2011 : The First International Conference on Ambient Computing, Applications, Services and Technologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-170-0

grammar used in [16] for activity recognition in which is 
added an attribute for the duration for each sub-activity.  
 
Figure 4.  The general structure of the proposed model for the activity recognition- emergency detection 
A part of the productions of the stochastic context-free 
grammar with attributes for the reading activity from the R2 
zone is described in Figure 5: 
 
The rule (1) of the grammar consists of the three 
analyzed activities: reading, having a snack and 
watching TV. The duration of the activity is the 
duration of one of the possible activities.  
 
The rest of the rules (2) – (7) represents the rules for 
the reading activity.  
 
Figure 5.  The stochastic context-free grammar with attributes for emergency detection in human activity recognition 
 
Rule (2) means that the reading activity is composed 
by two sub-activities: walking in the room in zone 
R2 (Walking) and standing in zone R2 near the 
bookshelf (R2_Standing_Bookshelf). The duration 
for the reading activity will be the sum of the 
duration of the two component sub-activities. 
 
The walking sub-activity (the rule (3)) is composed 
by a sequence of pairs (context: R2, human pose: 
standing). Also the duration of the walking sub-
activity is the sum of the duration of the component 
sub-activities. The duration of a sub-activity 
composed by context R2 and human pose standing is 
1 unit (the same in case of rule (7)).  
 
The rule (4) describes the standing near the 
bookshelf sub-activity, which means taking a book 
from the bookshelf (context: R2, near the bookshelf 
and the human pose: standing) followed by the one 
of the two sub-activities: walking (R2_Walking) or 
sitting in the armchair (R2_Sitting). The duration of 
this sub-activity is the duration of walking or sitting 
sub-activity.  
 
The 
walking 
sub-activity 
used 
for 
R2_Standing_Bookshelf (the rule (5)) is a little 
different of the walking sub-activity from rule (3). 
The rule R2_Walking is composed by a sequence of 
walking sub-activities, which must end with the 
sitting in the armchair (rule (6)). The duration for 
rule (6) is considered 1 unit as in case of the rule (7). 
Each production rule has associated a probability. 
The sum of the production probabilities for each 
non-terminal is one.  
The context ontology together with the daily programme 
ontology is integrated in the same ontology, named Home 
Medical HealthCare Ontology. Figure 6 presents a part of the 
ontology: (i) The context ontology (describes the living room 
presented in Figure 2 with 3 zones and some furniture 
objects); (ii) The daily programme ontology (the properties 
for several activities: walking, reading, resting and having a 
snack for a daily programme of a supervised person).  
For the moment all the emergency situations have the 
same level of alert. The model does not distinguish between 
a low and a high emergency situation. 
The parsing process consists of the bottom-up 
construction of the parse tree. Each sub-activity (which 
represents an internal node in the parse tree) will be inferred 
with the daily programme ontology in order to detect 
emergencies. Also this ontology will be used together with 
each recognized activity for verifying if an emergency is 
produced. In the case of a recognized activity the daily 
programme ontology is used together with the time of the 
day for verifying if an emergency appears. The context is 
inferred with each human pose in order to detect a 
(1) Start  Reading0.333  | HaveSnack0.333  | WatchTV0.333
Start.duration = Reading.duration 
(2) Reading  
 Walking R2_Standing_Bookshelf 1.0 
Reading.duration =  
           Walking.duration + R2_Standing_Bookshelf.duration 
(3) Walking 
  
             R2_Standing Walking 0.5 | R2 Standing 0.5 
Walking.duration =  
           R2_Standing.duration + Walking.duration | 1 
(4) R2_Standing_BookShelf   
             R2 Standing Bookshelf Walking0.5 |  
             R2 Standing Bookshelf R2_Sitting0.5 
R2_Standing_BookShelf.duration =  
            R2_Walking.duration | R2_Sitting.duration 
(5) R2_Walking 
 R2_Standing R2_Walking 0.5 |  
             R2 _Sitting 0.5 
R2_Walking.duration =  
            R2_Walking.duration + 1 | R2_Sitting.duration  
(6) R2_Sitting  
 R2 Sitting Armchair 1.0 
R2_Sitting.duration = 1 
(7) R2 Standing  
 R2 Standing 1.0 
R2 Standing.duration = 1
context  
ontology 
Human pose 
identification 
Activity 
Context 
identification 
context 
pose 
Sub-activity identification 
Parsing activity 
daily programme 
ontology
Context emergency 
time of the day 
ASCFG for 
 activity recognition 
Unnatural order emergency 
Duration emergency 
Duration emergency 
Unusual time emergency 
SCFG for  
human pose 
17
AMBIENT 2011 : The First International Conference on Ambient Computing, Applications, Services and Technologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-170-0

corresponding emergency, too. If a long duration for the 
activity/sub-activity, a wrong context, an unusual time of the 
day for the detected activity/sub-activity or activities 
conducted in unnatural model are detected, a corresponding 
message will be generated. 
 
 
Figure 6.   A part of the home medical HealthCare ontology
For example, we consider a set of observations: R2 
Standing R2 Standing R2 Standing R2 Standing R2 Standing 
Bookshelf R2 Sitting Armchair. For this situation the bottom 
up parsing tree is represented in Figure 7.  
 
Figure 7.  Example of a parsing tree for activity recognition 
The emergency detection is checked in the obtained 
parsing tree: 
 
Internal nodes whose children are leaves in the tree 
are first checked by the relation between context and 
pose; this verification is made in the daily 
programme ontology based on the location of the 
sub-activity corresponding to the internal node; in 
case of a mismatch a context emergency is 
generated. For example we have a context 
emergency if there is a node with its children R2 
Lying (lying on the floor in R2 zone). In the example 
from Figure 7 there is no context emergency. 
 
Internal nodes are checked for the duration of the 
corresponding sub-activity or activity. This is made 
using the daily programme ontology based on the 
duration of an activity. For example, the double 
circled node Walking from Figure 7 is verified by its 
corresponding duration. If its duration is longer than 
a normal value for the Walking sub-activity (the 
normal duration of the Walking activity is obtained 
from the daily programme ontology), a duration 
emergency will be generated. 
 
The root node is checked by the time of the day in 
the ontology. If an activity is identified at an unusual 
time an unusual emergency will be generated. Also 
the activity is checked by dependent activities. If an 
unusual order of the activities is detected, an 
unnatural order emergency will be generated.  
V. 
TESTING THE MODEL 
The proposed system was evaluated in a simulated 
environment. The room is modeled in 3D using 3D modeling 
software, OpenGL. The supervised human is also modeled 
using the same tools. Using a 3D modeling tool (the Blender 
3D software in this case), we generated the camera and 
subject 3D models. Then, a few 3D key frames have been 
created, representing the person’s key activities (e.g., 
walking in the room, standing by the table, sitting by the 
table, etc). Finally, the intermediate 3D positions have been 
generated using the interpolating functionality available in 
the tool. In this simulated environment there is no 
supervising camera or sensors (depth or movement sensors). 
In fact, the 3D scene is providing the very same essential 
information as the image annotation component. The 
Reading 
R2_Standing_Bookshelf 
Walking 
R2_Standing 
Walking 
R2 
Standing 
R2_Standing 
Walking 
R2 
Standing 
R2 
Standing 
R2_Sitting 
R2 
Sitting 
Armchair 
R2 
Standing 
is-a 
is-a 
Thing 
Rooms 
Furniture 
Living 
Room 
is-a 
is-a 
is-a
R1 
R2 
R3 
is-a 
is-a 
is-a 
TV set 
bookshelf 
armchair 
is-a 
is-a 
is-a 
is-a 
is-a 
is-a 
is-a 
is-a 
Zones 
Activities 
is-a 
Walking 
Reading 
Resting 
Have a 
snack 
is-a 
is-a 
is-a 
is-a 
is-part-of 
is-part-of 
precede 
precede 
18
AMBIENT 2011 : The First International Conference on Ambient Computing, Applications, Services and Technologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-170-0

viewing angle associated with the camera, the depth sensor 
or with the movement sensor is simulated by the field of 
view of the viewing frustum. The depth values obtained from 
the depth sensors are simulated by the distances between 
each object (furniture object or person) and the position of 
the camera from the scene. The daily programme ontology is 
developed in Protégé using OWL. Testing has been 
performed for the three activities described in Section III 
(reading, watching TV and having a snack) for which the 
three emergencies described above: context, duration and 
time of the day will be simulated. The results have been 
evaluated using the precision and recall metrics (precision 
indicates accuracy and recall indicates the robustness). The 
average values for precision and recall for emergencies 
detection are about 91.75%, respectively 95.65%, which 
indicates a good accuracy for the proposed model. 
VI. 
CONCLUSION AND FUTURE WORK 
The paper presented a model for daily activity 
recognition and emergency detection in a smart environment. 
The recognition process uses a context ontology (for the 
person’s context identification) together with a stochastic 
context-free grammar (for human pose recognition). A 
stochastic context- free grammar with an attribute is used for 
modeling 
emergencies 
detection 
in 
human 
activity 
recognition. The attribute grammar is used for modeling the 
duration of an activity. The duration of an activity together 
with the context in which the activity is performed and the 
time of the day when the activity is produced are used for 
inferring with the daily programme ontology for detecting 
emergencies. Based on the promising results obtained in case 
of this simulated environment, the system will be tested in a 
real smart environment, in which images from the 
supervising cameras and a set of collected data from a depth 
sensor and a movement sensor will be used.  We also plan to 
extend the grammar used for activity recognition to represent 
a larger set of activities. Also the emergency detection model 
will be improved with a degree of emergency associated with 
each such situation. Another development will have as a 
purpose the recognition of interleaved human activities. In 
this case the parsing of an activity will be made by 
identifying a list of sub-trees in the parsing tree from the 
grammar. The obtained sub-trees will be connected in a 
single tree by common nodes. 
ACKNOWLEDGMENT 
The work has been co-founded by the Sectoral 
Operational Programme Human Resources Development 
2007-2013 of the Romanian Ministry of Labour, Family and 
Social 
Protection 
through 
the 
financial 
Agreement 
POSDRU/89/1.5/S/62557. 
REFERENCES 
[1] L. 
Chen 
and 
C. 
Nugent, 
“Ontology-based 
Activity 
Recognition in Intelligent Pervasive Environments,” IJWIS, 
vol. 5 no. 4, 2009, pp. 410-430. 
[2] L. Fiore, D. Fehr, R. Bodor, A. Drenner, G. Somasundaram, 
and G. Papanikolopoulos, “Multi-Camera Human Activity 
Monitoring,“ Journal of Intelligent and Robotic Systems, vol. 
52, no. 1, 2008, pp. 5-43. 
[3] J. Parkka, M. Ermes, P. Korpipaa, J. Mantyjarvi, J. Peltola, 
and I. Korhonen, “Activity classification using realistic data 
from wearable sensors,”, IEEE Transactions on Information 
Technology in Biomedicine, vol. 10, no. 1, 2006, pp. 119-
128. 
[4] J. Yamato, J. Ohaya, and K. Ishii, “ Recognizing human 
action in time-sequential images using hidden markov 
model,” Computer Vision and Pattern Recognition, 1992, pp. 
379-385. 
[5] D. Zhang, D. Perez, and I. McCowan, “Semi-supervised 
adapted hmms for unusual event detection,” Computer Vision 
and Pattern Recognition, vol. 1, 2005, pp. 611-618. 
[6] C. Vogler and D. Metaxas, “A framework for recognizing the 
simultaneous aspects of American sigh language,” Computer 
Vision and Image Understanding, vol.  81, no. 3, 2001, pp. 
358-384. 
[7] H. Iwaki, G. Srivastava, A. Kosaka, J. Park, and A. Kah, “A 
Novel Evidence Accumulation Framework for Robust Multi-
Camera 
Person 
Detection,” 
ACM/IEEE 
International 
Conference on Distributed Smart Cameras, vol. 108, 2008, 
pp. 117-124. 
[8] D. L. Vail, M. M. Veloso, and J. D. Lafferty, “Conditional 
random fields for activity recognition,” International 
Conference on Intelligent Robots and Systems, 2007, pp. 
3379-3384. 
[9] P. Turaga, R. Chellappa, V. S. Subrahmanian, and O. Udrea, 
“Machine Recognition of Human Activities: A Survey,” IEEE 
Transactions on Circuits and System for Video Technology, 
vol.  18, no. 11, 2008, pp. 1473 – 1488. 
[10] Z. Zeng and Q. Ji, “Knowledge Based Activity Recognition 
with Dynamic Bayesian Network,” Springer-Verlag, 2010, 
pp.532-546. 
[11] M. S. Ryoo and J.K. Agarwal, “Recognition of Composite 
Human Activities through Context-Free Grammar based 
Representation,” IEEE Conference on Computer Vision and 
Pattern 
Recognition, 
2006, 
pp. 
1709-1718, 
doi>10.1109/CVPR.2006.242. 
[12] Y. A. Ivanov and A. F. Bobick, “Recognition of Visual 
Activities and Interactions by Stochastic Parsing, IEEE 
Transactions on Pattern Analysis and Machine Intelligence,  
vol. 22, no. 8, 2000, pp. 852-872. 
[13] D. Lymberopoulos, A. Barton-Sweeney, and A. Savvides, 
“An Easy-to-Program Sensor System for Parsing Out Human 
Activities,”  IEEE INFOCOM, 2009, pp. 900-908. 
[14] S. W. Joo and R. Chellappa, “Recognition of Multi-Object 
Events Using Attribute Grammars,” IEEE International 
Conference on Image Processing, 2006, pp. 2897-2900. 
[15] S. Mocanu, I. Mocanu, S. Anton, and C. Munteanu, 
“AmIHomCare: a complex ambient intelligent system for 
home medical assistance,” The 10th International Conference 
on Applied Computer and Applied Computational Science 
(ACACOS’11), 2011, pp. 181-186. 
[16] I. Mocanu and A.-M. Florea, “A Multi-Agent System for 
Human  Activity Recognition in Smart Environments,” 
unpublished. 
[17] I. Mocanu, “From content-based image retrieval by shape to 
image annotation”, Advances in Electrical and Computer 
Engineering, vol. 10, no. 4, 2010, pp. 49-56, doi 
10.4316/AECE.2010.04008.  
[18] P. Lyons, A. T. Cong, H. J. Steinhauer, S. Marsland, J. 
Dietrich, and H. W. Guesgen, „Exploring the responsibilities 
of single-inhabitant Smart Homes with Use Cases,“ Journal of 
Ambient Intelligence and Smart Environments, vol. 2, no. 3, 
2011, pp. 211-232, doi 10.3233/AIS-2010-0076.  
19
AMBIENT 2011 : The First International Conference on Ambient Computing, Applications, Services and Technologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-170-0

