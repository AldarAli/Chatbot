CalliSmart: an Adaptive Informed Environment for Intelligent Calligraphy Training
R´emy Frenoy∗, Indira Thouvenin∗, Yann Soullard∗, Olivier Gapenne†
∗Sorbonne University, Universit´e de technologie de Compi`egne, CNRS UMR 7253 Heudiasyc
CS 60 319 - 60 203 Compi`egne cedex
†Sorbonne University, Universit´e de technologie de Compi`egne, CNRS UMR 7338 Biomechanics and Bioengineering
CS 60 319 - 60 203 Compi`egne cedex
Emails: {remy.frenoy — indira.thouvenin — yann.soullard — olivier.gapenne}@utc.fr
Abstract—Gesture learning is a complex and multistep process
where trainees are supposed to improve several psychomotor and
cognitive skills. According to numerous studies, trainees need to
be provided with various types of feedback to improve these skills.
These studies also highlight that beneﬁts of a given type of feed-
back depend on trainees situation. Therefore, feedback must be
chosen according to an analysis of trainees activity. Sensorimotor
approaches have investigated the impact of feedback on speciﬁc
learning situations, but the analysis of gestural activity, which
would allow the automatic selection of an appropriate type of
feedback, is still a recurring issue. In this paper, we propose a new
model for gestural training systems based on smart interaction.
This model relies on a recognition module based on Naive Bayes
classiﬁers, representing trainees activity by a vector describing
their errors, and representing training environments by vectors
describing their set of implemented types of feedback. We present
a platform for calligraphy training we designed and developed
based on our model. Through a user study, we emphasize the
beneﬁts of our approach on trainees development.
Keywords–Training Systems, Interactive systems, Adaptive Sys-
tems, Gesture Recognition.
I.
INTRODUCTION
Gestural training systems have been studied in various
research ﬁelds, which can be divided into two families: sen-
sorimotor approaches and modeling approaches. Sensorimotor
approaches focus on the impact of providing a speciﬁc type
of feedback on trainees activity. Virtual training environments
belong to these approaches, and enhance training by providing
real-time 3D feedback. Such systems have been used for dif-
ferent kinds of gestures, such as welding gestures [1], obstetric
gestures [2], or pottery gestures [3]. Haptic systems are also
part of sensorimotor approaches, as they investigate trainees
kinesthetic memory [4] by adding proprioceptive cues during
visuo-motor learning tasks [5]. These systems have proven to
beneﬁt motor skill training, including within the context of
handwriting [6]. Although these ﬁelds focus on the impact of
providing a speciﬁc type of feedback in a given context, they
do not question the issue of modeling gestural activity, nor
the issue of adapting feedback according to this model. Yet
results have shown the beneﬁts of providing diversiﬁed [7]
and personalized [8] feedback on the learning experience.
Intelligent tutoring systems are part of modeling ap-
proaches. A key feature of these systems is the adaptation of
learning content and difﬁculty level to the trainee. This adapta-
tion requires an accurate student model [9] which allows for in-
dividualization [10]. These systems process interpretable data
(results from a form, answer to a multiple-choice question).
Such systems do not capture motor skills, which necessitates
the use of sensors and results in huge amount of data which
need to be processed to become interpretable. Furthermore, al-
though intelligent tutoring systems model students knowledge,
very few studies have tackled the issue of modeling gestural
activity.
Calligraphy training is an interesting case study. When
trainees learn calligraphy with a human teacher, the teacher
analyzes trainees gestural and cognitive activity. The teacher
also analyzes trainees drawing to identify patterns of error.
From this analysis, the teacher can provide various guidance
by giving verbal advice and focusing trainees attention on
speciﬁc characteristics, or demonstrating the gestures. With
such training, trainees build a knowledge based on their
experience and the kinesthetic memory of the gestures, leading
them to the acquisition of control and regularity, which are
essential skills to produce calligraphy. We believe that being
able to model users activity from sensor data, so that systems
adapt according to this model, would enhance trainees gestural
learning experience. Therefore, our goal is to model and link
highly variable sensor data representing trainees performances
over training time, and training environments containing their
set of implemented types of feedback.
This paper proposes CalliSmart, an intelligent interactive
system with gestural input, relying on a framework which
makes it possible to place trainees in a representation space,
from which it is possible to analyze the evolution of their
performances. By placing feedback types in this representation
space depending on their relevance in a given situation, the
system provides appropriate types of feedback to trainees ac-
cording to their activity. The paper is structured as follows: the
next section present an overview of related studies. Section III
introduces our interaction model. Experiments are presented in
Section IV, and results are exhibited in Section V. Finally, we
discuss these results and introduce future works in Section VI.
II.
RELATED WORK
This section introduces several studies investigating the
process of gesture learning, and the impact of feedback on
this process. As these studies advocate to provide a diversity
of feedback, research works on learning modeling and gesture
recognition are then presented.
A. Gesture learning
Trainees learn gestures through different steps, each step
involving cognitive, psychomotor or biophysical skills [4],
[11]. In each of these steps, trainees build very speciﬁc gestural
and kinesthetic abilities, and focus on very different parts of
their activity (Figure 1).
132
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

Figure 1. The three steps of motor skill learning, inspired from [11].
Although some questions still have to be answered, most
learning strategies advocate to give very simple and precise in-
formation to trainees in the cognitive step, trainees in this early
stage of learning being very prone to suffer from cognitive
overload. In the associative step, trainees need very speciﬁc
feedback to understand their errors and correct them. They
can also beneﬁt from knowledge of performance feedback (KP
feedback). Finally, in the autonomous step, trainees barely need
feedback, but can beneﬁt from knowledge of results feedback
(KR feedback). Hence, it is the variety of (appropriate) types of
feedback which helps trainees during their learning process by
enhancing their perception of their performance. This variety
is also essential to avoid the syndrome of dependence to the
teacher [12], where trainees improve their performances on a
training system but are unable to transfer these improvements
in a real environment.
B. Intelligent tutoring systems
Providing a variety of feedback types is a concern tackled
by Intelligent tutoring systems (ITS). ITS aim at modeling
the students activity by collecting knowledge about them.
Knowledge represented in these models can include students
skills, affect, experience, or stereotypes [13]. From these
models, ITS can analyze how trainees develop over time, and
use this knowledge to determine the most efﬁcient training
situation. To build and update these models, ITS use cognitive
techniques (model-tracing, constraint-based), or artiﬁcial in-
telligence techniques (formal logic, expert-systems, planning,
Bayesian belief networks). From a student representation,
ITS can provide various types of feedback by following a
learning strategy. The main learning strategies either follow
the behaviorist approach, which considers learning as a set of
modiﬁcations directly correlated with trainees actions within
the learning environment; the cognitive approach, which claims
that unobservable and internal constructs (perception, moti-
vation) inﬂuence the learning process; or the constructivist
approach, which holds that individuals construct the world in
their own way, implicating that training should be focused on
the student activity more than on training monolithic strategies.
ITS acquire interpretable data: a score from a test, an
answer to a multiple choice quiz. Thus, ITS cannot deal with
sensor data, as they are not explicit enough to be used directly.
Modeling gestural activity in the same fashion ITS model
students knowledge necessitates a recognition process to make
gestural data acquired from sensors interpretable.
C. Recognition
Research in gesture recognition has been growing to look
for the best way to make sense of sensor data. The most pop-
ular approaches [14] either rely on matching-based strategies
(Dynamic Time Warping, k-Nearest Neighbors), which com-
pute a distance between the data to label and labeled data from
a training database; or on learning models (Markovian models,
Support Vector Machines, Naive Bayes Classiﬁers), which are
optimized to model or discriminate training examples from
different classes. Such methods have numerous applications,
from intelligent training [15], to gestural training [3], or
human-robot collaboration on assembly lines [16]. A recurrent
issue when dealing with the recognition of gestural or cognitive
activity is the issue of multilabeling, when a data sample can
be labeled not only with one label, but possibly with a set of
labels [17]. The existing methods for multilabel classiﬁcation
can be divided into two main categories: the problem trans-
formation methods, which transform a multilabel classiﬁcation
problem into one or more single-label classiﬁcation problem,
and the algorithm adaptation methods, which extend speciﬁc
learning algorithms to directly handle multilabel data [18].
Within the context of gestural training, multilabel recognition
makes it possible to detect several patterns of error at once,
and hence to consider every aspects of trainees performance
when determining which types of feedback to provide.
D. Feedback
Numerous research projects have investigated the impact
of feedback which should, no matter whether it is delivered
by a teacher or a computer, “enhance learning, performance,
or both, engendering the formation of accurate, targeted con-
ceptualizations and skills” [19]. With the possibilities brought
by the emergence of tablets and haptic devices, feedback
has been studied through its sensory modalities (visual, au-
dio, visuo-haptic), certain modalities being more appropriate
than others depending on the context [20]. Temporal features
(static or dynamic feedback, temporal information) are also
determinant, studies showing that changing feedback temporal
features make trainees develop different components of their
gestures [21]. If some conﬁgurations have proven to be more
or less effective than others depending on the training situation,
it appears that each conﬁguration has its advantages and
drawbacks, depending upon the learning situation and trainees
abilities [19], [22].
III.
INTERACTION MODELING
Providing a variety of appropriate feedback types through-
out the learning enhance trainees learning [22]. A fundamental
issue when creating a gesture training system is therefore to
decide which type of feedback to provide in order to maximize
the beneﬁts for trainees learning. This issue can be split into
four issues: 1) The recognition and modeling of gestural and
cognitive activity. 2) The deﬁnition of a set of feedback types
the system can provide. 3)The selection of the type of feedback
to provide depending upon the situation. 4) The evaluation of
trainees learning throughout the training process.
To tackle these issues, the activity ﬁrst have to be cap-
tured. Then, the acquired data must be recognized and a
representation model of trainees learning state must be built.
Finally, various types of feedback have to be designed and
implemented. Depending on the modeled learning state, a
133
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

subset of feedback types is selected. This subset must be well-
chosen (appropriate according to trainees learning state) to
make them improve their skills (Figure 2).
Figure 2. The CalliSmart process for smart Human-Computer gestural
interaction, within the context of calligraphy training.
A. Capturing calligraphy features
Van Galen [23] deﬁnes handwriting as a “multi-component
task implying cognitive, psycho-motor and biophysical pro-
cesses”. Handwriting is a motor gesture, where performers
constantly analyze and modify their movements from their
perception of their current actions, and their internal repre-
sentation of the “ideal” actions. Furthermore, writers not only
react to their actions, but also have a spatial and temporal
representation of the shape they intend to draw. These rep-
resentations imply a principle of anticipation, which means
that performers have, besides modifying in real-time their
movements according to their perception, to anticipate their
future movements. Thus, learning handwriting necessitates
having a cognitive representation of the shape to draw, and a
perception of the different steps necessary in order to construct
this shape (acceleration, angle, curve). It is also essential to
spatially visualize the location of the current drawn shape, by
comparison with locations of the previous shapes and the next
ones which will be drawn (principle of anticipation, Figure 3).
In calligraphy, the goal is to analyze trainees performances
according to two main criteria, which are the regularity and the
visuo-spatial attention. Relying on these criteria, we propose
to analyze trainees activity from identiﬁed types of errors. For
each of them, we compute the probability of having the type
of error given the trainee’s performance. Trainees performance
can be modeled by the vector ⃗U = {x1, x2, x3, , xn} where n
is the number of patterns, and xi corresponds to the probability
of having the pattern i. Each pattern being a pattern of error,
⃗U = ⃗0 refers to an expert, and ⃗U = {1, 1, 1, , 1} refers to an
absolute novice.
B. Interaction modeling
Three phases of interaction can be distinguished from the
process illustrated in Figure 2:
•
The trainee performing on the system. (A)
•
The system providing feedback to the trainee. (B)
•
The trainee making changes/adjustments throughout
the process of interaction. (C)
We propose a space of representation S which aims at
representing these processes. First, (A) is modeled by the
vector ⃗U as previously explained. Each type of feedback
implemented in the system is represented in S by a vector
⃗F
=
{y1, y2, y3, , yn}, where n is the number of error
criteria and yi is the level of the ith error criteria for which
feedback type F is the most relevant. Hence, F is considered
optimal in the situation ⃗U = ⃗F (B). Each coordinate of ⃗F
is empirical and come from an expertise: the expert studies
each type of feedback and decide in which situation it should
be provided. Changes in trainees activity (C) can be tracked
through transition vectors ⃗Tri = ⃗Ui − ⃗Ui−j, 1 ≤ j ≤ i ≤ n,
n being the number of recorded performances for the studied
trainee.
C. Decision
In our approach, ⃗U represents the performance of a trainee,
and each vector ⃗Fi represents an element in the set F of
implemented feedback types. According to the representation,
the most appropriate feedback type is the one represented by
the closest vector to the current position of the user. Let ⃗Fa
be the most appropriate type of feedback in the situation ⃗Ut,
⃗Fa = argmin
⃗Fi∈F
(||⃗Ut − ⃗Fi||p)
(1)
IV.
EXPERIMENTS
By analyzing trainees performances throughout several
exercises, it is possible to investigate the inﬂuence of providing
various types of feedback on the evolution of their perfor-
mances, and hence on their progression. Experiments should
determine whether 1) providing feedback will improve the
learning process, and whether 2) providing feedback will re-
duce the variance between performances by enforcing trainees
attention on the task.
Within the process of calligraphy learning, a famous ex-
ercise is the “minimum” exercise (Figure 3). It is used to
train regularity and visuo-spatial attention by asking trainees
to repeat a similar pattern. On a perfectly executed exercise,
white spaces between elements should have the same area, and
elements should have the same shape in term of slope and size.
Figure 3. The “minimum” exercise in calligraphy.
The experiment focuses on the strait vertical lines of the
minimum exercise. Participants are asked to produce a series
of straight lines using a Wacom Cintiq tablet (Figure 4), with
the same obligations than in the minimum exercise: spaces
between lines should be regular, lines should be straight and
vertical. Staves are displayed to limit the calligraphy area. This
exercise exhibits the main features constituting the cognitive
and psycho-motor processes surrounding calligraphy and the
drawing of the “minimum” word.
134
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

Figure 4. The CalliSmart platform.
A. Recognition
A database was created to train the recognition module.
46 participants were involved in the creation of the database.
They had none to very little experience using a graphic table or
practicing calligraphy. Each participant was asked to perform
a series of three exercises, an exercise being a sequence
of 10 to 15 strokes. Experts classiﬁed and labeled these
exercises by examining both the gestures (participants were
video recorded) and the results (screenshots were taken at the
end of each exercise). Labels identify three patterns of error:
slope error, size error, and regularity errors (irregular spaces
between strokes). Several errors potentially appearing on a
single exercise, the recognition of an exercise is a multilabel
problem. The acquired database contains 138 examples labeled
by two experts. Examples are unequally distributed among
error classes, as some patterns appeared more often than
others. The training database has been built using a subset
of the 138 acquired examples, making balanced the number of
error patterns. The ﬁnal training database uses 40 examples
per error pattern. Recognition relies on four Naive Bayes
classiﬁers, one per class which are trained on examples from
the training database (one-vs.-rest strategy). A 5-fold cross-
validation was performed on the dataset. Classiﬁers used the
features described in Table I as a representation of an exercise.
Table II shows the recognition results, using classic multilabel
evaluation metrics [17]. As stated in [17], the subset accuracy
metric tends to drop fast when the number of labels grow, or
when the amount of data is small. In our context, ﬁnding the
exact combination of label is important, but not essential. The
most important feature of the recognition process is its ability
to recognize correct labels (errors trainees actually made).
Improving these results will be one of our challenges in the
future. An increase in the amount of training data and the use
of a discriminative model may lead to an improvement of the
results.
B. User study
1) Participants: A total of 28 people participated in the
study. Participants were people working at the university,
students in computer science, design and mechanics, with no
to very little expertise in calligraphy. They were randomly and
evenly distributed into the two experiment conditions described
below.
2) Experimental procedure: The ﬁrst group (no feedback
group) did not receive any feedback. The second group
(feedback group) received feedback from the following set
of implemented types of feedback: 1) Real-time feedback
assists trainees by making them focus on a speciﬁc category.
“Regularity” feedback displays where trainees should begin
their next stroke (Figure 5a); “slope” feedback colors the stroke
with a color from green to red depending on the slope (Figure
5b); “size” feedback highlights with a different color the limits
of the drawing space (Figure 5c). Trainees can be assisted
with every combination of feedback types, depending on the
recognition of their activity. 2) Knowledge of results feedback
(Figure 6), indicates the level of the trainee in each category
(“r”, “v”, “l”). KR feedback is always displayed.
(a)
(b)
(c)
Figure 5. Real-time feedback aiming at assisting trainees with regularity,
size, or slope error.
Figure 6. KR feedback providing trainees with explicit indications regarding
their performance.
Feedback was chosen depending on trainees activity during
a whole exercise. Hence, feedback depends on the previous
exercise and cannot change until the end of the current
exercise. Each participant was asked to perform a series of
six exercises, an exercise being itself a series of 10 to 15 lines
to draw. The ﬁrst series was not saved and allowed trainees
to familiarize with the platform. For the feedback group, the
system used this ﬁrst series to decide which feedback types to
provide during the ﬁrst recorded series. Our hypothesis are:
•
H1 Participants in the feedback group will improve
better than participants in the no feedback group.
•
H2 Variance between participants will be lower in the
feedback group than in the no feedback group.
At the end of the ﬁfth series, we asked participants to perform
a last series. This series was performed without any feedback
from the system for the two groups, to compare their perfor-
mances in the same conditions. This last experiment should
test our third hypothesis:
•
H3 Participants in the feedback group will outperform
participants in the no feedback group in real condi-
tions.
V.
RESULTS
To evaluate participants performances, a dataset of expert
performances was created, gathering 22 exercises performed
by three different people. The same representation was used
in the recognition and in the evaluation processes, participants
as well as experts being represented by their feature vectors
(Table I). In a similar way of a k-Nearest Neighbors algorithm,
135
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

TABLE I. Features computed from trainees activity.
Slope error
Angle of the most sloping stroke, using real stroke coordinates.
Angle of the most sloping stroke, using linear regressions of strokes.
Regularity error
max(distance)
min(distance) , using distances between consecutive strokes.
max(area)
min(area) , using areas between linear regressions of strokes.
(max(area)−min(area))
µ(area)
, using areas between linear regressions of strokes.
Size error
Maximum difference between stroke vertical size and stave size
TABLE II. Validation results of the recognition process on multilabel data.
Recall
Precision
Hamming Loss
Subset Accuracy
Accuracy
0.79
0.83
0.70
0.55
0.72
we evaluate our method by computing the Euclidean distance
between a trainee performance and its k-closest expert repre-
sentations. Such a method reduces potential bias induced by a
parametric modeling. In our experiment, the value k is empiri-
cally set to three. We carried a Shapiro-Wilk test on the result
data, which showed that data were not normally distributed.
Therefore, we performed the non-parametric Mann-Whitney
test to conﬁrm the efﬁciency of our method.
Figure 7. Distance between trainees and expert performances over the
training iterations.
Figure 7 illustrates a signiﬁcant improvement of perfor-
mances for the feedback group, from a distance of 2.88 at the
end of the ﬁrst exercise, to 1.75 at the end of the ﬁfth exercise,
while the no feedback group only slightly improved, from
a distance of 3.20 to 3.11. A two-tailed Mann-Whitney test
was performed between the two groups for the ﬁfth exercise,
which resulted in a p-value of 0.029. We can hence conﬁrm
our ﬁrst hypothesis (H1), which is signiﬁcant at a standard
0.05 threshold. Variance between participants in the feedback
group drops over the training, which implies a convergence
of trainees performances (Figure 7). Variance between partic-
ipants in the no feedback group stays high over the exercises.
These two observations conﬁrm our second hypothesis (H2).
Results obtained in the no feedback group can be explained
by two factors: incomprehension and weariness. The task
proposed in this experiment is repetitive, and participants
in the no feedback group did not see any changes in the
training environment throughout the exercises. From the fourth
exercise, they seem to suffer from a loss of focus as they do
not see any improvement or changes that would reﬂect their
performances. Participants often asked how well they were
performing, indicating that they were seeking for information
reﬂecting their performances. People in the feedback group
could see their improvement through the KR feedback at the
end of each exercise. Moreover, a real-time feedback tailored to
the errors made in the previous exercise was provided, helping
them understand their performance, and improve on the aspects
they needed the most. Figure 8 illustrates the results of the
last exercise with participants form each groups performing
in real conditions, without feedback. We note that participants
from the feedback group outperform participants from the no
feedback group. Moreover, performances of the participants in
the feedback group only decrease from a distance of 1,75 to
the expert to a distance of 1,88 between the ﬁfth exercise (with
feedback) and the sixth exercise (in real conditions). This result
is promising, since the dependence to the teacher syndrome
tends to make performances drop signiﬁcantly when trainees
trained on aided system ﬁrst perform in real conditions. How-
ever, variance between performances in the feedback group in
the sixth exercise grows compared to variance measured in
the ﬁfth exercise. This grow in the variance is reﬂected by the
Mann-Whitney test, which results for this last exercise in a p-
value of 0.05486. Differences between our two groups on this
last exercise is hence signiﬁcant at a 0.1 threshold, but not at a
0.05 threshold. Further experiments should thus be conducted
to fully conﬁrm our third hypothesis (H3).
Figure 8. In real conditions (without any feedback), performances of
participants trained with, and without feedback.
136
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

VI.
DISCUSSION AND CONCLUSION
In this paper, we proposed a new model for gestural
training systems based on smart interaction. In opposition to
intelligent tutoring systems input data, our input data come
from sensors and are not directly interpretable. Our system re-
lies on a recognition module based on Naive Bayes classiﬁers,
which aim at recognizing pattern of errors in trainees activity.
This module provides probabilistic outputs, one per pattern of
errors, that we use to build a representation of trainees activity
in n dimensions, n being the number of possible errors. This
representation is used to determine the types of feedback to
provide to the trainee.
An experiment comparing the progression of two groups,
one with feedback and one without feedback, showed that
trainees perform better when provided with appropriate feed-
back, compared with trainees trained by practicing in real
conditions. Variance between trainees performances was also
reduced when they were provided with feedback. A last exper-
iment, where participants in the feedback group had to perform
in real conditions, showed that they still outperform trainees
from the no feedback group, and that their performances only
slightly drop from training to real conditions. These last results
should be conﬁrmed by further experiment, but seemed to
highlight the beneﬁts of our system to reduce the effects of
dependence to the teacher.
In future works, we will extend our recognition system
so that it should be able to detect a larger number of errors,
and thus have a more precise recognition of the gestures.
More types of feedback should be implemented so that the
system can choose the appropriate conﬁguration in a larger
number of possible situations. An interesting issue regarding
feedback is how well it is adapted to a situation, and to a
trainee. In intelligent tutoring systems, the pertinence of a
speciﬁc feedback type is determined empirically or from study
results. One could argue that users have their own sensitivity
and comprehension (cognitive and constructivist approaches,
see Part II-B), and that systems should be able to reconsider,
as experienced human tutors do, what they thought to be
an appropriate type of feedback. We will investigate this
issue, and examine the possibility of adding another degree
of adaptation in our interactive gestural training system. We
will also evaluate the impact of this adaptation on trainees
learning experience.
ACKNOWLEDGMENT
This work, as part of the Descript project, is supported by
the Picardy region. The authors would like to thank Patrick
Doan, Morgane Rebulard and all the participants at the ESAD
for their work on the creation of our training database, and
Florian Baune for his work on the development of the platform.
REFERENCES
[1]
L. Da Dalto, F. Benus, and O. Balet, “The use and beneﬁts of Virtual
Reality tools for the welding training,” in 63rd Annual Assembly
& International Conference of the International Institute of Welding,
Istanbul, Turkey, 2010.
[2]
R. Moreau, V. Ochoa, M. Pham, P. Boulanger, T. Redarce, and
O. Dupuis, “A method to evaluate skill transfer and acquisition of
obstetric gestures based on the curvatures analysis of the position and
the orientation,” Journal of Biomedical Informatics, vol. 41, no. 6, Dec.
2008, pp. 991–1000.
[3]
S. Manitsaris, A. Glushkova, F. Bevilacqua, and F. Moutarde, “Cap-
ture, modeling, and recognition of expert technical gestures in wheel-
throwing art of pottery,” Journal on Computing and Cultural Heritage
(JOCCH), vol. 7, no. 2, 2014, p. 10.
[4]
D. Feygin, M. Keehner, and F. Tendick, “Haptic guidance: Experimental
evaluation of a haptic training method for a perceptual motor skill,”
in Haptic Interfaces for Virtual Environment and Teleoperator Systems,
2002. HAPTICS 2002. Proceedings. 10th Symposium on. IEEE, 2002,
pp. 40–47.
[5]
J. Bluteau, S. Coquillart, Y. Payan, and E. Gentaz, “Haptic guidance
improves the visuo-manual tracking of trajectories,” PLoS One, vol. 3,
no. 3, 2008, p. e1775.
[6]
G. Srimathveeravalli and K. Thenkurussi, “Motor skill training assis-
tance using haptic attributes,” in Eurohaptics Conference, 2005 and
Symposium on Haptic Interfaces for Virtual Environment and Teleoper-
ator Systems, 2005. World Haptics 2005. First Joint, 2005, pp. 452–457.
[7]
S. R. Serge, H. A. Priest, P. J. Durlach, and C. I. Johnson, “The effects
of static and adaptive performance feedback in game-based training,”
Computers in Human Behavior, vol. 29, no. 3, May 2013, pp. 1150–
1158.
[8]
S. Narciss, S. Sosnovsky, L. Schnaubert, E. Andr`es, A. Eichelmann,
G. Goguadze, and E. Melis, “Exploring feedback and student charac-
teristics relevant for personalizing feedback strategies,” Computers &
Education, vol. 71, Feb. 2014, pp. 56–76.
[9]
T. K¨aser, S. Klingler, A. G. Schwing, and M. Gross, “Beyond knowl-
edge tracing: Modeling skill topologies with bayesian networks,” in
Intelligent Tutoring Systems.
Springer, 2014, pp. 188–198.
[10]
Y. Wang and N. T. Heffernan, “The Student Skill Model,” in Intelligent
Tutoring Systems.
Springer, 2012, pp. 399–404.
[11]
P.M. Fitts and M.I. Posner, Human performance.
Belmont, CA:
Brooks/Cole, 1967.
[12]
B. Bayart, A. Pocheville, and A. Kheddar, “An adaptive haptic guidance
software module for i-touch: example through a handwriting teaching
simulation and a 3d maze,” in Haptic Audio Visual Environments and
their Applications, 2005. IEEE International Workshop on, 2005, pp.
6–pp.
[13]
B. P. Woolf, Building intelligent interactive tutors student-centered
strategies for revolutionizing e-learning.
Amsterdam; Boston: Morgan
Kaufmann Publishers/Elsevier, 2009.
[14]
S. Mitra and T. Acharya, “Gesture Recognition: A Survey,” IEEE
Transactions on Systems, Man and Cybernetics, Part C (Applications
and Reviews), vol. 37, no. 3, May 2007, pp. 311–324.
[15]
L. Fricoteaux, I. Thouvenin, and D. Mestre, “GULLIVER: a decision-
making system based on user observation for an adaptive training in
informed virtual environments,” Engineering Applications of Artiﬁcial
Intelligence, vol. 33, 2014, pp. 47–57.
[16]
E. Coupet´e, S. Manitsaris, and F. Moutarde, “Real-time recognition
of human gestures for collaborative robots on assembly-line,” in 3rd
International Digital Human Modeling Symposium (DHM2014), 2014,
pp. 7–p.
[17]
M.-L. Zhang and Z.-H. Zhou, “A review on multi-label learning
algorithms,” Knowledge and Data Engineering, IEEE Transactions on,
vol. 26, no. 8, 2014, pp. 1819–1837.
[18]
G. Tsoumakas and I. Katakis, “Multi-label classiﬁcation: An overview,”
Dept. of Informatics, Aristotle University of Thessaloniki, Greece, 2006.
[19]
V. J. Shute, “Focus on Formative Feedback,” Review of Educational
Research, vol. 78, no. 1, Mar. 2008, pp. 153–189.
[20]
J. Danna and J. Velay, “Basic and supplementary sensory feedback in
handwriting.” Frontiers in psychology, vol. 6, no. 169, 2014.
[21]
A. Basteris, L. Bracco, and V. Sanguineti, “Robot-assisted intermanual
transfer of handwriting skills,” Human Movement Science, vol. 31,
no. 5, Oct. 2012, pp. 1175–1190.
[22]
M. M. Nelson and C. D. Schunn, “The nature of feedback: how dif-
ferent types of peer feedback affect writing performance,” Instructional
Science, vol. 37, no. 4, Jul. 2009, pp. 375–401.
[23]
G. P. van Galen, “Handwriting: Issues for a psychomotor theory,”
Human Movement Science, 1991, pp. 165–191.
137
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

