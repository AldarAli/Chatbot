On Design of Optimized Low-Density Parity-Check
Codes Starting From Random Constructions
Fred Daneshgaran
ECE Department
California State University
Los Angeles, USA
e-mail: fdanesh@calstatela.edu
Massimiliano Laddomada
EE Department
Texas A&M University-Texarkana
Texarkana, USA
e-mail: mladdomada@tamut.edu
Marina Mondin
DELEN
Politecnico di Torino
Turin, ITALY
e-mail: mondin@polito.it
Abstract—In this paper we present a novel two step design
technique for Low Density Parity Check (LDPC) codes, which,
among the others, have been exploited for performance enhance-
ment of the second generation of Digital Video Broadcasting-
Satellite (DVB-S2). In the ﬁrst step we develop an efﬁcient
algorithm for construction of quasi-random LDPC codes via
minimization of a cost function related to the distribution of the
length of cycles in the Tanner graph of the code. The cost function
aims at constructing high girth bipartite graphs with reduced
number of cycles of low length. In the second optimization
step we aim at improving the asymptotic performance of the
code via edge perturbation. The design philosophy is to avoid
asymptotically weak LDPCs that have low minimum distance
values and could potentially perform badly under iterative soft
decoding at moderate to high Signal to Noise Ratio (SNR) values.
Subsequently, we present sample results of our LDPC design
strategy, present their simulated performance over an AWGN
channel and make comparisons to some of the construction
methods presented in the literature.
Keywords-Block codes; iterative decoding; LDPC; low density
parity check codes; minimum distance; near-codeword.
I. INTRODUCTION
Low-density parity-check codes were discovered by Gal-
lager [1] in 1962 but did not receive much attention at the time
essentially for complexity reasons. In [2], Tanner resurrected
LDPCs generalizing them through the introduction of the
so-called Tanner graph. Only recently in 1999, Mackay [3]
demonstrated that LDPCs when optimally decoded are capable
of achieving information rates up to the Shannon limit.
To date, there are three main classes of LDPC constructions
that can be summarized as follows:
• Density evolution optimized LDPCs: these LDPCs are
designed by exploiting some analytic properties of the
probability density functions of the log-likelihood ratios
(LLRs) associated with both the bit and check nodes in
the Tanner graph during iterative decoding [4].
• Combinatorial and Algebraically designed LDPCs
([5]-[12]): the approach is aimed at designing well struc-
tured LDPC codes based on cyclic difference families,
afﬁne conﬁgurations, Margulis-Ramanujan algebraic de-
signs and pseudorandom constructions.
• Graph-theoretically designed LDPCs ([13]-[15]): this
class of codes make use of graph-theoretical properties
to design good LDPCs.
• Randomly designed LDPCs ([16]-[20]): this class of
codes exploits random techniques to design parity-check
matrices of good LDPCs.
In this paper we present an effective algorithm for design of
”optimized” LDPCs. The design is accomplished in two steps.
Given a speciﬁc set of values (k, n) for the LDPC code, in the
ﬁrst step the goal is to design a related Tanner graph having a
pre-speciﬁed distribution of both bit and check node degrees.
In connection with this latter point, we note that we have not
taken into account optimal degree distributions, even though
we are conscious of the fact that optimal degree sequences
have been proposed aimed at designing capacity-achieving
degree sequences for the Binary Erasure Channel (BEC). We
invite the interested reader to review [21] for a systematic
study of capacity-achieving sequences of LDPCs for the BEC.
The objective function for the ﬁrst step in our design process
is related to the cycle-distribution of the LDPC. In the second
step, we consider the problems related to trapping sets/near-
codewords/stopping sets by an indirect method. In particular,
given the very high complexity of explicitly enumerating and
determining these sets which are problematic for iterative
decoding for any practically sized LDPC, we shall use a
speciﬁc instance of a recursive algorithm proposed in [22] to
optimize the LDPCs.
II. THE LDPC DESIGN ALGORITHM
In this section we present the basic rationales behind the
proposed quasi-random algorithm for LDPC design. It is
known that the belief-propagation decoder used for decoding
LDPCs provides optimum decoding over cycle-free Tanner
graphs T(H). Hence, an obvious design goal is to try to
minimize the inﬂuence of the cycles on the iterative decoder.
This in turn suggests that a good way of designing LDPCs
may be to try to maximize the smallest length cycle over all
the cycles in T(H) (i.e., to try to maximize the girth), while
simultaneously attempting to minimize the multiplicities of the
shortest length cycles in any bit node v1,i ∈ V1, ∀i = 1, . . . , n,
or equivalently, the multiplicities of the cycles in any check
nodes v2,j ∈ V2, ∀j = 1, . . . , m for increasing length of the
cycles above the minimum value. Another design issue that
should be considered for the LDPC is the minimum distance
of the code. In [22], based on experimental results we have
24
SPACOMM 2011 : The Third International Conference on Advances in Satellite and Space Communications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-128-1

found that the error-ﬂoor performance of a randomly-designed
LDPC code is often constrained by its minimum distance.
Note that it is known that structured codes present error-ﬂoor
performance that are constrained by near-codewords/stopping
sets, or more generally trapping sets [23], [24]. Unfortunately,
it is not a simple task to design a LDPC code by considering
both trapping sets and the minimum distance of the code.
This is essentially due to the combinatorial complexity of
the problem for any practically sized LDPC. In the approach
proposed in this paper, we attack the problem of achieving
both goals in two successive steps. In the ﬁrst step, we design
random LDPCs of a given size (k, n) and given bit node
distribution dv,i, ∀i = 1, . . . , n, whereby dv,i is the degree
of the i-th bit node in T(H), by inserting one edge in T(H)
at a time on a best effort basis via iterative minimization of a
suitable cost function strictly related to the cycle multiplicities
for any given bit node. The design is accomplished with a
constraint of guaranteeing regular check node degrees. This is
because experimental evidence in the literature suggests that
certain check node distributions lead to LDPCs with relatively
good performance in Additive White Gaussian Noise (AWGN)
channels. However, the algorithm proposed here is general
in that any suitable check node degree distribution can be
imposed during the design.
In a second step, we optimize the edge positions using
an instance of the algorithm proposed in [22], whose aim
is to maximize the minimum distance of a speciﬁc LDPC
code. Efﬁcient minimum distance estimation is needed in this
process and is conducted through a variant of the error-impulse
method proposed by Berrou [25].
We consider the parity-check matrix H of a generic LDPC
as a probabilistic space Ω = G(nV , M) whereby nV is the
number n = |V1| of bit nodes of the code plus the number
m = |V2| of the check nodes (i.e., in the case of a Tanner
graph T(H) associated to a LDPC code1 nV = n + m), and
M is the overall number of edges in T(H). For simplicity, in
what follows we consider regular LDPC codes in which the
number of ones in any column of H (i.e., the number of bit
node edges) is equal to dv.
Consider an algorithm to insert one edge at a time in order
to create a matrix H corresponding to a regular Tanner graph
T(H) containing dv edges for every bit node. Enumerate the
edges with i, where i = 1, . . . , M = n · dv = m · dc. Denote
by Xl the variable representing the number of cycles of length
l in T(H), so that Xl is a random variable over the space Ω.
Let Xl,i be the random variable representing the number of
length-l cycles resulting from the addition of the i-th edge in
T(H). A suitable algorithm for the design of random instance
of LDPC codes should try to at least minimize the number
of length-4 cycle (i.e., the random variable X4,i) for any edge
i = 1, . . . , M. A speciﬁc instance of this algorithm is proposed
in the following.
1Note that we consider matrix H with m rows and n columns. This simply
means that the actual rate of the code is R ≥ m/n. In the case in which the
m rows are linearly independent then m = n−k and the LDPC has full rate
k/n.
1
2
3
..
..
m
1 2 3 4 ...                              ... n
1
0
0
0
1
..
..
0
1
0
0
0
1
0
..
..
1
0
0
1
..
..
.......
q-th
row
p-th column
0
0
0
1
0
..
1
0
j-th edge,
j=1,...,d   
v
Fig. 1.
Edge-by-edge growth of a sample LDPC parity-check matrix.
1) Set the bit node degree distribution dv(j), j = 1, . . . , n.
2) Set the number i of inserted edges to zero.
3) For any j from 1 to n perform the following tasks:
• For any p from 1 to dv (j):
a) generate a random set P of Nm uniformly
distributed candidate positions whereby P =
{pk, k = 1, . . . , Nm : pk ∈ [1, . . . , m]},
b) choose the position pm where to insert the i-th
edge by minimizing the cost function,
pm = min
pk∈P X4,i(pk)
(1)
whereby, X4,i(pk) is the number of length-4
cycles over all the partial graphs T(H), when
the i-th edge is inserted at the j-th bit node in
the pk-th row of the parity check matrix.
c) Increase the inserted edge counter i ← i + 1.
• End (for p).
4) End (for j).
This algorithm is clearly suboptimal. An optimum algorithm
would require the minimization of X4,j(pk) for any inserted
edge j by re-positioning all the previous inserted edges for
i = 1, . . . , j − 1. Clearly, this approach is impractical due to
very high complexity. Our proposed algorithm on the other
hand evaluates the position in which to insert the i-th edge
without consideration about the positions of the previous
inserted edges. The next theorem assures the necessary
condition to decouple the effects of the selection of the i-th
edge from that of the (i + 1)-th edge, on the random variable
X4,i+1. This in turn suggests that on the average and for the
block length tending to inﬁnity, we can add one edge at a
time without consideration about the past (i.e., a greedy edge
insertion paradigm).
Theorem I: Consider the random construction of a Tanner
graph T(H) with vertex sets V1, V2, with |V1| = n, |V2| =
m = n·dv
dc , as proposed based on the greedy algorithm above,
with dv the average bit node degree and dc the average check
node degree. Then, for any i = 1, . . . , M − 1, we have:
lim
n→∞ E[X4,i+1|X4,i] = E[X4,i]
25
SPACOMM 2011 : The Third International Conference on Advances in Satellite and Space Communications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-128-1

Proof: Consider step (i + 1) (i.e., we have already inserted i
edges and we wish to add the (i + 1)-th edge). We conjecture
that the (i+1)-th edge does not introduce, on the average and
for n → ∞, any additional length-4 cycles in comparison to
the average number of length-4 cycles present at the end of
the previous step.
Suppose we add the (i+1)-th edge in Ti(H)2 corresponding
to the j-th edge in the p-th column, with j = 1, . . . , dv (in
Fig. 1 we have dv = 3). With this setup, the p-th column is
identiﬁed by p = ⌈ (i+1)
dv ⌉.
Consider the evaluation of the number of length-4 cycles in
Ti+1(H) after the insertion of the (i + 1)-th edge conditioned
on the number of length-4 cycles present at the end of the i-th
iteration (i.e., the conditioning X4,i+1|X4,i on the probabilistic
space Ω = G(nV , M)). By observing that the insertion of a
new edge can only increase the number of length-4 cycles
by at most a constant amount, the following relation holds
X4,i+1|X4,i = X4,i + c, ∀i = 1, . . . , M − 1. Hence, we have
the inequality:
X4,i ≤ X4,i+1|X4,i ≤ X4,i + c, ∀i = 1, . . . , M − 1
(2)
Of interest is the probability P (X4,i+1 − X4,i = 0|X4,i = χ)
(i.e., the probability that the generic (i + 1)-th edge does not
add any length-4 cycles conditioned on the fact that the number
of length-4 cycles in the previous stage was χ).
To ﬁnd this probability, consider the scheme of Fig. 1 in
which a pivot point identiﬁes at most (dc − 1) (dv − 1) inter-
section points, each point corresponding to the intersection of
a row and column whereby there exists a ’1’ in the q-th row
and p-th column. Note that the number of ones in any row
is less than or equal to dc, while the number of ones in any
column is less than or equal to dv.
The probability that no cycle of length-4 is generated by
insertion of a new edge at position (q, p) in H can be
lower-bounded by the probability that all the (dc − 1) (dv − 1)
intersection points identiﬁed above, will have zeros. Using
counting arguments, the probability of having a zero at any
given intersection is:
a = min
µn − dc
n
, m − dv
m
¶
,
from which we obtain the lower-bound:
P (X4,i+1 − X4,i = 0|X4,i = χ) ≥ a(dc−1)(dv−1).
Above is the probability that during the insertion of the j-th
edge in the p-th column, we do not have dc ones per row
and dv ones per column. From this lower-bound we get the
upper-bounded:
P (X4,i+1 − X4,i ≥ 1|X4,i = χ) ≤ 1 − a(dc−1)(dv−1)
From these results we can write:
E[X4,i+1|X4,i]
≤
(j − 1) · min (dc − 1, p − 1) ·
·
h
1 − a(dc−1)(dv−1)i
+ χ
(3)
2The subscript i in Ti(H) is used to signify the fact that the Tanner graph
contains the ﬁrst i edges.
where (j − 1) · min (dc − 1, p − 1) is the maximum number
of length-4 cycles that can be introduced. Suppose n−dc
n
<
m−dv
m
=⇒ a =
n−dc
n
= 1 − dc
n , from which one ob-
tains a(dc−1)(dv−1) ≈ 1 − (dc − 1) (dv − 1) dc
n , and in turn,
1 − a(dc−1)(dv−1) ≈ (dc − 1) (dv − 1) dc
n . Hence, (3) can be
written as follows:
E[X4,i+1|X4,i] ≤ χ+(dv − 1)2 (dc − 1) dc
n ≈ χ+ d2
cd2
v
n
(4)
In the limit, for block size tending to inﬁnity, one obtains the
result:
lim
n→∞ E[X4,i+1|X4,i] = χ = E[X4,i]
(5)
2
The length-4 cycles are not the only one problematic factor
limiting the LDPC performance. In our LDPC design, we have
used a more general cost function taking into account longer
length cycles as well. The cost function adopted for LDPC
design takes on the general form:
f(Ti(H)) =
lmax
X
l=4
Xl,i · L−l
(6)
where i is the index of the edge to be inserted, and lmax
is the greatest cycle length taken into account during the
LDPC design. In the previous equation, Ti(H) is used to
signify the fact that the cost function is evaluated on the
partially constructed Tanner graph after insertion of the i-
th edge. A good tradeoff between code performance and
complexity burden can be obtained by considering lmax = 8.
The constant L is a weighting factor useful for making the
smallest length cycles more undesirable than longer length
cycles. Extensive tests suggests that the value L = 10 may be
a good compromise value for LDPC design.
It is clear that the proposed algorithm aims at minimizing
the cycle distribution at each bit node in T(H). However, as
noted in the introduction, with this design philosophy, while
the randomly designed LDPC may have good performance
especially for low Eb/No ratios, the random approach does
not assure either a good minimum distance, or a good cycle
clustering. For tackling this issue, we used a second optimiza-
tion step aiming at code optimization in the error-ﬂoor.
III. OPTIMIZATION OF THE RANDOMLY DESIGNED LDPCS
As noted above, the second step in our LDPC design algo-
rithm is an optimization step whereby we aim at improving the
performance of the code in the error-ﬂoor region. Implicit in
such a strategy is a need for an efﬁcient algorithm to estimate
the minimum distance of a given LDPC. The performance
of LDPC codes may be limited by pseudo-codewords. There
are however cases when the LDPC decoder behaves as a
Maximum-Likelihood (ML) decoder. This is specially so for
randomly constructed LDPC codes operating at medium to
high SNR values. In such cases, estimation of the minimum
distance dm can be useful to assess asymptotic performance.
In short, apart from theoretical interest in designing LDPCs
with large dm, the technique is useful in eliminating LDPC
26
SPACOMM 2011 : The Third International Conference on Advances in Satellite and Space Communications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-128-1

codes that are poor by virtue of having a low dm. However,
we emphasize that if a code has a high dm, simulations would
still be needed to assess real performance.
An effective algorithm for estimating the minimum distance
of turbo codes, called the Error Impulse (EI) was proposed in
[25]. Although the rationale behind the method hypothesized
a ML decoder, the algorithm has shown reasonably good
performance with the sub-optimal iterative decoding algo-
rithms used for turbo-codes. In order to keep the presentation
concise, we refer the interested reader to [25] for details on the
theoretical rationale beyond the algorithm. Sufﬁce it to say that
the algorithm exploits the capabilities of a ML soft decoder
to prevent EI input patterns. With a reasoning based on the
Euclidean space geometry, in [25] it was shown that under the
hypothesis that the all-zero codeword is transmitted, the min-
imum distance of a linear code is equal to the minimum error
impulse strength Ai over all the codeword bits i = 1, . . . , n
which is able to make the iterative decoder diverge from the
detected all-zero vector. A drawback of this algorithm for
LDPCs is that it could converge toward a wrong minimum
distance because of the sub-optimality of the iterative decoder
and presence of decoding cycles.
In what follows, we shall brieﬂy review the algorithm
proposed in [22] with the modiﬁcations suited to what is
needed in this paper. Unlike the EI technique whereby one
can only obtain information about the minimum distance
of the code, the proposed algorithm evaluates the minimum
distance by enumerating the codewords, along with their
multiplicities of the input error events to which the sum-
product decoder for LDPCs converge when perturbed by an
error pattern constituted by at most two EIs located in two
different codeword positions. The idea is to perturb the all-
zero transmitted codeword with a noise pattern able to make
the iterative decoder diverge from the all-zero decoded word
toward a codeword bc that with high probability, would be
the minimum distance codeword (i.e., the codeword with the
smallest Hamming distance from the all-zero codeword). Then,
knowing the strength and position i (with i = 1, . . . , n)
where the impulse is applied in the span of the codeword
that makes the decoder diverge from the all-zero codeword, in
the proposed algorithm we apply a second impulse spanning
all the codeword bit positions j (∀i ̸= j and j = 1, . . . , n) in
order to list all the detected codewords close to bc and different
from the all-zero codeword.
We consider transmission of an i.i.d. source bit sequence
of length k, encoded with a LDPC of size (k, n), rate Ro =
k/n, and with BPSK-modulation transmitted over an AWGN
channel. In this way, the i-th received sample yi at the output
of the matched ﬁlter at the receiver is yi = (2ci − 1) + ni,
whereby ci is the i−th transmitted codeword bit, and ni is
Gaussian noise with variance σ2
n =
1
2RoEb/No .
The algorithm proposed here for estimation of the minimum
distance of a generic LDPC code speciﬁed by its parity-check
matrix H is as follows:
1) Assume that the minimum distance of the LDPC is in the
range [dl, du], where dl and du are two positive integers.
2) Set Am = du + 1
2, the maximum strength of one EI.
3) Consider the i-th bit node on which an EI has to be
applied:
a) set A = dl − 1
2;
b) set ﬂag=true;
c) while ((ﬂag is true) and (A ≤ Am − 1))
• A = A + 1 (grow the impulse strength one unit
at a time until the LDPC decoder fails to decode
the all-zero vector);
• set yj to −1, ∀j = 1, . . . , n (all-zero transmitted
codeword);
• set an impulse of strength A at the i-th bit node,
i.e., yi = yi + A;
• each bit node vi is assigned an a-posteriori Log-
Likelihood Ratio (LLR) evaluated as Lv,i =
2
σ2n yi;
– for any iteration of the LDPC decoder from
1 to a maximum number of iterations Nit
perform the following tasks:
If the Hamming weight di
m = wH(bci) of
the codeword bci obtained by the decoder is
different from zero and bci has not been yet
encountered during the search, then store di
m
and update the multiplicities of the codewords
with Hamming weights di
m;
– if the decoded codeword bc is different from
the all-zero vector then set the ﬂag to false;
d) end of while;
e) For j = 1 to n, and j ̸= i (apply a second EI at
position j)
• set yt to −1, ∀t = 1, . . . , n (all-zero transmitted
codeword);
• set an impulse of strength A at the i−-th bit
node, i.e., yi = yi + A;
• set an impulse of strength Am at the j−th bit
node, i.e., yj = yj + Am;
– for any iteration of the LDPC decoder from
1 to a maximum number of iterations Nit
perform the following tasks:
If the Hamming weight di,j
m = wH(bci,j) of
the codeword bci,j obtained by the decoder is
different from zero and bci,j has not yet been
encountered during the search, then store di,j
m ,
update the multiplicities of the codewords
with Hamming weights di,j
m ;
f) End of For j = 1 to n
Some considerations are in order. The algorithm above is used
on a randomly designed LDPC one bit node at the time. It
allows one to obtain a set of codeword weights along with the
respective multiplicities due to EIs located in the positions i
and j (if any) in the span of the codeword length.
In the LDPC optimization we have conducted, the algorithm
outputs a cost function resembling the Frame Error Rate (FER)
27
SPACOMM 2011 : The Third International Conference on Advances in Satellite and Space Communications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-128-1

TABLE I
PARAMETERS OF THE LDPCS USED FOR SIMULATION.
(k, n)
(252, 504)
(504, 1008)
(252, 504)
(504, 1008)
L1
L2
L3
L4
dv
3
3
3
3
dc
6
6
6
6
C4
0
0
0
0
C6
1
0
0
0
C8
1250
509
474
10
Nit
80
80
80
80
upper-bound:
F =
dmax
X
d=dmin
µde−Rc
Eb
No d
(7)
whereby µd is the multiplicity of all the codewords with
Hamming weight d provided by the algorithm during the i-th
iteration. In case no low-weight codeword distances are found,
the algorithm generates d = ∞. The latter is used to signify
the fact that the LDPC decoder, when perturbed by an EI in the
generic bit node position i, corrects this error pattern providing
the all-zeros codeword. Another way to look at this algorithm
is to consider it as a way of identifying weak bit nodes in the
code, i.e., the ones for which the application of an EI makes
the decoder converge toward a codeword different from the
all-zero codeword. Once the weak bit-nodes are identiﬁed,
the edges at these weak locations are perturbed randomly
while maintaining the node degrees. During perturbation, the
associated set of cost functions based on (7) are recomputed
and the conﬁguration with least cost is selected.
IV. SIMULATION RESULTS
In this section, we report on some of these results and
comparisons to other constructions reported in the literature.
Using the notation:
λ(x) =
dvmax
X
i=1
λixi−1, ρ(x) =
dcmax
X
i=1
ρixi−1
(8)
where, λi is the percentage of bit nodes of degree i, and ρi is
the percentage of check nodes of degree i, the degree distri-
butions for our designed LDPC codes labelled L1, L2, L3, L4
in Table (I) are as follows:
L1 :
λ(x)
= 0.0019 + 0.498x + 0.496x3 + 0.0039x4,
ρ(x)
= 0.0079x4 + 0.98x5 + 0.011x6;
L2 :
λ(x)
= 0.001 + 0.499x + 0.5x3,
ρ(x)
= 0.0019x4 + 0.9981x5;
L3 :
λ(x)
= x2, ρ(x) = x5;
L4 :
λ(x)
= x2, ρ(x) = x5.
LDPCs labelled L3 and L4 are regular LDPCs, while LDPCs
labelled L1, L2 are considered as systematic (n, k) codes.
Each codeword c is composed of a systematic part u, and
a parity part pu forming c = [u, pu]. With this setup and
given the matrix Hn−k,n of the LDPC code, it is possible to
1
1.5
2
2.5
3
3.5
10
−8
10
−7
10
−6
10
−5
10
−4
10
−3
10
−2
10
−1
Eb/N0−[dB]
BER
L1
L2
L3
L4
PEG−(252,504)
PEG−(504,1008)
MacKay−(252,504)
MacKay−(504,1008)
Fig. 2.
BER performance of codes L1, L2, L3 whose details are shown
in Table (I).
decompose Hn−k,n as Hn−k,n = (Hu, Hpu), where Hu is
an (n−k)×(k) matrix specifying the source bits participating
in each check equation, and Hpu is a (n−k)×(n−k) matrix
of the form:
Hpu =




1
0
. . .
0
0
1
1
0
. . .
0
. . .
. . .
. . .
. . .
. . .
0
. . .
0
1
1



 .
(9)
These LDPC codes have been designed in two steps. In the ﬁrst
step we designed a random bipartite graph with the algorithm
proposed in section II whose objective is to insert one edge
at the time by choosing the edge positions in such a way as
to minimize the cost function in (6) evaluated with lmax = 8.
In the second step we optimized the randomly constructed
LDPCs by applying the algorithm proposed in section III.
In particular, for any edge at any bit node, we evaluated a
new candidate position in the same column in such a way as
to minimize the cost function in (7). Between potential edge
positions yielding the same value of the cost function in (7),
we have chosen the one minimizing our ﬁrst cost function on
the cycle distribution in (6).
For comparison purposes, the LDPCs whose performance
are shown in Figs. 3 and 4 are respectively, the Ramanujan
LDPC with parameters q = 13, p = 5, dv = 3, dc = 6
and block length n = 2184 [23], and the Margulis code with
parameters p = 11, girth 8 and block length n = 2640. As
pointed out in [23], the Ramanujan q = 13, p = 5 code
is useless as it is evident from the BER/FER performance
shown in Fig. 3 since the error-ﬂoor is heavily affected by
codewords with weight 14 which feature prominently in the
BER/FER performance. The Margulis code with block length
n = 2640 on the contrary, is a good algebraic code for FER
values higher than 5·10−6 ÷10−5. Below this FER threshold,
this code has performance affected by near-codewords instead
of low-weight codewords, leading to the observed error-ﬂoor.
We optimized both algebraic codes via edge perturbation
by repositioning every edge in any bit node of the respective
parity check matrices, by choosing a new position in such a
28
SPACOMM 2011 : The Third International Conference on Advances in Satellite and Space Communications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-128-1

1.4
1.5
1.6
1.7
1.8
1.9
2
2.1
2.2
2.3
2.4
10
−8
10
−7
10
−6
10
−5
10
−4
10
−3
10
−2
10
−1
10
0
Eb/No
BER/FER
Ram. (13,5)−BER
Ram. (13,5)−FER
Ram. (13,5)−Fail R.
Optimized−BER
Optimized−FER
Fig. 3.
Performance of the optimized Ramanujan (13, 5) LDPC code.
0.8
1
1.2
1.4
1.6
1.8
2
2.2
2.4
10
−8
10
−7
10
−6
10
−5
10
−4
10
−3
10
−2
10
−1
10
0
Eb/No−[dB]
FER
Ram. 2640
Optimized
Fig. 4.
Performance of the optimized Margulis 2640, p = 11 LDPC code.
way as to minimize the cost function in (7). Between potential
edge positions yielding the same value of the cost function in
(7), we have chosen the one minimizing our ﬁrst cost function
on the cycle distribution in (6).
V. CONCLUSIONS
In this paper we have presented a two phase design process
for LDPC codes with the aim of satisfying several require-
ments simultaneously: 1) constructing LDPCs with quasi-
random structure that have proven to perform well with sub-
optimum iterative soft decoding algorithms, 2) constructing
tanner graphs for the code with large girth and in general with
desirable cycle distribution, and 3) optimizing the designed
codes in the error-ﬂoor region via edge perturbation coupled
by an efﬁcient minimum distance estimation algorithm.
REFERENCES
[1] R.G. Gallager, “Low-density parity-check codes”, IRE Transactions on
Information Theory, pp. 21 - 28, Jan. 1962.
[2] R.M. Tanner, “A recursive approach to low complexity codes”, IEEE
Transactions on Information Theory, vol. 27, pp. 533-547, Sept. 1981.
[3] D.J.C. Mackay, “Good error-correcting codes based on very sparse
matrices”, IEEE Transactions on Information Theory, vol. 45, no. 2, pp.
399 - 431, March 1999.
[4] T.J. Richardson, M.A. Shokrollahi, and R.L. Urbanke, “Design of
capacity-approaching irregular low-density parity-check codes”, IEEE
Transactions on Information Theory, vol. 47, no. 2, pp. 619 - 637, Feb.
2001.
[5] B. Vasic and O. Milenkovic, “Combinatorial constructions of low-
density parity-check codes for iterative decoding,” IEEE Transactions
on Information Theory, vol. 50, no. 6, pp. 1156- 1176, June 2004.
[6] S.J. Johnson and S.R. Weller, “Construction of low-density parity-check
codes from Kirkman triple systems”, IEEE Global Telecommunication
Conference, vol. 2, pp. 970 - 974, Nov. 2001.
[7] J. Rosenthal and P.O. Vontobel, “Constructions of LDPC codes using
Ramanujan graphs and ideas from Margulis”, Proc. of 38th Allerton
Conference on Communication, Control and Computing, pp. 248 - 257,
October 2000.
[8] G. A. Margulis, “Explicit constructions of graphs without short cycles
and low-density codes”, Combinatorica, vol. 2, pp. 71-78, 1982.
[9] R. Echard and Shih-Chun Chang, “The π-rotation low-density parity
check codes”, IEEE Global Telecommunications Conference, vol. 2,
pp.980 - 984, Nov. 2001.
[10] A. Prabhakar and K. Narayanan, “Pseudorandom construction of low-
density parity-check codes using linear congruential sequences”, IEEE
Transactions on Communications, vol. 50, no. 9, pp. 1389-1396, Sep.
2002.
[11] B. Ammar, B. Honary, Y. Kou, J. Xu, and S. Lin, “Construction of low-
density parity-check codes based on balanced incomplete block designs”,
IEEE Transactions on Information Theory, vol. 50, no. 6, pp. 1257 -
1268, June 2004.
[12] L. Chen, J. Xu, I. Djurdjevic, and S. Lin, “Near-Shannon-limit quasi-
cyclic low-density parity-check codes”, IEEE Transactions on Commu-
nications, vol. 52, no. 7, pp. 1038 - 1042, July 2004.
[13] I. Djurdjevic, S. Lin, and K. Abdel-Ghaffar, “Graph-theoretic construc-
tion of low-density parity-check codes”, Communications Letters, IEEE,
vol. 7, no. 4, pp. 171 - 173, April 2003.
[14] Hu. Xiao-Yu, E. Eleftheriou, and D.M. Arnold, “Progressive edge-
growth Tanner graphs”, IEEE Global Telecommunications Conference,
vol. 2, pp. 995 - 1001, Nov. 2001.
[15] M.G. Luby, M. Mitzenmacher, M.A. Shokrollahi, and D.A. Spielman,
“Improved low-density parity-check codes using irregular graphs”, IEEE
Transactions on Information Theory, vol.47, no. 2, pp. 585 - 598, Feb
2001.
[16] S.A.M. Baghdady, Y.A. Fahmy, and M.M.S. El-Soudani, “An incremen-
tal redundancy short length LDPC codes based on random construction
techniques”; IEEE 17th International Conference on Telecommunications
(ICT) pp. 18-22, 2010.
[17] S. Shebl, N. El-Fishawy, A.A. Elazm, and F.A. El-Samie,“A random
construction of LDPC codes using a sub-optimal search algorithm”;
National Radio Science Conference, pp. 1-10, 2009.
[18] C. Liang, W. Songyan, Y. Shijun, W. Ziyu, Z. Wenjun, and G.
Yunfeng,“Semi-random Construction of Rate-Compatible Low-Density
Parity-Check Codes”; Proceedings of the Third International Conference
on Wireless and Mobile Communications, March 2007.
[19] Z. Huang, L. Shen, and Z. Ye,“A new random construction for low-
density parity-check codes”; Proceedings of International Conference on
Communications, Circuits and Systems, vol. 1, pp. 139-142, 2005.
[20] L. Dengsheng, L. Qiang, and L. Shaoqian,“Semi-random construction
of quasi-cyclic LDPC codes”; Proceedings of International Conference
on Communications, Circuits and Systems, vol. 1, pp. 9-13, 2005.
[21] P. Oswald and A. Shokrollahi, “Capacity-achieving sequences for the
erasure channel”, IEEE Transactions on Information Theory, vol. 48, no.
12, pp. 3017 - 3028, Dec. 2002.
[22] F. Daneshgaran, M. Laddomada, and M. Mondin, “An algorithm for the
computation of the minimum distance of LDPC codes”, ETT-European
Transactions on Telecommunications, vol. 17, no. 1, pp. 57-62, Jan.
2006.
[23] D.J.C.
MacKay
and
M.S.
Postol,
“Weakness
of
Margulis
and
Ramanujan-Margulis low-density parity-check codes”, Electronic Notes
in Theoretical Computer Science, vol. 74, Pub. by Elsevier Science B.
V., 2003.
[24] T. Richardson, “Error ﬂoors of LDPC codes”, In Proc. of 41st Annual
Allerton Conf. on Comm., Control, and Comp., October 2003.
[25] C. Berrou, S. Vaton, M. J´ez´equel, and C. Douillard, “Computing the
minimum distance of linear codes by the error impulse method”; IEEE
Globecom 2002, pp. 1017-1020, Taipei, Taiwan, 2002.
29
SPACOMM 2011 : The Third International Conference on Advances in Satellite and Space Communications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-128-1

