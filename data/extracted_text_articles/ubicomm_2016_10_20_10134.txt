An Ontology-Based Affective Computing Approach for Passenger Safety Engagement
on Cruise Ships
Annarita Cinquepalmi
DEI - Politecnico di Bari
Via E. Orabona 4
Bari, Italy I-70125
Email: annarita.cinquepalmi@poliba.it
Umberto Straccia
Istituto di Scienza e Tecnologie dell’Informazione
Consiglio Nazionale delle Ricerche
ISTI-CNR, Pisa, Italy
Email: straccia@isti.cnr.it
Abstract—The safety of cruise passengers is a key element
for a cruise company. Among various aspects, the ability to
interpret and recognize cruisers’ emotions, so that he/she feel
safe, plays a central role in human communication. Affective
computing addresses the computational processing of emotions.
Current automatic emotion recognizers basically use automated
classiﬁcation tools to label emotions without capturing relations
between biosignals and observations measured by the various
sensors. This work proposes instead an Ontology Web Language
(OWL) ontology-based emotion recognition framework by (i)
monitoring human body vital signals through wearable, non-
invasive sensors; and then the (ii) emotion detection is based
on a ontology-based matchmaking process via non-standard
automated reasoning services. A key factor is the use of so-called
vague/fuzzy concepts, which are intrinsic in the realm of emotions
and their dynamic evolution. To this end, we exploit Fuzzy
Description Logics (Fuzzy DLs), which are the logical foundation
of fuzzy OWL ontologies, i.e., OWL ontologies extended with
vague/fuzzy concepts. An early prototype has been implemented
w.r.t. a reference dataset and a preliminary experiment has being
carried out with the aim to monitor the emotions experienced
by cruise passengers while viewing safety video instructions.
Keywords - Affective Computing; Semantic Matchmaking;
Fuzzy OWL 2.
I. INTRODUCTION
The number of people taking cruises across the world has
increased year-on-year. The Cruise Lines International Asso-
ciation [1] estimates that 24 million passengers are expected
to cruise this year. Despite statistics, passengers opinion about
cruise ship safety changed since Costa Concordia accident in
January 2012 off the coast of Italy (32 people died). Among
others, passenger safety training is crucial for cruise company.
To this end, it appears to be useful to monitor and capture
passengers emotions, when viewing safety video instructions,
to improve the emotional condition or prevent harmful health
states of the passengers. According to [2], Affective Com-
puting (AC) aims to create computational systems, which
are Emotionally Intelligent (EmI), i.e., capable to recognize,
understand and express emotions in order to improve users’
well-being. EmI systems may establish empathy with the user,
e.g., through an interactive automated agent, i.e., affective
avatar designed to perceive user emotional experiences when
engaged in speciﬁc activities.
Physiological signals have been used increasingly in AC
thanks to technological improvements in low-cost miniaturized
unobtrusive wearable biosensors for continuous monitoring.
Recently, manufacturers have being developing increasingly
robust and cost-effective biosensors for fast and sensitive
analysis of human body vital signals. Over the last decade,
EmI systems have gained momentum for a wide number of
applications in several important companies, e.g., NeuroFocus
[3] utilized electroencephalography (EEG), eye tracking, and
biometrics to capture the non-conscious aspects, emotions, and
preferences of consumer decision-making; and EmSense [4]
developed the proprietary unobtrusive EmBandTMhardware for
measuring positive/negative emotional response and cognitive
engagement to advertising.
Emotion-aware systems identify speciﬁc outcomes from
biosensors and respond by triggering appropriate actions
within a given context. Additional examples include: (i) mon-
itoring the elderly to recognize signs of health issues [5],
such as sadness bouts as a symptom in depressed patients,
and alerting healthcare providers; (ii) increasing safety of
drivers by observing their emotions [6] and, suggesting a
relaxation technique if a state of anger or frustration is detected
(biofeedback); and (iii) improving user satisfaction in smart
home environments [7], by controlling domotic devices to
favor comfort and resting.
Nevertheless, most existing approaches are still quite intru-
sive. Furthermore, studies are tipically carried out in controlled
laboratory conditions, hardly transferable to real scenarios.
Basically, they rely on conventional computing architectures
running procedures for signal processing and features ex-
traction, which have high computational costs, affecting the
performance in real time applications.
This paper proposes a quasi-real-time computing frame-
work, which only leverages off-the-shelf technology for
biosignal monitoring and analysis, attempting to go beyond
current simple emotion classiﬁcation by exploiting fuzzy
OWL Ontologies [8][9]. Biosignals and features are described
through semantic annotations based on a reference ontology.
In particular, fuzzy OWL enables the description and ma-
nipulation of vague concepts, such as emotions. Semantic-
based processing of raw sensor data makes them machine-
understandable and allows ontology-based knowledge to be
203
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-505-0
UBICOMM 2016 : The Tenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

processed efﬁciently, even in mobile and pervasive contexts
with severe resource limitations in memory, storage and en-
ergy consumption. For this purpose, the optimized Mini-ME
embedded reasoning engine [10] is adopted.
Our framework works in three fundamental stages: (i)
detect most relevant biosignals features; (ii) build an annotated
description of the emotional dimensional model in terms of
valence (V) and arousal (A) [11] via the FuzzyDL-Learner
[12][13][14][15]; and (iii) use matchmaking to recognize the
emotion from its dimensional features. Non-standard inference
services [16] are exploited to compare annotations of the
valence/arousal (VA) space, discovering the most emotion(s)
experienced by the user.
The ultimate goal of the framework is to provide helpful and
timely user feedback and/or provide customized services. The
free public DECAF data set [17] was used for the initial imple-
mentation and experimentation of the proposed framework, in
order to build a Fuzzy OWL ontology of emotions correlated
with biosignals and the continuous VA model. Experiments on
the proposed framework are still ongoing; this paper provides
a proof of concept on the feasibility of our approach.
The remainder of the paper is organized as follows. In
Section II, a literature analysis is given, Section III describes
the framework in detail, while a representative case study
for passenger safety engagement on cruise ships is described
in Section IV. The conducted experiment is illustrated in
Section V. The paper closes with concluding remarks and
future perspectives.
II. RELATED WORK
Biosignals are multichannel time-varying recordings of pa-
rameters of the central and/or the autonomic nervous system.
They are known to convey information that can be used for
emotion assessment [18]. Using biosignals has some advan-
tages over other methods: (i) they are relatively robust to
voluntary control and manipulation, because they are governed
by the human autonomous nervous system; (ii) using wireless
wearable sensors they can be collected anytime and anywhere
without active user input; (iii) they can be easily correlated
with external channels like facial expression.
The literature about emotion recognition through biosensors
shows a standardized procedure to build EmI systems, sum-
marized in the four following stages: (i) signal acquisition;
(ii) preprocessing (iii) feature extraction; and (iv) machine
learning based classiﬁcation [2][19]. They exploit conventional
ﬁxed computer architectures, thus preventing many realistic
application scenarios.
Recent developements in Body Area Network (BAN) allow
data gathered from wearable sensors routed through multi-
hop wireless links toward a portable computing device (e.g.,
a smartphone) [20]. In mobile real-time emotion detection
systems, performance of the processing pipeline is critical in
terms of both computational efﬁciency and classiﬁcation accu-
racy. Furthermore, classiﬁcation yields trivial labels, without
a formally structured description about the characteristics of
the elicited user emotion.
The Semantic Web initiative generated standard logic-
based languages for the representation of ontologies to en-
able machine-understandable characterization of knowledge
domains. Emotion recognition approaches exploiting Semantic
Web technologies exist in literature, although they are a mi-
nority. Zhang et al. [21] proposed a system based on reasoning
rules applying a Decision Tree, but mining was exploited only
to map data to a single class. Furthermore, a rule-based system
is useful only if there is an exact match between rules and
the data: this is quite rare in complex domains like emotion
characterization.
The complexity of emotions, the non-linearity of biosignals,
the impossibility to ﬁnd a single model to represent emotions
can be faced by adopting fuzzy systems [22]. They are
generally robust and have the ability to process inaccurate and
vague data.
Let us recap that, although a large amount of work has been
carried out about fuzzy logic-based machine learning [23],
fuzzy ontology-based machine learning techniques have been
scarcely investigated in general [8] and not at all in the context
of EmI. Together with the adoption of non-standard inference
services, supporting approximate matches, this appears to be
an interesting ingredient to improve EmI system performance
in terms of ﬁne-graned emotion categorization, ﬂexible clas-
siﬁcation and logic-based explanation of the outcomes.
III. EMOTIONALLY INTELLIGENT SYSTEM: FRAMEWORK
AND APPROACH
SEMANTIC ANNOTATOR
µ(x)
x
RAW DATA
BIOFEEDBACK
GENERATOR
INFERRED 
EMOTIONS
Fuzzy DL 
KB
Wireless Body Area Network
WBAN 
Coordinator
EEG
ECG
Resp
GSR
Fuzzy-DL 
Learner
Mini-ME
Matchmaker
Figure 1. Proposed Framework.
Our framework extends the standard emotion recognition
works discussed in Section II. Workﬂow steps are basically
the same, but semantic-based enhancements change the way
each step is performed. The main peculiarities of the proposed
approach are: (i) a real-time emotional patterns detection based
on Fuzzy DLs [8]. Fuzzy DLs are the logical foundation of
fuzzy OWL ontologies, i.e., OWL ontologies extended with
vague/fuzzy concepts [9][24]; (ii) a semantic-based matchmak-
ing process to recognize the most likely emotion, and (iii) a
feedback action to improve the user’s emotional state.
The overall architecture is depicted in Fig. 1. Autonomous
and unobtrusive sensor nodes can form a body area network
or body sensor network (BSN) [25]. Gathered physiological
204
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-505-0
UBICOMM 2016 : The Tenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

parameters are routed through multiple wireless links in the
BAN to a portable device (e.g., a smartphone) with constrained
computational resources for real-time DAQ (Data Acquisition).
Physiological signals in response to stimuli are collected and
used as the EmI system input. Before these data streams are
fed into the computational model, feature extraction techniques
are exploited.
The ﬁrst efforts toward affect recognition have focused
on ﬁnding the link between users emotional state and its
corresponding physiological state, translating low-level data
captured by sensing devices to high-level abstractions ex-
pressed by a semantic annotation. The goal of the seman-
tic annotator component is to build a semantic annotation
combining physiological features and bidimensional emotion
parameters: valence or evaluation and arousal or activation.
Valence represents how positive or negative (i.e., pleasant or
unpleasant) an emotion is, while arousal represents a pas-
sive/active scale, ranging from calm to excited. The key idea in
the above model is to represent emotions with just a coordinate
system conveying basic attributes. As a consequence, any
emotion could be represented as a point in this space [11].
Thus, each emotional state can be deﬁned as a combination
of these dimensions, e.g., anger can be characterized by high
arousal and negative valence, happiness by low arousal and
positive valence, and sadness by low arousal and negative
valence. If the emotion is completely neutral it should be
assigned to the center point of the space.
Exploiting the FuzzyDL-Learner [13][14][15], concept
emotion descriptions are automatically learned from biosignal
features compiled into an OWL 2 [26] ontology. Through non-
standard inference services [16], the semantic annotation is
compared with emotion descriptions contained in the ontology,
created in a training step from a reference biosignal dataset.
Non-standard inference services for semantic matchmaking,
implemented in the Mini-ME reasoner [10], produce the most
appropriate elicited user emotion(s). The system captures the
best action to enhance user’s affective states, giving a user
feedback.
A prototypical fuzzy ontology modeling the domain of
interest has been deﬁned, using fuzzy OWL [9]. The logical
foundation of fuzzy OWL are Fuzzy DLs, an extension to clas-
sical DLs with the aim of dealing with fuzzy/vague/imprecise
information (for more details see [8][24]). Roughly, in Fuzzy
DLs, there are fuzzy concepts (representing classes of ob-
jects), fuzzy roles (a.k.a. properties, joining pairs of objects),
individuals (speciﬁc named objects) and fuzzy datatypes (or
fuzzy concrete domains deﬁned over an interval of the rational
numbers). The important aspect to know is that, unlike usually,
objects may be an instance of a fuzzy concept to some degree
in [0, 1], while in the non-fuzzy case an object is either
instance or not an instance of a concept. Axioms are statements
which represent is-a relations between concepts. The logical
statement has a degree of truth allowing to deﬁne new fuzzy
concepts from other ones during the learning process. It is
beyond the scope of this work to illustrate the details of Fuzzy
DLs. We refer the reader to [8].
The FuzzyDL-Learner system is used to learn automatically
to identify relationship between human affective states and
bidimensional emotional characteristics. The main feature of
the FuzzyDL-Learner system is that it allows to learn graded
fuzzy OWL 2 descriptions of a selected target class in terms
of speciﬁc inclusion axioms expressed in OWL EL [27], in
which, fuzzy concepts may occur to improve both the accuracy
of the description, as well as their readability. The learner
uses the pFOIL-DL learning algorithm [15] to automatically
induce fuzzy concepts descriptions. pFOIL-DL is inspired on
FOIL [28], a popular Inductive Logic Programming algorithm
for learning sets of rules. The three main differences from
FOIL are: (i) pFOIL-DL uses a probabilistic measure to score
concept expressions, (ii) it does not remove positive examples
covered from the training set, but leaves it unchanged after
each learned rule and (iii) it evaluates the goodness of an
induced rule not independently of previously learned rules,
but considering the whole set of learnt expressions. Addi-
tionally, FuzzyDL-Learner automatically fuzziﬁes the range
of the real-valued bidimensional emotion parameters and ﬁnds
relationship between emotions and the VA space. Furthermore,
it may provide an automatic natural language translation of
the learned classiﬁcation emotion rules. The conjunction of
the dimensional value intervals associated to each emotion –
as determined by the training set– becomes the annotation for
that emotion. In this way, each emotion can be described as
the conjunction of qualitative features, valence and arousal.
For instance, the following is a learned description for the
emotion Fear
∃hasArousal.Arousal low ⊓
∃hasV alence.V alence high
⊑
Fear
dictating that Fear is identiﬁed by low arousal values and
high valence values, where low arousal (resp. high valence) are
automatically determined as illustrated in Fig. 2. The output
constitutes the annotated dataset and is the factual knowledge
in the reference fuzzy Ontology.
The subsequent classiﬁcation task exploits a semantic-based
matchmaking process computing non-standard inferences, im-
plemented in the Mini-ME embedded reasoning engine [10].
In a generic setting, given a request R and a set of resources S
expressed w.r.t. a reference ontology, semantic matchmaking
allows to ﬁnd and rank the best matching resources through
non-standard inference procedures called Concept Contraction
and Concept Abduction [16]. If R and S have conﬂicting
characteristics, Concept Contraction determines new concepts
G (Give up) and K (Keep); G is the explanation about what in
R is incompatible with S, while K represents the compatible
part. In addition, a penalty value is computed, which is
the semantic distance of the description w.r.t. the request.
Otherwise, if there is compatibility between R and S but
R does not match S fully, Concept Abduction extracts the
concept expression H (Hypothesis), expressing what should be
hypothesized in S in order to completely satisfy R. A related
penalty value of a service A w.r.t. a request B is computed
as:
d(A, B) = 100(1 − penalty(c) + penalty(a)
max penalty(a)
)
(1)
where penalty(c) and penalty(a) are the penalty induced
by Concept Contraction
and Concept Abduction
between
205
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-505-0
UBICOMM 2016 : The Tenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

-1.61                 0.16   
1.92                  3.69                 5.45
veryLow
low
medium               high               veryHigh
hasArousal
-6.08                  -3.27                   -0.46                    2.35                    5.16
veryLow
low
medium                high             veryHigh
hasValence
Figure 2. Fuzzy concepts obtained from the datatype properties hasArousal
and hasValence.
each service/resource annotation and the request. Penalty is
normalized w.r.t. the maximum possible semantic distance
from the request A, i.e., the one of the most generic DL
concept (denoted ⊤); this distance depends only on the ref-
erence ontology. Finally, semantic afﬁnity is expressed by
a percentage of scores and the service with highest rank is
selected by the requester.
We have adapted the semantic matchmaking problem to the
discovery of user emotions in the following way. The request
is deﬁned by a semantic description expressed as the logical
conjunction of information about emotional bidimensional
features extracted from unlabeled user input. Resources are
the semantic descriptions populating the previously annotated
dataset. The annotated dataset and fuzzy concepts descriptions
are fed to the matchmaking reasoner, and ranked penalty
values associated with a logic-based explanation are obtained
from the semantic matchmaking process. The emotion with
the lowest penalty is identiﬁed as the best matching emotion
from the current user’s biosignals.
IV. CASE STUDY: EMOTIONS IN VIEWING SAFETY VIDEO
INSTRUCTIONS
The proposal explores how emotions affect consumer deci-
sion making in Emotional or Experiental Marketing [29]. In
contrast to traditional marketing, emotional marketers focus
to understand what inﬂuences consumer decision-making and
stimulates their sense and minds. Consumer experience is not
often caused by rational choice: typically, emotional responses
drive human opinion and experience. The selected reference
scenario and case study aims to capture passengers cruise
emotions when viewing safety video instructions immediately
after sailing. The video provides clear instructions and explains
in detail the actions each person on board should follow in
the event of an emergency. Passengers convey the emotion
elicited, after viewing, in terms of valence and arousal. The
subsequent FuzzyDL-Learner in conjunction with semantic-
based matchmaking make a detailed analysis of emotions and
behaviors fully transparent to the user. The feedback is to
suggest what parts of the safety video should be changed and
in what way in order to favor cruiser engagement and serenity,
so that he/she feel safe to travel with a cruise company and
will enjoy their stay.
TABLE I. pFoil LEARNED CONCEPT DESCRIPTIONS.
Target Class
Induced Axiom
Fear
∃hasArousal.Arousal low ⊓
∃hasV alence.V alence high
∃hasArousal.Arousal medium ⊓
∃hasV alence.V alence veryHigh
∃hasArousal.Arousal low ⊓
∃hasV alence.V alence veryHigh
Amusement
∃hasArousal.Arousal low ⊓
∃hasV alence.V alence medium
∃hasArousal.Arousal low ⊓
∃hasV alence.V alence veryLow
∃hasArousal.Arousal low
Shock
∃hasArousal.Arousal low ⊓
∃hasV alence.V alence high
∃hasArousal.Arousal veryLow ⊓
∃hasV alence.V alence high
Disgust
∃hasArousal.Arousal low ⊓
∃hasV alence.V alence high
∃hasArousal.Arousal veryLow ⊓
∃hasV alence.V alence high
∃hasArousal.Arousal high ⊓
∃hasV alence.V alence veryHigh
Fun
∃hasArousal.Arousal low
∃hasArousal.Arousal medium ⊓
∃hasV alence.V alence veryLow
Anger
∃hasArousal.Arousal high
∃hasArousal.Arousal medium ⊓
∃hasV alence.V alence high
∃hasArousal.Arousal veryHigh
∃hasArousal.Arousal high ⊓
∃hasV alence.V alence veryHigh
Excitement
∃hasArousal.Arousal high
∃hasArousal.Arousal medium ⊓
∃hasV alence.V alence low
∃hasArousal.Arousal veryLow ⊓
∃hasV alence.V alence high
The freely accessible DECAF [17] database for affect
recognition and tagging was used to assess the feasibility of
our approach. It is a multimodal dataset for decoding user
physiological responses to multimedia content: it consists of a
collection of peripheral physiological signals and multi-modal
recordings, taken from 30 healthy subjects. The records incor-
porate magnetoencephalogram, horizontal electrooculogram,
electrocardiogram, trapezius electromyogram, and near infra-
red facial video signals. The participants watched 36 emotional
videos and gave feedback in terms of valence and arousal.
Arousal expresses the intensity of the emotional feeling built
up when a subject watched a safety video, ranging on a
discrete scale of 0 (very calm) to 4 (very aroused), valence
refers to how was the feeling after watching a clip on a scale
of -2 (unpleasant) to 2 (very pleasant). The chosen video clips
are also associated with emotional tags.
Our prototypal system exploits the Fuzzy-DL Learner and
the Mini-ME matchmaker for emotion detection. The work-
ﬂow starts with valence, arousal participants’ self-assessment
ratings information. To make sense of the data, z-score nor-
malization rescaling is required. For each video normalized
arousal and valence scores are calculated by taking the mean
and standard deviation of arousal and valence ratings listed
in [17], considered as ground truth. In order to enable a
fully automated emotion annotation and matchmaking process,
206
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-505-0
UBICOMM 2016 : The Tenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

the above meaningful emotional features are translated to an
OWL ontology. A two-step modeling was devised to tie VA
parameters to emotions. The former exploits bidimensional
features as input to the FuzzyDL-Learner in order to fuzzify
valence and arousal and to create a fuzzy OWL ontology
by identifying axioms that express each emotional label. The
latter maps the DECAF dataset to an annotated dataset to
transform raw data into higher level knowledge according to
previous fuzziﬁed arousal/valence space.
Seven emotional classes were considered to induce concept
descriptions: Amusement, Anger, Disgust, Excitement, Fear,
Fun and Shock. The discretization method adopted by pFOIL-
DL partitioned valence and arousal numeric datatypes into
5 fuzzy sets (veryLow, low, medium, high, veryHigh) with
associated membership functions, as depicted in Figure 2. The
learned expressions are reported in Table
I. These axioms
form our fuzzy OWL ontology. As a matter of example,
e.g., anger has been characterized by high arousal and negative
valence while amusement by low arousal and positive valence.
The goal of the second step is to build the annotated dataset,
connoting each valence, arousal value according to the fuzzy
interval obtained in the previous phase. For example, assume
subject with ID 9, after viewing a video, may reports V=0 and
A=2. Then, self-assessment valence/arousal ratings provided
by participants are processed as follows:
1) Valence/arousal ratings are z-score normalized consid-
ering ground truth mean and standard deviation in
the training set. The chosen video clip has µA=1.20,
σA=0.96, µV =1.56 and σV =0.50. The normalized rat-
ings are, thus, A=0.83 and V =-3.12.
2) The semantic description of the subject, according
to the reference ontology, is composed. According to
fuzzy concepts obtained previously, normalized ratings
are both in the low range, so a semantic description is
expressed as:
SubjectId 9: ∀hasArousal.low ⊓ ∃hasArousal ⊓
∀hasV alence.low ⊓ ∃hasV alence
3) Annotated dataset and concept descriptions learned
by FuzzyDL-Learner are then fed to the match-
maker in order to detect the subject’s emotion(s).
In
the
case
under
examination,
ranked
penalty
obtained
from
the
semantic
matchmaking
process
are: Amusement:16.18, Fun:27.27, Excitement:36.36,
Disgust:42.86, Fear:45.45, Shock:57.18, Anger:60.53.
Amusement has the lowest semantic distance and there-
fore the best matching emotion.
4) Finally, based on the elicited emotion, the most suitable
feedback could be applied in order to improve the
emotional condition or prevent harmful health states of
the passengers.
V. EXPERIMENTS
The experimental setup used to test the accuracy of our
implementation consisted of a smaller sample number than
DECAF [17]. 30 subjects were involved in the experiment
watching 20 emotional videos, making a total of 600 individ-
ual records. The chosen video clips were shown in random
TABLE II. CONFUSION MATRIX. a)AMUSEMENT b)ANGER
c)DISGUST d)EXCITEMENT e)FEAR f)FUN g)SHOCK
.
Real/Predict
a
b
c
d
e
f
g
a
102 6
3
4
3
0
2
b
5
111 0
1
3
0
0
c
19
7
21
5
4
4
0
d
4
15
3
36
1
0
1
e
1
11
2
5
40
0
1
f
41
21
4
5
1
46
2
g
11
12
2
5
8
5
17
0
30
60
90
120
Amusement
Anger
Disgust
Excitement
Fear
Fun
Shock
N° instances
Correctly classified instances
 Incorrectly classified instances
Figure 3. Classiﬁcation result.
order eliciting 7 emotions, namely amusement, anger, disgust,
excitement, fear, fun ad shock.
Table II shows thee confusion matrix of emotions classiﬁca-
tion. On a total of 600 instances, 373 were correctly classiﬁed
with an accuracy of 62.17%. A graphical representation of the
results is shown in Fig. 3. The overall weighted classiﬁcation
precision, recall and F-Measure are 0.735, 0.660 and 0.695
respectively.
A relevant issue is the user subjectivity associated with
emotional perception: values assigned to a given impression
may be subjective. For instance, Fun emotion has been mis-
takenly classiﬁed as Amusement because both are pleasant and
not aroused emotions. For this reason, tolerance is a crucial
factor to be considered. In summary, our preliminary results
reveal that the semantic-based approach in conjunction with
fuzzy ontology-based approach seems to be a promising route
towards improving standard machine learning based emotion
classiﬁcation techniques.
VI. CONCLUSION AND FUTURE WORK
The paper presented early work on a novel framework for
emotion recognition from biosignals via semantic annotation
and matchmaking in conjunction with a fuzzy ontology-based
approach. Raw sensor data, without any descriptive metadata,
have limited use as they are hard to discover, integrate or
interpret. One challenge is to develop and test a frame-
work for expressing and classifying complex patterns from
biosignals, allowing emotion recognition through emotional
model. To this end, FuzzyDL-Learner extracts fuzzy emotional
concepts creating a fuzzy OWL ontology. Then, by exploiting
a matchmaker, the semantic descriptions of the test sample are
compared with annotations contained in the fuzzy ontology.
The matchmaker returns then the most similar emotion as
output.
207
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-505-0
UBICOMM 2016 : The Tenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

The proposed approach is currently under prototypical im-
plementation. Experimental evaluation on proper testbeds is
ongoing and will allow to assess effectiveness w.r.t. the state
of the art in AC. A further endeavor is validating the reference
dataset quality and improving the accuracy of the proposed
framework.
REFERENCES
[1] Cruise Lines International Association. [Online]. Available: http:
//www.Cruising.org 2016.09.28
[2] R. W. Picard, E. Vyzas, and J. Healey, “Toward machine emotional
intelligence: Analysis of affective physiological state,” IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, vol. 23, no. 10, pp.
1175–1191, 2001.
[3] Consumer Neuroscience. [Online]. Available: http://www.neurofocus.
com 2016.09.28
[4] EmSense Corporation. [Online]. Available: http://www.emsense.com
2016.08.05
[5] V. Stanford, “Biosignals offer potential for direct interfaces and health
monitoring,” Pervasive Computing, IEEE, vol. 3, no. 1, pp. 99–103,
2004.
[6] J. A. Healey and R. W. Picard, “Detecting stress during real-world driv-
ing tasks using physiological sensors,” IEEE Transactions on Intelligent
Transportation Systems, vol. 6, no. 2, pp. 156–166, 2005.
[7] D. J. Cook et al., “Assessing the quality of activities in a smart
environment,” Methods Inf Med, vol. 48, no. 5, pp. 480–485, 2009.
[8] U. Straccia, Foundations of Fuzzy Logic and Semantic Web Languages.
CRC Press, 2013.
[9] F. Bobillo and U. Straccia, “Fuzzy ontology representation using OWL
2,” International Journal of Approximate Reasoning, vol. 52, pp. 1073–
1094, 2011.
[10] F. Scioscia et al., “A mobile matchmaker for the Ubiquitous Semantic
Web,” International Journal on Semantic Web and Information Systems
(IJSWIS), vol. 10, no. 4, pp. 77–100, 2014.
[11] J. A. Russell, “A circumplex model of affect,” Journal of personality
and social psychology, vol. 39, no. 6, pp. 1161–1178, 1980.
[12] The
FuzzyDL-Learner
System.
[Online].
Available:
http://www.
umbertostraccia.it/cs/software/FuzzyDL-Learner/index.html 2016.09.28
[13] F. A. Lisi and U. Straccia, “A FOIL-Like Method for Learning un-
der Incompleteness and Vagueness,” 23rd International Conference on
Inductive Logic Programming, vol. 8812, pp. 123–139, 2014, revised
Selected Papers.
[14] F. A. Lisi and U. Straccia, “Learning in description logics with fuzzy
concrete domains,” Fundamenta Informaticae, vol. 140, no. 3-4, pp.
373–391, 2015.
[15] U. Straccia and M. Mucci, “pFOIL-DL: Learning (Fuzzy) EL Concept
Descriptions from Crisp OWL Data Using a Probabilistic Ensemble
Estimation,” Proceedings of the 30th Annual ACM Symposium on
Applied Computing (SAC-15), pp. 345–352, 2015.
[16] M. Ruta, E. Di Sciascio, and F. Scioscia, “Concept abduction and
contraction in semantic-based P2P environments,” Web Intelligence and
Agent Systems, vol. 9, no. 3, pp. 179–207, 2011.
[17] M. K. Abadi et al., “DECAF: MEG-based multimodal database for
decoding affective physiological responses,” IEEE Transactions on Af-
fective Computing, vol. 6, no. 3, pp. 209–222, 2015.
[18] J. Healey, “Physiological sensing of emotion,” The Oxford handbook of
affective computing, pp. 204–216, 2014.
[19] F. Nasoz, K. Alvarez, C. L. Lisetti, and N. Finkelstein, “Emotion recog-
nition from physiological signals using wireless sensors for presence
technologies,” Cognition, Technology & Work, vol. 6, no. 1, pp. 4–14,
2004.
[20] M. Chen, S. Gonzalez, A. Vasilakos, H. Cao, and V. C. Leung, “Body
area networks: A survey,” Mobile networks and applications, vol. 16,
no. 2, pp. 171–193, 2011.
[21] X. Zhang, B. Hu, P. Moore, J. Chen, and L. Zhou, “Emotiono: an
ontology with rule-based reasoning for emotion recognition,” Neural
Information Processing, pp. 89–98, 2011.
[22] R. L. Mandryk and M. S. Atkins, “A fuzzy physiological approach for
continuously modeling emotion during interaction with play technolo-
gies,” International Journal of Human-Computer Studies, vol. 65, no. 4,
pp. 329–347, 2007.
[23] M. E. Cintra, M. C. Monard, and H. A. Camargo, “On rule learning
methods: a comparative analysis of classic and fuzzy approaches,” Soft
Computing: State of the Art Theory and Novel Applications, pp. 89–104,
2013.
[24] F. Bobillo and U. Straccia, “The Fuzzy Ontology Reasoner fuzzyDL,”
Knowledge-Based Systems, vol. 95, pp. 12–34, 2016.
[25] B. Latr´e, B. Braem, I. Moerman, C. Blondia, and P. Demeester, “A
survey on wireless body area networks,” Wireless Networks, vol. 17,
no. 1, pp. 1–18, 2011.
[26] W3C OWL Working Group. OWL 2 Web Ontology Language Document
Overview (Second Edition). W3C Recommendation 11 December 2012.
[Online]. Available: http://www.w3.org/TR/owl2-overview/
[27] OWL 2 Web Ontology Language Proﬁles,
http://www.w3.org/TR/
2009/REC-owl2-proﬁles-20091027/, W3C, 2009 (accessed Semptember
27, 2016).
[28] J. R. Quinlan, “Learning logical deﬁnitions from relations,” Machine
Learning, vol. 5, pp. 239–266, 1990.
[29] B. H. Schmitt, Experiential marketing: How to get customers to sense,
feel, think, act, relate.
Simon and Schuster, 2000.
208
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-505-0
UBICOMM 2016 : The Tenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

