An Attempt to Evaluate Chances and Limitations of Social Information Retrieval
Christoph Fuchs
Department of Informatics
TU M¨unchen
Garching bei M¨unchen, Germany
Email: fuchsc@in.tum.de
Georg Groh
Department of Informatics
TU M¨unchen
Garching bei M¨unchen, Germany
Email: grohg@in.tum.de
Abstract—We present an approach to evaluate a novel concept
for distributed social information retrieval. The concept is based
on the idea that users can query private information spaces of
socially close people (“friends”), facilitating social interactions
that correspond with typical human information sharing behavior
to a higher extent. Thereby, we hope to establish more efﬁcient
and socially compatible information sharing among peers in social
and collaborative networks. We give a short overview on related
research from information science, psychology, and economics,
explain and motivate our research questions, summarize our
early ﬁndings, and sketch the setup of our upcoming empirical
experiment.
Keywords–Social search; distributed social information re-
trieval; information seeking; social networking
I.
INTRODUCTION
Relying on our social network to satisfy information needs
is a strategy that is deeply linked to human social behavior
[1]. Social media heavily builds upon the users’ willingness
to participate and share information. While current social
networking sites like Facebook, Google+, or Twitter offer
features to target information items to a speciﬁc audience,
they don’t facilitate social information retrieval in a way that
optimally corresponds with human behavior. Users’ readiness
to share previously unshared information is impacted by a
set of social mechanisms. We would like to leverage these
concepts in order to provide a more efﬁcient way of distributed
social information retrieval, allowing users to beneﬁt from
collaboration with their contacts. Thereby, we focus on a
scenario, where information seekers can query other users’
information spaces (related to asking questions in normal
human-human interaction). An information space constitutes a
repository of private information items, generated by (but not
necessarily limited to) analyzing the user’s actions (e.g., web
browsing, online transactions, communication) and contextual
data (e.g., location, type of activity, other people present).
Information seekers can query the information spaces of others
(referred to as information providers) using their agent (e.g.,
implemented in a mobile device). An information provider’s
agent which received a query would analyze the information
provider’s private information space and – subject to the con-
crete conﬁguration – recommend matching information items
to the information provider as potential items for sharing. Upon
conﬁrmation, the results and additional comments given from
the information provider would get shared with the information
seeker.
The paper’s main contribution is the documentation of
the social search concept and the method to evaluate it.
Other approaches for social search [2], [3], distributed social
networks [4], or P2P ﬁle sharing [5] focus on questions related
to the technical implementation, whereas our work aims to
offer a different perspective on the topic, namely the social
mechanisms that inﬂuence information dissemination in social
networks fostering collaboration among users and the potential
beneﬁts from integrating social context.
The paper is structured as follows: Section II explains and
motivates the research questions, Section III details relevant
areas of research, which either build a basis for our concept
or describe an approach that goes a similar track (in the latter
case, the differences to our concept are explained). In Section
IV, we introduce the planned empirical experiment, state how
we will answer the research questions, and present ﬁrst results
obtained from pre-studies.
II.
RESEARCH QUESTIONS
To evaluate the corner stones of a social information
retrieval system as outlined above, we analyzed literature in
related ﬁelds (computer science, psychology, and economics).
For some assumptions, documented research does either not
provide an unambiguous answer or does not take the speciﬁc
circumstances into account. Therefore, we planned to design
a large-scale experiment which should help to answer the
following questions:
A. RQ1: How do social context and interaction archetypes
inﬂuence users’ data sharing sensitivity?
One of the basic ideas of social media is that people
proactively share information with a wider audience (e.g., a
group of other users considered as “friends”). One possible
reason why social media can’t harness its full potential in
reality is that a large number of positive use cases rely on users
who share the information – what they don’t do to the required
extent. We would like to analyze to which degree social
context, i.e., the social closeness of information seeker and
provider, and the type of interaction (e.g., directed/broadcasted
request/reply, anonymous/not anonymous request/reply) inﬂu-
ence the users’ willingness to ask for or share information.
It seems to be reasonable that the type of interaction may
inﬂuence the users’ willingness to share information with other
users. This hypothesis is going to be evaluated with the dataset
obtained from the described experiment. By considering the
natural information sharing preferences of users in the design
of a distributed social information retrieval system we hope to
increase the amount of individually available information for
social search.
60
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-436-7
COLLA 2015 : The Fifth International Conference on Advanced Collaborative Networks, Systems and Applications

B. RQ2a: How relevant are information items taken from
non-public information spaces of socially close people when
satisfying information needs?
When solving information needs, having access to origi-
nally private information does not necessarily result in higher
satisfaction levels for the information seeker. Unpublished
information held in private information spaces might, e.g.,
not have undergone the same degree of rigorous review as
published work, might be common everyday knowledge or
irrelevant and therefore possibly not be suited to satisfy in-
formation needs. The main objective of this research question
is to verify whether friends’ private information spaces contain
relevant information.
C. RQ2b: Does social context imply a valuable contribution to
retrieving information from the unconscious information need
(serendipitous information)?
Theories on homophily [6] suggest that socially close
people have similar preferences and therefore keep information
items that are of potential (mutual) interest in their informa-
tion spaces. Referring to Mizzaro’s model of relevance [7]
we would like to investigate whether information spaces of
socially close users could foster ﬁnding information items that
are considered as serendipitous by the information seeking
users.
D. RQ3: Which social concepts impact the users’ routing
decisions?
In a majority of existing approaches for P2P document re-
trieval systems, routing decisions for queries are based mainly
on content characteristics (i.e., does a speciﬁc node store a
certain document?). In these settings, the social relationship
between information seeker and provider is not important – the
document is standardized and not linked to the speciﬁc social
context: It is not important for the seeker where the document
comes from – as long as it contains the expected content. In
scenarios where social search is expected to perform best [8],
the source of an information can be of importance. Selecting
a user as an information provider is not only based on the
availability of content, but on other (more social) criteria as
well (referred to as “social concepts”). Given a system which
allows routing of queries to potential information providers
within ones own social network to satisfy information needs,
we would like to understand why some people are chosen
as information providers and others not. Borgatti and Cross
[9] already published some theories on social interaction in
information retrieval, but focus only on professional settings
(in the work environment of large organizations). We assume
that a more general situation might reveal different results since
the workplace implies a speciﬁc set of rules, which do not
apply in broader environments.
E. RQ4: Which category of information needs could beneﬁt
from social information retrieval?
Traditional web search engines excel at ﬁnding published
factual information, like Mozart’s date of birth. The informa-
tion items in the information spaces of others might be much
more subjective than publicly available information – therefore
they might be relevant for certain types of information needs,
which would proﬁt from various subjective recommendations
and/or opinions, as Oeldorf-Hirsch et al. [8] already suggested
for SMQA (it is important to note that Oeldorf-Hirsch et
al.’s study only allowed public broadcasting of questions and
therefore investigated a different setting).
III.
RELEATED WORK
A. Information Retrieval
1) Models & Approaches: Elementary concepts of infor-
mation retrieval approaches include traditional vector space
models based on term frequency-inverse document frequency
(TF-IDF, [10, p. 118]), where documents are represented as
vectors in a multi-dimensional vector space. The dimensions
are deﬁned by the terms which are derived from the words
occurring in the documents of the collection. The position of
a document within this vector space is deﬁned by calculating
the term frequency (how often does a speciﬁc word occur in
a document) and the inverse document frequency (how many
documents of the collection contain the word). By combining
those two factors, it is possible to identify words describing
the prevalent content of the document and at the same time
differentiating the document from the other documents in
the collection [10]. One of the main assumptions in most
TF-IDF based approaches is that the order of words does
not matter (bag-of-words assumption). BM25F, an improved
version of BM25 (Best Matching), also relies on the bag-of-
word assumption but distinguishes between different ﬁelds of
a document and adjusts the weighting according to the im-
portance of the respective ﬁeld [11]. More recent approaches,
like term weights-IDF (TW-IDF) [12], use a graph-based
representation which outperforms classical approaches, like
BM25, by considering the relations between terms using a
unweighted directed graph.
Our work builds upon these concepts: each user’s informa-
tion space has to be indexed using those classical techniques
in combination with probabilistic elements like topic mod-
els/Latent Dirichlet Allocation (LDA) [13] to suggest personal
information items to be shared with an information seeker.
2) Relevance & Serendipity: In naive TF-IDF approaches,
the relevance of a document for a query is often calculated
using a metric like cosine similarity or Euclidian distance
to compare document vectors and query vector. Beyond this
mechanical way of calculating relevance, Mizzaro [7] dis-
tinguished between real (“objective”) information need and
perceived (“subjective”) information need which have some
overlap, but are not equal. The information seeking user is
only aware of the perceived information need and uses this as
a starting point when formulating the query. During the search
process, the user’s mental model about the topic of interest
evolves and the user’s subjective information need iteratively
changes while consuming more information (and ideally would
cover more of the real information need). As a consequence,
information items might be relevant according to the user’s
real information need, but might not be considered as relevant
by an algorithm which is designed to maximize the relevance
for the user’s query (because the latter is derived from the
perceived information need). This allows serendipity, where
items do not necessarily ﬁt the entered query but are considered
as relevant by the user. Previous literature covers measurement
[14], exploration [15], [16], and formalization [17], [18], [19]
of serendipity.
In our work, we would like to evaluate which social
relations make occurrences of serendipity happen more likely
61
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-436-7
COLLA 2015 : The Fifth International Conference on Advanced Collaborative Networks, Systems and Applications

to allow the user to consciously manipulate the answer’s
degree of serendipity by selecting information providers from
different social communities. Thereby, we deﬁne serendipity
as combination of relevance and unexpectedness of the result.
3) Distributed & Personalized Search: Several approaches
for Distributed Search have been proposed in the past, ex-
amples relying on agents are (among others) DS4 [2], [3],
Blogracy [20] (where the authors also provide a comprehensive
overview of distributed social networking approaches), RAIS
[21], or DIAMS [22]. YaCy [23] forms a distributed index
for web search and Callan [24] provides an early overview
of distributed information retrieval, coining the term “fed-
erated search” where an information seeker queries several
search engines in parallel. Shokouhi and Si [25] profoundly
summarize approaches for the sub-steps in federated search.
To include the information seeker’s individual context in the
evaluation of potential search results, several attempts have
been made to personalize search results. Micarelli et al. [26],
Steichen et al. [27], and Ghorab et al. [28] published com-
prehensive surveys, clustering the existing approaches. Some
approaches also personalize results based on the information
seeker’s social network [29] or use the social network to
rank information [30]. Carmel et al. [31] compare different
strategies to use information obtained from different social
networks (familiarity-based, similarity-based, overall network
with both types of edges) to personalize search results. Their
comparison with personalization based on topics suggests that
all three personalization strategies relying on social networks
outperform the topic-based approach (e.g., indexing and rank-
ing).
Our intended concept combines several characteristics of
other approaches: The idea of selecting different information
providers (and thus repositories) is comparable to federated
search [24] or DS4 [2], [3], where the social component is
not taken into account to the same extent. Other approaches
like YaCy [23], Carmel et al.’s [31], or SNDocRank [30] cover
parts of the search process.
B. Social Search
1) Deﬁnition: McDonnell and Shiri [32] list a variety of
deﬁnitions for social search; for the remaining part of this
chapter, we deﬁne social search broadly as integrating others
in the search process and therefore are very close to Evan et
al.’s deﬁnition [33].
2) Social Context: By analyzing usage patterns of mobile
search, Teevan et al. [34] and Church and Oliver [35] show
that social context highly inﬂuences the search process, ei-
ther by searching collaboratively or by discussing the search
results with others. While Teevan et al. and Church/Oliver
only consider the short-term social context during the search
process, Kramr et al. [36] use clusters of users with similar
interests to disambiguate queries (and thus rely on the long-
term social context). After having conducted an online survey
with 150 participants, Evans and Chi [37] conclude that social
interactions “play a key role throughout the search process”.
Their ﬁndings suggest that existing tools do not fully meet the
users’ requirements.
Our objective is to understand the users’ social behavior
and to build a concept to improve information dissemination
among users.
3) Social Media Question Asking: While many studies
cover the social aspects of search performed using traditional
web search engines, some also investigate social interaction
when users try to get information from their social contacts. In
Social Media Question Asking (SMQA), information seekers
satisfy information needs by asking other people via social
network platforms like Twitter, Facebook, or Google+. Efron
and Winget [38] propose a taxonomy of questions asked in
a microblogging environment, Paul et al. [39], and Teevan et
al. [40] identify patterns for question asking and answering,
Lampe et al. [41] investigate Facebook’s value as an informa-
tion service while Oeldorf-Hirsch et al. [8] compare SMQA
with searching on traditional web search engines.
Those ﬁndings show that there are speciﬁc types of infor-
mation needs which people prefer to solve by leveraging the
knowledge of their peers. Our concept aims to improve this
process by reducing involved social costs and increasing the
efﬁciency of the process (e.g., by recommending information
items, which might be suitable answers, to the information
provider – in later versions, an automatic reply could also be
possible).
C. Motivation to share information
Alan P. Fiske suggests in [42] that human social life
could be explained by combining four psychological mod-
els, namely communal sharing (CS), authority ranking (AR),
equality matching (EM), and market pricing (MP). Following
this approach, information sharing could be considered as a
social act, allowing to express the underlying motivation as a
combination of Fiske’s models. In CS, people treat members
of their speciﬁc group as equivalents. People within the group
behave altruistic and are sometimes linked by kinship. In
AR, people are ordered linearly according to some social
hierarchical dimension. People with higher ranks typically
have privileges, prestige, and prerogatives, which people with
lower ranks don’t have. EM describes a relation between
two people who try to keep the balance of their relationship
even. This is the standard behavior between people who meet
multiple times and follow a tit-for-tat strategy or some other
reciprocal granting of favors. In contrast, in MP relationships
all relevant features are reduced to a lower dimensional value
or utility metric (e.g., price) that is used to compare different
factors. This is the default relationship for people who only
meet once and don’t plan any further encounters. Applying
these concepts to distributed social search, the motivation to
provide information to the information seeker highly depends
on the type of relationship: Following a CS regime, people
would be much more interested in sharing information while
offering information to socially more distant friends or even
strangers would follow a more strict EM or even MP regime.
AR regimes could be characteristic for certain professional
settings.
Manski [43] models social interactions based on the con-
cepts expectation (agents choose actions based on the ex-
perience of others who had the same problem), constraint
(the respective good is limited and therefore needs to be
shared/allocated wisely), preference (own choice depends on
others’ choice), and equilibrium (occurs when all agents’
actions are mutually consistent). Jackson and Rogers [44]
analyze theoretic games in social networks and distinguish
62
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-436-7
COLLA 2015 : The Fifth International Conference on Advanced Collaborative Networks, Systems and Applications

between strategic complements and strategic substitutes. Ex-
amples for strategic complements are, e.g., the majority game
(a user’s payoff is higher when she/he does the same as her/his
neighbors), which could model for example the adoption
of new technologies. Strategic substitutes describe situations
where a user’s payoff is lower when she/he does the same as
her/his neighbors (e.g., best shot public goods game; it doesn’t
make any sense for a user to buy a book when she/he can
borrow it from her/his neighbors). With chronobot [45], Li
and Chang implemented a bidding system for tasks with the
required time as currency, including a proposal to determine
exchange rates according to preference or expertise levels.
Using Fiske’s model above, this system would follow a clear
MP approach, offering standardized prices calculated based
on objective input parameters. Social relationships and human
traits in sharing information are not explicitly considered.
By conducting our planned experiment, we would like
to understand users’ social behavior when sharing or asking
for information in the social information retrieval scenario
described in in the introduction section. We will build upon
Fiske’s work [42] and use it as a framework to distinguish
different types of social interactions. Assuming that users are
acting rationally, Jackson and Roger’s theories [44] might show
parallels when analyzing the underlying market mechanisms of
our scenario.
IV.
FIRST RESULTS & PROPOSED RESEARCH OUTLINE
We plan to conduct a larger experiment on distributed
information retrieval with 150 − 200 participants within the
coming months, allowing us to generate empirical data to
answer the research questions outlined above. In some cases,
we already did pre-studies to obtain ﬁrst insights. The par-
ticipants will disclose their individual social networks, assign
weights to their social edges (tie strength, knowledge sim-
ilarity, social context similarity, sympathy) and provide an
index to something we consider as their private information
space (visited URLs on the web, extracted from their browser
history, crawled and indexed using LDA [13]). In addition, we
will receive information about individually viewed and bought
products from a leading online store. The experiment consists
of three parts (manual query mode, automatic query mode, and
semantic product search):
Manual query mode – Participants deﬁne three queries
they would like to solve by asking people within their social
network. During query deﬁnition and assignment of potential
information providers to the queries, users are asked to justify
their decisions. In addition to the self-deﬁned queries, each
participant will also be asked to satisfy three predeﬁned infor-
mation needs taken from domains which are suitable for social
information retrieval (based on [8]). Information providers will
be asked to answer the query and to ﬁll out an online survey,
information seekers are expected to review the received results
and rate them.
Automatic query mode – Participants deﬁne queries, a
background task uses a randomly selected strategy to choose
potential information providers (possible strategies include tie
strength, knowledge similarity, social context similarity, and
sympathy). Since all participants of the experiment uploaded
an index to their private information space in advance, it is
possible to query the index of the identiﬁed group of informa-
tion providers in the background. In case of any matches, the
respective information provider is informed about the incoming
query and the identiﬁed result within her/his information space
and is asked to provide the information (i.e., the URL to
the site corresponding to the index position) and ﬁll out a
survey. After the information seeker received the response,
she/he is also asked to evaluate the results. To allow further
comparisons, one of the answering information providers for
each query will be an (undisclosed) technical user account,
querying a traditional web search engine and returning the
ﬁrst ﬁve resulting URLs to the information seeker.
Semantic product search – The participants will be asked
to search for items using a customized user interface to a
well-known online store, where items which have been viewed
at and/or bought by friends are highlighted. In addition to
the results obtained from the normal search functionality of
the online store, products viewed/bought by close friends
(identiﬁed by various strategies) will be added to the result
list (without revealing the friends’ identities). Those additional
products do not necessarily match the search query exactly, but
might be considered as relevant due to the social relationship
between the product owner/viewer and the information seeker.
Participants will be asked to evaluate usefulness and degree
of predictability/novelty for each item in the result list. In
addition, click behavior will be recorded.
A. RQ1: How do social context and interaction archetypes
inﬂuence users’ data sharing sensitivity?
In a small pre-study (online survey with 112 participants)
[46], we re-run a modiﬁed and reduced version of Oeldorf-
Hirsch et al.’s [8] experiment. Oeldorf-Hirsch’s observation
was that people are quite hesitant to ask others for help in
a social media environment. Our hypothesis was that this
might be caused by the fact that users had to post questions
visible to a majority or all of their friends (“broadcast”) on the
social network platform. Our ﬁndings suggest that people’s
willingness to ask for information highly depends on the
audience – if it is possible to target a single recipient or a
limited audience, social means for information retrieval are
considered much more often.
In the upcoming experiment, we plan to ask the user
who provides an information item whether she/he has already
shared the information item on any public media channel (like
Facebook, Twitter, Google+, etc.), whether she/he would share
it on a social media channel, and whether she/he would share it
with a friend who asks for it. In addition, we ask the potential
information provider to assess the information item’s degree
of privacy (using a slider on a scale from 0 to 100, with
expressive descriptions for minimum/maximum values). One
possible outcome is that the degree of information sharing (i.e.,
how much “privacy” does someone share?) highly depends
on the social context (audience) and the type of interaction
(reactive, proactive).
B. RQ2a: How relevant are information items taken from
non-public information spaces of socially close people when
satisfying information needs?
Analyzing two datasets obtained from Twitter and Face-
book [47], our early ﬁndings suggest that content created
by socially close people is of higher interest for us than
content from strangers. During the social information retrieval
experiment we will ask the information seekers to assess the
63
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-436-7
COLLA 2015 : The Fifth International Conference on Advanced Collaborative Networks, Systems and Applications

quality of responses given by the information providers in
order to obtain a measureable value for relevance, novelty, and
personalization. In addition, we plan to correlate the results
with social metrics like tie strength, knowledge similarity,
social context similarity, and sympathy.
C. RQ2b: Does social context imply a valuable contribution to
retrieving information from the unconscious information need
(serendipitous information)?
Focusing on the use case to buy a product, we will compare
the relevance of product items returned from a well-known
online store with those items taken from the list of viewed and
bought items from people within the own, individual social
network (deﬁned using the max/min values of tie strength,
knowledge similarity, social context similarity, and sympathy).
We will compare the degree of relevance and novelty between
the different groups of origin.
D. RQ3: Which social concepts impact the users’ routing
decisions?
When adding a user as a recipient of a search query in
the manual query mode of the experiment, we will ask the
user to justify her/his choice. During the assessment of the
result quality, we ask the user which other contacts could have
also been potential information providers (and why the user
hesitated to nominate them). We also gather information about
the motives for sharing information to be able to describe the
relationship between the information seeker and provider using
Fiske’s [42] model.
E. RQ4: Which category of information needs could beneﬁt
from social information retrieval?
In a different study, we used highly specialized websites
as proxies for speciﬁc topics to derive the degree of socialness
for the topic. After a ﬁrst initial pre-study we plan to elaborate
on this, scaling the experiment with the help of crowdsourcing
platforms and a larger URL database. In the upcoming study,
we will ask the participants to provide queries which are
considered to be suited for social information retrieval. We plan
to validate these expectations using the quality assessments
of the results and will compare these ﬁndings with previous
literature.
V.
SUMMARY & CONCLUSION
The objective of this paper is to propose a concept for
“distributed social information retrieval” and a possible eval-
uation approach. We explained and motivated the research
questions, described ﬁrst results and outlined the agenda for
the following experiment. By understanding the underlying
psychological details, we would like to create a system that
facilitates information retrieval among social peers and allows
to efﬁciently incorporate the knowledge that is available within
one’s own social network.
REFERENCES
[1]
C. A. Johnson, “Choosing People: The Role of Social Capital in
Information Seeking Behaviour,” Information Research, vol. 10,
no.
1,
2004.
[Online].
Available:
http://InformationR.net/ir/10-
1/paper201.html [retrieved: 2015.07.21]
[2]
D. Kontominas, P. Raftopoulou, C. Tryfonopoulos, and E. G. Petrakis,
“DS4: A Distributed Social and Semantic Search System,” in Advances
in Information Retrieval – 35th European Conference on IR Research,
ser. ECIR ’13.
Springer, 2013, pp. 832–836.
[3]
P. Raftopoulou, C. Tryfonopoulos, E. G. Petrakis, and N. Zevlis, “DS4:
Introducing Semantic Friendship in Distributed Social Networks,” in
Proceedings of the 21st International Conference on Cooperative Infor-
mation Systems, ser. CoopIS ’13, 2013.
[4]
H. Li, K. Bok, and J. Yoo, “An Efﬁcient Mobile Social Network
for Enhancing Contents Sharing over Mobile Ad-hoc Networks,” in
Proceedings of the International Conference on Parallel and Distributed
Computing, Applications and Technologies, ser. PDCAT, 2012, pp. 111
– 116.
[5]
K. Chen, H. Shen, and H. Zhang, “Leveraging Social Networks for
P2P Content-Based File Sharing in Mobile Ad Hoc Networks,” in
Proceedings of the International Conference on Mobile Adhoc and
Sensor Systems, ser. MASS, 2011.
[6]
D. Kempe, J. Kleinberg, S. Oren, and A. Slivkins, “Selection
and
Inﬂuence
in
Cultural
Dynamics,”
arXiv:1304.7468
[cs.GT],
2013. [Online]. Available: http://arxiv.org/abs/1304.7468 [retrieved:
2015.07.21]
[7]
S. Mizzaro, “How Many Relevances in Information Retrieval?” Inter-
acting with Computers, vol. 10, no. 3, 1998, pp. 303–320.
[8]
A. Oeldorf-Hirsch, B. Hecht, M. R. Morris, J. Teevan, and D. Gergle,
“To Search or to Ask: The Routing of Information Needs Between
Traditional Search Engines and Social Networks,” in Proceedings of the
17th Conference on Computer Supported Cooperative Work & Social
Computing, ser. CSCW ’14.
New York, NY, USA: ACM, 2014, pp.
16–27.
[9]
S. P. Borgatti and R. Cross, “A Relational View of Information Seeking
and Learning in Social Networks,” Management Science, vol. 49, no. 4,
2003, pp. 432–445.
[10]
C. D. Manning, P. Raghavan, and H. Sch¨utze, Introduction to Informa-
tion Retrieval.
Cambridge University Press, 2008.
[11]
H.
Zaragoza,
N.
Craswell,
M.
Taylor,
S.
Saria,
and
S.
Robertson,
“Microsoft
Cambridge
at
TREC-13:
Web
and
HARD
Tracks,”
in
Proceedings
of
TREC-2004,
2004.
[Online].
Available:
http://trec.nist.gov/pubs/trec13/papers/microsoft-
cambridge.web.hard.pdf [retrieved: 2015.07.21]
[12]
F. Rousseau and M. Vazirgiannis, “Graph-of-Word and TW-IDF: New
Approach to Ad Hoc IR,” in Proceedings of the 22nd ACM International
Conference on Information & Knowledge Management, ser. CIKM ’13.
New York, NY, USA: ACM, 2013, pp. 59–68.
[13]
D. M. Blei, A. Y. Ng, and M. I. Jordan, “Latent Dirichlet Allocation,”
The Journal of Machine Learning Research, vol. 3, 2003, pp. 993–1022.
[14]
I. Bordino, Y. Mejova, and M. Lalmas, “Penguins in Sweaters, or
Serendipitous Entity Search on User-Generated Content,” in Proceed-
ings of the 22nd ACM International Conference on Information &
Knowledge Management, ser. CIKM ’13. New York, NY, USA: ACM,
2013, pp. 109–118.
[15]
M. D¨ork, S. Carpendale, and C. Williamson, “The Information Flaneur:
A Fresh Look at Information Seeking,” in Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems, ser. CHI ’11,
no. 10.
New York, NY, USA: ACM, 2011, pp. 1215–1224.
[16]
M. D¨ork, N. H. Riche, G. Ramos, and S. Dumais, “PivotPaths: Strolling
Through Faceted Information Spaces,” in IEEE Transactions On Visual-
ization and Computer Graphics, ser. InfoVis ’12, vol. 18, no. 12. IEEE,
2012, pp. 2709–2718.
[17]
T. E. Workman, M. Fiszman, T. C. Rindﬂesch, and D. Nahl, “Framing
Serendipitous Information-Seeking Behavior for Facilitating Literature-
Based Discovery: A Proposed Model,” Journal of the Association for
Information Science and Technology, vol. 65, no. 3, 2014, pp. 501–512.
[18]
A. Thudt, U. Hinrichs, and S. Carpendale, “The Bohemian Bookshelf:
Supporting Serendipitous Book Discoveries Through Information Visu-
alization,” in Proceedings of the SIGCHI Conference on Human Factors
in Computing Systems, ser. CHI ’12.
New York, NY, USA: ACM,
2012, pp. 1461–1470.
[19]
M. Schedl, D. Hauger, and D. Schnitzer, “A Model for Serendipitous
Music Retrieval,” in Proceedings of the 2nd Workshop on Context-
awareness in Retrieval and Recommendation, ser. CaRR ’12.
New
York, NY, USA: ACM, 2012, pp. 10–13.
[20]
E. Franchi, A. Poggi, and M. Tomaiuolo, “Supporting Social Networks
With Agent-Based Services,” International Journal of Virtual Commu-
nities and Social Networking, vol. 5, no. 1, 2013, pp. 62–74.
64
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-436-7
COLLA 2015 : The Fifth International Conference on Advanced Collaborative Networks, Systems and Applications

[21]
M. Mari, A. Poggi, M. Tomaiuolo, and P. Turci, “Enhancing Information
Sharing Through Agents,” in Proceedings of the 8th International BI
Conference on Agent-oriented Information Systems IV, 2006, pp. 202–
211.
[22]
J. R. Chen, S. R. Wolfe, and S. D. Wragg, “A Distributed Multi-Agent
System for Collaborative Information Management and Sharing,” in
Proceedings of the Ninth International Conference on Information and
Knowledge Management, ser. CIKM ’00.
ACM, 2000, pp. 382–388.
[23]
M. Christen, “YaCy Decentralized Web Search,” 2015. [Online].
Available: http://yacy.net/en/index.html [retrieved: 2015.07.21]
[24]
J. Callan, “Distributed Information Retrieval,” The Information Re-
trieval Series, vol. 7, 2000, pp. 127–150.
[25]
M. Shokouhi and L. Si, “Federated Search,” Foundations and Trends in
Information Retrieval, vol. 5, no. 1, 2011, pp. 1–102.
[26]
A. Micarelli, F. Gasparetti, F. Sciarrone, and S. Gauch, “Personalized
Search on the World Wide Web,” Lecture Notes in Computer Science,
vol. 4321, 2007, pp. 195–230.
[27]
B. Steichen, H. Ashman, and V. Wade, “A Comparative Survey of Per-
sonalised Information Retrieval and Adaptive Hypermedia Techniques,”
Information Processing & Management, vol. 48, no. 4, 2012, pp. 698–
724.
[28]
M. R. Ghorab, D. Zhou, A. O’Connor, and V. Wade, “Personalised
Information Retrieval: Survey and Classiﬁcation,” User Modeling and
User-Adapted Interaction, vol. 23, no. 4, 2013, pp. 381–443.
[29]
D. Lu and Q. Li, “Personalized Search on Flickr Based on Searcher’s
Preference Prediction,” in Proceedings of the 20th International Con-
ference Companion on World Wide Web, ser. WWW ’11.
New York,
NY, USA: ACM, 2011, pp. 81–82.
[30]
L. Gou, X. L. Zhang, H.-H. Chen, J.-H. Kim, and C. L. Giles, “Social
Network Document Ranking,” in Proceedings of the 10th Annual Joint
Conference on Digital Libraries, ser. JCDL ’10.
New York, NY, USA:
ACM, 2010, pp. 313–322.
[31]
D. Carmel, N. Zwerdling, I. Guy, S. Ofek-Koifman, N. Har’el, I. Ronen,
E. Uziel, S. Yogev, and S. Chernov, “Personalized Social Search Based
on the User’s Social Network,” in Proceedings of the 18th ACM
Conference on Information and Knowledge Management, ser. CIKM
’09.
New York, NY, USA: ACM, 2009, pp. 1227–1236.
[32]
M. McDonnell and A. Shiri, “Social Search: A Taxonomy of, and a
User-Centred Approach to, Social Web Search,” Program: Electronic
Library and Information Systems, vol. 45, no. 1, 2011, pp. 6–28.
[33]
B. M. Evans, S. Kairam, and P. Pirolli, “Exploring the Cognitive
Consequences of Social Search,” in CHI Extended Abstracts on Human
Factors in Computing Systems, ser. CHI EA ’09. New York, NY, USA:
ACM, 2009, pp. 3377–3382.
[34]
J. Teevan, A. Karlson, S. Amini, A. J. B. Brush, and J. Krumm,
“Understanding the Importance of Location, Time, and People in
Mobile Local Search Behavior,” in Proceedings of the 13th International
Conference on Human Computer Interaction with Mobile Devices and
Services, ser. MobileHCI ’11.
New York, NY, USA: ACM, 2011, pp.
77–80.
[35]
K. Church and N. Oliver, “Understanding Mobile Web and Mobile
Search Use in Today’s Dynamic Mobile Landscape,” in Proceedings
of the 13th International Conference on Human Computer Interaction
with Mobile Devices and Services, ser. MobileHCI ’11.
New York,
NY, USA: ACM, 2011, pp. 67–76.
[36]
T. Kram´ar, M. Barla, and M. Bielikov´a, “Disambiguating Search by
Leveraging a Social Context Based on the Stream of User’s Activity,”
Lecture Notes in Computer Science, vol. 6075, 2010, pp. 387–392.
[37]
B. M. Evans and E. H. Chi, “Towards a Model of Understanding Social
Search,” in Proceedings of the 2008 ACM Conference on Computer
Supported Cooperative Work, ser. CSCW ’08.
New York, NY, USA:
ACM, 2008, pp. 485–494.
[38]
M. Efron and M. Winget, “Questions are Content: A Taxonomy of
Questions in a Microblogging Environment,” in Proceedings of the 73rd
ASIS&T Annual Meeting on Navigating Streams in an Information
Ecosystem, ser. ASIS&T ’10.
American Society for Information
Science, 2010, pp. 27:1–27:10.
[39]
S. A. Paul, L. Hong, and E. H. Chi, “Is Twitter a Good Place for
Asking Questions? A Characterization Study,” in Proceedings of the
Fifth International AAAI Conference on Weblogs and Social Media,
2011.
[40]
J. Teevan, M. R. Morris, and K. Panovich, “Factors Affecting Response
Quantity, Quality, and Speed for Questions Asked via Social Network
Status Messages,” in Proceedings of the 5th International Conference
on Weblogs and Social Media, ser. ICWSM ’11.
Association for the
Advancement of Artiﬁcial Intelligence (AAAI), 2011, pp. 630–633.
[41]
C. Lampe, J. Vitak, R. Gray, and N. Ellison, “Perceptions of Facebook’s
Value as an Information Source,” in Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems, ser. CHI ’12.
New York, NY, USA: ACM, 2012, pp. 3195–3204.
[42]
A. P. Fiske, “The Four Elementary Forms of Sociality: Framework for
a Uniﬁed Theory of Social Relations,” Psychological Review, vol. 99,
no. 4, 1992, pp. 689–723.
[43]
C. F. Manski, “Economic Analysis of Social Interactions,” NBER
Working
Paper
Series,
no.
7580,
2000.
[Online].
Available:
http://www.nber.org/papers/w7580 [retrieved: 2015.07.21]
[44]
M. O. Jackson and Y. Zenou, “Games on Networks,” Handbook of
Game Theory, vol. 4, 2014.
[45]
X. Li and S.-K. Chang, “User Proﬁling in the Chronobot/Virtual
Classroom System,” International Journal of Software Engineering and
Knowledge Engineering, vol. 17, no. 2, 2007, pp. 191–206.
[46]
C. Fuchs and G. Groh, “Appropriateness of Search Engines, Social
Networks, and Directly Approaching Friends to Satisfy Information
Needs,” in Proceedings of the 5th Workshop on Social Network
Analysis in Applications, ser. SNAA ’15, Paris, France, August 2015,
forthcoming.
[47]
C. Fuchs, J. Hauffa, and G. Groh, “Does Friendship Matter? An Anal-
ysis of Social Ties and Content Relevance in Twitter and Facebook,”
in Proceedings of the Service Summit Workshop and Service Summit
2015.
Karlsruhe Institute of Technology, 2015.
65
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-436-7
COLLA 2015 : The Fifth International Conference on Advanced Collaborative Networks, Systems and Applications

