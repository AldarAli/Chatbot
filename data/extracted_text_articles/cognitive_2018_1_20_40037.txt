Feature Extraction Process with an Adaptive Filter on Brain Signals Motion 
Intention Classification
Luis F. Marín-Urías, J. Alejandro Vásquez-
Santacruz, Rogelio de J. Portillo-Vélez, Félix O. 
Rivera-Hernández 
Facultad de Ingeniería 
Universidad Veracruzana 
Boca del Río, Ver. Mexico 
e-mail: luismarin@uv.mx 
Mario Castelán 
Robótica y Manufactura Avanzada 
CINVESTAV - IPN 
Ramos Arispe, 25900, Mexico 
e-mail: mario.mcastelan@cinvestav.mx 
  
 
 
Abstract—Identifying 
motor 
imagery 
from 
an 
electroencephalogram (EEG) has been researched from 
different 
perspectives 
and 
methods 
of 
classification. 
Translating a brain signal into a language understandable for 
machines relies on feature extraction techniques, which vary 
from working on the frequency domain to dealing with raw 
data. Using statistical information to classify motor imagery 
has shown encouraging results. In this paper we benefit from 
statistical approaches and propose a different perspective to 
boost results obtained through brain signals provided by a low 
cost EEG. Our motivation is based on the natural separability 
of classes exhibited by statistical indicators such as the mean 
and standard deviation. A special emphasis in our method is 
made on filtering data to subject readings in an adaptive 
manner, leading to a successful classification rate of 97%, 
outperforming Hjorth's mobility and complexity measure, a 
state-of the art technique used in EEG signal classification. 
Keywords: BCI; EEG; Motion Intention Classification; 
Motor Imagery; KNN. 
I. 
 INTRODUCTION 
In order to improve self-sufficiency in people with 
reduced motion capabilities, it is necessary to create assistive 
technologies that not only are governed by a specific control 
strategy for a desired task, but that also allow the 
interpretation of motion intentions. 
Giving this self-sufficiency has been partially addressed 
from different perspectives. For instance, an autonomous 
service robot may facilitate users with objects they desire 
[1][2], easing quality of life but lacking in providing a 
sensation of independency. Another approach has been to 
provide robots with a tele-operation based control [3] or even 
using exoskeletons with muscular signal activation [14]. 
These are significant approaches that offer a greater 
sensation of self-sufficiency to users. Still, patients that have 
suffered motion disorder diseases like sclerosis and 
Parkinson are not able to steadily control robots or 
exoskeletons, neither by using hands or extremities nor by 
using signals provided by muscular nervous terminals. 
Identifying brain motion intentions is therefore an open 
problem as stated in [4], where a review of motion command 
identification is developed.  
Most of the work done on classifying brain signals uses a 
fixed band pass filter based on the work in Yuan et al. [4] 
where fixed frequencies are established for each type of data 
describing a mental state for a specific activity. Nevertheless, 
the brain is a labile organ, i.e., neural signals change through 
time while performing activities, which is known as 
neuroplasticity.  
In order to identify and decode elements of information, 
non-stationary models are required. For this reason, some 
signal treatment strategy is needed to identify neural 
activities, as in the work of Wang et al. [5], where a method 
to modulate brain signals through a mathematical model was 
proposed. 
From the efforts of Hazarika et al. [11], authors have 
used the discrete wavelet transform to obtain features and 
classify epileptic seizures by means of artificial neural 
networks (ANNs) as in  [12] or Support Vector Machines 
(SVM) as in the work of [10]. Other classification 
approaches can be found in [9]. As statistical features 
obtained from wavelets are more susceptible to time-
frequency localization than Fourier Transform, which is 
band limited, the latter assumes a more feasible approach for 
analysis.  
Using statistical data to classify elements from brain 
signals has been analyzed in [6][18] in order to obtain human 
emotions from different statistical methods, such as the mean 
and standard deviation analysis. The results of their work 
indicated that these two features are not effective enough 
compared to other approaches. Nevertheless, since their 
analysis is developed directly from raw data, a lack of pre-
processing operations may be a cause for the modest success 
exhibited by the mean and STD statistical analysis. Another     
feature extraction method based on statistical data is used in 
[19], where three features are obtained from the Fisher ratio 
of the Hjorth's activity, complexity and mobility in order to 
classify motor imagery. These statistical methods include 
time rather than only frequency domain as in STFT, 
increasing the flexibility of data.  
Brainwaves of motor imagery classification have also 
been used to control either virtual [15][16] or real [3] objects 
that respond to motion commands in two or three 
dimensions. This has been achieved by using a 64-channel 
7
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

 
EEG cap to describe thoughts, supported by a specific 
control technique. 
The main objective of our paper is to gather and classify 
motion intention commands from brainwaves by using a low 
cost EEG. Non-invasive EEG brain-computer interface 
systems have gained interest inside the research community. 
On one hand, they represent a harmless solution for humans; 
on the other hand, it is possible to obtain reliable enough 
information from brain signals after some processing of the 
data.  
This paper is structured as follows: in Section II, the 
general structure of the motion intention classification is 
introduced. Additionally, it is explained how pre-processing 
data through an adaptive filter is useful for achieving feature 
vector separability. In Section III, results are presented. 
Finally, in Section IV, we discuss the concluding remarks 
about the proposed approach. 
 
II. 
DATA ACQUISITION AND FILTERING 
The Motion Intention Classificator (MIC) system is 
basically done throughout three phases: 1) pre-processing 
raw information from brainwaves,  2) extraction of dominant 
features and 3) classification of the resulting features. These 
phases normally act sequentially and are interdependent. 
Figure 1 shows the inner work of a general architecture to 
interpret raw brainwaves into commands for tele-operation.   
The 
output 
features 
depend 
on 
the 
extraction 
methodology, which in this paper is addressed with a 
statistical mean-STD approach and with the Hjorth's 
Mobility and Complexity technique. 
 
Figure 1.  General Architecture of the MIC. 
 
 
A. Preprocessing data 
 
In order to obtain features from brainwave signals, it is 
required to set information that will serve as training data to 
be filtered from the noise induced by sensor readings.  
For setting the training data it is necessary to split raw 
data into sections according to a defined task that a test 
subject should execute. Once this has been carried out, 
synchronization with the training system is developed by 
parsing corresponding sections labeled with the task. 
In particular, the test subject is guided by computer 
images indicating a command of motion intention. The 
image is basically a geometric form that suggests the subject 
to concentrate on a particular mental task during 18 seconds 
with a specific intermittent signal  (2 seconds of a displaying 
task and 2 seconds of a neutral activity). This pattern is 
periodically repeated with a different command after T 
seconds for resting between tasks, as depicted in Figure 2. 
Four different active tasks of motion intention (here referred 
to as activities) are intended to be extracted: Right (R), Left 
(L), Up (U) and Down (D), while one more for no intention 
activity is considered as Neutral (N). The data acquisition 
process is an important part of this approach and it is 
illustrated in Figure 2, showing the alternation of the N 
activity (marked as checkerboard patterns) on each of the 
tasks. The total process lasted 97s for each test subject. We 
have set T to 5s between tasks to avoid interference. 
We asked 14 naive subjects to sit in front of a monitor 
giving instructions to them, the subjects must be focused on 
thinking the action indicated while avoiding body motions 
during the 97s experiment. After some experiments, we 
could notice that the neutral activity was correlated with its 
precedent mental activity, i.e., the N activity had some 
remaining “inertia'' from previous R, L, U and D tasks. In 
other words, while the training of the N activity was 
expected to occur during the 2s pause between each trial, in 
reality there was a presence of neutrality preceded by a non-
neutral emotion. This led to different Neutral Activities (NR, 
NL, NU, ND), which we used for classification. 
 
B. Filtering Data 
 
One key element proposed in our approach is the 
implementation of an adaptive filter, which is based on 
statistical information.  
Raw data, as used in the work of [6], is usually 
contaminated with noise that makes it difficult to perform the 
appropriate classification of different activities. This effect 
can be seen in Figure 3, where features from each class 
(represented as geometric figures), which have been obtained 
from raw data, appear not only close to each other but also 
mixed, i.e., they are hardly separable and their classification 
is harder. For this reason, applying a filter becomes 
necessary to reduce the noise coming from sensor signals. 
 
8
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

 
 
 
Figure 2.  Training session schema, task mental activities are in colors (duration 2s), while neutral activities are in grey between each training task. 
 
Figure 3.  Features extracted without pre-procesing data with two different feature extraction methods. Note how it is difficult to separate features due to 
their proximity between each activity class.. 
 
It is common to use a band pass filter based on fixed 
frequencies as in [18] for each brain region or for different 
kinds of mental activities. As mentioned above, the filter 
used in our approach is based on statistical information from 
raw data for each sensor, each set and each subject. It is 
worth noticing that our filter is not based on channels, but in 
information from activities (L, R, U, D and N). 
Let us define the high (µmax) and low (µmin) thresholds 
from data as: 
 
 
with: 
 
  
where xkj is the training set with the elements of a mental 
action k from sensor j, and w is the amplitude of the 
brainwave at the sample time ti in a total of m discrete 
readings from sensor.  
9
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

 
Figure 4.   Illustrating thresholds high µmax and low µmin used on each brain wave. Data above or below these thresholds are dismissed.
 
Setting thresholds in this way (as depicted in Figure 4) 
provides flexibility to the filter band so that the filter adapts 
to each subject and to the wave characteristics. This makes 
feature vectors belonging to one activity be closer to those 
from the same activity, and makes them more separated from 
those belonging to another class. The effects of the filter are 
more noticeable when comparing Figure 3a with Figure 5 
and Figure 3b with Figure 6. Similar filters have been used in 
[17] to classify frog call sounds (from different frogs), and 
are also commonly used in data transmission. 
 
C. Feature Extraction. 
After separating wave sections corresponding to mental 
activities and afer having filtered noise, it is necessary to 
reduce dimensionality by obtaining characteristics from 
waves, which facilitates classification.  
Due to the nature of the Emotiv Epoc device, there are 14 
analyzed individual signals (AF3, F7, F3, FC5, T7, P7, O1, 
O2, P8, T8, FC6, F4, F8, AF4). Additionally, a couple of 
features for each signal are required to extract corresponding 
activities, which are represented by a classification feature 
vector in the training set. In total, 28 features for each mental 
activity, period and subject are acquired and stored as 
features. 
We present two statistical methods for comparison: M1) 
taking mean and standard deviation as shown in Fig. 5, a 
close approach to what has been done in [6] and [18], but 
applied to motor imagery instead of emotions, and compare 
it with another statistical feature extraction method called 
M2) the Hjorth's mobility and complexity, a similar approach 
to what has been developed in [19]. Note that we do not take 
into account the Fisher ratio because in [19] they use it to 
find the dominant frequency to adapt in the training phase. 
This action is solved in our filter phase. Furthermore, we do 
not take into account Hjorth's Activity as a feature, which is 
highly correlated with Complexity and Mobility, so as to 
avoid redundant information. The behavior of M2 can be 
observed in Figure 6. Note how, while Figure 5 reveals a 
more noticeable separability between classes, Figure 6 shows 
how some features are highly separated although classes are 
still mixing. 
III. 
CLASSIFICATION RESULTS 
 
For experiments, 14 subjects were selected to generate the 
knowledge base; each subject participated at different times 
of the day (3 times per day for each subject) and in some 
subjects 
different 
“head/hair 
conditions” 
(wet/dry, 
with/without hair products). The knowledge base is formed 
leaving one subject out to test the classification results. The 
sensor used in the experiments is the Emotive Epoc one, 
which is a non-invasive sensor that provides 14 signals from 
each user; this is a low cost sensor that naturally induces 
noise through the wireless communication with the computer 
(RF). Nevertheless, the approach presented here is a generic 
approach that can be used with any sensor model, also 
improving classification rate in the presence of noise. 
Even when extracted features are filtered to increase the 
distance between them in the plot, as depicted in Figures 5 
and 6, those features are not linearly separable, so it is 
necessary to implement a different method to identify each 
mental activity from brainwaves.  
We propose using a kNN (k Nearest Neighbors) 
algorithm, where different values of k are analyzed  (the 
number of neighbors from all activities) to identify which of 
them fits the best results. This algorithm has been widely 
used in many classification problems for its simplicity of 
training. As we had the hypothesis that features obtained in 
this way would generate equidistant clusters, kNN appeared 
to fit the best and helped us prove that a good outcome could 
be achieved. 
 
10
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

 
Figure 5.  4D plot showing features after filtering distances on two signals (FC5 and FC6), with Mean FC5  vs Mean FC6  represented by the X and Y axis, 
while STD FC5 vs STD FC6 are represented by Z. Colors (from blue to red) refer to distances.
 
Figure 6.  4D plot showing two perspectives of the distance on two signals (FC5 and FC6) using Hjorth's mobility and complexity features after filtering,  
axes and colors (from blue to red) refer to distances.
The results from the classification algorithms over Mean 
and STD are presented in Table I, where it can be noticed 
that it is best to only consider three neighbors for 
effectiveness, training and search times. This can be caused 
by the structure of the class, which seems to be arranged 
more along lines (as seen in Figures 5 and 6) than along 
equidistant clusters. 
Figure 7 and Table II present the difference between both 
methods M1 and M2. From the figure, it is noticeable how 
using an STD-mean strategy provides better results than 
Hjorth's Mobility and Complexity in all cases of 
classification, since the overall percentage of effectiveness is 
higher. Even though the method M2 has a lower accuracy 
rate than M1, it shows better results in motor imagery 
classification than in [19] (79.1%) where the same features 
are used. In Figure 7 and 8, the dashed line represents M1 
while the continuous line represents M2; the X-axis refers to 
neighbor number.  
 
 
 
11
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

 
 
TABLE I.  
KNN K-VALUES, EFFECTIVENESS, TRAINING TIME AND 
SEARCH TIME OVER MEAN AND STD 
K 
Avg. Performance 
Effectiveness (%) 
Training(s)  
Search(s) 
3 
97.23  
0.000641731 
0.0006567 
5 
96.27 
0.000661157 
0.00066496 
9 
94.67 
0.000644846 
0.00068063 
13 
94.00 
0.000644687 
0.00068448 
17 
89.20 
0.000647488 
0.00070822 
25 
82.80 
0.000638758 
0.00073605 
30 
78.40 
0.000653181 
0.000760 
 
 
TABLE II.  
KNN AVG. OF EFFECTIVENESS COMPARISSON BETWEEN 
M1 AND M2 
K 
Avg. Effectivenes (%) 
M1 
M2  
3 
97.23 ± 3.7 
94.27 ± 4.39 
5 
96.27 ± 3.1 
91.87 ± 7.2 
9 
94.67 ± 3.91 
83.2 ± 8.37 
13 
94.00 ± 4.57 
79.33 ± 8.24 
17 
89.20 ± 10.05 
78.93 ± 7.95 
25 
82.80 ± 17.92 
75.20 ± 6.66 
30 
78.40 ± 18.99 
74.93 ± 12.15 
 
Figure 7.  Effectiveness rates of classification between the two feature 
extraction methods M1 (blue) and M2 (red). 
 
In Table III, we show 250 classification tests done with 
50 cases of each class (the same 14 subjects with different 
conditions in cross-validation) for k=3 while leaving one 
subject out and validating with the rest. From the table it can 
be inferred that the errors in classification are mainly related 
with the Left activity. This can be related with the structure 
of the training process, where Left activity is the first in the 
training set. 
 
TABLE III.  
CLASSIFICATION  
Intention 
Confusion Matrix for k=3 using only mean and 
standard deviation 
Left 
Right 
Neutral 
Front 
Back 
Left 
50 
0 
0 
0 
0 
Right 
3 
47 
0 
0 
0 
Neutral 
1 
1 
48 
0 
0 
Front 
0 
0 
0 
50 
0 
Back 
2 
0 
0 
0 
48 
 
Figure 8.  Searching time between methods M1 and M2. 
IV. 
CONCLUSION AND FUTURE WORK 
We have presented a statistical-based approach to train, 
filter and classify motion intentions from brain signals. Our 
method was motivated by the good separability of classes 
provided by the mean and standard deviations of the 
gathered data. Filtering and performing data acquisition in 
this manner allow us to report satisfactory results, reaching 
above 97% of accuracy on our test data and with a “lazy” 
classifier such as kNN, allowing the brain signals to become 
suitable not only for tele-operation purposes, but also for the 
purposes of emotion recognition. As an additional result, 
brain inertia could be observed from the experiments. We 
found that this brain behavior depended on the previous 
immediate motion intention of the subject, pushing the 
neutral intention to be closely related with previous brain 
activities, deeper experiments in this subject will be needed 
in order to obtain more quantitative results. This inertia 
helped us re-organize the training process by inserting 
neutral actions between each activity, thus redefining the 
usual methodology in literature where “pause” is not taken 
into account as a part of the knowledge base.  
As an extension to this work, we will seek for obtaining a 
bigger sample of subjects in order to avoid biasing our 
12
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

results. Also, it is recommendable to use some other 
classification techniques (e.g., Artificial Neural Networks) to 
obtain more stable results. Furthermore, we plan to 
implement our methodology on a real-time tele-operation 
system, which could be used to identify emotions and mental 
states that are relevant in tele-operation issues. For this, it 
may be necessary to induce emotions while acquiring at the 
same time the mental states.  
 
 
REFERENCES 
[1] 
E. A. Sisbot,  L. F. Marin-Urias, R. Alami, and T. Simeon, ”A human 
Aware Robot Motion Planner”, IEEE Transactions on Robotics, Vol 
25. Issue: 5, pp. 874-883 Oct. 2007.  
[2] 
E. A. Sisbot,  L. F. Marin-Urias, X. Broker, D. Sidobre, and R. Alami  
”Synthesizing robot motions Adapted to human presence”, Intl. J. of 
Social Robotics,  Vol. 2 Issue 3, pp. 329-343, Sep. 2010.  
[3] 
K. LaFleur, ”Quadcopter control in three-dimensional space using a 
noninvasive motor imagery-based braincomputer interface”. Journal 
of Neural Engineering, Vol. 10. (2013)  
[4] 
H. Yuan, and B. He, ”Brain-Computer Interfaces Using Sensorimotor 
Rythms: Current State and Future Perspectives”, IEEE Transactions 
On Biomedical Engineering, Vol. 61 NO. 5, pp 1425-1435, May, 
2014.  
[5] 
Y. Wang et al., ”Tracking Neural Modulation Depth by Dual 
Sequential Monte Carlo Estimation Point Process for Brain-Machine 
Interfaces.”, IEEE Transactions On Biomedical Engineering, Vol. 63 
NO. 8,p.p 1728- 1741, May, 2016.  
[6] 
T. Y. Chai, S. S. Woo, M Rizon and C.S. Tan, ”Classification of 
human emotions from EEG signals using statistical features and 
neural network”, International Journal of Integrated Engineering, 1 
(3), 71-79, 2010.  
[7] 
I. Juarez-Moreno, L.F Marin-Urias, J.A. Vasquez-Santacruz, M. 
Vigueras-Zuñiga “Interface de comunicación remota entre un sistema 
clasificador de ondas cerebrales y un robot móvil”, Revista de 
aplicaciones de ingeniera, Volumen 3 No. 9 Pg. 109-116 2016  
[8] 
E. A. Sisbot, L. F. Marin-Urias, X. Broquere, D. Sidobre, R Alami 
Synthe- sizing robot motions adapted to human presence International 
Journal of Social Robotics 2 (3), 329-343 2010  
[9] 
A. Subasi, ”EEG Signal Clasification using wavelet feature estraction 
and a mixture of expert model, Expert Systems with Applications”, 
vol. 32 , 1084-1093, 2007.  
[10] A. Subasi, and M. I. Gursoy, ”EEG Signal Classification using PCA, 
ICA, LDA and support vector machines”, Expert Systems with 
Applications, vol. 37, 8659-8666, 2010.  
[11] N. Hazarika, J. Z. Chen, A.C. Tsoi, and A. Sergejew, ”Classification 
of EEG signals Using the wavelet transform”, Journal of Signal 
Procesing, Vol.59, 61-72. 1997  
[12] H. Adeli, Z. Zhou and N. Dadmehr, ”Analysis of EEG records in an 
epileptic patient using wavelet transform”. Journal of Neuroscience 
Methods, vol. 123, 69-87. 2003  
[13] N. Kwak, N. Muller, and S. Lee, ”A lower limb exoskeleton control 
system based on visual evoked potentials”. Journal of Neural 
Engineering, Vol. 12, No. 15, 2015.  
[14] K. Kiguchi, T. Tanaka and T. Fukuda, ”Neuro-Fuzzy control of a 
robotic exoskeleton with EMG signals”. IEEE Transactions on Fuzzy 
Systems, Vol 12, No. 14. 2004.  
[15] D. J. McFarland, W. A. Sarnacki, and J. R. Wolpaw, 
”Electroencephalographic (EEG) control of three dimensional 
movement” Journal of Neural Engineering, vol.7 No. 3 036007, 2010.  
[16] A. S. Roye, A. J. Doud, M. L. Rose and B. He, ”EEG control of a 
virtual helicopter in 3 dimensional space using intelligent control 
strategies”, IEEE Transactions Neural Systems Rehabilitation 
Engineering, Vol. 18. No. 6, pp 581-589, Dec. 2010.  
[17] J. Xie, M. Towsey,  L. Zhang, J.  Zhang and P. Roe, ”Feature 
Extraction Based on Bandpass Filtering for Frog Call Classification”, 
International Conference on Image and Signal Processing ICISP 
2016: Image and Signal Processing pp 231-239, Trois- Rivires, QC, 
Canada, May 30 - June 1, 2016.  
[18] K. Takahashi ”Remarks on SVM-Based Emotion Recognition from 
Multi-Modal Bio-Potential Signals”, IEEE International Workshop on 
Robot and Human Interactive Communication Proceedings of the, 
Kurashiki, Okoyama Japan, September 20-22 2004.  
[19] S. Oh, Y. Lee, and H. Kim, ”A Novel EEG Feature Extraction 
Method Using Hjorth Parameter”, International Jour- nal of 
Electronics and Electrical Engineering Vol. 2, No. 2, June, 2014  
 
 
13
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

