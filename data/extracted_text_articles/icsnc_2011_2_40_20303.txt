Mobile broadband everywhere : the satellite a solution for a rapid and large 3,9G
deployment
Caroline BES and Christelle BOUSTIE
CNES (French Space Agency)
Toulouse, France
caroline.bes@cnes.fr, christelle.boustie@cnes.fr
Ari HULKKONEN*, Juha YLITALO*,
Ulla.ELSILA* and Pekka PIRINEN+
* Elektrobit Wireless Communications
+University of Oulu, Centre for Wireless
Communications
Oulu, Finland
Ari.Hulkkonen@elektrobit.com ;
Juha.Ylitalo@elektrobit.com;
Ulla.Elsila@elektrobit.com ; pekkap@ee.oulu.fi
Abstract— The aim of this paper is to demonstrate the
feasibility
of
the
concept
of
a
complementary
Satellite
Component to the LTE (3GPP Long-Term Evolution, also
known as 3,9G) and/or WiMAX (Worldwide Inter-operability
for
Microwave
Access)
terrestrial
network
that
mobile
network operators intend to deploy to support a mass market
offer of “Internet connectivity while on the move” and to show
its benefit in ensuring truly global coverage.
In this paper, we show that the cohabitation of the terrestrial
network and the satellite at the same frequency on the same
global coverage is possible.
I.
INTRODUCTION
Hybrid
integrated
system
(associating
satellite
and
terrestrial transmitters) is an opportunity for this sector to
complete the coverage of current commercial mass market
and to answer to governmental user needs.
“Integrated system” refers to a system composed of a LTE
and/or WiMAX terrestrial network and a multibeam satellite
component that re-uses the same frequency band than the
terrestrial’s one. This integrated system improves the spectral
efficiency of the overall system and spatially optimize the
use of the frequency bands.
Figure 1. Hybrid integrated network
The main mission of this concept is then to offer a hybrid
satellite
and
terrestrial
variation
of
pure
terrestrial
technologies
for
commercial
deployment
of
mobile
broadband, with nomadic terminal (Ultra Mobile PC -
UMPC) as main target. This axis appears promising since it
provides a solution to commercial operators enabling them to
cover rapidly a large chunk of the territory and not only 15 to
20% of the surface as it is foreseen for real mobile
broadband (approximately 2 Mbps per user on a UMPC like
terminal within a few years) deployment based on sole
terrestrial components of LTE and/or WiMAX. It then gives
the operators a real opportunity to make use of their
spectrum beyond the first 15-20% of the territory (e.g.:
spectrum usage of UMTS in the first 5 years).
Indeed, deploying more sites in rural areas would be so
expensive for the parts of lowest density of population that
another solution is now considered: CNES is working on a
next-generation mobile satellite system quickly deployable,
tightly integrated with terrestrial networks, and behaving as
“terrestrial cells in the sky”. The terrestrial component will
cover high density built-up areas and the satellite component
will bring services to the rest of the coverage area.
The sharing of the terrestrial frequency bands with satellite
component allows a better spectrum management mostly on
rural zone. However, frequency reuse between terrestrial and
satellite components may imply co-channel interferences
between them.
In this paper, we show that the satellite component has a
minimum impact in term of interference on terrestrial
network and we present a solution of integrated system.
II.
SATELLITE AND TERRESTRIAL SUB-SYSTEM
A.
Satellite sub-system
Mobile satellite next generation system becomes an
appropriate solution for rural coverage in terms of capacity
performance thanks to the use of a large deployable antenna
allowing (around 24 m of diameter) a large number of thin
beams with between 100-160 km of diameter on ground. The
beam densification is in favor of a better frequency reuse and
of an increase of the capacity density.
43
ICSNC 2011 : The Sixth International Conference on Systems and Networks Communications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-166-3

Figure 2. Example of hybrid integrated system deployment on earth
Figure 3. Example of satellite European coverage (around 400 beams)
At our latitude, geostationary orbits are seen at low elevation
angle (between 30° and 40°) and require high shadowing
margin to have a good availability of the service. The choice
of Highly inclined Earth Orbit (HEO) for next-generation
mobile
satellite
system
allows
a
high
geographical
availability at our latitude even in suburban zone thanks to
the fact that the satellite elevation is better than 60°
everywhere on the satellite coverage zone. This better
propagation condition (less shadowing margin) promotes the
use of better spectral efficiency modulations and improves
the global capacity.
B.
Terrestrial sub-system
The integration of the satellite component and the
terrestrial component of the radio network is performed at
the physical layer. Therefore, the physical layer of the
satellite component is following either the LTE or the
WiMAX standard. Some modifications may be required,
though.
1)
Cellular standards
a) LTE
The 3rd Generation Partnership project (3GPP) has
standardized LTE (3GPP Long Term Evolution) to meet the
demand of rapidly growing mobile user data traffic. LTE
applies in downlink the orthogonal frequency division
multiple access (OFDMA) technique to enable efficient
time-frequency
radio
resource
allocation
for
improved
system performance. OFDMA is a multiple access technique
based
on
orthogonal
frequency
division
multiplexing
(OFDM), a digital multi-carrier modulation scheme that is
widely used in wireless systems but relatively new to
cellular.
b) WiMAX
WiMAX
is
also
an
OFDMA
based
broadband
technology especially for high-speed internet data access. It
applies OFDM modulation both in downlink and uplink.
From the physical layer point of view, the mobile WiMAX
(IEEE802.16e) applies the adaptive radio link techniques in a
similar manner as LTE.
c) Fractional Frequency reuse
However, OFDM does have some disadvantages. The
subcarriers are closely spaced making OFDM sensitive to
frequency errors and phase noise. For the same reason,
OFDM is also sensitive to Doppler shift, which causes
interference between the subcarriers. It is known that OFDM
will be more difficult to operate than CDMA at the edge of
cells. Therefore, some form of frequency planning at the cell
edges will be required as shown in the Figure 4.
Different bandwidths can be allocated to cell edges and to
cell centers and the band division can be either hard or soft.
Several subbands can be reused at the cell edges to avoid
inter-cell interference and, moreover, the powers for cell
edges and cell centers can be controlled to guarantee users
QoS
requirement
and
further
reduce
the
inter-cell
interference (Figure 4).
Figure 4. Frequency planning in OFDM
LTE and WiMAX are aimed at frequency reuse 1 scheme.
This target is facilitated by several link and system level
features, which introduce techniques for mitigating and
coordinating intra- and inter-cell interference.
2)
Interference mitigation in the terrestrial system
These next generations of cellular network aim to provide
an increase of their capacity by maximising the use of the
frequency spectrum. This implies the use of sophisticated
interference mitigation techniques.
44
ICSNC 2011 : The Sixth International Conference on Systems and Networks Communications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-166-3

These techniques are classified into three major categories
such
as
interference
cancellation
through
receiver
processing,
interference
randomization
by
frequency
hopping, and interference avoidance achieved by restrictions
imposed in resource usage in terms of resource partitioning
and power allocation. The benefits of these techniques are
mutually exclusive, and hence, a combination of these
approaches is likely to be employed in the system.
In traditional interference avoidance, inter-cell interference is
handled by the classical clustering
technique. However,
while this technique reduces interference for the cell edge
user terminals, it compromises system throughput due to
resource partitioning.
As stated before, LTE and WiMAX networks have been
designed for a reuse factor of 1 and downlink transmissions
are based on OFDM. In addition to data allocation in both
time and frequency domains, it creates new possibilities to
utilize the available spectrum by flexible and intelligent
subcarriers allocation, which is based on both frequency and
time domain utilization. In case of a single frequency
network this would be one of the ways to avoid interference
from the satellite spot
beams operating on the same
frequency sub-band.
III.
RESULTS
A.
Influence of the satellite in term of power
The power flux density (PFD) emitted by the satellite is
considered as constant upon all the coverage of the Satellite
system: -104 dBW/m2/MHz. This PFD is considered as
interference from the terrestrial point of view and causes a
decrease of the LTE/WiMAX cell size.
Figure 5. System topology for LTE simulation
Figure 5 presents the system configuration and Figure 6
shows different diameters of a single cell with a given
emitted power of the base station 1. Diameter for the cell
alone (without interference) 2. Diameter with the influence
of a neighbour cell 3. Diameter with the influence of a
neighbour terrestrial cell and the satellite spot beam.
Cell range variation (Reuse 1)
0
2
4
6
8
10
12
14
16
18
20
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
1.2
1.3
1.4
1.5
Distance Terminal - Base station (km)
Global throughput (Mbps)
Cell without interference
Cell affected by neighboring base
station interference
Cell affected by neighboring base
station and satellite interference
Figure 6
B.
STUDY OF THE INFLUENCE OF THE SATELLITE
1)
Influence of the satellite on LTE/WiMAX network
Tolerating the high interference levels that occur in reuse
1 networks is based on both adaptive 2-dimensional
scheduling,
which
can
utilize
the
radio
channel
characteristics in an optimum way. In addition, interference
cancellation
is
improved
with
multiantenna
receivers.
Considering all this, it seemed possible that LTE would
provide
acceptable
performance
with
satellite
overlay
scenario without major design or network level changes.
The downlink of both LTE and WiMAX systems is based
on multicarrier modulation and it occupies relatively wide
bandwidth. The terrestrial radio channel, on the other hand,
introduces quite strong frequency selective fading, which
means that an advanced multi-dimensional scheduling can
allocate dynamically the best slot in both time and
frequency domain to each user. Therefore, the HSDPA time
domain scheduling principles are valid also in LTE [1]. As
the radio channels between an individual mobile user, base
stations and the satellite are non-correlating, a good slot can
almost certainly be found for each user.
This
study
also
investigated
the
affect
of
optimal
scheduling. This gave an upper bound on the throughput
performance at the cell edge of an LTE link. As a lower
bound, the full band average signal to interference plus
noise ratio (SINR) was also calculated. Three scenarios are
compared: 1) no interference, 2) terrestrial interference only,
and 3) terrestrial and satellite overlay interference.
2)
Simulation methodology
The simulation aim is to investigate the affect of
interference on the LTE throughput (the effect on a WiMAX
system would be very similar).
45
ICSNC 2011 : The Sixth International Conference on Systems and Networks Communications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-166-3

In short, the mobile user is spread in a region that includes
both sides of the cell edge. The transmit power is set to 20
W on a 5 MHz bandwidth and the antenna gain is 15 dBi.
The carrier frequency is 3.45 GHz and the terminal noise -
107.5 dBm. The spread is repeated for a number of channel
impulse response (IR) realizations generated by the IMT-A
[2]
channel
model
generator.
Each
channel
snapshot
corresponds to a random snapshot of the defined scenario’s
propagation conditions. Thus, with a sufficient number of
snapshots (or drops) we obtain a statistically stable average
of the channel conditions.
For each channel snapshot, the IR is converted to a
frequency response from which the SINR is calculated, both
across the entire bandwidth and for each LTE resource
block individually. LTE resource scheduling is emulated by
choosing the resource block (RB) that produces the highest
SINR as the scheduled RB. This should give a good upper-
bound on the performance enhancement from scheduling.
As a lower bound, the full band SINR, which is the average
SINR of the RB, is considered.
On Figure 7, the minimum throughput is plotted for the
“scheduled” resource blocks as a function of the mobile user
location. This analysis takes into account the pilot overhead
and the discrete coding and modulation schemes in the LTE
downlink. The modulation and coding schemes and their
respective SINR requirements are taken from [3].
Figure 7 Single Ressource Block throughput in presence of interference
To calculate the cell capacity in terms of throughput, 25
users were placed randomly from 0.1km up to 6km from the
eNodeB and a single resource block was allocated for each
user.
The cell centre capacity for 5 MHz bandwidth was then
obtained for the users at a distance of 0-3km from the
eNodeB from the throughput simulation values shown in
Figure 7. Correspondingly, the cell edge capacity was
obtained from the throughput values for users at 3-6km from
the eNodeB. 10000 simulation rounds with 25 different
random UE positions in each round were performed for
achieving average throughput values. Results are presented
on Table 1.
5 MHz throughput in cell (Mbps)
Interference scenario
Cell
Cell centre
Cell edge
No interference
10.7
15.12
6.43
Intercell interferences
9.63
14.69
4.74
Intercell + satellite interf.
9.36
14.44
4.46
Table 1 Average throughput values in an LTE cell (5MHz
bandwidth)
The simulation results show that it is the inter-cell
interference which dominates the throughput loss while the
satellite interference plays a minor role. In fact, the loss due
to the satellite interference is only at about 2.8%, 1.7%, and
5.9% levels at entire cell, cell centre, and cell edge,
respectively. Thus the impact is at largest at cell edge, as
expected.
IV.
CONCLUSIONS
Based on the simulations it seems that introducing a
satellite overlay network on top of a terrestrial LTE or
WiMAX
network
will
not
introduce
a
significant
interference issue in the case sophisticated interference
compensation techniques are used. LTE has been designed
to handle reuse 1 scenario, which means the entire network
is using the same operating frequency band. This creates a
high intercell interference level, which must be handled
anyway. Adaptive mechanisms are supported by LTE and
also WiMAX thus enabling efficient interference avoidance
and compensation. The satellite overlay component does not
increase the total interference level significantly and it was
estimated that the capacity loss in a cell is only less than 1%
and even at the cell edges the performance criteria will be
met. The study clearly shows that a satellite overlay
component can be introduced and integrated to LTE or
WiMAX terrestrial network.
ACKNOWLEDGMENT
Caroline Bès and Christelle Boustie thank warmly
Athéna Ibrahim for her help.
REFERENCES
[1]
H. Holma and A. Toskala, Eds., WCDMA for UMTS, HSPA
Evolution and LTE. Wiley 2007
[2]
ITU-R M.2135-1, Guidelines for evaluation of radio interface
technologies for IMT-Advanced.12/2009. Internet:
http://www.itu.int/dms_pub/itu-r/opb/rep/R-REP-M.2135-1-2009-
PDF-E.pdf, retrieved 02.02.2011.
[3]
Sesia, Stefania, Issam Toufik, and Matthew Baker, “LTE-the UMTS
long term evolution: from theory to practice”. West Sussex: John
Wiley & Sons, 2009.
46
ICSNC 2011 : The Sixth International Conference on Systems and Networks Communications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-166-3

