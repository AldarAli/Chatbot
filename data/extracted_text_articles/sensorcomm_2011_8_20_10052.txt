Energy Efficient 2-Tiers Weighted in-Sensor Data Cleaning 
 
Jacques M. Bahi, Abdallah Makhoul, Maguy Medlej 
Computer Science Laboratory (LIFC) 
University of Franche-Comté 
Rue Engel-Gros, 90016, Belfort, France 
{jacques.bahi, abdallah.makhoul, maguy.medlej}@univ-fcomte.fr
 
 
Abstract— Managing efficiently the battery and power 
consumption became a major challenge in sensor networks. 
Data transmission is very costly in terms of energy which leads 
to think of a data cleaning technique in order to reduce the size 
of packets sent to the sink. However, the quality of the 
information should be preserved during the in-network 
transmission. This paper introduces a tree-based bi-level 
periodic data cleaning approach implemented on the source 
node and the aggregator levels. Our contribution in this paper 
is two folds. First we look on a periodic basis at each data 
measured and periodically clean it while taking into 
consideration the number of occurrences of the measures 
captured which we shall call weight. A data cleaning is 
performed between groups of nodes on the level of the 
aggregator which, contains lists of measures along with their 
weights. This algorithm will not tolerate the effect of the 
information that each data measurement provides by 
preserving the weight of each measure. The experimental 
results show the effectiveness of this technique in terms of 
energy efficiency and quality of the information by focusing on 
a periodical data cleaning while taking into consideration the 
weight of the data captured. 
Keywords- Sensor Networks, periodic data aggregation, tree 
based algorithms, quality of information. 
I. 
 INTRODUCTION  
Controlling and predicting natural disasters, preventing 
failures, improving food production, overall productivity and 
improving human well being became eminent demand thus 
pushing subjects’ related to think of instantly recurrent 
information collection and prediction mechanisms  all 
serving the above purposes among others. Monitoring large 
range of application areas, mostly in which power or 
infrastructure limitations make a wired solution costly, 
challenging or even impossible, constituted an essential goal 
for scientific researchers’ worldwide. Latest researches show 
that this task is dedicated to spatially distributed autonomous 
devices. Such devices, or nodes, combined with routers and a 
gateway constitute a wireless sensor network (WSN). 
Wireless sensor networks are composed of large distributed 
number of sensor nodes; each sensor node has a separate 
sensing, processing, storage, and communication unit. The 
sensing unit is responsible for gathering data from its 
environment whereas the processing unit in the form of a 
microprocessor manages the tasks. Memory is used to store 
temporary data or data generated during processing. The 
communication unit communicates with the environment. 
The distributed measurement nodes communicate wirelessly 
to a central gateway, which, provides a connection to the 
wired world where collecting, processing, analyzing, and 
presenting of measurement data is needed. Each collects a 
considerable amount of raw data which is sent periodically to 
a central sink (gateway).  Each sensor node is powered by a 
battery which, supplies energy; however sensor nodes are 
tightly limited in battery, power and memory storage. As a 
result, a sensor node is not expected to carry huge amount of 
data or complex computations. It is important to highlight 
that a sensor network usually consists of thousands or ten 
thousands of nodes deployed redundantly in order to ensure 
reliability and where each single sensor is expected to 
cooperate with other sensors to provide service. Thus the 
collected data is partially redundant and is subject to 
aggregation offering. The major challenge in a wireless 
sensor network is improving the lifetime of the network in 
other word managing efficiently the battery and power 
consumption. Recent researches focused on such task as it is 
difficult and cost ineffective to recharge the battery. Energy 
is mainly consumed during data transmission from the 
source node to the sink (gateway) making network data 
transmission one of the core issues to address by reducing 
energy consumption within the wireless sensor network. 
Furthermore, data accuracy is another main design concern 
in wireless sensor networks. In order to avoid any faulty 
alarms, the distributed measurements nodes communicate 
wirelessly to a central gateway, providing “interaction 
between people or computers and surrounding environment” 
[3]. To achieve data accuracy we strongly believe that only 
the right information should be communicated through the 
wireless sensor networks. The authors intrigued by such 
interesting challenge suggest through this article a multilevel 
data cleaning algorithm aiming to optimize the volume of 
data transmitted by saving energy consumption and reducing 
bandwidth on the network level. 
This article introduces a periodic multilevel data 
cleaning algorithm aiming to optimize the volume of data 
transmitted thus saving energy consumption and reducing 
bandwidth on the network level. Instead of sending each 
sensor node’s raw data to a base station, the data is cleaned 
periodically at the first level of the sensor node then another 
“data aggregator “ sensor node  collects the information from 
its associated nodes. We shall call this first level “in-sensor 
process periodic cleaning” approach. A second cleaning is 
applied on the level of the aggregator node itself. The 
197
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

cleaned data is finally sent from the aggregator to the base 
station.  It is important to note that the weight of each 
measure (number of occurrences of each measure in the set) 
is preserved through both described above techniques thus 
preserving the quality of information provided by each 
measure. The described approach pioneers in the field of 
focusing on a periodical data cleaning while taking into 
consideration the weight of the data captured. 
The rest of the paper is organized as follows: The 1st 
section presents and accredits data cleaning and aggregation 
related work and research. While the second introduces the 
first level periodic data cleaning algorithm applied on the 
sensor node level. The third presents a heuristic method 
aiming to clean data on the aggregator level and index the 
data cleaned by a weight significant of its redundancy and 
quality. The fourth section shows the experimental results of 
our suggested multi cleaning algorithm and its contribution 
to the network life through optimizing energy consumption. 
We conclude by emphasizing the added value of our 
approach and its contribution to the world of wireless sensor 
network research. 
II. 
RELATED WORK 
Limited battery power and high transmission cost in 
wireless sensor networks make in-network cleaning and 
aggregation a challenging area 
for research. Data 
transmission is the most costly operation in sensors [1], 
compared with it, the energy cost of in-network computation 
is trivial and negligible. Reducing the number of packets 
being transmitted in the network will eventually lead to 
energy consumption reduction. In order to reduce the 
number of packets, data cleaning and data aggregation 
related approaches have been conducted. Based on this, we 
have 
presented some 
network 
data 
reduction 
and 
aggregation related works that fall into different levels of 
data cleaning approach: In-network approach between hops 
or on the level of the sensor itself where each sensor takes 
up some computation according to the applications (e.g., 
query processing, data collection, event detection, and so 
on). Several performance measures like network lifetime, 
data accuracy, false alarm, high data redundancy, latency 
and scalability need to be considered concurrently [4][5]. 
Zhuang and Chen Hong Kong [2] focuse on the outliers 
cleaning within multi-hops by including wavelet based 
outlier correction and neighboring DTW (Dynamic Time 
Warping) distance-based outlier removal. The cleaning 
process is accomplished during multi-hop data forwarding 
process, and made use of the neighboring relation in the 
hop-count based routing algorithm. On the other hand, data 
aggregation methods in sensor networks have been reported 
[11]. Zheng, Chen, and Qiu [12] propose a method to build 
an aggregation tree model in WSN such that the captured 
data are aggregated along the route from the leaf cells to the 
root of the tree. In this scheme, the tree is not built directly 
on sensors, but on the non overlapping cells which, are 
divided with equal sizes in the target terrain. A 
representative sensor in each cell acts in name of the whole 
cell, including forwarding and aggregation of the sensing 
data in its cell and the receiving data from the neighbor 
cells. In light of large-scale and high-density sensor nodes, 
the scheme cuts down the data transmission overhead from 
three aspects. Firstly, primary aggregation should be 
conducted in the cell, based on the observation that the 
measurement data in one small cell are almost identical. 
Secondly, aggregation operation in one large-scale network 
should be directed to avoid the dynamic change of 
aggregation 
topology. 
Finally, 
using 
cell-by-cell 
communication instead of hop-by-hop communication 
reduces the density of communication and the complexity of 
the 
aggregation 
topology 
in 
the 
network. 
Greedy 
aggregation is proposed in [9][11], where a tree is 
constructed to indicate the path from each sensor node to the 
sink. The shortest path linking a node to the sink is used as 
the initialization of the tree. Then, the shortest paths linking 
the remaining nodes to the current tree will be incrementally 
added to enlarge the tree. With this technique, the packets 
will be aggregated as early as possible and the aggregated 
packet will be directly routed back to the sink. However, the 
efficiency of the greedy incremental method is entirely 
determined by the shortest path. The data transmission is not 
reliable since once the path is broken, a large region will be 
disconnected and will not be able to send information to the 
sink. 
All the presented work didn’t take into consideration the 
accuracy of the information affected by the number of 
similarity between measures. In this paper we shall focus on 
periodic data collection at the first level of sensor nodes. We 
consider that at each determined time interval the sensing 
unit is configured to capture measurements. At this level, our 
approach consists of comparing measurement captured at an 
interval of time t with measurements already captured at a 
previous interval in order to perform some in-sensor 
processing and evaluate data. We shall call this in-sensor 
process periodic data cleaning approach. Our aim is to 
periodically clean the data captured from noisy and 
redundant measures while maintaining an acceptable level of 
quality and accuracy of the information that is deduced from 
the captured measures. The measures' occurrences are called 
weighted measures in this article and will serve as a 
parameter passed to all data cleaning levels and subsequently 
saving accuracy of the purged data. Such scheme will form 
in future works training set for the classifier, predicting with 
reasonable accuracy the class of each instance fed. When 
applying the suggested algorithm, it cleans periodically the 
data while assigning to each measure its proper weight. The 
cleaning will be processed in two steps: the source node will 
constitute the first step whereas a special sensor node called 
aggregator receiving the data from different source nodes 
will conduct data cleaning at the second step. 
III. 
DATA AGGREGATION SCHEMA 
This section gives the main definitions and notations, 
together with our approach that will be used for an efficient 
198
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

and accurate in sensor nodes data reduction. The main focus 
is the periodic data collection where each sensor takes 
measurement at regular time interval. We classify our 
approach as 2 tiers data cleaning approach: the source node 
will constitute the first tier whereas a special sensor node 
called aggregator receiving the data from different source 
nodes will be the subject of data cleaning at the second tier. 
Fig. 1 illustrates our tree based data aggregation scheme. At 
the first tier exists the source nodes. The second tier contains 
the aggregator. 
 
Figure 1.  Tree based data aggregation scheme 
A. Definitions and Notations 
The set of sensor nodes is denoted by N = {1, 2, …, n}, 
where n is the number of nodes. Each node is composed of 
many sensors S that produce a measurable response to a 
change in a physical condition like temperature or pressure 
or humidity, etc. Each sensor node takes a vector of 
measurements M[t] = (m[t1],…m[t-1]) at regular time 
interval t during a period . The unit time is called slot, 
whose 
length 
is 
the 
time 
interval 
between 
two 
measurements. After -1 slots, each sensor node Ni will 
have a vector of measurements Mi as follows: 
      
 
 
 
 
Definition1: Substitution  between two measures 
At each interval I and for each sensor s, we associate to 
each measure ms[ti] a function noted  Substitution(m[ti], 
m[tj]) which, define a kind of similarity to unify or not with a 
measure ms[tj]  taken a time tj  / j< i. 
Substitution m ti , m[tj] =
 
 
 
.
1    if | m[ti −  m tj || ≤ δ
 
0                            otherwise.
       
  
where  is a threshold fixed by the application.  
 
Definition2:  Weight of a measure 
Intuitively, redundancy gives more importance to some 
information which, are represented by many features and 
may occult less than others that are less present. We define 
weight of the measure m at a time t the total number of 
measures captured after the time t and can be unified with m. 
 
Weight(m[ti]) = 
j=ti+1Substitution(m[ti], m[tj]) 
 
Definition3:  Cell’s  measure 
On the level of an aggregator A, we define a cell’s 
measure cell Ca[i] = A[i](i, mi) such that the cell contains 
the received measure mi from the node ni with its 
corresponding weight i. A cell Ca[i] is built based on 
distinct measures and weights existing in the aggregator A. 
we refer to Ca[i](m) as the measure in a cell while the 
respective weight is Ca[i](). 
B. First Tier: Periodic data Cleaning 
The proposed method calculates on periodic basis the 
substitution function between the measures already captured 
and the current measure captured at the current period. If the 
substitution is equal to 1, which, means that the new measure 
can be unified with the existing measure on which we are 
performing the substitution function, the weight of the 
existing measure is incremented by 1 and the new measure is 
disregarded. Algorithm1 illustrates the first tier. At the end 
of this algorithm, no redundant measure will exist. Each 
sensor will send to the aggregator a set of reduced measures 
associated to their corresponding weight and ready for the 
2nd tier data cleaning algorithm. 
C. Second  Tier: Weighted  data Cleaning 
We define a special node for each set of nodes which, 
we shall call “aggregator”, such aggregator will receive data 
from its set of nodes. We assume that the aggregator is more 
powerful than its set of nodes N. At this stage each 
aggregator will hold n lists for each type of measurement 
where n is the number of nodes associated to this aggregator 
and each list contains measures with their related weights. 
Our approach aims at reducing data transmitted from the 
aggregators to the sink subsequently reducing energy 
consumption. The obvious idea will suggest looping each 
list comparing its measures with the remaining lists looking 
for redundant data. Such approach proved to be costly in 
terms of data processing since it will scan the whole existing 
set many times and is attributed a complexity of O(n!). Our 
approach, illustrated in Algorithm. 2, suggests building 
progressively a dynamic arraylist as follows: 
We define A = Union of all existing lists in the aggregator: 
A = ((j, m[t,i])|iN). Than we select a random measure 
with its related weight from A in order to create the first cell 
of our dynamic array list by placing the above random value 
in it. We continue by selecting value (i, mi) from A and 
calculating the Substitution function for each selected value 
mi with the array list values { (i, mi), jarray list values}. 
The first measure mj answering Substitution (mi, mj) = 1 is 
observed and the weight of matched values are added. If no 
match occurs the value is added to the dynamic array list by 
creating a new cell. Finally, the selected value mi is deleted 
Sink 
Aggregators 
Sensor 
nodes 






















ms[tπ 1]
........
ms[t2]
s[t1]
m
........ m3[tπ 1]
m3[t2]
3[t1]
m
m2[tπ 1]
.......
m2[t2]
2[t1]
m
m1[tπ 1]
.......
m1[t2]
1[t1]
m
s
M
3
M
2
M
1
M
199
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

Algorithm1: First Tier Data Cleaning. 
Input:  
New measure m[ti]. 
Output:  
Reduced set of measurements M. 
For each slot ti  during a period  do 
Get a measure m[ti] 
For each measure m[tj] do 
     If  Substitution (m[ti], m[tj]) = 1  then  
            j 
j+1 // j is the weight(m[tj]) 
            Disregard  m ti  
     Else i  
   i+1  //i is the weight(m[ti]) 
            Add m[ti] to M: M
{(M(j, m[t,i])}   
 
    End if 
         End for 
End For 
 
 
 
Algorithm2: Second  Tier Data Cleaning. 
Input:  
N: number of nodes associated to one aggregator A. 
K: number of measurements received by the aggregator 
A. 
A= (nk,m| nN, kK )= {(nk, mnk)| nN, kK} = 
{(11, m11), (12, m12) ,.., (21, m21), …., (nk, mnk)}. 
 Output:  
Final dataset sent to the sink. 
Initialization: 
We create a cell Ca[1] which contain a random value 
from the set A. 
L
K 
T
1  //T is the number of cells created 
For i 
2 to L do 
    Remove
False 
    For j=1 to T do 
    Compute Substitution(Ca[j](m),A[i](m))  
    If Substitution(Ca[j](m),A[i](m)) =1 Then 
Ca[j]() 
 Ca[j]()+ A[i]() 
Remove A[i](, m) from the set A 
Remove
True 
   End if 
   End For 
 If remove 
False Then  
   
Build a cell Ca[j+1] to contain A[i](, m) 
   
Remove A[i](, m) from A  
   
Remove
True 
End if 
L
 length (A) 
T
 number of cells created for an aggregator. 
End For 
Send to the sink the built Array list of measures and 
weights. 
 
 
 
 
 
 
 
 
 
 
from A. As we proceed in the algorithm an array list is built 
up. 
D. Illustrative Example: 
Let AM be the set of values related to one type of 
measures received from different nodes connected to an 
aggregator A. 
AM = {(11, m11), (12, m12), .., (21, m21), …., (nk, mnk)}. 
We create the first cell in the array list where we place the 
first value (11, m11).For each (ij, mij)
 
we compute 
Substitution (Ca[1](m), mij) where m is a measure from AM. 
If the function returns 1 it means that these two measures 
are similar. Then the weights are added to each other and we 
remove (12, m12) from the set A, else we create a cell Ca[2] 
for m12 affected of  the weight 12 as shown in Table I.  At 
the end we remove (12, m12) from the set A. 
TABLE I.  
ARRAYLIST UNDER CREATION 
Cells 
Ca[1] 
Ca[2] 
 
11,, m11 
12, m12 
 
Supposing we are in the case where the measures are not 
similar we continue as follows:  
We move to (13, m13), then we check if the similarity is 
reached with the measure m. If so, the weights are added as 
follows: Ca[1]() = Ca[1]() + 13 and m=m13 is removed 
from the set A. Otherwise we continue checking the 
similarity with the measure existing in the second cell. If 
Substitution (Ca[2](m), m13) =1 then Ca[2]() = Ca[2]() + 
13  and m13 is removed from the set A. If the measure is not 
similar with any of the existing measure in the array we 
create a cell Ca[3] for m13 affected by its weight 13 before 
we remove (13, m13) from the set A. Instead of looping 
through the entire set of values in A, we are only scanning 
the cells progressively created in the dynamic array list 
while computing the Substitution function. If the latter is not 
verified then we create a new cell containing the measure 
with its related weight otherwise we are only adding the 
weight to an existing slot as in Table II. 
TABLE II.  
SAMPLE OF THE RESULT SET  SENT TO THE AGGREGATOR 
Cells 
Ca[1] 
Ca[2] 
Weight 
11, m11 
(12+13),m12 
IV. 
EXPERIMENTAL RESULTS 
To validate the approach presented in this paper, we 
developed a C# based simulator that we ran on the readings 
collected from 46 sensors deployed in the Intel Berkeley 
Research Lab [13]. Every 31 seconds, sensors with weather 
boards were collecting humidity, temperature, light and 
voltage values. In our experiments, we are interested in two 
sensors measurements: the temperature and the humidity. 
Each node reads an average of 83000 values of each 
measurement per day and per field. Our approach consists 
of a two tiers aggregation: (1) first tier where the 
aggregation is done on a periodic basis every 31 seconds (2) 
200
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

second tier where the aggregation is done on the level of the 
aggregator that receives the input from a group of nodes. 
A. First tier: periodic data aggregation 
At the first tier, data is filtered on a periodic basis where 
each period is constituted of 31 seconds. At each period, 
each measure is affected by its weight. The result depends 
from the threshold delta that we choose to vary between 0.01 
and 0.07 based on the variation of measurements. Fig. 4 
shows the percentage of data sent to the aggregator. 
Obviously the data size is disproportional to the threshold 
data. The goal of this tier is to reduce the size of the data 
collected by each node while preserving the frequency of 
each value as to not affect the analysis on the sink level. The 
experimental results show that a minimum of 5% of the total 
set for each measure remains. The size of the affected 
probability for each value is equal to the number of items 
existing in the message to be sent to the aggregator. The total 
size of the messages sent to the aggregator is then equal to 
the total number of measures to be sent in addition to the 
total number of affected probability. As per the experimental 
results displayed in Fig. 2, minimum of 10% for each 
measure is sent to the aggregator. 
 
Figure 2.  First Tier Data Aggregation 
B. Second Tier: Group weighted data aggregation 
At this level, sets of weighted data measures are 
received by the aggregator. The cleaning on the level of the 
aggregator can’t ignore the weight of each measure. 
Weighted data aggregation between sets is performed at the 
level of the aggregator taking as input the sets received and 
giving as output one reduced set containing the cleaned 
measure associated with their weight. The weight of each 
measure can define the probability of the s data measure 
existence in this aggregator. Result in Fig. 3 shows that 
maximum 13% of the data is sent to the sink adding to it 
13% related to their respective probability of occurrence. We 
conclude that only 26% of the size of messages received by 
each aggregator A will be sent to the sink. 
 
Figure 3.  Second  Tier Data Aggregation 
C. Energy study 
Sensor nodes that are used to form a sensor network 
are normally operated by a small battery which has small 
amount of energy. Therefore, in wireless sensor networks 
reducing energy consumption of each sensor node is one 
of the prominent issues to address in the network lifetime, 
since 
wireless 
communications consume significant 
amount of battery power, sensor nodes should be energy 
efficient in transmitting data. Protocols can reduce 
transmitted power in two ways. First where nodes can emit 
to short distances such as data sinks or cluster nodes. The 
cluster node can then send the data over a larger distance 
preserving the power of the smaller nodes. The second is 
by reducing the number of bits (amount of data) sent 
across the wireless network.  Our approach reduces the 
overhead by detecting and cleaning redundant measures 
while preserving the information integrity. To evaluate the 
energy consumption of our approach we used the same 
radio model as discussed in [20]. In this model, a 
radio dissipates Eelec = 50 nJ/bit to run the 
transmitter or receiver circuitry and βamp = 100 
pj/bit/m2 for the transmitter amplifier. The radios 
have power control and can expend the minimum 
required energy to reach the intended recipients as 
well as they can be turned off to avoid receiving 
unintended transmissions. The equations used to calculate 
transmission costs and receiving costs for a k-bit messages 
and a distance d are respectively shown below in (1) and 
(2) : 
elec ampd

Relec


Receiving is also a high cost operation, therefore, the 
number of receptions and transmissions should be minimal. 
In our simulations, we used a measure length k of 64 bits 
which, corresponds to a packet length. With these radio 
parameters, when d2 is 500m2, the energy spent in the 
amplifier part is equal to the energy spent in the electronics 
part, and therefore, the cost to transmit a packet will be twice 
the cost to receive. 
0
20
40
60
0.01 0.02 0.03 0.04 0.05 0.06 0.07
1
Percentage of data sent 
to the aggregator
Threshold δ
First aggregation tier
Humidity
Temperature
6
8
10
12
14
0.01 0.02 0.03 0.04 0.05 0.06 0.07
1
Percentage of final data 
set sent to the sink
Threshold δ
Second aggregation tier
Humidity
Temperature
201
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

At the first level, and at the end of the period, each node 
will contain m messages affected each by a weight . The 
size of the message sent by each node is equal to the number 
of weight sent in addition to the number of values sent. We 
consider that each value is equal to 64 bits. The total energy 
consumed is equal to the sum of the energy consumed by 
each node when the packet is sent to the aggregator from the 
source nodes and can be calculated as follows:  
aggdxdxelecβamp
delec

 At the second level, the energy consumption will be 
equal to the energy consumed when the aggregator send the 
data to the sink in addition to the energy consumed by the 
sink when receiving the data as shown in (4). 
sinkd TxdRx elecβamp
delec

The total energy consumed on the level of the network 
is calculated as follows: 
aggdsinkd 

To evaluate the energy consumption of our approach we 
compared it to a classical clustering approach, where every 
node sends all its measures to a cluster head which, in his 
turn relays all the received data to the sink. Fig. 4 shows that 
our approach outperforms clustering approaches and 
minimizes the energy consumption by at least 50%. 
Our approach is efficient since the information integrity 
is fully preserved. All taken measurements appearing in the 
final set arrived to the sink along with their weight. 
Therefore, we can consider that our approach decreases the 
amount of redundant data forwarded to the sink and performs 
an overall lossless process in terms of information and 
integrity by conserving the weight of each measure. 
V. 
CONCLUSION 
Data aggregation is a well known technique to achieve 
energy efficiency, in wireless sensor networks, when 
propagating data from sensor nodes to the sink. The main 
idea behind is that rather than sending all captured data from 
sensors to the sink, multiple redundant data are aggregated 
as they are forwarded by the sensor network. In our 
approach, we proposed two-tiers weighted periodic data 
aggregation method. We provided two non complex 
algorithms that allow at the first level sensor nodes, and at 
the second level aggregators to identify and reduce duplicate 
sensor measurements. The experimental results show the 
effectiveness of our approach in reducing the amount of 
redundant 
data; furthermore, 
we confirm that 
the  
proposed method outperforms existing clustering method in 
terms of energy consumption. 
As part of our future work, we plan to show the 
effectiveness of this approach in data mining and how the 
weighted measures in the training set will serve the 
classifier predicting with reasonable accuracy the class of 
each instance fed. 
 
Figure 4.  Energy Consumption. 
VI. 
REFERENCES 
[1] G. Pottie and W. Kaiser, “Wireless integrated network 
sensors," Communications of the ACM, vol. 43, no. 5, 
p.51C58, 2000. 
[2]  Y. Zhuang and L. Chen Hong Kong, “In-network Outlier 
Cleaning for Data Collection in Sensor Networks,” 
Proceedings of the First International VLDB Workshop on 
Clean Databases,(CleanDB06), 2006. 
[3] R. Verdone, D. Dardari, G. Mazzini, and A. Conti, “Wireless 
Sensor and Actuator Networks,” Academic Press/Elsevier, 
London, 2008. 
[4] R. Rajagopalan and P. K. Varshney, "Data-Aggregation 
Techniques 
in 
Sensor 
Networks: 
A 
Survey," 
IEEE 
Communication Surveys and Tutorials, Vol. 8, No. 4,  pp. 48-
63, December 2006.  
[5] X. Li, "A Survey on Data Aggregation in Wireless Sensor 
Networks," Project Report for CMPT 765, Spring 2006. 
[6] A. Bakhtiar Qutub, N. Pissinou, and K. Makki, “Belief based 
data cleaning for wireless sensor networks,” Wireless 
Communications and Mobile Computing, 11: n/a. doi: 
10.1002/wcm.970, 2011. 
[7] A. Mehdi Esnaashari and M. R. Meybodi, “ Data aggregation 
in sensor networks using learning automata,” Wireless 
Networks, 16(3):687–699, 2010.  
[8] R E. Elnahrawy and B. Nath, “Cleaning and querying noisy 
sensors,” In Proceeding of International Workshop of 
Wireless Sensor Networks and Applications (WSNA), 2003. 
[9]  B.J. Chen, K. Jameison, H. Balakrishnan, and R. Morns, 
Span: “An Energy Efficient coordination Algorithm for 
Topology Maitnenance in Ad-Hoc Wireless Networks,” 
Wireless Networks 8(5):481-494, 2002. 
[10] H. Albert, R. Kravets and I. Gupta, "Building Trees Based On 
Aggregation Efficiency in Sensor Networks," Ad Hoc 
Networks, Vol. 5, No. 8, November 2007, pp. 1317-1328. 
[11] E. Fasolo, M. Rossi, J. Widmer, and M. Zorzi, "In-network 
Aggregation Techniques for Wireless Sensor Networks: A 
Survey, " IEEE Wireless Communications, Vol. 14, No. 2, pp. 
70-87, April 2007. 
[12] Y. Zheng, K. Chen, and W. Qiu, “Building Representative-
Based Data Aggregation Tree in Wireless Sensor Networks, 
Mathematical Problems in Engineering, vol. 2010, Article ID 
732892, 11 pages, 2010. 
[13] http://db.csail.mit.edu/labdata/labdata.html, Apr. 2004, Last 
access March 2011. 
 
0
2
4
0.01 0.02 0.03 0.04 0.05 0.06 0.07
Total energy 
consumption (J)
Threshold δ
Energy Consumption
Without our approach
Our Approach
202
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

