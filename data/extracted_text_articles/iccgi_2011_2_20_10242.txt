Background Speech Cancellation using a 
Generalized Subspace Speech Enhancement 
Method 
 
Radu Mihnea Udrea, Constantin Paleologu, Silviu Ciochina 
Telecommunications Department 
“Politehnica” University of Bucharest 
Bucharest, Romania 
mihnea@comm.pub.ro, pale@comm.pub.ro, silviu@comm.pub.ro 
 
 
Abstract— This paper presents a speech enhancement method 
for reducing undesired babble noise, or background speech, 
that affects the desired speech, using a generalized subspace 
approach. The subspace decomposition is obtained with a 
nonunitary transform based on diagonalization of the clean 
speech and background distortion covariance matrices. The 
clean signal is estimating using an optimal subspace estimator 
that nulls the signal components in the distortion signal 
subspace and keeps the components in the signal subspace. 
Objective and subjective measures show a better suppression 
of background speech that other subspace-based methods that 
were proposed for white noise. 
Keywords-speech enhancement; colored noise; subspace 
I. 
 INTRODUCTION 
Over the years, many applications of acoustic noise 
reduction and speech enhancement require high performance 
and efficient algorithms. Spectral subtraction [1] is perhaps 
one of the most popular speech enhancement algorithm due 
to its low complexity. Even if several methods were 
proposed [2], [3] to reduce speech distortions and “musical 
noise” introduced by this algorithm, still there is a 
compromise to be made between reducing speech distortion 
and reducing residual noise. 
Another approach of more recent speech enhancement 
algorithms is based on decomposition of the noisy signal in 
two subspaces: signal subspace and noise subspace. An 
estimate of the clean signal can be made by nulling the 
components of the signal in the noise subspace and retaining 
only the components of the signal in the signal subspace. The 
subspace decomposition can be done using the eigenvalue 
decomposition (EVD) [4]-[6] or the singular value 
decomposition (SVD) [7].  
In [4], an optimal estimator that minimizes the speech 
distortion subject to the constraint that the residual noise fell 
below a preset threshold is proposed using the eigenvalue 
decomposition of the covariance matrix. The decomposition 
of the vector space of the noisy signal into a signal and noise 
subspace can be obtained by applying the Karhunen–Loéve 
transform (KLT) to the noisy signal. The KLT components 
representing the signal subspace were modified by a gain 
function determined by the estimator, while the remaining 
KLT components representing the noise subspace were 
nulled. The enhanced signal was obtained from the inverse 
KLT of the modified components. This subspace approach 
was based on the assumption that the input noise was white. 
The work in [4] was extended for colored noise. In [5] it 
is given a proper noise shaping for colored noise without 
prewhitening, first by classifying the noisy speech frames 
into speech-dominated and noise-dominated frames and then 
using a different KLT matrix for these frames to construct 
the estimator. In [6] a generalized subspace approach with 
built-in prewhitening for enhancing speech corrupted with 
colored noise is determined.  
In this paper we propose a nonunitary transform, based 
on the simultaneous diagonalization of the clean speech and 
the 
background 
distortion 
covariance 
matrices. 
No 
assumptions were made about the covariance matrix of the 
KLT-transformed noise vectors, hence this estimator is 
optimal. 
This paper is organized as follows. In Section II, the 
subspace approach using time-domain constraints is 
presented for white noise and for colored noise (like babble 
talk). Section II also gives an expression, different that in [6], 
for the subspace estimator for any type of distortion signal 
which is uncorrelated to speech. Implementation details are 
provided in Section III, experimental results are given in 
Section IV, and the conclusions are given in Section V. 
II. 
SUBSPACE APPROACH FOR SPEECH ENHANCEMENT 
The linear model for the clean speech signal assumes that 
each K-dimensional vector x can be represented as: 
 
1
,
M
m
m
m
s
M
K
=
=
<
∑
x
b
 
(1) 
where 
1
{ ,
,
M }
s
… s
 are zero mean random variables, and 
1,
,
M
b
… b
 are K-dimensional complex basis vectors, which 
27
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

are assumed linearly independent. For speech signals, such 
representation is possible also, when M<K.   
The model (1) can be expressed as: 
 
=
⋅
x
B s  
(2) 
where B is a K
× M
 matrix whose rank is M and s is an M-
dimensional vector. The covariance matrix of x is given by: 
 
{
}
T
T
E
⋅
=
⋅
⋅
x
s
R
x x
B R
B

 
(3) 
where 
s
R  is the covariance matrix of the vector s, which is 
assumed positive definite. Hence, the rank of 
x
R  is M, and it 
has K
− M
 zero eigenvalues. 
Let d being the K-dimensional vector of the noise 
(distortion) signal. Assuming the distortion signal is additive 
and uncorrelated with the speech signal, we can write the 
corrupted signal as: 
 
=
⋅ +
=
+
y
B s
d
x
d  
(4) 
where y is the K-dimensional corrupted speech vector. 
The clean speech linear estimator will be: 
 
ˆ =
⋅
x
H y  
(5) 
where H is a K
× K
 matrix. The error signal resulted from 
this estimation is given by: 
 
ˆ
(
)
x
d
ε
ε
ε
=
−
=
−
⋅
+
⋅
=
+
x
x
H
I
x
H d
 
(6) 
Let  
 
(
)
(
)
2
2
T
T
x
x
x
x
x
T
T
d
d
d
d
d
E
tr E
E
tr E
ε
ε ε
ε ε
ε
ε ε
ε ε
⎡
⎤
⎡
⎤
=
=
⎣
⎦
⎣
⎦
⎡
⎤
⎡
⎤
=
=
⎣
⎦
⎣
⎦
 
(7) 
be the energy of the speech distortion and, respectively, the 
energy of the residual noise vector. The linear estimator can 
be obtained [4] by solving the following time-domain 
constrained (TDC) optimization problem: 
 
2
2
2
min
1
subject to:
x
H
d
d
K
ε
ε
≤ ασ
 
(8) 
where 0
1
≤ α
≤
. The estimator derived in this way 
minimizes the signal distortion over all linear filters which 
result in the permissible residual noise level. The solution to 
(8) is given by [4]: 
 
(
)
1
opt
μ
−
=
+
x
x
d
H
R
R
R
 
(9) 
where 
x
R  and 
d
R  are the covariance matrices of the clean 
speech and noise respectively, and μ  is the Lagrange 
multiplier. 
Consider the eigen-decomposition of 
x
R  
 
T
x =
x
R
UΔ U  
(10) 
where U is the eigenvector unitary matrix and 
x
Δ  is the 
diagonal eigenvalue matrix of 
x
R .  
The optimal filter from (9) can be simplified using (10) 
to:  
 
(
)
1
T
T
opt
μ
−
=
+
x
x
d
H
UΔ
Δ
U R U
U . 
(11) 
A. White Noise Subspace Estimator 
For white noise with variance 
2
d
σ , 
2
d
d
R
= σ I
 and the 
estimator from (11) reduces to White Noise Subspace 
Estimator (WNSE) [4]: 
 
(
)
1
2
T
T
WNSE
d
WNSE
μσ
−
=
+
=
⋅
⋅
x
x
H
UΔ
Δ
I
U
U G
U . (12) 
where 
 
(
)
1
2
WNSE
μσd
−
=
+
x
x
G
Δ
Δ
I
. 
(13) 
The gain matrix 
GWNSE
 is diagonal with elements (gains): 
 
( )
2
( )
( )
x
WNSE
x
d
m
g
m
m
λ
λ
μσ
=
+
. 
(14) 
Hence, the signal estimate is obtained by applying the 
Karhunen-Loève transform (KLT) to the noisy signal, then 
modify the components of the KLT by a gain function and 
finally, by inverse KLT of the modified components. A 
block diagram of this estimator is shown in Fig. 1. 
 
 
 
 
 
KLT 
noisy 
signal 
y 
gWNSE(1) 
 
 
 
gWNSE(K) 
enhanced
signal 
ˆx  
 
 
IKLT 
 
Figure 1.  Signal subspace linear estimator 
 
28
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

B. Colored Noise Subspace Estimator 
If the distortion is not white noise, the matrix 
T
d
U R U  is 
not diagonal since U, being the eigenvector matrix of the 
symmetric matrix 
x
R , diagonalizes 
x
R  and not 
d
R . There 
is a matrix V that simultaneously diagonalize 
x
R  and 
d
R . 
As stated in [6], consider the basis matrix Σ  satisfying 
the following equations:  
 
−1
=
=
d
x
Σ
R R
ΣV
VΛ
 
(15) 
where Λ and V are the eigenvalue matrix and eigenvector 
matrix respectively of Σ . Applying diagonalizing matrix V 
will result the fully diagonal eigenvalues matrices of 
x
R  and 
d
R : 
 
T
T
=
≠
=
x
x
d
d
V R V
Λ
Λ
V R V
Λ
 
(16) 
where 
x
Λ and 
d
Λ  are the eigenvalue matrices of  
x
R  and 
d
R , respectively.  
The resulted equations (16) are more general than the 
relations in [6] (where it is considered that  
Λx =
Λ  and 
Λd =
I ). The approach proposed in (16) allows applying the 
subspace method to any type of distortion signal which is 
uncorrelated to speech signal. 
Applying the eigen-decomposition of Σ  from (15) and 
using (16), the optimal linear Colored Noise Subspace 
Estimator (CNSE) can be expressed as: 
 
(
)
1
T
CNSE
T
T
CNSE
μ
−
−
=
+
=
=
⋅
⋅
d
x
x
d
H
R VΛ
Λ
Λ
V
V
G
V
. 
(17) 
where 
 
(
)
1
CNSE
μ
−
=
+
x
x
d
G
Λ
Λ
Λ
. 
(18) 
In case of the colored noise, the corrupted signal is 
decorrelated with the non-KLT matrix 
VT
, then it is 
modified by the signal subspace gain matrix 
GCNSE
, and, 
finally, the enhanced signal estimate is obtain by the inverse 
non-KLT matrix 
V−T
. 
Since we have no access to the covariance matrix 
x
R  of 
the clean speech signal, the matrix Σ  is estimated from the 
noisy speech signal. Assuming that speech is uncorrelated 
with noise, we have 
 
=
+
y
x
d
R
R
R . 
(19) 
and so 
 
1
1
−
−
=
=
−
d
x
d
y
Σ
R R
R R
I . 
(20) 
The estimation of μ in the gain function (14) or (18) 
affects the quality of speech. A large value of μ would reduce 
the residual noise but would introduce speech distortion. A 
small value of μ would minimize the speech distortion at the 
expense of higher values of residual noise. A trade-off 
between residual noise and speech distortion can be obtained 
by making μ dependent on the short-time SNR: 
 
0
0
dB
SNR
s
μ
= μ
−
. 
(21) 
where 
0
μ  and 
0s  are constants chosen experimentally [6] as 
explained in the implementation section. 
III. 
ALGORITHM IMPLEMENTATION 
The proposed algorithm can be implemented, for each 
speech frame, as follows: 
• 
The distortion covariance matrix 
d
R  is computed 
prior to the starting of the speech signal during 
speech-absent frames. 
• 
The matrix Σ  is estimated using (20) from the noisy 
signal covariance matrix 
y
R  and the inverse of 
d
R . 
• 
The eigen-decomposition of Σ  is performed using 
(15). Extract the eigenvector matrix V and 
eigenvalue matrix Λ . 
• 
The dimension of the speech signal subspace is 
estimated, considering that the eigenvalues of Σ  are 
ordered 
1
2
K
λ
λ
λ
≥
≥
… ≥
, from: 
 
{
}
1
arg max
0
k
k K
M
λ
≤ ≤
=
>
. 
(22) 
• 
The μ factor is computed as a linear function of SNR 
[6]: 
 
0
0
5
5
5
20
1
20
dB
dB
dB
dB
SNR
SNR
SNR
s
SNR
μ
μ
⎧
< −
⎪⎪
=
−
− <
<
⎨
⎪
⎪
≥
⎩
. 
(23) 
where 
0
0
10
4.2,
6.25,
10log
dB
s
SNR
SNR
μ =
=
=
. 
• 
SNR can be computed directly from the eigenvalues 
kλ of Σ  using the following equation [6]: 
 
(
)
(
)
1
M
T
k
k
T
tr
SNR
K
tr
λ
=
=
= ∑
x
d
V R V
V R V
. 
(24) 
29
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

• 
Compute the optimal estimator 
GCNSE
 using (18) 
and estimate the desired signal using (5). 
The covariance matrices 
x
R  and 
d
R were estimated as 
Toeplitz matrices using K samples of the unbiased 
autorcorrelation sequence, without using future or past 
frames. We choose 
K = 40
 samples for speech sampled at 8 
kHz. The estimators were applied to frames of the corrupted 
signal 50% overlapped each other. The covariance matrices 
were estimated by windowing with rectangular windows. 
The enhanced speech signal estimation was obtained using 
overlap and add approach with Hamming windowing.  
IV. 
EXPERIMENTAL RESULTS 
We used 20 sentences produced by 10 male and 10 
female speakers. For distortion signal we used other speech 
signals added as babble noise to the clean speech at SNR = 5 
dB. For comparative purposes, we also evaluated the 
algorithm performances applying as a distortion signal white 
noise at the same SNR. 
The Perceptual Evaluation for Speech Quality (PESQ) 
distance measure and the overall (global) SNR [8] measures 
were adopted for evaluation of the proposed algorithms. We 
used the ITU-T Recommendation P.862 (PESQ) [9] to obtain 
a perceptual evaluation of the enhanced speech quality. The 
Mean Opinion Score (MOS) obtained in the evaluation 
process is between 0 and 5 where 0 represents a very 
annoying distortion of the perceived signal and 5 represents 
imperceptible quality degradation. 
TABLE I.  
MEAN PESQ AND MEAN GLOBAL SNR FOR WHITE NOISE 
DISTORTION AT 5dB 
 
Male Speakers 
Female Speakers 
 
SNR 
PESQ 
SNR 
PESQ 
Noisy Speech 
4.6 dB 
1.78 
4.8 dB 
1.71 
WNSE 
11.1 dB 
2.36 
10.9 dB 
2.21 
CNSE 
11.3 dB 
2.47 
10.8 dB 
2.22 
TABLE II.  
MEAN PESQ MEAN GLOBAL SNR FOR BABBLE SPEECH 
DISTORTION AT 5dB 
 
Male Speakers 
Female Speakers 
 
SNR 
PESQ 
SNR 
PESQ 
Noisy Speech 
5.3 dB 
0.72 
5.2 dB 
0.69 
WNSE 
6.7 dB 
1.06 
6.9 dB 
0.81 
CNSE 
7.3 dB 
1.45 
7.1 dB 
1.42 
 
Tables I and II give the mean results for 20 TIMIT 
sentences corrupted by speechshaped noise at 5 dB. The 
results are given separately for male and female speakers. As 
can be seen from Tables I and II, in case of speech corrupted 
of white noise at 5dB SNR, the proposed approach reduces 
to Ephraim and Van Trees approach [4]. In case of speech 
corrupted by background babble talk distortion, our proposed 
approach (CNSE) outperformed Ephraim and Trees 
approach [4] for both male and female speakers. 
Subjective listening tests confirmed the results in Tables 
I and II and that with the proposed method, the background 
noise was imperceptible. Since in our experiments, no voice 
detection algorithm (VAD) was used to update the noise 
covariance matrix, we expect further improvements in 
performance if we use a reliable VAD algorithm to update 
the noise covariance matrix. 
V. 
CONCLUSIONS 
A speech enhancement for reducing undesired babble 
noise, or background speech, that affects the desired speech, 
using a generalized subspace approach was proposed. The 
proposed 
approach 
is 
based 
on 
the 
simultaneous 
diagonalization of the covariance matrices of the speech 
signal and the colored noise signal. In case of the colored 
noise, the corrupted signal is decorrelated with the non-KLT 
matrix, it is modified by a gain matrix, and, finally, the 
enhanced speech is estimated by inverse non-KLT matrix. 
Better SNR and perceptual scores were obtained that 
applying the standard KLT decomposition used by Ephraim 
and Van Trees [3] for enhancing speech corrupted by white 
noise.  
ACKNOWLEDGMENT 
The work has been funded by the Sectoral Operational 
Programme Human Resources Development 2007-2013 of 
the Romanian Ministry of Labour, Family and Social 
Protection 
through 
the 
Financial 
Agreement  
POSDRU/89/1.5/S/62557. 
REFERENCES 
[1] 
M. Berouti, R. Schwartz, and J. Makhoul, “Enhancement of speech 
corrupted by acoustic noise,” in Proc. IEEE Int. Conf. Acoust., 
Speech, Signal Processing, pp. 208–211, 1979. 
[2] 
R. Martin, “Spectral subtraction based on minimum statistics”, Proc. 
Eur. Signal Process., pp. 1182-1185, 1994. 
[3] 
R. M. Udrea, N. Vizireanu, S. Ciochina, and S. Halunga “Nonlinear 
spectral subtraction method for colored noise reduction using multi-
band Bark scale”, Signal Processing, Volume 88 Issue 5, Elsevier 
North-Holland, Inc., pp. 1299-1303, May 2008. 
[4] 
Y. Ephraim and H. L. Van Trees, “A signal subspace approach for 
speech enhancement,” IEEE Trans. Speech Audio Processing, vol. 3, 
pp. 251-266, 1995. 
[5] 
U. Mittal and N. Phamdo, “Signal/noise KLT based approach for 
enhancing speech degraded by colored noise,” IEEE Trans. Speech 
Audio Processing, vol. 8, pp. 159–167, Mar. 2000. 
[6] 
Y. Hu and P. C. Loizou, “A generalized subspace approach for 
enhancing speech corrupted by colored noise,” IEEE Transactions on 
Speech and Audio Processing, vol. 11, no. 4, pp. 334-341, 2003. 
[7] 
S. H. Jensen, P. C. Hansen, S. D. Hansen, and J. A. Sørensen, 
“Reduction of broad-band noise in speech by truncated QSVD,” IEEE 
Trans. Speech Audio Processing, vol. 3, pp. 439–448, Nov. 1995. 
[8] 
J. R. Deller, J. Hansen, and J. G. Proakis, Discrete-Time Processing 
of Speech Signals. New York: IEEE Press, 2000. 
[9] 
ITU-T, Perceptual evaluation of speech quality PESQ, an objective 
method for end-to-end speech quality assessment of narrowband 
telephone networks and speech codecs, ITU-T Recommendation 
P.862, 2000. 
30
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

