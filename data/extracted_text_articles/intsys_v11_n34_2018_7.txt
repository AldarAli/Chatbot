202
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Developing an Approach toward Automatic Error Detection in Learners’  
English Writing Based on the Source Language 
 
Koichi Kawamura1, Harumi Kashiwagi2, Min Kang1 
1Graduate School of Intercultural Studies 
2Institute for Promotion of Higher Education 
Kobe University 
Kobe, Japan 
email: kawamura51@stu.kobe-u.ac.jp, kasiwagi@kobe-u.ac.jp, kang@kobe-u.ac.jp
 
Abstract— Automatic error detection systems for English 
writing have been improving since they were first introduced 
and are being applied to foreign language learning. However, 
these systems mainly focus on local errors, such as grammatical 
aspects in the target language and ignore the meaning intended 
in the source language. As a result, it is quite difficult to detect 
global errors using existing error detection systems. In this 
paper, we propose a new automatic error detection system to 
solve this problem. In order to determine whether the structure 
of an English sentence is in error or not, criteria for error 
determination must first be defined. Our system is based on the 
idea that criteria for error determination are created by the 
correspondence relation between Japanese and English using 
sentence patterns. In order to evaluate our system, by way of 
illustration, seven sentence patterns based on two grammar 
categories and four POS (part of speech) categories were 
selected. Automatic error detection using these seven sentence 
patterns was carried out on 100 Japanese sentences with 
subjects and their corresponding English sentences. As a result, 
we concluded that, using the sentence patterns in the source 
language, automatic error detection is effective when based on 
our criteria for error determination. 
 
 Keywords-Error Detection; Sentence Pattern; Global Error; 
Parser; Source Language; Criteria for Error Determination. 
I. 
 INTRODUCTION 
In this research paper we develop an approach toward 
automatic error detection in learners’ English writing based 
on our previous work [1]. 
For English learners, writing is the most difficult skill to 
improve compared to speaking, reading and listening. 
“Writing abilities are not naturally acquired; they must be 
culturally (rather than biologically) transmitted in every 
generation, whether in school or in other assisting 
environments” [2]. Despite this linguistic feature, writing is 
not taught enough in schools relative to the other skills [3]. 
Possible reasons for this are curriculum guidelines based on 
the Grammar-Translation Method, and the burden on 
teachers [4]. Thus, a writing support tool for self-access is 
needed in order to heighten the writing skill without any 
assisting environment, and this will also lead to the 
cultivation of the learner’s autonomy. 
 Meanwhile, for English teachers, writing is burdensome 
to teach as they must detect and grasp learners’ errors one by 
one which is very time consuming. Generally, it is accepted 
that English essays written by learners with low proficiency 
contain a lot of errors. Of these errors, global errors 
negatively affect the structure of the whole sentence, and this 
limits the readers’ comprehension. Therefore, it is necessary 
for teachers not to overlook such errors when proofreading 
an essay. However, in order to detect global errors, teachers 
would have to devote an inordinate amount of attention 
discovering all the potential structural errors. Thus, teachers 
have a tendency to overlook some structural errors due to 
time constraints. To reduce this burden on teachers, a writing 
support tool for structural error detection is needed. 
II. 
TERMS AND RELATED WORK 
In Section I, we stated the necessity of a writing support 
tool for automatic structural error detection. In this section, 
we are going to survey error and state the purpose of this 
study. 
A.  Terms of Error 
There are two types of writing style based on the learner’s 
proficiency; Japanese-English 
translation 
writing 
for 
beginner level learners (mainly for junior high school 
students and high school students) and free essay writing for 
advanced level learners (mainly for high school students and 
college students) [4].  
Generally, detectable errors are influenced by the writing 
style. Errors related to the learner’s passive knowledge 
should be detected by the Japanese-English translation 
writing. On the other hand, errors related to the learner’s 
active knowledge should be detected by the free essay writing. 
Because of this, a writing support tool must be decided for 
each type of writing instruction. Thus, a writing support tool 
which can cope with both types of writing instruction would 
be conducive for English education. 

203
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
In order to clarify the characteristics of errors made by 
Japanese English learners, scholars’ research has focused on 
two approaches; detecting errors automatically [5]-[7] and 
detecting errors manually [8]-[10]. In this section we look at 
an example and examine how the latter type of research has 
been done. 
In this study [9], learners’ errors are classified into four 
categories; semantic error, logical error, pragmatic error, and 
grammatical error. Each category is further classified into 
either an error which actually hinders the comprehension of 
a sentence (global error), or an error which does not affect the 
comprehension of a sentence (local error). The author found 
that more than 70% of logical errors and pragmatic errors 
hinder comprehension, on the other hand, more than 60% of 
semantic errors and grammatical errors do not affect 
comprehension. This result indicates that it is difficult to 
detect logical errors and pragmatic errors automatically and 
suggests the importance of additional resources. Moreover, 
the ratio of error which hinders comprehension (global error) 
to total error is approximately 23%. Although this ratio is 
small, it is still significant. This shows that current automatic 
error detection is not suitable for detecting global errors. Thus, 
a writing support tool which targets global error is needed. 
Global error includes a variety of errors such as semantic 
error, logical error, pragmatic error, grammatical error and so 
on. Thus, it is difficult to identify the error if we only have 
reference to the target language without any additional 
information. However, it is possible to identify the error if the 
source language is included which makes the source language 
(Japanese) indispensable for detecting global error. 
B. Previous Research 
As mentioned in the previous section, both students 
learning English and teachers teaching English are in a 
difficult situation. In order to address these pedagogical 
shortcomings, a number of writing support tools, especially 
automatic error detection systems using natural language 
processing technology are being used. They are being 
applied in foreign language learning classes to support 
students to acquire better writing skills and reduce the 
burden on teachers.  
Automatic error detection systems perform excellently 
with single grammatical errors, such as spelling, article usage, 
subject-verb agreement, prepositions and aspect errors [11]-
[14]. Scholars focus on article and preposition errors in 
particular, because these errors appear in ESL (English as a 
second language) learners’ essays and account for 20-50% of 
all grammar errors [15]. Given this situation, few error 
detection systems look at structural errors which lead to 
global errors [16]. In addition, although deep learning has had 
a strong influence on the field of Natural Language 
Processing over the last few years [17, 18], the building of a 
deep learning model is still at the stage of inception and no 
deep learning system for education practices has yet been 
proposed. Thus, current automatic error detection systems are 
limited in that they do not cover all types of learners’ errors. 
From an English education perspective, a support tool for 
structural error detection is needed. 
Moreover, most of the systems now in use are designed 
to analyze the target language (English) only. This unilateral 
approach may cause a discrepancy between the system’s 
automatic correction feedback and the learner’s intention 
[19]. English learners, especially those with low proficiency, 
when confronted with difficulties, tend to apply a 
communication strategy which avoids complicated structures 
and phrases in order not to make errors in an English essay 
[20]. That is, they write what they can, not what they want. 
Consequently, English teachers can not recognize learners’ 
errors as deviations from the source language (Japanese) 
since the errors do not surface. In order to overcome this 
problem, the target language as well as the source language 
should be an object of analysis.  
Therefore, a new automatic error detection system which 
can easily identify structural errors, cope with various types 
of global errors, and recognize learners’ intentions is needed.  
C. Purpose 
The purpose of this study is to propose just such a new 
automatic error detection system, one which can easily 
determine whether a sentence structure is correct or not by 
comparing the basic sentence elements (subject and 
predicate) of Japanese and English using parsers based on 
sentence patterns. In our previous study, six sentence patterns 
were established, and four sentence patterns selected from 
them were examined by way of illustration in order to 
evaluate our approach [1]. In this study, we are going to 
extend sentence patterns from six to nine including two 
grammar categories in order to enhance the versatility. 
This approach is based on the results of our previous 
studies, which showed that “detecting English errors using 
sentence patterns is more promising than detection that 
depends on full sentences” [1] [21]. 
D. The Structure of this Paper 
In Section III, we propose an approach for a new 
automatic error detection system that can determine whether 
an English sentence structure is in error or not. In Section IV, 
we automatically detect structural errors according to criteria 
for error determination created by the corresponding relation 
between Japanese (source language) and English (target 
language). We then evaluate the accuracy of criteria for error 
determination based on the seven sentence patterns for 
illustration. In Section V, we refer to the efficacy of our new 
automatic error detection system using sentence patterns in 
the source language and the target language, and its wider 
potential. 
III. 
APPROACH 
In Section II, we surveyed error and stated the purpose of 
this study. In this section, we are going to suggest a method 
suitable for detecting errors automatically and its procedure.  

204
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
A. Procedure 
In order to facilitate the detection of structural errors, we 
focus on the subject and predicate, two of the basic sentence 
elements, and compare them in the source language 
(Japanese) and the corresponding target language (English). 
To conduct the comparison, we classify a number of sentence 
patterns and create criteria for error determination: rules 
based on the correspondence relation between Japanese and 
English using sentence patterns. We compare the basic 
sentence elements (a primary subject and predicate) of the 
source language and the corresponding target language using 
parsers based on sentence patterns and criteria for error 
determination. This approach follows the procedure below. 
 
1. Select Japanese sentences and corresponding 
English sentences written by Japanese English 
learners as analytical data. 
2. Set up a Japanese parser, CaboCha and an English 
parser, the Stanford Parser. 
3. Automatically extract sets of sentence elements, 
primary subjects and predicates (verb) by a parser 
based on specific extraction rules. 
4. Automatically sort the sets of primary subjects and 
predicates (verb) based on preselected Japanese 
sentence patterns. 
5. Compare the extracted sentence patterns with the 
defined sentence patterns based on the criteria for 
determination. 
6. Obtain the results of error determination as 
feedback (ERROR, POSSIBLE, UNKNOWN). 
 
In the above feedback, ERROR stands for “an outright 
error.” POSSIBLE stands for “not an error, but may not be a 
correct answer.” UNKNOWN stands for “indeterminable.” 
B. Sentence Elements 
Although each Japanese and English sentence contains 
various elements, such as subjects, predicates (verbs), objects, 
complements, etc., this study examines the set of a primary 
subject and predicate (verb) only. This is because all major 
sentence patterns contain a subject and a predicate verb in 
academic writing [22]-[24]. Additionally, it is efficient for 
teachers to determine whether the learners’ English is 
grammatically correct by checking sets of a primary subject 
and a predicate verb only. This will support teachers in 
detecting errors since learners’ errors are not always clear, and 
teachers have difficulty determining where the problems lie. 
C. Parsers and Extraction Rules 
To extract sets of primary subjects and predicates from 
Japanese sentences, the parser, Japanese Dependency 
Structure Analyzer, CaboCha [25] was utilized. To extract 
sets of primary subjects and predicate verbs from the 
corresponding English sentences, the Stanford Parser [26] 
was utilized. Table I indicates details of both parsers and 
extraction rules of subjects and predicates (verb).  
TABLE I. EXTRACTION RULES OF CABOCHA AND THE STANFORD PARSER 
Parser 
CaboCha 0.69 
The Stanford 
Parser 3.6.0 
Target Language 
Japanese 
English 
Extraction 
Rule 
Subject 
A clause including a 
case particle “が
(GA)” or a binding 
particle “は (WA)” or 
“も (MO)” which has 
a dependency 
structure with the 
predicate 
A nominal subject 
or a clausal subject 
Predicate 
(Verb) 
The last clause 
 
A verb (transitive 
or intransitive) or a 
“be” verb + copula 
which has a 
dependency 
structure with the 
subject 
*が (GA), は (WA), も (MO) are particles in Japanese grammar that 
immediately follow a noun, a verb, an adjective, and indicate the subject of 
a sentence. 
 
In this study, the process of extracting a set of a primary 
subject and a predicate (verb) utilized CaboCha and the 
Stanford Parser as described in our previous study [27]. 
Figures 1 and 2 indicate a sample result of parsing by 
CaboCha and the Stanford Parser. For CaboCha, Japanese 
sentence “今日は良い天気です。(Kyou Wa Yoi Tenki 
Desu.)” is used as an illustration. (“今日は良い天気です。” 
is the same meaning as “It is fine today.”) For the Stanford 
Parser, the English sentence “It is fine today.” is used as an 
illustration. Hereinafter, in this study Romanization is used 
when a Japanese sentence appears.  
In Figure 1, “chunk” stands for a Japanese phrase. 
CaboCha divides a Japanese sentence into several phrases, 
and indicates the dependency relation between the phrases. 
“chunk id” is a phrase number. “chunk link” has the same 
number as chunk id if a dependency relationship exists. “tok” 
stands for a morpheme. “tok id” is a morpheme number.  “tok 
feature” is morpheme information such as part of speech, 
conjugation and so on. Extracting a set of a subject and a 
predicate (verb) of a Japanese sentence utilizing CaboCha 
follows the procedure below. 
 
1. Parse the Japanese sentence “今日は良い天気です。 
(Kyou Wa Yoi Tenki Desu.)” to obtain its 
dependency structure information (Fig.1). 
2. Extract the last chunk which is tagged with the 
biggest “chunk id” as the “predicate.” In this case, 

205
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
the “predicate” is “天気 (Tenki)” and “です (Desu)” 
since the biggest “chunk id” is “2.” 
3. Extract all chunks whose “chunk link” is the same 
number as the “chunk id” of the “predicate” of the 
possible “subject.” 
4. Select the “subject” from the chunk whose “tok 
feature” has the case particle “は (WA),” or  the 
binding particle “が (GA)” or “も (MO).” 
 
Example 
Sentence 
JPN: 
今日は良い天気です。 
ROM: 
(Kyou Wa Yoi Tenki Desu.) 
ENG: 
(It is fine today.) 
<sentence> 
<chunk id="0" link="2" rel="D" score="-1.137013" head="0" 
func="1"> 
<tok id="0" feature="名詞,副詞可能,*,*,*,*,今日,キョウ,キョー">今日
</tok> 
<tok id="1" feature="助詞,係助詞,*,*,*,*,は,ハ,ワ">は</tok> 
</chunk> 
<chunk id="1" link="2" rel="D" score="-1.137013" head="2" 
func="2"> 
<tok id="2" feature="形容詞,自立,*,*,形容詞・アウオ段,基本形,良い,
ヨイ,ヨイ">良い</tok> 
</chunk> 
<chunk id="2" link="-1" rel="D" score="0.000000" head="3" 
func="4"> 
<tok id="3" feature="名詞,一般,*,*,*,*,天気,テンキ,テンキ">天気
</tok> 
<tok id="4" feature="助動詞,*,*,*,特殊・デス,基本形,です,デス,デス
">です</tok> 
</chunk> 
</sentence> 
*JPN is an abbreviation of Japanese. ROM is an abbreviation of 
Romanization. ENG is an abbreviation of English. 
Figure 1. Sample of Parsing Result by CaboCha 
 
Example 
Sentence 
ENG: 
It is fine today. 
JPN: 
(今日は良い天気です。) 
ROM: 
(Kyou Wa Yoi Tenki Desu.) 
((u'fine', u'JJ'), u'nsubj', (u'It', u'PRP')) 
((u'fine', u'JJ'), u'cop', (u'is', u'VBZ')) 
((u'fine', u'JJ'), u'nmod:tmod', (u'today', u'NN')) 
Figure 2. Sample of Parsing Results by the Stanford Parser 
 
In Figure 2, “nsubj” stands for nominal subject. “cop” 
stands for copula. Copula is a linking verb that connects a 
subject to its complement. Extracting a set of a subject and a 
predicate (verb) of an English sentence utilizing the Stanford 
Parser follows the procedure below. 
 
1. Parse the English sentence “It is fine today.” to 
obtain its dependency structure information (Fig.2). 
2. Extract a phrase which is tagged with “nsubj” as the 
“subject.” In this case, the “subject” is “It.” 
3. Extract the part of the “predicate” which has a 
dependency relationship with the “subject.” In this 
case, the part of the “predicate” is “fine.” 
4. Extract the part of the “predicate” (fine) and the 
“copula” (is) which have a dependency relationship 
with the “subject” (It).  
D. Sentence Patterns and Criteria for Determination 
1. Grammar Points 
There are six specific grammar points; 1. Tense (present 
/ past), 2. Polarity (affirmative / negative), 3. Modal Auxiliary 
(ability), 4. be Verb (existence / state), 5. General Verb 
(thinking / cognitive), 6. Personal Pronoun (first person). 
These are selected on the basis of sentence patterns from two 
perspectives; technology and English education. Six 
grammar points were classified into two categories; A. 
Grammar Category (1, 2), B. Part of Speech (POS) Category 
(3, 4, 5, 6), and these two categories are independent of each 
other. Including a Grammar Category is a key feature of 
progress from our previous study [1]. As we explained in our 
previous study, the primacy of our research depends on the 
concept of using error detection to find grammar points based 
on unique characteristics of sentence structure. From the 
perspective of technology, we have found it possible to 
simplify and make error determination for all of these six 
grammar points. 
From the perspective of English education, these six 
grammar points are indispensable and are part of a 
rudimentary knowledge of English. This is because all of 
these six grammar points are included in the official junior 
high school textbook (Table II). Thus, these grammar points 
are requisite knowledge for beginner level learners. Other 
than these grammar points, Polarity and Tense are especially 
important for beginner level learners to have a good 
command of English.  
As for Grammar Category regarding Tense, Japanese is 
an agglutinative language, while English is an inflectional 
language. In Japanese, the tense is expressed by adding 
conjugation or an adverb. Thus, it is difficult for Japanese 
learners to have a good command of inflection. Regarding 
Polarity, there are three types of negative vocabulary (quasi-
negation, partial negation, double negative) and various types 
of negative words (not, never, no, hardly, scarcely, rarely, 
seldom, few, little). Also, in terms of answering questions in 
English, the appropriate use of negative vocabulary depends 
on whether the person’s question is positive or not. In 
Japanese the appropriate use of negative vocabulary does not 
depend on whether the person’s question is positive or not. 

206
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Thus, it is difficult for Japanese learners to grasp the concept 
of English Polarity.  
TABLE II. ENGLISH GRAMMAR LIST 
7th Grade 
8th Grade 
9th Grade 
Demonstrative 
Pronoun 
Past Tense (be verb) 
Passive Voice 
be Verb (state) 
Future Tense 
Present Perfect 
Negative 
Modal Auxiliary 
Sentence Pattern 
General Verb 
be Verb (existence) 
Participle 
Article 
Gerund 
Relative Pronoun 
Plural Form 
Infinitive 
- 
Personal Pronoun 
Comparative degree 
- 
Third person 
Singular Present 
form “S” 
- 
- 
Imperative Form 
- 
- 
Interrogative 
- 
- 
Progressive Form 
- 
- 
Modal Auxiliary 
(ability) 
- 
- 
Past Tense (general 
verb) 
- 
- 
*This list is integrated from the six textbooks authorized by the Ministry of 
Education, Culture, Sports, Science and Technology. 
TABLE III. FREQUENCY LIST BY BNC 
 
General Verb 
Modal Auxiliary 
Verb 
Pronoun 
1 
know 
would 
it 
2 
see 
will 
I 
3 
think  
can 
you 
4 
want 
could 
he 
5 
get 
may 
they 
*BNC stands for “British National Corpus.” Top 5 words in each POS. 
 
As for the POS category, for native speakers of English, 
“think” and “know”, “can” and “I” are very frequently used 
in each part of speech: general verb, modal auxiliary and 
pronoun (Table III). Thus, learners should be familiar with 
them because of their linguistical importance. 
 
2. Sentence Pattern 
We classified the following nine sentence patterns 
including six grammar points (Tables IV, V), because they 
are significant pedagogically and linguistically. The patterns 
were classified into two groups (predicate-based and subject-
based).  
TABLE IV. JAPANESE SENTENCE PATTERNS 1 
Type 
Predicate-Based Sentence Patterns 
A 
a 
JPN 
ROM 
主語＋（ある / いる） 
Subject + (ARU / IRU) 
b 
JPN 
ROM 
主語＋（ない / いない） 
Subject + (NAI / INAI) 
c 
JPN 
ROM 
主語＋（あった / いた） 
Subject + (ATTA / ITA) 
d 
JPN 
ROM 
主語＋（なかった / いなかった） 
Subject + (NAKATTA / INAKATTA) 
B 
a 
JPN 
ROM 
主語＋名詞＋（です / である / だ） 
Subject + Noun + (DESU / DEARU / DA) 
b 
JPN 
ROM 
主語＋名詞＋（でない / ではありません） 
Subject + Noun + (DENAI / DEWAARIMASEN) 
c 
JPN 
ROM 
主語＋名詞＋（でした / であった / だった） 
Subject + Noun + (DESHITA / DEATTA / DATTA) 
d 
JPN 
ROM 
 
主語＋名詞＋（でなかった / ではありませんでした） 
Subject + Noun + (DENAKATTA / 
DEWAARIMASENDESHITA) 
C 
a 
JPN 
ROM 
主語＋形容詞＋（です /φ） 
Subject + Adjective + (DESU / φ) 
b 
JPN 
ROM 
主語＋形容詞＋（ない / ではない） 
Subject + Adjective + (NAI / DEWANAI) 
c 
JPN 
ROM 
主語＋形容詞＋た 
Subject + Adjective + TA 
d 
JPN 
ROM 
 
主語＋形容詞＋（なかった / ではなかった） 
Subject + Adjective + (NAKATTA / 
DEWANAKATTA 
D 
a 
JPN 
ROM 
主語＋（できる / できます） 
Subject + (DEKIRU / DEKIMASU) 
b 
JPN 
ROM 
主語＋（できない / できません） 
Subject + (DEKINAI / DEKIMASEN) 
c 
JPN 
ROM 
主語＋（できた / できました） 
Subject + (DEKITA / DEKIMASHITA) 
d 
JPN 
ROM 
 
主語＋（できなかった/ できませんでした） 
Subject + (DEKINAKATTA / 
DEKIMASENDESHITA) 
E 
a 
JPN 
ROM 
主語＋（思う / 考える） 
Subject + (OMOU / KANGAERU) 
b 
JPN 
ROM 
主語＋（思わない / 考えない） 
Subject + (OMOWANAI / KANGAENAI) 
c 
JPN 
ROM 
主語＋（思った / 考えた） 
Subject + (OMOTTA / KANGAETA) 

207
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
d 
JPN 
ROM 
 
主語＋（思わなかった / 考えなかった） 
Subject + (OMOWANAKATTA / 
KANGAENAKATTA) 
F 
a 
JPN 
ROM 
主語＋（知る / わかる） 
Subject + (SHIRU / WAKARU) 
b 
JPN 
ROM 
主語＋（知らない / わからない） 
Subject + (SHIRANAI / WAKARANAI) 
c 
JPN 
ROM 
主語＋（知った / わかった） 
Subject + (SHITTA / WAKATTA) 
d 
JPN 
ROM 
 
主語＋（知らなかった/ わからなかった） 
Subject + (SHIRANAKATTA / 
WAKARANAKATTA) 
 
G 
 
- 
JPN 
ROM 
 
主語＋述語動詞（存在動詞、思考動詞を除く） 
Subject + Predicate Verb (excluding Verbs which 
means existence and thinking) 
*P-B is an acronym of “Predicate-Based.” S-B is an acronym of “Subject-
Based.”  “a” is present・affirmative. “b” is present・negative. “c” is past・
affirmative, “d” is past・negative. Japanese sentence patterns  
 
First, the predicate-based sentence pattern was sub-
classified into seven sentence patterns: A) Subject + Verb 
(ARU / IRU), B) Subject + Noun + Auxiliary Verb (DESU / 
DEARU / DA), C) Subject + Adjective + Auxiliary Verb 
(DESU / φ), D) Subject + Auxiliary Verb (DEKIMASU / 
DEKIRU), E) Subject + Verb (OMOU / KANGAERU), F) 
Subject + Verb (SHIRU / WAKARU), G) Subject + Verb 
(excluding verbs which mean existence and thinking). In 
addition, each predicate-based sentence pattern has four sub-
classifications which are combinations of Tense and Polarity; 
a) present ・ affirmative (pre_aff), b) present ・ negative 
(pre_neg), c) past・affirmative (past_aff), d) past・negative 
(past_ neg). Table IV indicates predicate-based sentence 
patterns. Not all Japanese sentence patterns are listed. 
TABLE V. JAPANESE SENTENCE PATTERNS 2 
Type 
Subject-based Sentence Patterns 
H 
JPN 
ROM 
〜（する）こと＋（は / が / も）＋述語動詞 
~ (SURU) KOTO + (WA / GA / MO) + Predicate 
I 
JPN 
ROM 
私＋（は / が / も）＋述語 
WATASHI + (WA / GA / MO) + Predicate 
 
Second, the subject-based sentence pattern was sub-
classified into two sentence patterns: H) ~ (SURU) KOTO + 
(WA / GA / MO) + Predicate Verb (excluding an auxiliary 
verb), I) WATASHI + (WA / GA / MO) + Predicate Verb. 
Table V indicates these Japanese subject-based sentence 
patterns. 
 
 
 
3. Criteria for Determination 
The following is a supplementary explanation of each 
sentence pattern: A) ARU and IRU represent the “be” verb 
existence, B) DESU, DEARU and DA represent the “be” verb 
state, C) DESU also represents the “be” verb state, D) 
DEKIRU represents the modal auxiliary ability, E) OMOU 
and KANGAERU represent the general verb thinking, F) 
SHIRU and WAKARU represent the general verb cognitive, 
H) ~ (SURU) KOTO represents an inanimate subject, such as 
a formal subject, a gerund or an infinitive in English, I) 
WATASHI represents the personal pronoun “I”. In Japanese 
verbs, the plain form is used. 
TABLE VI. SENTENCE PATTERN AND ITS CRITERIA FOR ERROR 
DETERMINATION 
S.P. 
Type 
Criteria for Error Determination 
A 
a 
If predicate verb is not {am, is, are, be, have, has, 
exist, exists}, it should be ERROR. 
b 
If predicate verb is not {am not, is not, are not, be not, 
do not have, dose not have, do not exist, does not 
exist}, it should be ERROR. 
c 
If predicate verb is not {was, were, had, existed}, it 
should be ERROR. 
d 
If predicate verb is not {was not, were not, did not 
have, did not exist}, it should be ERROR. 
B 
a 
If predicate verb is not {am, is, are, be}, it should be 
ERROR. 
b 
If predicate verb is not {am not, is not, are not, be 
not}, it should be ERROR. 
c 
If predicate verb is not {was, were}, it should be 
ERROR. 
d 
If predicate verb is not {was not, were not}, it should 
be ERROR. 
C 
a 
If predicate verb is not {am, is, are, be}, it should be 
ERROR. 
b 
If predicate verb is not {am not, is not, are not, be 
not}, it should be ERROR. 
c 
If predicate verb is not {was, were}, it should be 
ERROR. 
d 
If predicate verb is not {was not, were not}, it should 
be ERROR. 
D 
a 
If predicate verb is not {can V, be able to V, am able 
to V, is able to V, are able to V}, it should be ERROR. 
b 
If predicate verb is not {can not V, cannot V, not be 
able to V, am not able to V, is not able to V, are not 
able to V}, it should be ERROR. 
c 
If predicate verb is not {could V, was able to V, were 
able to V}, it should be ERROR. 

208
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
d 
If predicate verb is not {could not V, was not able to 
V, were not able to}, it should be ERROR. 
E 
a 
If predicate verb is not {think, believe, consider, 
guess, suppose, assume}, it should be ERROR. 
b 
If predicate verb is not {does not think, do not think, 
does not believe, do not believe, does not consider, 
do not consider, does not guess, do not guess, does 
not suppose, do not suppose, does not assume, do 
not assume}, it should be ERROR. 
c 
If predicate verb is not {thought, believed, 
considered, guessed, supposed, assumed}, it should 
be ERROR. 
d 
If predicate verb is not {did not think, did not believe, 
did not consider, did not guess, did not suppose, did 
not assume}, it should be ERROR. 
F 
a 
If predicate verb is not {know, get to know, 
understand, find, notice, realize, recognize}, it 
should be ERROR. 
b 
If predicate verb is not {does not know, do not know, 
does not get to know, do not get to know, does not 
understand, do not understand, does not find, do 
not find, does not notice, do not notice, does not 
realize, do not realize, does not recognize, do not 
recognize}, it should be ERROR. 
c 
If predicate verb is not {knew, got to know, 
understood, found, noticed, realized, recognized}, it 
should be ERROR. 
d 
If predicate verb is not {did not know, did not get to 
know, did not understand, did not find, did not 
notice, did not realize, did not recognize}, it should 
be ERROR. 
G 
- 
If predicate verb does not meet semantic agreements, 
it should be ERROR 
H 
 
- 
If subject is not {it, to verb, verb-ing}, it should be 
ERROR. 
I 
 
- 
If subject is not {I}, it should be ERROR. 
*S.P. is an acronym of “sentence pattern.”  The above highlighted sentence 
patterns are dealt with in this study as an illustration. 
 
The predicate-based sentence pattern A) “Subject + Verb 
(ARU / IRU)” always corresponds with a “be” verb, “have” 
or “exist” in English. If they are missing, the English sentence 
would be in error. “B) Subject + Noun + Auxiliary Verb 
(DESU / DEARU / DA)” and “C) Subject + Adjective + 
Auxiliary Verb (DESU /φ)” always correspond with a “be” 
verb in English, without the “be” verb, the English sentence 
would be in error. Sentence pattern D) “Subject + Auxiliary 
Verb (DEKIMASU / DEKIRU)” always corresponds with 
“can” or “be able to” in English, without them, the English 
sentence would be in error. Sentence pattern E) “Subject + 
Verb (OMOU / KANGAERU)” always corresponds with 
“think,” “believe,” “consider,” “guess,” “suppose,” “assume” 
in English, without a “thinking” verb, the English sentence 
would be in error. Sentence pattern F) “Subject + Verb 
(SHIRU / WAKARU)” always corresponds with “know,” 
“understand,” find,” “notice,” “realize,” “recognize” in 
English, without a “cognitive” verb, the English sentence 
would be in error. Sentence pattern G) “Subject + Verb” is 
the most common, if semantic agreement in terms of 
predicate (verb) is missing, an error would occur.  
The subject-based sentence pattern H) “~ (SURU) KOTO 
+ (WA / GA / MO) + Predicate Verb” always corresponds 
with an inanimate subject, such as a formal subject, a gerund 
or an infinitive in English, without the inanimate subject, the 
English sentence would be in error. Sentence pattern I) 
“WATASHI + (WA / GA / MO) + Predicate Verb” is the 
most basic form, without the subject “I” in the English 
sentence, it would be in error. 
Table VI above shows nine sentence patterns and their 
original criteria for determination whether a sentence is 
correct or not. 
IV. 
RESULTS AND DISCUSSION 
In Section III we suggested a method suitable for 
detecting errors automatically and its procedure. In this 
section, we are first going to examine our method and then 
draw a conclusion. 
In order to evaluate our approach, by way of illustration, 
automatic error detection using seven sentence patterns (A, B, 
C, D, E, F and I) was carried out on Japanese sentences with 
subjects and their corresponding English sentences. 
This study utilized 1,499 sentences for analysis from essay 
data written by 110 Japanese EFL (English as a foreign 
language) college students. The proficiency level of all the 
learners was equivalent to the A1 level of the Common 
European Framework of Reference (CEFR). All the 
participants were required to write an essay in Japanese with 
the following prompts: “It is important for college students to 
have a part time job” and “Smoking should be completely 
banned at all the restaurants in the country.”  They then had to 
translate their Japanese essay into English. The essay had to 
be 200 - 300 words, written in under one hour, with no use of 
a dictionary or internet enabled devices. 
For parsing, 100 Japanese sentences with subjects and the 
corresponding English sentences were randomly selected 
from essay data including grammatically correct sentences 
and incorrect sentences. As a result of parsing, 31sentences 
were analyzed by predicate-based sentence patterns, and also 
10 sentences were analyzed by subject-based sentence 
patterns. Each of the sentences are classified based on 
sentence patterns.  
 

209
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
TABLE VII. SAMPLE RESULTS OF EXTRACTION AND ERROR DETERMINATION 
 
Results of Extraction 
Results of Error Determination 
JPN 
ENG 
Type of S.P. 
S.S. 
Sub. 
Pre. 
Sub. 
Pre. 
Sub-based 
Pre-based 
Sub-based 
Pre-based 
1 
理由は 
においだ 
reason 
smell 
UNKNOWN 
B_aff_pre 
UNKNOWN 
POSSIBLE 
2 
ことも 
あります 
Family 
go 
H 
A_aff_pre 
UNKNOWN 
ERROR 
3 
可能性も 
ある 
we 
have 
UNKNOWN 
A_aff_pre 
UNKNOWN 
POSSIBLE 
• 
• 
• 
• 
• 
• 
• 
• 
• 
31 
私も 
思います 
I 
think 
I 
E_aff_pre 
POSSIBLE 
POSSIBLE 
*Sub. is an abbreviation of “subject.” Pre. is an abbreviation of “predicate.” S.P. is an acronym of “sentence pattern.” S.S. is an acronym of “sentence structure.”   
 
In order to obtain feedback, comparisons between Japanese 
primary subjects and predicates and the corresponding 
English primary subjects and predicate verbs were conducted 
based on the extraction by parser and sorted based on sentence 
pattern. 
Table VII shows sample results of extraction and 
determination. This table provides feedback to teachers. The 
results of extraction (left side) show sets of Japanese subjects 
and predicates and corresponding sets of English subjects and 
predicate verbs. The results of error determination (right side) 
show the type of sentence pattern and feedback (ERROR, 
POSSIBLE, UNKNOWN). An explanation of feedback can 
be found in Section III. “ERROR” represents global error 
where the structure of a sentence is wrong. “POSSIBLE” 
represents that the structure of the sentence is correct in 
agreement only for the subject and predicate. “UNKNOWN” 
stands for indeterminable because no relevant sentence pattern 
is seen. Teachers will be able to find learners’ grammatical 
weak points through the ERROR feedback in Table VII and 
then focus their attention on the sentence patterns during the 
course of classroom English education. In this way our system 
can support teachers of English writing. Although there are 
many “UNKNOWN”s in Table VII, the number of “ERROR” 
and “POSSIBLE” will allow teachers to efficiently detect 
where the problems lie and thus reduce their burden.  
To better evaluate the results shown in Table VII, the 
aggregate results were calculated manually in order of 
sentence pattern as shown in Table VIII. This also shows the 
evaluation results of the accuracy of criteria for error detection 
for both predicate-based sentence patterns (A, B, C, D, E, F) 
and the subject-based sentence pattern (I). Manual 
determination follows these steps; 1) Manually extract sets of 
sentence elements, a primary subject and a predicate (verb) 
based on specific extraction rules, 2) Manually sort the sets of 
subjects and predicates (verbs) based on preselected Japanese 
sentence patterns, 3) Manually compare the extracted 
sentence patterns with the defined sentence patterns based on 
the criteria for determination, 4) Obtain the results of error 
determination. The numbers in Results of Manual 
Determination are errors identified 
by criteria 
for 
determination (Table VI). 
TABLE VIII. EVALUATION RESULTS OF THE PREDICATE BASED SENTENCE 
PATTERNS AND THE SUBJECT BASED SENTENCE PATTERNS 
 
Results of 
Determination 
by Error 
Detection System 
Results of 
Manual 
Determination 
Type 
S.P. 
ER. 
PO. 
UN. 
ER. 
Predicate 
Based 
A-a 
8 
2 
6 
0 
1  
A-b 
1 
1 
0 
0 
1 
A-c 
0 
- 
- 
- 
- 
A-d 
0 
- 
- 
- 
- 
B-a 
13 
1 
12 
0 
1 
B-b 
0 
- 
- 
- 
- 
B-c 
0 
- 
- 
- 
- 
B-d 
0 
- 
- 
- 
- 
C-a 
0 
- 
- 
- 
- 
C-b 
1 
1 
0 
0 
0 
C-c 
0 
- 
- 
- 
- 
C-d 
0 
- 
- 
- 
- 
D-a 
0 
- 
- 
- 
- 
D-b 
0 
- 
- 
- 
- 
D-c 
0 
- 
- 
- 
- 
D-d 
0 
- 
- 
- 
- 
E-a 
7 
0 
7 
0 
0 
E-b 
0 
- 
- 
- 
- 
E-c 
0 
- 
- 
- 
- 
E-d 
0 
- 
- 
- 
- 
F-a 
0 
- 
- 
- 
- 
F-b 
0 
- 
- 
- 
- 
F-c 
1 
0 
1 
0 
0 
F-d 
0 
- 
- 
- 
- 
Total 
31 
5 
26 
0 
3 
Subject 
Based 
I 
10 
0 
6 
4 
2 
Total 
10 
0 
6 
4 
2 

210
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
In the above table, ER. stands for “ERROR.” PO. stands 
for “POSSIBLE.” UN. stands for “UNKNOWN.” ( - )  stands 
for “unanalyzed” due to non-applicability. 
 
Comparing the results of determination by error detection 
system with the results of manual determination in Table VIII, 
we obtained the following: 
 
Sentence Pattern A   
Our system classified 9 sentences into sentence pattern A. 
All of them were subclassified into appropriate sentence 
patterns. Of these 9 sentences, 3 sentences were classified into 
ERROR, and 6 sentences were classified into POSSIBLE. 
Agreement between manual determination and automatic 
determination was found to be 8 out of 9. This indicates our 
system is highly reliable for the “be” verb existence. However, 
our system could not determine one sentence appropriately 
which had a negative phrase as a subject. On getting this result, 
we realized the importance of idiomatic expressions. 
 
Sentence Pattern B  
Our system classified 13 sentences into sentence pattern B. 
All of them were subclassified into appropriate sentence 
patterns. Of these 13 sentences, 1 sentence was classified into 
ERROR, and 12 sentences were classified into POSSIBLE. 
Agreement between manual determination and automatic 
determination was 100%. This indicates our system is highly 
reliable for the “be” verb state.  
 
Sentence Pattern C  
Our system classified 1 sentence into sentence pattern C. 
This sentence was subclassified into an inappropriate sentence 
pattern. Agreement between manual determination and 
automatic determination was 0 out of 1, because of a problem 
dealing with homonyms. It is possible to solve this by 
customizing homonym information into our system. 
 
Sentence Pattern D 
No sentence was found in this category. 
 
Sentence Pattern E 
Our system classified 7sentences into sentence pattern E. 
All of them were subclassified into an appropriate sentence 
pattern. All 7 sentences were classified into POSSIBLE. 
Agreement between manual determination and automatic 
determination was 100%. This indicates our system is highly 
reliable for the “thinking” verb.  
 
Sentence Pattern F  
Our system classified 1 sentence into sentence pattern F. 
This sentence was subclassified into an appropriate sentence 
pattern. This sentence was classified into POSSIBLE. 
Agreement between manual determination and automatic 
determination was 100%. This indicates our system should be 
reliable for the “cognitive” verb.  
 
Sentence Pattern I   
Our system classified 10 sentences into sentence pattern I. 
All 10 sentences were subclassified into an appropriate 
sentence pattern. Of these sentences, 6 sentences were 
classified into POSSIBLE, and 4 sentences were classified 
into UNKNOWN. Agreement between manual determination 
and automatic determination was 6 out of 10. 
 
We still need to address a couple of issues; 1) deficiencies 
in sentence patterns, 2) deficiencies in the parser.  
Concerning deficiencies in sentence patterns, for example, 
when the subject is a negative phrase, the system still has 
difficulty dealing with it, as in the sentence “Nothing is as 
good as part time job for learning society.” With respect to 
Deficiencies in the parser, our system is tied to the results of 
the parser CaboCha. Since it is not 100% accurate, any 
deficiencies are reflected in our system. 
Given the nature of these results, it will be possible to 
improve the deficiencies in the ability of the system to handle 
additional types of sentence patterns. However, it is not 
possible for us to improve on the deficiencies in the parser. 
V. 
CONCLUSION 
In this study, we proposed an approach toward an 
automatic error detection system. Our approach is based on 
the idea that criteria for error determination are constructed 
by the correspondence relation of the core sentence elements, 
a subject and a predicate verb, between the source language 
and the target language utilizing sentence patterns.  
As a result of examining the accuracy of our criteria for 
error determination based on the seven sentence patterns 
chosen, we concluded that if we use sentence patterns in the 
source language, automatic error detection was effective 
when based on our criteria for error determination.  
In addition, we assume our approach will be applied to 
other languages if it is possible to extract the set of a subject 
and predicate verb from the source language and the target 
language, as we do here. Arabic, Chinese, French, German 
and Spanish are suitable for our approach because the 
Stanford Parser supports these languages. However, Chinese, 
like Japanese, is not written with a space between words and 
therefore needs morphological analysis as a pretreatment 
before parsing.  
We are working to handle sentences that have no subject, 
as well as sentences that have multiple subjects, and expand 
the number of sentence patterns in order to respond to as wide 
a range of English essays as possible. From the characteristics 
of our pattern-driven approach to structural error detection, 
the accuracy of error determination is influenced by the 
extraction rate of a subject and a predicate verb. Topic-
prominent languages which allow subject optional sentences, 
such as Japanese, Chinese and Indonesian, will have a 
negative impact on the accuracy of error detection because it 
is impossible to extract a subject based on the ability of 
present parsers. Therefore, it will be necessary to create rules 
which can compensate for the omitted subjects.  
Moreover, the ability of developing sentence patterns, 
unlike other language error detection systems, will enable the 
system to deal with various learners’ global errors which is a 
key point of our approach. 

211
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
ACKNOWLEDGEMENT 
This work was partially supported by JSPS KAKENHI 
Grant Number JP17K01081. 
REFERENCES 
[1] 
K. Kawamura, H. Kashiwagi, and M. Kang, “An approach 
toward automatic error detection in learners’ English writing 
based on the source language,” Proceedings of The Tenth 
International Conference on Mobile, Hybrid, and On-line 
Learning, eLmL 2018, pp. 62-65, 2018. 
[2] 
W. Grabe and R. B. Kaplan, “Theory and practice of writing: 
An applied linguistics perspective,” Harlow: Pearson 
Education, p. 6, 1996. 
[3] 
Y. Takada, “21seiki no daigakueigo: Monbukagakushou 
itakukenkyuu 
eigokyouiku 
ni 
kansuru 
kenkyuu,” 
dai4kenkyuugurupu 
(Daigaku 
ni 
okeru 
eigokyouiku) 
saishuuhoukokusho, p. 12, 2004. 
[4] 
C. Baba, “Raiteingushidode motomerareteirumono,” In H. 
Kimura, T. Kimura, and O. Shiki (Eds.), Theory and practice 
in reading and writing: Nurturing independent learning (pp. 
119-134), Tokyo: Taishukan, 2010. 
[5] 
Y. Tono, “A computer learner corpus based analysis of the 
acquisition order of English grammatical morphemes,” In L. 
Burnard and T. McEnery (Eds.), Rethinking language 
pedagogy from a corpus perspective (pp. 124-132), Frankfurt 
am Main: Peter Lang, 2000. 
[6] 
M. Sugiura, “Collocational knowledge of L2 learners of 
English: A case study of Japanese learners,” Language and 
computer, 38, pp. 303-323, 2002. 
[7] 
Y. Kobayashi, “An error analysis of “because” in Japanese 
EFL 
learners’ 
written 
English,” 
Kantoukosuhinetsu 
Eigokyouikugakkai Kenkyukiyou, 23, pp. 11-21, 2009. 
[8] 
E. Matsui, “Eisakubun ni okeru nihonjinteki ayamari,” Tokyo: 
Taishuukan, 1979. 
[9] 
M. Miyata, “Kokomade tsujiru nihonjineigo: Atarashi 
raiteinguno susume,” Tokyo: Taishuukan, 2002. 
[10] Y. Kudo, “A study on the characteristics of global errors made 
by learners of different levels of writing ability,” ARCLE 
(Action Research Center for Language Education) REVIEW3, 
pp. 110-121, 2009. 
[11] R. Nagata, T. Wakana, F. Masui, A. Kawai, and N. Isu, 
“Detecting article errors based on the mass count distinction,” 
Proceedings of the Second international joint conference on 
Natural Language Processing, pp. 815-826, 2005. 
[12] J. Lee and S. Seneff, “Correcting misuse of verb forms,” 
Proceedings of the 46th Annual Meeting of the Association for 
Computational Linguistics, pp. 174-182, 2008. 
[13] A. Rozovskaya and D. Roth, “Algorithm selection and model 
adaptation for ESL correction task,” Proceedings of the 49th 
Annual Meeting of the Association for Computational 
Linguistics, pp. 924-933, 2011. 
[14] T. Tajiri, M. Komachi, and Y. Matsumoto, “Tense and aspect 
error correction for ESL learners using global context,” 
Proceedings of ACL, pp. 198-202, 2012. 
[15] C. Leacock, M. Chodorow, M. Gamon, and J. Tetreault, 
“Automated grammatical error detection for language 
learners,” Morgan & Claypool Publisher, 2014. 
[16] S. Shao, K. Ohtsuki, H. Kiyomitsu, and M. Kang, “Tracking 
verb phrases for formative feedback in foreign language 
writing,” Proceedings of The Tenth International Conference 
on Mobile, Hybrid, and On-line Learning, eLmL 2018, pp. 58-
61, 2018. 
[17] C. D. Manning, “Computational linguistics and deep learning,” 
Computational Linguistics, 41(4), pp. 701-707, 2015. 
[18] P. Etoori, M. Chinnakotla, and R. Mamidi, “Automatic 
spelling correction for resource-scarce languages using deep 
learning,” Proceedings of ACL 2018, Student Research 
Workshop, pp. 146-152, 2018. 
[19] K. Kawamura, H. Kashiwagi, and M. Kang, “On the potential 
of error analysis using source language in learner’s written 
English,” Research report of JET conference, JSET, 17(2), pp. 
225-232, 2017. 
[20] E. Tarone, “Communication strategies, foreigner talk, and 
repair in interlanguage,” Langauge learning, 30, pp. 417-431, 
1980. 
[21] K. Kawamura, H. Kashiwagi, and M. Kang, “An approach of 
semi-automatic correction feedback for learners’ English 
writing using the source language,” Proceedings of 
Symposium on Language and Sustainability in Asia 2017, 
SELSA2017, pp. 11-16, 2017. 
[22] R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik, “A 
comprehensive grammar of the English language,” London, 
UK: Longman, 1985. 
[23] D. Biber, S. Johansson, G. Leech, S. Conrad, and E. Finegan, 
“Longman grammar of spoken and written English,” Essex, 
UK: Pearson Education Limited, 1999. 
[24] S. Ando, “Eigo no ronri, nihongo no ronri [The logic of 
English, the logic of Japanese],” Tokyo: Taishuukan, 1986. 
[25] T. Kudo and Y. Matsumoto, “Fast methods for Kernel-based 
text analysis,” ACL 2003 in Sapporo, Japan, 2003. 
[26] D. Klein and C. D. Manning, “Accurate unlexicalized parsing,” 
Proceedings of the 41st Meeting of the Association for 
Computational Linguistics, pp. 423-430, 2003. 
[27] K. Kawamura, “Examining a subject and predicate extraction 
using parser,” Intercultural Studies Review, 31, pp. 51-64, 
2018.
 

