Intelligent Multimedia Mind Maps to Support Media Pre-Production 
 
Erik Mannens, Ruben Verborgh, Rik Van de Walle 
ELIS – Multimedia Lab 
iMinds – Ghent University 
Ghent, Belgium 
{erik.mannens, ruben.verborgh, rik.vandewalle}@ugent.be 
Simon Debacq, Maarten Verwaest 
Limecraft 
Ghent, Belgium 
{simon.debacq, maarten.verwaest}@limecraft.com
 
 
Abstract—To date, there are almost no tools that support the 
elaboration and research of project ideas in media pre-
production. The typical tools that are being used are merely a 
browser and a simple text editor. Therefore, it is our goal to 
improve this pre-production process by structuring the 
multimedia and accompanying annotations found by the 
creator, by providing functionality that makes it easier to find 
appropriate multimedia in a more efficient way, and by 
providing the possibility to work together. To achieve these 
goals, intelligent multimedia mind maps are introduced. These 
mind maps offer the possibility to structure your multimedia 
information and accompanying annotations by creating 
relations between the multimedia. By automatic connecting to 
external sources, the user can rapidly search different 
information sources without visiting them one by one. 
Furthermore, the content that is added to the mind map is 
analyzed and enriched; these enrichments are then used to give 
the user extra recommendations based on the content of the 
current mind map. Subsequently, an architecture for these 
needs has been designed and implemented as an architectural 
concept. Finally, this architectural concept is evaluated 
positively by several people that are active in the media 
production industry. 
Keywords - media pre-production; mind maps; information 
search; semantic web. 
I. 
 INTRODUCTION 
In professional media pre-production [1], there is little 
support to elaborate on an idea. Usually, one only uses a 
browser and a text editor as tools, i.e., one to search for 
information and one to gather the information [2], but most 
of the idea is in their brain and not on virtual and/or 
collaborative “paper”. 
The main problem with the current research method is 
that there is almost no logical structure, as most of the 
structure is in the brain of the creators. In a co-production, 
this problem becomes even bigger, because the idea is spread 
over multiple brains. A result of the lack of structure is that it 
is hard to reuse information in future productions, because 
existing documents –if they still exist at all– are hard to 
comprehend, since it is a linear list of non-related pieces of 
information, and thus, it is hard to find the necessary 
information, certainly for people that did not perform the 
research in the first place. Another problem is the fact that 
information is widely spread, and thus, creators have to use 
several 
search 
engines 
within 
different 
distributed 
information bases. 
We counter these problems by introducing the notion of 
intelligent multimedia mind maps [3]. First of all, this 
multimedia mind map structures the found multimedia. This 
structure, as such, has little short-term impact, but has a big 
long-term influence, since it is easier to reuse older work as 
re-finding 
sources 
is 
self-evident 
by 
reusing 
the 
accompanying annotations. Secondly, the information from 
the multimedia mind map can be used to suggest new 
relevant information; hence from now on our implemented 
automatic 
recommendations 
makes 
us 
talk 
about 
“intelligent” multimedia mind maps.  
Section 2 describes the concept of mind mapping, 
whereas Section 3 explains why current search services will 
be reused. Furthermore, Section 4 elaborates on the 
Architectural Concept, and afterwards, Section 5 evaluates 
our solution. Finally, Section 6 draws conclusions and looks 
at future extensions. 
II. 
MIND MAPPING 
A mind map [4] is a tree structure where you start with a 
main topic, preferably the center of your mind map. 
Subsequently, you associate subtopics with the main topic; 
thereafter you do the same with the subtopics. To have a 
view on what’s available we searched for existing mind map 
software. There are plenty, but most of them only support 
text. However, there are two that have more functionality. 
Mind42 [5] furthermore supports images and collaboration, 
but lacks support for videos and connection with external 
sources. On the other hand, Visual Understanding 
Environment (VUE) [6] supports images and limited 
connection with not-modifiable external sources, but lacks 
support for videos, and collaboration. Our envisioned 
intelligent multimedia mind maps do fully support text, 
images, audio & video, external links via Linked Open Data 
(LOD), and collaborative user management.  
III. 
SEARCH SERVICE 
There are many multimedia sources and most of them 
have a search service, which is optimized for their own 
needs. Both local and generic services are apparent, i.e., an 
example of such a local service is MediaLoep [7], which 
provides a service to search the VRT [8] video archive. The 
most well known generic multimedia search engine is 
Google’s YouTube [9]. Therefore, it is not our goal to 
provide our own search service but to integrate existing 
services by using and incorporating their Application 
Programming Interfaces (API). 
50
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-342-1
CONTENT 2014 : The Sixth International Conference on Creative Content Technologies

IV. 
ARCHITECTURAL CONCEPT 
Before creating an architectural concept, a generically 
extensible architecture was designed according to the generic 
requirements, resulting from the analysis of the problems in 
current methods of topic research in media pre-production, 
and conforming the Attribute-Driven Design (ADD) [10] 
principles. This resulted in a 3-tiered layer architecture, as 
shown in Figure 1. The top-layer communicates with the 
client and forwards commands to the second layer, i.e., the 
model layer, which –among other things– comprises the state 
of the mind map and uses the services from the bottom layer, 
the service layer. There are three main services in the bottom 
layer, i.e., storage, enrichment, and recommendation. The 
storage service is a module that is used to communicate with 
a database. In this case, a graph database was chosen, 
because of better performance on traversing related data, and 
greater flexibility [11]. 
 
 
Figure 1.  Generic Architecture of the Architectural Concept. 
The enrichment service is decomposed according to a 
composite pattern [12]. This way it is easy to add and 
remove enrichers, which are modules that analyze the 
content and return important features. For the architectural 
concept Named Entity Recognition (NER) was performed 
using Apache Stanbol [13], which was chosen over 
DBpediaSpotlight [14] as such, because the first includes the 
DBpediaSpotlight service and gives more possibilities with 
modifiability in mind, e.g., you can incorporate your own 
thesaurus and/or ontology. Mind you, in the current 
architectural concept there is only a text enricher, but this 
can easily be extended to enrichers for other multimedia 
formats. 
The recommendation service is similar to the enrichment 
service and is also decomposed into a composite pattern. 
This makes it easy to always add extra modules that connect 
with external sources with their accompanying search 
functionality. To be able to show this functionality in the 
architectural concept three modules, i.e., a connection with 
Flickr [15], Wikipedia [16] & its LOD counterpart DBPedia 
[17], and YouTube, were implemented. These three initial 
sources were chosen because they offer three different 
multimedia formats and they have a publicly available and 
well-documented API. In Figure 2, you can see an overview 
of the resulting architectural concept application. 
V. 
EVALUATION 
Firstly, our predefined goals –especially the goal to 
improve the structuring and reuse of the content– were 
confirmed by the people of both Limecraft [18] and Taglicht 
Media [19]. They both have the need for more structure in 
their research, because it is hard to find content again, 
certainly when they share their research with others. 
Structuring content according to a mind map structure is 
a beginning, but there was need for more functionality, 
including named relationships and cross-linking. The 
integration of external LOD sources was a great addition, 
because the creator can simply add a piece of content to the 
mind map, but the current implementation has it flaws. The 
user always has to add the complete piece of content, but is 
usually only interested in a quote or a small piece of the 
content. Another remark is that it should not only be possible 
to search external sources, but also the content that’s in some 
other mind maps. This would be useful in very large mind 
maps, certainly when you don’t know how the content was 
structured in the first place. 
Also the recommendation functionality is a nice feature 
to have, but there are some limitations as well. It cannot 
replace the human brain and therefore, it is only suited to 
define high-level concepts, which is useful to rapidly divide 
research work. It cannot, at least for now, give the user a full 
background of his developing topic. 
VI. 
CONCLUSION AND FUTURE WORK 
The provided solution for the predefined goals show 
potential, certainly the structural functionality as this is a big 
problem right now. Because reuse of research data saves a 
lot of time, it has a big impact on the value chain of future 
productions. However, before our tool can be used in 
professional media production, there’s a need to improve the 
application taking the feedback of the previous section into 
account, i.e., the incorporation of media fragments and the 
search between implemented intelligent mind maps. 
Next to the improvements to the current application 
there’s also the possibility to add some extra functionality. 
The mind map could be more intelligent by adding the 
possibility that when you add a piece of content you get 
suggestions how this piece of content is related to the content 
in the current mind map. For example, when you have two 
nodes as pictured in Figure 2, one about “Caesar” and one 
about “Pompey”, and you add a node about “Julia” you get 
the suggestion to add it to the node about “Caesar” with 
relation ’daughter’ and/or to the node about “Pompey” with 
the relation ’wife’. 
Other extensions are to provide export functionality for 
the multimedia mind maps to support interoperability or to 
add the functionality to create a scenario. Merging the two 
applications –scenario creation and multimedia mind map– 
in one application makes it easy to switch between creating 
the scenario and expanding the mind map, which is useful 
because these processes happen in an iterative and parallel 
way anyway [20]. Another advantage would be to drag and 
drop parts of the mind map, e.g., quotes, into the scenario. 
51
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-342-1
CONTENT 2014 : The Sixth International Conference on Creative Content Technologies

ACKNOWLEDGMENT 
The research activities that have been described in this 
paper were funded by Ghent University and iMinds 
(Interdisciplinary Institute for Technology) a research 
institute founded by the Flemish Government. 
REFERENCES 
[1] L. Hardman, Z. Obrenovic, F. Nack, B. Kerhervé, and K. 
Piersol, “Canonical processes of semantically annotated 
media production”, ACM Multimedia Systems Journal, vol. 
14, no. 6, September 2008, pp. 327–340. 
[2] D. Van Rijsselbergen, B. Van De Keer, and R. Van de Walle, 
“The 
canonical 
expression 
of 
the 
drama 
product 
manufacturing process”, ACM Multimedia Systems Journal, 
vol. 14, no. 6, September 2008, pp. 395-403. 
[3] M. Davies, “Concept mapping, mind mapping and argument 
mapping: what are the differences and do they matter?”, 
Journal of Higher Education, vol. 62, no. 3, September 2011, 
pp. 279-301. 
[4] M. J. Eppler, “A comparison between concept maps, mind 
maps, conceptual diagrams, and visual metaphors as 
complementary tools for knowledge construction and 
sharing”, Information Visualization, vol. 5, no. 3, September 
2006, pp. 202–210. 
[5] Mind42 
[Online]. 
Available 
from: 
http://mind42.com/ 
[retrieved: April, 2014]. 
[6] Visual Understanding Environment [Online]. Available from: 
http://vue.tufts.edu/ [retrieved: April, 2014]. 
[7] P. Debevere, D. Van Deursen, E. Mannens, R. Van de Walle, 
K. Braeckman, and R. De Sutter, “MediaLoep: Optimizing 
search in a broadcaster archive”, Proceedings of the 12th 
International Workshop on Image Analysis for Multimedia 
Interactive Services (WIAMIS 2011), April 2011, pp. 1-2. 
[8] VRT - Vlaamse Radio & Televisie - Belgian’s regional 
broadcaster [Online]. Available from: http://www.vrt.be/ 
[retrieved: April, 2014]. 
[9] YouTube [Online]. Available from: http://www.youtube.com/ 
[retrieved: April, 2014]. 
[10] L. Bass, P. Clements, and R. Kazman, “Software Architecture 
in Practice”, Addison-Wesley, third edition, October 2012. 
[11] C. Vicknair, M. Macias, Z. Zhao, X. Nan, Y. Chen, and D. 
Wilkins, “A comparison of a graph database and a relational 
database: a data provenance perspective”, Proceedings of the 
48th annual Southeast regional conference, April 2010, pp. 
42. 
[12] E. Gamma, R. Helm, R. Johnson, and J. Vlissides, “Design 
Patterns: Elements of Reusable Object-Oriented Software”, 
Addison-Wesley, November 1994. 
[13] Apache 
Stanbol 
[Online]. 
Available 
from: 
http://stanbol.apache.org/ [retrieved: April, 2014]. 
[14] P. N. Mendes, M. Jakob, A. Garcia-Silva, and C. Bizer, 
“Dbpedia spotlight: shedding light on the web of documents”, 
Proceedings of the 7th International Conference on Semantic 
Systems, September 2011, pp. 1–8. 
[15] Flickr 
API 
[Online]. 
Available 
from: 
http://www.flickr.com/services/api/ [retrieved: April, 2014]. 
[16] Wikipedia 
API 
[Online]. 
Available 
from: 
http://www.mediawiki.org/wiki/API [retrieved: April, 2014]. 
[17] DBPedia 
API 
[Online]. 
Available 
from: 
http://wiki.dbpedia.org/lookup/ [retrieved: April, 2014]. 
[18] Limecraft 
[Online]. 
Available 
from: 
http://www.limecraft.com/ [retrieved: April, 2014]. 
[19] Taglicht 
Media 
[Online]. 
Available 
from: 
http://www.taglichtmedia.de/en/ [retrieved: April, 2014]. 
[20] A. 
Rosenthal, 
“Writing, 
Directing 
and 
Producing 
Documentary Films and Videos”, Southern Illinois University 
Press, June 2007. 
 
 
Figure 2.  Architectural Concept Multimedia Mind Map Application. 
52
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-342-1
CONTENT 2014 : The Sixth International Conference on Creative Content Technologies

