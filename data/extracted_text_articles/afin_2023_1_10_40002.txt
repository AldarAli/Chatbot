The Research on a Cloud Intelligence Communication Platform 
of Smart Edge Devices Supporting for Metaverse Spatial Reality 
Joon-Kyung LEE*, Tae-Sang CHOI, Sang-Sik YOON 
Content Research Division*, ETRI 
DaeJeon, South KOREA 
e-mail: {leejk, choits, ssyoon90}@etri.re.kr 
Young-Hwa KIM, Soon-Seok SHIN, Shin-Kyu KIM 
SoulSystems Inc. 
PanGyo, South JOREA 
e-mail: {yhkim, ssshin, sk.kim}@soulsystems.co.kr
Abstract—This paper would like to introduce a new Device 
Edge Computing (DEC) that connects wearable devices with 
multimodal sensor hubs (supersensitive cameras, supersonic 
complex sensors, etc.) and (B)5G public/private networks. This 
DEC has studied the function/performance requirements of 
metaverse devices that support super-reality and super space-
reality eXtended reality (XR) services that directly feel the 
high-sensitivity sensing of remote virtual objects, and proposes 
a quality-guaranteed cloud intelligent network architecture 
platform to support advanced services of metaverse space 
reality 
content. 
Keywords-DEC; Metaverse Wearable Devices; Spatial-Reality.
I.
INTRODUCTION
Recently, in the non-face-to-face era such as COVID-19, 
we are actively researching and developing the "metaverse 
daily service" era that can remotely control the real and 
virtual objects ((Non-)IIoT vs. Avatar) by remotely 
connecting to a metaverse communication platform without 
going to a smart factory or smart farm, etc [1]. In addition, 
the advanced Information & Communication Technology 
(ICT) countries in the metaverse research field of 
communication, media, and content are actively providing 
virtual and reality space due to the development of ultra-
high-speed, ultra-low-latency mobile networks, ultra-real 
media User Interface (UI) / User eXperience (UX), and the 
advanced Cloud-based Software Defined Network (SDN) / 
Network Functions Virtualisation (NFV) / virtual Deep 
Packet Inspection (vDPI), 5G/6G & Multi-access Edge 
Computing (MEC), Virtual Reality (VR), Augmented 
Reality (AR) / Mixed Reality (MR) / XR media and their 
ultra-immersive contents technology. 
Currently, the main characteristics of metaverse-
supported physical communication, media, and content for 
hybrid Brain Computer Interface (BCI) & XR services 
would be required as follows: 
1) Measure and analyze various willingness and sentiment 
with multi-modal sensor detection of smart wearable 
device [4]. 
2) Recognize and respond to the environment-surrounding 
risk factors in advance through Big-Data and AI 
analysis. 
3) Enhance and apply the collective intelligence 
communication through {body intelligence (brainwave 
& willingness & emotion) + hydrology Convolutional 
Neural Network (CNN) / Reinforcement Neural 
Network (RNN) / Spiking Neural Network (SNN) + 
Internet Cloud intelligence}, 
4) Acquire the determining system of situation, inference, 
simulation for ensemble of global heterogeneous 
signals through a multi-modal signal hub 
So, we believe that metaverse services will be provided 
in the following short-term period, mid-term period, and 
long-term period forms in terms of applying the following 
metaverse scenarios: 
Short-term period: In the event of an emergency, rescue 
workers at a disaster site, wearing augmented reality 
(AR/XR) glasses receive the emergency evacuating 
information from a remote location to safely rescue the 
victims via AR Tele-Presence/Navigation. 
Mid-term period: A healthy running emotional exercise 
between couples living apart from Seoul and Jeju Island 
while feeling friendly remote five senses through the 
immersive spatial-reality AR/XR glasses and human 
intelligence edge devices as shown below in Fig. 1. 
Figure 1. Metaverse Running Healthy with Remote Virtual Partners [Mid-
term period] 
1
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-093-3
AFIN 2023 : The Fifteenth International Conference on Advances in Future Internet

Long-term period: Like Luc Besson's SF movie "Valerian: 
City of a Thousand Planets," a true metaverse service that 
connects to virtual space in a desert-like real space to 
experience the XR/hologram-type surroundings and main 
character movements 
In 
the 
above 
service 
scenarios, 
the 
following 
specifications would be required for Metaverse Wearable 
UI/UX devices and their supporting DEC devices (Fig 2): 
Figure 2. Metaverse Wearable XR Glasses 
•  Smart Thin-Client Wearable Device: {Social feed 
analysis (object feature point/area extraction accuracy: 
65.0 APoks, Learning performance: 0.25sec) & AI-
imaging (Cascaded R-CNN, Location/Area Detection 
Accuracy: 69.5/64.0%, 20fps, Similar Product Search 
Accuracy: 63.8%, Style Tag Extraction Accuracy: 
73.85%)}, examples: UI/UX such as Electro Encephalo 
Graphy (EEG) helmet, AR glasses, XR goggles, AR 
interlocking ring/thimble, etc. [1]
•  Smart Edge Devices: high-performance spatial scanning 
holographic camera/projection as an extension of WiFi-
Access Point (AP) {Multi-View-Point 2D Web-Cam 
Scanner and ALG-motion (2+ people, up to 27 joints) 
motion recognition technology create 31.5-inch 8K 
glasses-free-3D Light Field (LF)-hologram realistic 
content}, 
Communication 
Intelligence 
On-device 
AI/Computing (AIoT), etc [1]. 
The remaining of the paper is structured as follows: The 
overall of Section 2 presents the Metaverse DEC Cloud 
Network Architecture and its required DEC’s detail 
specifications in Section 2.A, 2.B, 2.C. 
II.
MAIN RESEARCH ISSUES
In section II, we would show the relationship of 
metaverse device and direction of cloud intelligence 
communication platform in II.A, and detailed research and 
developing 
direction 
of 
DEC 
cloud 
intelligence 
communication platform for Metaverse in II.B, and the 
future Metaverse services’ challenges expecting functions & 
performances in II.C. 
A. Relationship of Metaverse Device and Direction of 
Cloud Intelligence Communication Platform 
In an ultra-low delay, high broadband, and ultra-
connected intelligent communication environment under 
5G/MEC [2] and 6G/DEC [6], the metaverse user devices 
would be advanced as listed in Table I. 
TABLE I. MAIN CHARACTERISTICS OF METAVERSE USER DEVICES
The AR/XR/hologram glasses, drone-attached intelligent 
five-sensory 
device 
edge 
computing 
(DEC) 
4D, 
automatically adjusting 4D (3D+five senses) space size and 
visibility/light of indoor and outdoor environments, 
recognizing and identifying 4D (3D+five senses) metadata 
required to identify object information, we think that it is 
necessary to secure a new five-sense experience-type 
Spatial-Reality metaverse technology that connects virtual 
information about see-through objects reflected from remote 
locations 
by 
cluster 
control 
communication 
and 
synchronization only with gaze/speech/gesture-UI access. 
It is necessary for supporting a complete thin-client 
communication structure between smart wearable devices 
[3][5] worn on the body and smart edge devices that support 
off-loading the insufficient network/computing /storage-
caching performance of all-in-one wearable devices. It is 
thought that research on a "metaverse device communication 
platform that supports physical enhancement spatial-reality" 
that expands to five senses (such as visual/hearing/scent/ 
taste/touch) and cloud intelligence is needed. 
Therefore, this basic study will be conducted in the 
following directions as the below of Fig. 3: 
Figure 3. On-Premise DEC Study Direction (Red) according to Metaverse 
Evolution (Yellow) 
2
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-093-3
AFIN 2023 : The Fifteenth International Conference on Advances in Future Internet

• Research direction 1: The realistic immersive wearable 
device computing requires ultra-small, light-weight, and 
low-power AIoT(AI of Things) audio-visual intelligence 
that satisfies metaverse services: Indoor and outdoor real-
world/object-cognitive 
and 
3D-space 
correlation 
analysis/control method. 
• Research direction 2: The real-time & time-sensitive 
deterministic 
multi-collaboration 
Visual 
Intelligent 
Device Edge Computing (DEC) with cloud intelligence 
communication platform structure that provides visual 
safety and visual work efficiency. 
B. Detailed Research and Development Direction of DEC 
Cloud 
Intelligence 
Communication 
Platform 
for 
Metaverse 
Prior to the metaverse era, VR/AR composite rendering 
support was simply a trend provided by Local Server (Thin-
Client structure), but VR/AR support is gradually 
approaching MEC (Edge Cloud) in the 5G era. In the future, 
it is expected that it will be developed into a DEC for on-
time provision of XR/Hologram next-generation XR 
contents beyond VR/AR. Therefore, the DEC concept is 
expressed in Device Cloud terms in 2021, and the 
establishment of the concept has not been clearly confirmed 
in international standardization. For the metaverse-support 
DEC R&D, this ETRI established domains in two directions 
for effective preemptive responses as in Fig. 4. 
1) Cloud Intelligence Communication Edge Device 
Requirements & Specification based on Metaverse 
Service Characteristics: User Device Requirements & 
System Requirements - Definitions Established 
2) The Platform of DEC Structure/Function/Performance 
of Cloud Intelligence Communication Edge Device 
based on Metaverse Service Quality Assurance 
Figure 4. Cloud intelligence communication type DEC type of 5(6)G 
network application location/structure (red box) 
C. Future 
Metaverse 
Services 
Expect 
Functional/ 
Performance Challenges 
1) Edge Access-Point (AP) device requirements (Fig. 5) 
- Visual Intelligent Edge Device-HardWare(HW) 
• 3D high-precision position/coordinate and size SLAM 
calculations, 
fixed/mobile/drone-attached 
variable-
lightening, high-density resolution and motion-to-photon 
(HW-MTP), edge GPU/TPU/NPU (biological) chips & 
AP (Application Processor) boards 
- Visual Intelligent Edge Device-SoftWare(SW) 
•  Multi-Collaborative Virtual Space Infrastructure 
Dynamic Configuration, Real/Virtual Object Matching 
Precision, 
Eye-movement/Biological/Body-gesture 
Automatic Tracking and Situation Cognition, μ-Service 
Device-dedicated 
OS/SDK/IDE 
SW 
Development 
Environment 
- Visual Intelligent Edge Device-AIoT 
•  Real-object property correlation analysis, correlation 
matching 
with 
virtual 
objects, 
multi-collaboration 
spectrum optimization, real-time caching of device’s 
location/gesture 
transformation 
content, 
real-time 
resource optimization, privacy of fixed/movement 
objects, etc 
- Visual Intelligent Edge Device-Network Computing 
• Location/posture conversion Round Trip Time (RTT) 
ultra-low latency, Physical/Virtual/Container Network 
Function (PNF/VNF/CNF)-mixed micro-service silo 
structure with RESTful bus structure, DEC net 
computing 
virtualization 
with 
5G-CorePlane 
AF(Application Function) and MEC standard model 
linkage, and Multicast/Broadcast support on XCF & 
XUF functional modules for multiple collaborations on 
5G-CorePlane 
2) Wearable Device Requirements Specifications (Fig 5) 
Figure 5. ETRI Trustworthy AR Platform (an example) 
3
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-093-3
AFIN 2023 : The Fifteenth International Conference on Advances in Future Internet

- Analysis of the possibility of achieving 95% of the final 
metaverse (XR/SR) realistic recognition rate based on 
cognitive 
advancement 
(95%) 
in 
body 
(brain 
wave/biological) targets 
• Metaverse virtual space deployment time: 10 seconds →
1 second → 10ms or less 
• Metaverse {brain wave→real virtual object} directive 
response time: 1 second→10ms→1ms or less 
• Metaverse EEG-Intention/Emotional/Immersion Content: 
(Video) AR/XR →3D (real) Hologram→ 4D (feeling) 
Hologram 
- (AR/VR/XR) Key features of wearable device requirements 
as Tele-Presence services evolve 
• Short-term period: Remote IoT-control Service in TR-
Presence: Remote IoT access and cyan-tracking object-
control based on Tele-Presence {Connected IoT access 
and simple gaze/voice reflected in mutual AR glasses 
between AR-DECs (Head Mounted Display (HMD) 
100% already achieved)-Command control (HMD 100% 
already achieved) (HMD visualization RTT average 
23ms achieved) 
• Mid-term period: Remote tactile (five senses) analysis/ 
transmission and fine-feeling (sense) object-control on 
Tele-Experience 
• Long-term period: Remote Thinking (intention, emotion) 
analysis and communication on Tele-Hologram and 
physical-AI-based all-thing (people/things)-control 
III. CONCLUSIONS
Currently, this study is planning to establish a linkage 
structure between metaverse user devices, Device Cloud, 
5G/MEC and 6G/DEC, derive a real/virtual-object content 
metaverse platform environment between 5G/6G Control 
Plane and wearable/edge devices, and identify metaverse 
content creation levels as shown in Fig. 6. 
Figure 6. DEC Prototype Device & Server Platform (from ETRI & 
KoreaTech Univ.) 
The results of this study will be a preemptive research 
opportunity in the development of intelligent edge device 
communication platforms that provide as follows (Fig. 7): 
1) High angle, high precision, and xyz space coordinate 3D 
space risk detection and work efficiency in everyday 
life 
2) A preemptive research opportunity for the development 
of an intelligent edge device communication platform 
that provides life safety audio/visual-moving_guide 
through recognition/ inference of the elderly/children's 
behavior observation. 
Figure 7. The DEC adapting to 5G Core Plane Prototype 
ACKNOWLEDGMENT
This work is now supported by Institute for Information 
& communications Technology Promotion (IITP) grant 
funded by the Korea government (MSIP) (The Development 
of Autonomic Management System based on LAMPAD-AI 
for 
Network 
Anomaly 
(LAMPAD-A3M), 
RS-2023-
00233883) 
REFERENCES
[1] Many 
speakers 
at 
home 
and 
abroad, 
"Ultra-realistic 
(3F/AR/VR) Technology and Metaverse", 2021Ultra-realistic 
Display Online Workshop, 2021.07.12.~18 
[2] Lee Joon-kyung and three others, "Hyper-connected 5G 
Network Architecture for Smart ETRI-TR Glass Platform", 
Autumn Conference of the Korean Sensor Association, 2019 
[3] Lee Joon-kyung and three others, "Rendering and Voice 
Recognition of Industrial HMD AR Glasses," Korea 
Electronics Association Summer Conference, 2020 
[4] Lee Joon-kyung and seven others, "Basic Study of Brainwave 
Augmented Reality Brain2XR-Platform that Can Walk with 
Brain Visualization Just by Thinking," CICS-2020 Information 
and Control Conference 
[5] Lee Joon-kyung and three others, "Voice & Gesture-
Recognizing Command Launcher and WebRTC-based Remote 
Rendering for HMD-AR Glass," Autumn Conference of the 
Korean Sensor Association, 2020 
[6] Lee Joon-kyung and two others, "Study on 5G-Trust 
Augmented Reality(TR) Device Edge Cloud Architecture," 
JCCI-202
4
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-093-3
AFIN 2023 : The Fifteenth International Conference on Advances in Future Internet

