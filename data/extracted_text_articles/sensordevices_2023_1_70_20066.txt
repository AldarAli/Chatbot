Beam-shaping for a LIDAR System for Urban 
Scenarios 
Marcus Baumgart1, Rainer Reichert3, Boris Kirillov2, Marcus Hennecke2, Martin Pfennigbauer3, Andreas 
Hofbauer3, Andreas Tortschanoff1 
 1Photonics Systems, Silicon Austria Labs, Villach, Austria 
2Infineon Technologies Austria, Graz, Austria 
3Riegl, Horn, Austria 
E-mail address of the corresponding author: andreas.tortschanoff@silicon-austria.com 
 
Abstract—Automotive LIDAR sensors are generally 
considered 
as 
enabling 
technology 
for 
higher-level 
autonomous driving. Different concepts to design such a 
sensor can be found in the industry. In the course of an 
Austrian research project, a MEMS based LIDAR system for 
automotive applications is currently developed and within 
this paper we describe the overall system concept and, in 
some detail, the requirements and the design of the emitter 
optics which turn out to be rather complex, in order to enable 
the sensor to detect objects of about 10 cm x 13 cm size at a 
distance of 80 m and a field-of-view of 20° x 90. 
Keywords—LIDAR; MEMS; scanner; beam shaping. 
 
I. INTRODUCTION  
Light detection and ranging (LIDAR) is arguably one of 
the key components for future autonomous driving and 
there is much interest in developing robust, compact and 
price-effective solutions. Consequently there has been a lot 
of research in recent years [1],[2],[3],[4]. Among different 
scanning technologies, Microelectromechanical Systems 
(MEMS) scanning mirrors provide unrivalled advantages in 
terms of size, speed and cost over other types of laser 
scanners, making them ideal for LiDAR in a wide range of 
applications [5]. 
Current Advanced Driver Assistance Systems (ADAS) 
focus on comparatively simple scenarios with objects 
behaving in predictable ways, such as highway traffic or 
parking 
assistance 
without 
pedestrians, 
cyclists 
or 
transversal traffic. Yet, there is an urgent need to extend 
ADAS and Automated Driving (AD) to handle urban traffic 
scenarios. Also, the ‘European new car assessment 
programme’ now defines test cases that involve Vulnerable 
Road Users (VRUs) such as adult pedestrians, children and 
cyclists in urban scenarios [6]. 
For complex scenarios, like urban traffic, high 
resolution and large field of view is a key requirement, 
which is challenging to achieve. The Austrian project 
“Integrated LIDAR Sensors for Safe & Smart Automated 
Mobility” (iLIDS4SAM) addresses this issue by developing 
a novel LIDAR-based system for predictive assessment of 
hazardous situations involving VRUs in an urban 
setting [7]. Within this project a compact LIDAR system, 
based on a MEMS scanner mirror is developed. 
The remaining of the paper is structured as follows. 
Section II presents the general concept of the ilids4sam-
LIDAR. In Section III we describe in detail the emitter-
optics and, finally, in Section IV provide a short summary 
and outlook. 
II. CONCEPT 
As outlined above the targeted scenario of urban traffic 
necessitates high resolution, large field of view and robust 
operation under ambient light conditions. The target 
specifications, we deduced for the LIDAR system, are listed 
in Table 1. 
TABLE 1: TARGET SPECIFICATIONS OF THE LIDAR SYSTEM 
Quantity 
Target-specification 
Wavelength 
905 nm 
Field of view 
60° x 20 ° 
Distance 
Up to 80 m 
Resolution 
<0.07° (≙ 10cm@80m) 
Depth resolution 
30 cm 
Framerate 
25 fps 
 
The key component of the LIDAR is a 1D MEMS 
scanner mirror [8], which is electrostatically actuated. In its 
latest generation, the MEMS features a mirror-diameter of 
5 mm, a mechanical amplitude of the tilting angle of 10° 
(corresponding to an optical scanning range of 40°) and a 
frequency of 2 kHz.  
LD
Y-Scan
(MEMS)
X-Scan
(polygon)
Object
Reception 
optics
APD
 
 
Fig. 1. Overall system concept and design of the full system. 
38
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-091-9
SENSORDEVICES 2023 : The Fourteenth International Conference on Sensor Device Technologies and Applications

 
Fig. 2: Optical layout of the LIDAR emitter optics comprise a collimation of the laser diode stack, the MEMS scanner mirror and a multi element 
lens for beam shaping. 
 
Layout oft he LIDAR emitter optics: blabla… 
The concept foresees that the beam is scanned via this 
MEMS in one direction, while the second dimension is 
scanned via a subsequent larger polygon scanner. This 
approach enables scanning of the required field of view and 
use of a large second scanner enables high collection 
efficiency of the back scattered light in the corresponding 
dimension. Thus, for one dimension, the light collection can 
be 
performed 
behind 
the 
scanning 
optics, 
which 
significantly reduces background light levels on the 
detectors, because only back reflected light is detected. 
Thus, rather than observing the whole scene, the detector 
channel only detects a line, strongly improving signal to 
noise, in particular, for the (realistic) situation of strong 
background from sunlight. 
Since LIDAR is based on measuring the backscattered 
light system, the measurement time for an individual point 
cannot be arbitrary short for long range LIDAR based on 
pulsed time of flight (e.g., a minimum waiting time of ~0.5 
µs is required for 80m distance). Therefore, it would not be 
possible to measure the required point-cloud with the 
specified density and framerate by pure point-scanning. 
Some way of multiplexing is required. While in previous 
realizations, relying on pure 1D scanning, a vertical line 
was scanned and detected with a linear detector array, here 
we follow a hybrid approach and scan in two dimensions, 
albeit still the measurement is multiplexed by projecting a 
line, which is detected on a line-detector with 16 APDs.  
While this paper focuses on the beamshaping, 
performed in the emitter branch, a more detailed description 
of the overall LiDAR system can be found in [9]. Most 
relevant for this presentation are the resulting requirements 
for the scanned laser beam. Besides ensuring that the whole 
FOV is scanned as efficiently as possible, there are 
stringent requirements on the beam-profile. The beam 
should ideally feature a top hat profile in the form of a thin 
line, with minimal vertical divergence, but an accurately 
defined horizontal divergence with a full width of 1.5°.  
 
III. EMITTER DESIGN 
The crucial part of the overall LIDAR system, is the 
design of the emitter optics which have to fulfill the 
following requirements: 
• 
Collimation of the laser diode bar to a beam with 
well-defined asymmetric divergence. 
• 
Fine calibration of the field of view of the sensor 
since the mirror maximal amplitude does not well 
correspond to the whole FOV. 
 
Simulations were performed using Zemax, Opticsstudio. 
The overall optical layout is shown in Fig. 2. It consists 
of sub-units, namely the laser diodes and first beam 
collimation, the MEMS scanner mirror, which scans the 
beam in one dimension and subsequently beam shaping 
optics to generate the required characteristics, before hitting 
the second scanner device, which is a rotating polygon 
mirror. These elements are shortly outlined in the 
following. 
 
A. 
Collimation 
The laser diode is a stack with 8 emitters with a pitch of 
400 µm and each consisting of 3 epitaxially stacked 
emitters, resulting in three stacked lines in the emission 
profiles.  
Collimation of this stack is done using a cylindrical 
lenslet array placed at a distance of 1mm in front of the 
emitting facets for slow axis collimation and, a fast axis 
collimation, placed at a larger distance, for beam 
collimation of the vertical axis, where small divergence is 
required. 
 
Intensity (arb.units)
Direction (°)
-10
-8
-6
-4
-2
0
2
4
6
8
10
(a)
(b)
 
Fig. 3: (a) laser diode with a cylindrical lenslet array for slow axis 
collimation, (b) angular profile of combined beam in slow axis 
As shown in Fig. 3, in this configuration we can achieve 
a nearly perfect top-hat-profile in angular space for the slow 
39
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-091-9
SENSORDEVICES 2023 : The Fourteenth International Conference on Sensor Device Technologies and Applications

axis collimation. The divergence still has to be reduced by a 
factor of 4 in order to achieve the targeted divergence of 
1.5°. This step is performed by telescope-optics after the 
MEMS.  
For fast axis collimation an aspheric lens with a focal 
distance of 4 mm is used, in order to collimate the beam in 
the vertical axis.  
 
 
LD Array
PCB
Slow-Axis collimation
Fast-Axis 
collimation
 
Fig. 4: 3D sketch of the laser diode collimation. 
A sketch of the arrangement of the laserdiode bar and 
the cylindrical collimation optics is shown in Fig. 4 and Fig. 
5 shows the beam profile, which is obtained after 
collimation directly in front of the MEMS scanner. 
 
X-Position (mm)
Y-Position (mm)
-5
0
5
5
0
-5
Y-Direction (°)
X-Direction (°)
(a)
-5
0
5
5
0
-5
(b)
 
Fig. 5: Beam profile directly after collimation before the MEMS mirror: 
(a) intensity distribution (b) radial distribution 
 
B. 
MEMS 
The MEMS mirror is an electrostatically driven scanner. It 
has a diameter of 5 mm, and a mechanical amplitude of +/-
10°. It´s resonance frequency is above 2kHz, which makes 
it very insensitive to mechanical vibrations. 
 
(a)
  (b)
 
Fig. 6: (a) typical MEMS scanner mirror [4] (b) housing with tilted cap 
In the set-up the MEMS is hit by the beam under a small 
angle of 30° for efficient coverage of the mirror area. 
Furthermore, it is packaged with a tilted cover window, so 
that the static reflection from the window does not lie 
within the field of view of the LIDAR scanner. 
C. 
Telescope for beam shaping 
Following the MEMS element, we have designed an 
anamorphic telescope, which provides a magnification of 
2x and 4x for horizontal and vertical direction, respectively. 
This ensures that the field of view generated by the MEMS 
scanner is reduced from 40° optical scan to the 20°, which 
are the target value for the vertical FOV. Also, the 4x 
magnification decreases the vertical divergence of the beam 
to <0.07°, which matches to the required resolution.  
The telescope design (see Fig. 7) includes eight lens-
elements. Several simpler designs were also evaluated, but 
they did not provide sufficient quality.  
 
Fig. 7. Side-view and top-view of the optical design of the telescope 
optics. 
As demonstrated in Fig. 8, this design provides the 
required specifications. 
a
   b
 
Fig. 8  Beam profile in the (a) nearfield and (b) farfield (Note that for the 
near-field the spatial and for the far-field the angular distribution is 
plotted.) 
The differences in magnification for the horizontal axis, 
depending on MEMS tilt angle and y-aberrations due to 
axes crosstalk are noticeable and partially impact 
performance. This can be seen in the far field pattern, 
shown in Fig. 9. 
2.5 m
1.0 m
MEMS tilt angle: 0°
76.0% efficiency* 
in rectangle
2.5 m
1.0 m
MEMS tilt angle: 1
84.3%
in 
 
2.5 m
1.0 m
MEMS tilt angle: 0°
76.0% efficiency* 
in rectangle
2.5 m
1.0 m
MEMS tilt angle: 10°
84.3% efficiency* 
in rectangle
 
Fig. 9 Far-field intensity distribution at a distance of 80m for mirror tilt 
angles of 0° and 10°, which is the maximal tilt. 
40
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-091-9
SENSORDEVICES 2023 : The Fourteenth International Conference on Sensor Device Technologies and Applications

D. 
Overall system assembly 
For the first demonstrator system, based on the 
presented design, we aim for an elegant breadboard style 
with still a partially adjustable mechanical frame for the 
optical system, including e.g., translational stages, since 
tolerances of some of the components are ill defined. 
Furthermore, we were aiming at the use of standard 
components as far as possible, rather than pushing towards 
maximal miniaturization.  
Fig. 10 shows a photo of the first assembled emitter unit 
mock-up, 
where, 
however, 
still 
some 
functional 
components are missing. 
 
Fig. 10: Picture of the assembled emitter unit, waiting for the final 
components and electronics. 
 
IV. CONCLUSIONS AND OUTLOOK 
We presented an overview of the design of the emitter 
part for a LIDAR system, which is under development. In 
the simulations presented we could fulfill all requirements 
and specifications. The assembly of a demonstrator on the 
level of elegant breadboard is ongoing and first results from 
characterization of the emitter unit, as well as the complete 
LIDAR sensor, are expected in the next months. The 
complete LIDAR system will be tested in real-word use-
cases. Further developments will target miniaturization and 
a ruggedized and cost optimized version. 
 
ACKNOWLEDGMENT  
This work has been jointly supported by the BMK 
within the program “ICT of the future” under grant 
agreement no. 878713 (iLIDS4SAM-Project) and by 
Silicon Austria Labs (SAL), owned by the Republic of 
Austria, the Styrian Business Promotion Agency, the 
federal state of Carinthia, the Upper Austrian Research, and 
the Austrian Association for the Electric and Electronics 
Industry. 
REFERENCES 
[1] Y. Li and J. Ibanez-Guzman, “Lidar for autonomous driving: 
The principles, challenges, and trends for automotive lidar 
and perception systems.” IEEE Signal Processing Magazine, 
37(4), 50-61 (2020), doi:10.1109/MSP.2020.2973615; 
[2] R. Roriz, J. Cabral, and T. Gomes, “Automotive LiDAR 
technology: A survey.” IEEE Transactions on Intelligent 
Transportation 
Systems, 
23(7), 
6282-6297 
(2021), 
doi:10.1109/TITS.2021.3086804 
[3] H. Holzhüter, J. Bödewadt, S. Bayesteh, A. Aschinger, and 
H. Blume, “Technical concepts of automotive LiDAR 
sensors: a review”. Optical Engineering, 62(3), 031213-
031213 (2023), doi:10.1117/1.OE.62.3.031213 
[4] T. Goelles, B. Schlager, and S. Muckenhuber, ”Fault 
detection, isolation, identification and recovery (fdiir) 
methods for automotive perception sensors including a 
detailed literature survey for lidar”. Sensors, 20(13), 3662 
(2020), doi: 10.3390/s20133662 
[5] D. Wang, C. Watkins, and H. Xie, “MEMS mirrors for 
LiDAR: A review.” Micromachines, 11(5), 456 (2020), 
doi:10.3390/mi11050456 
[6] https://www.euroncap.com/en/for-
engineers/protocols/vulnerable-road-user-vru-protection/ 
(visited 09/07/2023) 
[7] https://www.ilids4sam.at (visited 08/2/2023) 
[8] H.W. Yoo, N. Druml, D. Brunner, C. Schwarzl, T. Thurner, 
M. Hennecke, and G. Schitter, G. “MEMS-based lidar for 
autonomous driving”. Elektrotech. Inftech. 135, 408–415 
(2018) 
[9] A. Hofbauer, R. Reichert, M. E. Hennecke, M. Baumgart, 
and A. Tortschanoff, “Design and development of an 
integrated 
LiDAR 
sensor 
for 
autonomous 
driving”, 
Proceedings of SPIE Sensors and Imaging, 12737-29, (2023) 
[10] N. Druml, I. Maksymova, T. Thurner, D. van Lierop, M. 
Hennecke, and A. Foroutan, “1D MEMS micro-scanning 
LiDAR,” Conference on Sensor Device Technologies and 
Applications (SENSORDEVICES 2018), Sept. 2018, ISBN: 
978-1-61208-660-6 
 
 
 
 
 
41
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-091-9
SENSORDEVICES 2023 : The Fourteenth International Conference on Sensor Device Technologies and Applications

