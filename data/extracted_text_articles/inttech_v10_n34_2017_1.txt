Internet Access Service Quality Perceived by the User 
 
 
Janusz H. Klink 
Telecommunications and Teleinformatics Department 
Wroclaw University of Science and Technology 
Wroclaw, Poland 
e-mail: janusz.klink @ pwr  . edu . pl 
 
 
Abstract— This paper presents the selected issues of Internet 
Access Service quality. A special attention was paid to the 
user’s point of view. According to the European documents, 
users have right to be informed of IT services offered by their 
providers. The providers are involved in service quality 
measurement, but they often put emphasis on the objective 
parameters, which are relatively easy to measure and to 
compare with other competitors’ offers. The issue is: how 
service quality is perceived by users and, finally, how to 
correlate these two different points of view. The author 
discusses the selected objective measures of the Internet Access 
Service and presents different factors that influence the 
Internet quality perceived by users. The author shows how the 
users assess Internet Access through the lens of services they 
use. An example of building the Quality of Experience model 
for the WWW service will be presented. 
Keywords-Internet access; quality assessment; QoS; QoE; 
WWW quality model. 
I. 
 INTRODUCTION 
The Internet is supposed to be used as a vital medium for 
conducting business, as well as aiding work, play and 
communication between users in the next years. I will also 
be the center of the future economy, which will be based on 
network-based knowledge. Therefore, it has a wide appeal 
with service providers and consumers, research and 
regulation authorities, etc. [1][2][3]. 
In March 2010, the European Commission has launched 
a strategy titled “Europe 2020”, which sets the objectives for 
smart, sustainable and inclusive growth of the European 
Union by 2020. The Digital Agenda forms one of the seven 
pillars of the strategy and defines the key enabling role that 
the use of Information and Communication Technologies 
(ICT) will have to play in Europe in future years. It is 
supposed to support a better quality of life, e.g., through 
better health care, safer and more efficient transport, a 
cleaner environment, new media opportunities and easier 
access to public services and cultural content. It is assumed 
that by 2020 all Europeans will have access to Internet 
speeds of above 30 Mbps and at least 50% of the households 
will subscribe to Internet connections above 100 Mbps. 
According to the European Commission, the digital 
sector grows seven times faster than other parts of industry. 
Thus, in September 2016, new Commission strategy 
documents on Connectivity for a European Gigabit Society 
were adopted [4]. They set a vision of Europe where 
“availability and take-up of very high capacity networks 
enable the widespread use of products, services and 
applications in the Single Digital Market”. A vision of 
“Broadband Europe” assumes the building of the Gigabit 
Society by 2025 and relies on three main strategic objectives: 
 
Gigabit connectivity for all main of socio-economic 
drivers, 
 
uninterrupted 5G coverage for all urban areas and 
major terrestrial transport paths, 
 
access to connectivity offering at least 100 Mbps for 
all European households. 
Consumer research has revealed that price is still the 
most important attribute taken into account when choosing 
an Internet access service for 20% of users [5]. The second 
decision-making factor is the data cap, i.e., the monthly limit 
on the amount of data a user can use with an Internet 
connection. Moreover, what happens when a user hits their 
limit is a very important issue. Internet Service Providers 
then (ISPs) engage in different actions such as slowing down 
data speeds, charging extra fees, or preventing further usage. 
The next important factors, which may influence user 
attitude to an ISP offer, are service differentiation and traffic 
management such as prioritization, blocking or throttling. 
These practices aim to preserve the appropriate conditions 
for providing high-quality services. Nonetheless, in recent 
years these activities have raised questions about network 
neutrality, which assumes that all content and applications 
should receive equal treatment. Moreover, neutrality also 
means that providers neither impose nor discriminate in 
favor of using a particular type of technology [6][7]. 
Consumer awareness of network neutrality and traffic 
management is rather low. On one hand most people have 
very little knowledge about these terms and, on the other 
hand, they do not see the influence of these issues on their 
Internet usage. As is shown in [8], consumers care very little 
for all the technicalities connected with data transport and 
the role of ISPs. Users are not interested in net neutrality or 
traffic management practices and instead are tied to their 
experience of traffic management effects. 
The WIK-Consult study, which concentrates on contract-
based consulting services for public and private institutions, 
asked a series of questions about the way consumers would 
97
International Journal on Advances in Internet Technology, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/internet_technology/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

respond to specific changes in the traffic management 
policies operated by their ISP, e.g., the introduction of 
throttling on video traffic, or of data caps. A significant 
majority of respondents said that they would even change the 
provider in response to some significant changes in the 
traffic management policies of their ISP [5]. 
The issues mentioned above show a much higher interest 
of users in their ISP traffic engineering operations when 
these activities touch the concrete services and influence the 
users’ experience. Nowadays, users not only trust the service 
level agreements of their providers, but also want to be able 
to check them. 
This paper, as an extended version of [1], is organized as 
follows. In Section II the author presents a general overview 
of IAS structure. Next, in Section III, the main parameters 
that may influence quality are discussed and the objective 
quality measurements of IAS, according to the present 
standards, are presented. Section IV describes the subjective 
service quality issues, i.e., perceived by users. The author 
underlines the difference between objective quality measures 
and the subjective users’ perception of different services 
used by them. He validates the need to build quality models 
for the most popular services and mentions WWW browsing 
as one of them. In Section V, the Quality of Experience 
(QoE) model for the WWW service is discussed. The author 
presents the laboratory test-bed, measurement results and 
method of the model derivation. The paper ends with a 
conclusion and the plans for future work. 
II. 
INTERNET ACCESS SERVICE 
One of the major factors influencing the decision of users 
when choosing an ISP is the Internet Access connection 
throughput offered by the provider. However, there are many 
misunderstandings regarding this term. Physically, it is a 
combination of different connections and services that are 
needed to establish a functioning Internet access. Each of 
them can be treated as a separate service. Most users, 
however, treat Internet access as an access to the end-to-end 
services available on the Internet. A purely physical access to 
the Internet has no practical meaning to them. Thus, Internet 
access is generally understood as a platform that provides 
access to Internet services. 
It should be noted that some e2e services, that require 
two-way communication, engage Internet accesses of each 
end-user taking part in the meeting (Fig. 1). 
 
 
ISP
Access
leg
Interconnection leg
 
ISP
Access
leg
Interconnection
Points
End-to-end Internet electronic communication
Service
Access
Point
 
Figure 1.  Illustration of the contributing elements of the e2e 
communication [28]. 
PUBLIC
INTERNET
 
NXP
IXP2
Access / aggregation network
End user
equipment
GW
IXP1
IXP3
ISP
Network
termination
Access
termination
Network
gateway
National
eXchange Point
International
eXchange Point
PGW
Peering
gateway
 
Figure 2.  General overview of elements and network sections of IAS. 
From the technical point of view, however, the primary 
meaning of the term Internet access should be understood as 
a physical and logical access to the core of the network, 
including all functionalities needed to enable the user to 
establish a connection to further entities in the Internet and to 
run advanced services [9]. 
Providers often advertise the maximum values of the 
throughput, which is rarely accessible, due to variable traffic 
load and the still increasing demand for data transmission 
bandwidth in recent years. Many users often expect such 
throughputs for most of the day, irrespective of the time and 
network conditions. According to the CISCO forecast, 
presented in Visual Networking Index [10], global IP traffic 
will increase nearly threefold over the next 5 years and by 
2020 will reach 2.3 ZB per year. Moreover, traffic load 
varies significantly during the day. Busy-hour (the busiest 
60-minute period in a day) Internet traffic is growing more 
rapidly than average Internet traffic. It increased by 51 
percent in 2015, compared with a 29-percent growth in 
average traffic. It means that service providers will face even 
higher network load fluctuations and more serious traffic 
engineering problems than up to now. 
Users can be connected to the various ISPs via the access 
networks, 
using 
wired 
or 
wireless 
connections. 
Communication over the Internet requires data interchange 
over different National and International eXchange Points 
(NXPs and IXPs). Fig. 2 presents a generic overview of the 
elements, network sections and interfaces of the IAS 
according to [11]. 
A very important issue is the proper definition of the 
Internet Access Service (IAS). The answer to this question is 
not only crucial for the users, who are usually not familiar 
with the technical details, but also for the providers as well, 
because it determines the user-to-network and network-to-
network interfaces and also the responsibilities of the 
providers. 
Finally, it says how IAS quality should be measured and 
how the results can be interpreted and compared between 
different providers and their end-users. It is especially 
important in the light of European regulation [12] on the 
rights of users to be informed about the quality of their 
services. 
 
III. 
IAS MEASUREMENTS 
Identifying the parameters that may affect the quality of 
service, locating the points at which the measurements 
98
International Journal on Advances in Internet Technology, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/internet_technology/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

should be performed and specifying the measurement 
scenarios is a sequence that should be done before the 
measurements. Simply speaking, one should specify “what, 
where and how” should be measured to provide ISPs and 
users with a thorough knowledge of the quality of service. 
The measurements fall into two groups: so called “In-
net” and “Over-The-Top” (OTT). The first case covers the 
ISP’s area - the area on which it acts. European Consumer 
Center (ECC) Report [11] specifies a list of technical quality 
parameters proposed to be measured during a technical 
evaluation of IAS. 
Many National Regulatory Authorities (NRAs) or other 
national institutions agree that the list is too long. They also 
consider it to be too complicated and incomprehensible to 
the average user. Thus, they propose the selection of a subset 
of parameters. After consulting an abundance of documents 
[9][11][13] and different points of view, the ECC has 
proposed a list of minimum technical parameters that take 
their influence on the most popular Internet applications into 
account. Table I, based on [11], illustrates popular services 
and the relevance of the network performance parameters to 
the performance or quality of those services. The relevance 
ranges from “−” (irrelevant) to “+++” (very relevant). 
The following quality metrics have been selected: data 
transmission rate, delay, delay variation, packet loss ratio, 
and packet error ratio. 
The data transmission rate is probably the most relevant 
parameter, nearly mentioned in every ISP’s offer. It is 
defined as the data transmission rate that is achieved 
separately for downloading and uploading specified test files 
between a remote website and a user’s terminal equipment 
[9]. The next parameter is delay, defined as half the time (in 
ms) that is needed for an ICMP packet to reach a valid IP 
address. This parameter also has a significant influence on 
many applications available over the Internet and is already 
being used by many NRAs, operators and web-based speed 
meters. There are also some applications that are very 
sensitive to delay variation and this parameter is therefore 
selected for measurements. The exact definition of delay 
variation can be found in [13][14]. 
IP packets can sometimes be dropped, e.g., due to a small 
buffer size of the network nodes or poor (radio) connection, 
even if the transmission rate, delay, and delay variation 
remain good enough. Such packet loss can significantly 
affect all data-based applications. 
TABLE I.  
RELEVANCE OF NETWORK IMPAIRMENT PARAMETERS 
                                 TO VARIOUS APPLICATIONS 
Service 
Data transmission 
speed 
Delay 
Delay 
variation 
Packet 
loss 
Packet 
error 
Down 
Up 
Browse (text) 
++ 
− 
++ 
− 
+++ 
+++ 
Browse 
(media) 
+++ 
− 
++ 
+ 
+++ 
+++ 
Download file 
+++ 
− 
+ 
− 
+++ 
+++ 
Transactions 
− 
− 
++ 
− 
+++ 
+++ 
Streaming 
media 
+++ 
− 
+ 
− 
+ 
+ 
VoIP 
+ 
+ 
+++ 
+++ 
+ 
+ 
Gaming 
+ 
+ 
+++ 
++ 
+++ 
+++ 
Moreover, UDP-based applications, such as Voice over 
IP may also not work properly in such conditions. Packet 
loss ratio can be defined as the ratio of the total lost IP 
packet occurrences to the total number of packets in the 
population under examination [14]. The parameter that may 
have an influence on the quality of service is the packet error 
rate and was therefore also included in the basic set of 
measured parameters shown in Table 1. The IP packet error 
ratio is sometimes called the packet error ratio and is defined 
as the ratio of the total faulty IP packet occurrences to the 
total number of successful IP packet deliveries plus the 
faulty IP packet occurrences within a population of interest. 
Internet access is no longer provided by a single network 
or service provider, as was the case with traditional voice 
communication in Public Switched Telephone Networks 
(PSTNs). Nowadays, a user gains an indirect access to the 
public Internet, as shown in Fig 2. Therefore, the overall 
quality of services (or, in general, Internet access) is a 
combination of the performance of all the elements involved 
in the connection. 
Different approaches to QoS measurements are discussed 
in literature. One of the classifications points out the methods 
as follows: 
 
carried out by the carefully selected users running 
the measurement tests from designated locations (or 
users’ homes) and using special purpose equipment 
[11][15][16], 
 
large-scale user-driven tests, performed by software 
agents installed on PCs, tablets, smartphones, etc. 
[15]. 
 
On the other hand, the measurements can be performed 
by network or service providers, regulators or designated 
third-party institutions. Different solutions are used in 
different countries. Many providers do it individually but 
their results may be regarded by users as non-objective. 
Thus, external institutions are needed here. Such institutions 
are very often national regulators or the external companies 
hired by the regulators. The first solution is used, e.g., in 
Portugal [15], while the second approach, based on “QoS 
Memorandum” [17], is used in Poland. 
 
OTT
PUBLIC
INTERNET
 
NXP
IXP2
Access / aggregation
network
End user
equipment
GW
IXP1
IXP3
ISP
PGW
QoS evaluation of the ISP leg
QoS evaluation of access to a national IXP
QoS evaluation of access to an international IXP
Measurement
Servers
(MSs)
”Unknown”
MS
QoS parameters over Internet from the user to the ”unknown” server
Application
Provider
Network
(APN)
In-net
Measurements
OTT
 
Figure 3.  Internet Access Service quality assessment. 
99
International Journal on Advances in Internet Technology, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/internet_technology/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

On the European level, the minimum set of QoS 
parameters and measurement methods for retail Internet 
Access Service has been described in [11]. According to this, 
the measuring points to be used during the IAS quality 
assessment may be specified (Fig. 3). 
Three evaluation methods (scenarios) are relevant to the 
measurements connected with IAS quality assessment. The 
methods encompass an examination of the access network, 
the ISP network and the network connections to NXP or 
IXP. 
Their names are listed below: 
– QoS evaluation within the ISP leg, 
– QoS evaluation between the Network Termination 
Point (NTP) and NXP(s), 
– QoS evaluation between the NTP and IXP(s). 
 
Depending on the scenario, the measurement server 
should be located in the right place (cf. Fig. 3). 
In order to test only the access network, the test server 
should be located as close as possible to the gateway (GW) 
between the access network and the ISP network. In the case 
of evaluating the entire ISP leg quality, the test server should 
be placed near the public Internet interface (PGW in Fig. 3). 
According to the definition, the ISP leg consists of the access 
network part and the ISP network part of the connection of 
the customer to the ISP [11]. Based on [9], a measurement 
set-up for the ISP leg quality evaluation is presented in 
Fig. 4. 
It should be possible to perform the tests both by the ISP 
and the user (assuming that the ISP provides a software 
client or a web based application for this purpose). 
The test server shall be connected to the edge of the ISP 
network (Fig. 5) [11]. 
 
 
Test PC
physical
access
concentration/transit
Local switch
Test Server
Gateway
Access network
ISP Network
 
Figure 4.  Measurement set-up for the ISP leg quality evaluation. 
 
 
End user
equipment
Network
Termination
Measurement 
server
Network
Gateway
Local concentration 
function
Peering
Gateway
Server 
collecting and 
analysing test 
results
Gateway
Access network
ISP Network
Internet Service Provider Network QoS parameters
Access
Termination
Peering
Gateway
 
Figure 5.  QoS evaluation of the ISP leg. 
 
End user
equipment
Network
Termination
Measurement 
Server
Network
Gateway
Local concentration 
function
Peering
Gateway
Server collecting 
and analysing 
test results
Gateway
Access network
ISP Network
Access
Termination
Peering
Gateway
Internet 
Exchange Point 
Network
National IXP 
Gateway
National IXP 
Gateway
 
Figure 6.  QoS evaluation of access to a national IXP. 
Locating the test server in the National eXchange Point 
(NXP) allows the network performance parameters of 
different ISPs to be compared (Fig. 6).  
The comparability of the IASs of different ISPs can be 
reached in the best way, if all ISPs are connected on a similar 
way to the central measuring point. 
In the case of bigger countries it can be difficult to fulfill 
this condition. There may be few IXPs present and due to 
that, the ISPs are not connected on a similar way to the 
central measuring point. However, the impact of these 
circumstances may not be considered significant enough to 
make the values incomparable, because the bottleneck of the 
ISP’s network usually do not lie within the backbone of the 
ISP’s 
network 
but 
within 
the 
Access 
leg 
and/or 
Interconnection points [11]. 
The quality results achieved in this scenario seem to be 
far closer to the quality of Internet connection, as perceived 
by users, than the results in the “ISP leg” scenario. 
It is recommended to perform this kind of measurements 
by the measuring organization, which can be NRA, other 
relevant national institution or an independent organization. 
The measuring tools are not strictly specified by any 
standardization document. These can be dedicated hardware 
solution, software client or web based applications.  
It can be seen that the Internet Access Service quality 
assessment is therefore a very demanding issue, especially as 
users care about their own quality experience, which is 
commonly understood as unrestricted, high-quality and 
having a reliable access to the applications they use and the 
content they seek out online. This is the reason for 
performing the second type of measurements presented in 
Fig. 3. They were called “OTT measurements”, because they 
allow the performance parameters of specific applications 
run by the users to be tested and thus they, in general, better 
reflect the quality of service as perceived by the user. 
Nonetheless, these are measurements of the objective 
parameters and, in the next step, should be transformed into 
the quality measures as perceived by users. Mapping the 
measured QoS factors to the QoE ones is often quite a 
complicated process. The next paragraph presents an 
example of WWW service quality assessment as perceived 
by users. 
100
International Journal on Advances in Internet Technology, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/internet_technology/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

IV. 
SERVICE QUALITY PERCEIVED BY USERS 
In this paragraph, the author presents an example of the 
service quality assessment procedure based on the WWW 
service. The WWW is one of the most popular services, if 
not the most important of all, used by Internet users. Many of 
them assess the Internet quality through the lens of web 
browsing and information searching on the Internet. The 
main parameter that influences the service quality, as 
perceived by the user, is web page opening (loading) time. In 
other words, the end-to-end (e2e) delay between the user’s 
request and the time when the page is open on the user’s 
display is the most important. The WWW service quality 
evaluation procedure will be treated as one of the factors that 
influence the user’s perception of the IAS. The WWW 
service evaluation in the real network may be performed as 
shown in Fig. 7. 
The objective QoS parameter that is measured here is 
delay between the times when user sends a request to open 
required web page and the time when the information 
appears on the display of his PC. 
Beside objective measuring of the web page opening 
times, the subjective user’s perception of the service should 
be determined. In another words, service quality perceived 
by the end-users, i.e., the relation between QoS and QoE, 
should be found. It means that the QoE model for the service 
should be determined. By presenting the WWW quality 
assessment, the author would like to underline that 
measuring and presenting only the objective network 
performance parameters to the customers, discussed in 
previous sections of the paper, may not be sufficient for 
determining the IAS quality as perceived by the users. There 
is a need to check the service quality experienced by them. 
Building such a model requires a big amount of tests to be 
conducted. The best way to determine the QoS-QoE relation 
is to perform the tests in a controlled environment. 
One of the important things is to prepare a proper 
measurement scenario, taking into account main factors 
influencing web-QoE. Many of these factors are known, but 
in literature they are sometimes grouped into different 
categories and not all of them are taken into account in every 
research. 
According to [18], the influence factors (IFs) may be 
grouped according to the following categories: 
– user influence factors (UIFs), 
– system influence factors (SIFs), 
– context influence factors (CIFs). 
 
PUBLIC
INTERNET
 
NXP
Access / aggregation
network
End user
equipment
GW
ISP
PGW
WWW
server
Quality assessment of the WWW service
Application
Provider
Network
(APN)
 
Figure 7.  WWW service quality assessment. 
A very similar, but a little bit different, categorization is 
presented in [19], where four categories are listed, as 
follows:  
– user, 
– technology, 
– content, 
– environment. 
Referring to the previous classification, it can be noted 
that the most significant UIFs seem to be user’s perception, 
interest, expectations, experience of application and/or 
network performance, etc. In today’s ICT environment, the 
users’ expectations, satisfaction and (perceived) quality of 
experience (QoE), are being recognized as crucial 
determinants for the success of the technology, even more 
important than technological performance and excellence 
[20]. 
The set of SIFs consists of: 
– server-related influence factors, 
– content-related influence factors, 
– delivery network influence factors, 
– client influence factors. 
 
To better understand the relations between SIFs, a typical 
Web-QoE delivery chain was shown in Fig. 8 [18]. 
According to the classification listed above, the most 
important SIFs are response time (determined by CPU, 
operating system, memory, software, etc.) and capacity of 
the links connecting the server to the Internet. However, the 
perceived response times may be lowered by the cashing 
elements in the delivery network. 
The next sub-set of SIFs constitute content-related 
influence factors. They are very crucial for web-QoE, 
especially because the Web content is typically constituted 
by a mix of different element types. It  consists of text, 
pictures, audio and video files. Additionally, the structure of 
the HTML pages (and the scripts) determines the actual 
loading behavior of the page according to the utilized objects 
(number, type, size, order, etc.) [21]. 
Another group of SIFs are client influence factors. These 
are: web-page loading procedure, processing power, browser 
implementation, 
operating 
system, 
TCP/IP 
stack, 
configuration etc. 
The last, but not least, factor which may have a critical 
influence on the user behavior and his QoE is the context in 
which a web page is accessed. The range of CIFs spans: 
– location: cafeteria, office, home, 
– interactivity: high/low level interactivity, 
– task type: business, entertainment, 
– task urgency: urgent vs. casual (without time 
constraints). 
 
 
Internet
Access
network
Core
network
Server + content
Produced quality
Device
User
Perceived quality
 
Figure 8.  Delivery chain for a typical web-page. 
 
101
International Journal on Advances in Internet Technology, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/internet_technology/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Application 
and network
User
perception
tU1
tU2
tU3
tU4
tU5
Time
tA1
tA2
tA3
tA4
tA5
tU0
 
Figure 9.  User’s perspective of the perceptual events in a web page view 
cycle. 
As it was mentioned before, the time (delay) is one of the 
main factors that influence user perception of the service. 
When user requests a web page, the download of content 
from web server is initiated and progressively fetched and 
rendered by the browser. During this time the user 
encounters several events that indicate the progress of the 
page loading process. However, the objectively measureable 
times are a little bit different from the characteristic moments 
of web browsing process that are perceived by the user and 
decide on user’s appraisal of the service (see Fig. 9). For 
more details regarding the impact of these different points of 
view on the web-QoE assessment please see [22] and [18]. 
According to [18], the meaning of the times presented in 
Fig. 9 is as follows: 
 
tU0 the moment in time when the user requests a new web 
page (typically by clicking or pressing enter "Enter"), 
 
tU1 the moment in time when a change in the status bar 
happens, 
 
tU2 the moment in time when the previously viewed web 
page vanishes (the content of the requested page has not 
yet started to render), 
 
tU3 the moment in time when the first element of the 
requested page appears on the screen, 
 
tU4 the moment in time when, from the user’s point of view, 
the page is sufficiently rendered such that he can access 
the required information, 
 
tU5 the moment of time when the visible portion of the web 
page (as determined by screen or browser windows size) 
is fully rendered, 
 
tA1 the moment in time when the initial HTTP request is sent 
by the browser, 
 
tA2 the moment in time when the first HTML element is 
received, 
 
tA3 the moment in time when the HTML page is processed 
by the browser (observed at application level), 
 
tA4 the moment of time when all objects of the page are 
downloaded from the server at the browser's device, 
 
tA5 the moment of time when the page is completely 
rendered and displayed on the screen. 
 
It should be noted that the distance between the 
perceptual events in Fig. 9 is shown as being equal, but in 
real-world browser implementations they may be different. 
The influence factors listed above show that the Web-
QoE description is not a simple task. It requires a big effort 
and usually is time-consuming and expensive. The question 
arises: how to measure the users’ satisfaction of IP-based 
services as WWW? 
One of the methods of expressing the users’ satisfaction 
is an Application Performance Index (APDEX) [23]. It is an 
industry open standard that allows to measure the satisfaction 
with the response times of web applications and/or services 
and their conversion into one commonly understood factor 
(AI). 
The magnitude of this factor can be described as a value 
on a scale between 0 and 1. It can be calculated using (1) as 
follows: 
 
AI = (SR + (TR / 2)) / NR 
(1) 
where: AI  an evaluation score according to the Apdex 
method; SR  satisfied requests (number of users’ requests 
when the service response times were satisfied for them); 
TR  tolerating requests (number of users’ requests when the 
service response times were tolerated by them); NR  the 
total number of users’ requests. 
The final result (AI) depends heavily on the threshold 
time T. It is the value of the delay which, in the user’s 
opinion, represents a negligible reduction of service quality 
(Fig. 10). Thus, it can be assumed that the web page load 
time of no longer than T guarantees high user satisfaction of 
WWW service. On the other hand, it was observed that 4T is 
the upper limit of delay tolerated by the user. In practice, this 
problem involves fixing the maximum value of T that will 
guarantee, in the user’s opinion, a very good quality of 
service. In other words, T should be the maximum time 
which does not distract the user’s attention from the service 
during waiting for an application response. For delays which 
are longer than T and do not exceed F = 4T, users notice a 
deterioration in the service quality, but they tolerate it. 
APDEX can also be treated as a simplified Service Level 
Agreement (SLA) solution that gives application owners 
better insight into how satisfied users are, in contrast to 
traditional metrics like average response time, which can be 
skewed by a few very long responses. 
Finding the QoS/QoE relation is often a starting point to 
the cost-effective service provision and quality management 
process. This often leads to finding of more sophisticated 
relationships between objectively measured parameters and 
subjective quality as perceived by the users. Such kind of 
investigation, including preparation of the a special 
laboratory 
test-bed 
and 
measurement 
scenario, 
and 
performing of the tests, was presented in the next section. 
 
Satisfaction 
zone
Tolerance 
zone
Frustration 
zone
Time
T
F = 4T
0
Negligible 
reduction of 
the service 
quality does 
not distract 
users’ 
attention
Users notice a 
deterioration in the 
service quality but 
can accept it
Long waiting 
is 
unacceptable 
and users may 
abandon the 
process
 
Figure 10.  Threshold values for the Apdex Method. 
102
International Journal on Advances in Internet Technology, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/internet_technology/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

V. 
THE LABORATORY TEST-BED 
The laboratory test-bed used by the author is presented in 
Fig. 11. It consists of a WWW client with a dedicated 
measuring tool, a test server that hosts a set of special 
prepared WWW pages and the Network Emulator (NE). 
All the machines and software run under the MS 
Windows operating system. As a user client, the Mozilla 
Firefox browser was used while the measuring tool was the 
Wireshark protocol analyzer. The NE was capable of 
emulating the impairment parameters such as network delay, 
jitter and packet loss. This stage of the measurements only 
studied the impact of the delay on the service quality as 
perceived by the users. The delays were randomly generated 
by the NE on the interval from 0 to 20 s, while the users tried 
to open the web pages on the test server. Next, the packets 
were captured by the Wireshark and analyzed. The users did 
not know the strict values of the delays, but they did see the 
effects of the delay and tried to assess whether the web page 
opening time was acceptable or not. It was clear that these 
delays had a decisive influence on the WWW service quality 
as experienced by the users. It was expected that increase in 
end-to-end delay would lead to deterioration of users’ 
satisfaction of the service. Quality of Experience was 
expressed by the user’s evaluation grades according to the 
Mean Opinion Score (MOS) scale [24].  
During the experiment the subjects (testers) were asked 
to independently rate each sample and provide their opinions 
using a "rating scale". The purpose of the scale was to 
translate a subject's quality assessment into a numerical 
value that can be averaged across subjects and other 
experimental factors. The Absolute Category Rating (ACR) 
5-point scale (most common) was used, as follows: 
– Excellent 5, 
– Good 4, 
– Fair 3, 
– Poor 2, 
– Bad 1. 
The ACR scale is a discrete scale, meaning that the 
subject's response is limited to one of the five values listed 
above. However, the averaging process used to combine 
results from different subjects means that MOS values are 
not confined to integer values [25]. The first observations 
confirmed the expectations, that users’ grades should be 
inversely proportional to the e2e delays. It was also noticed 
that the subjective opinion of users depended highly on the 
page properties, i.e., their content, layout, construction 
(static, dynamic), etc. For subjective measurements the 
WWW reference page was needed. Static web pages were 
launched on the test server and the contents of these pages 
were different, but they were of the same style. In this 
experiment as a content a photo gallery was used. 
 
User 
device
User
Access Network
Network
Emulator
(NE)
Internet
Test server (TS)
with local content
Router
 
Figure 11.  The laboratory test-bed for the WWW QoE assessment. 
The main goal was to build as simple web page as 
possible, but with interesting content.  
As a result, the obtained QoE model was similar to the 
presented in [22], where the test page was prepared 
according to the ETSI reference page requirements [26]. The 
relatively small differences require further study. Therefore, 
the next investigations will be devoted to carry out more 
detail QoE analysis, taking into account different contents of 
the web, i.a. based on the ETSI recommendations. It should 
also give the answer the question of the impact of the content 
on the experiment results. 
It should be also noted that the structure and preparation 
of the test groups can have the influence. The testers 
evaluating the quality of the WWW service, as described in 
[22], were divided into two categories: the first consisted of 
professionals, the second included non-professionals, i.e. 
people with little computer experience. Evaluation results 
presented by the two categories had similar trends, though 
the marks they awarded were inversely proportionate to the 
page opening delays. In long-period observations, however, 
a significant difference between these groups was observed: 
professionals tended to be more radical in their evaluations 
than non-professionals, who were relatively moderate. 
The current scenario assumed that every user, when 
evaluating web opening times (equivalents of end-to-end 
delays during normal web browser use), should give his 
grade after seeing several photos so that he would be better 
able to make a judgment. The test was performed on a user’s 
PC (WWW client with a measurement tool). Additionally, 
Wireshark software installed on the client’s PC (as a second 
tool) was used to capture IP packet streams and to register 
the end-to-end delay time. This was defined as the difference 
between the point in time at which the web page was 
requested and the point in time at which all data needed for 
the display of the web page were received. The end-to-end 
delay was varied throughout the course of the experiment 
using the NE. It was noticed that the web page opening times 
that were registered at the user site played a crucial role in 
the subjective evaluation of WWW service quality (QoE). 
There were groups of “professional” users (each group of 10) 
taking part in the experiment (70 users in total). They gave 
their subjective grades for WWW service quality in a range 
from 1 to 5 on the MOS scale. More than 1500 test 
measurements were conducted. In the next step the statistical 
analysis has been performed. 
VI. 
THE QOE MODEL 
The measurements show that the grades of users are 
inversely proportionate to the web page opening times. To 
speak in more detail, the people who took part in the 
evaluation test were quite critical with regards to the service 
under analysis: a rapid decrease in the quality can be 
observed for the web page opening times (T) covered in the 
first few seconds. It shows that users are very critical in their 
opinions and do not accept long delays. The longer the web 
opening times, the lower grades users give. For the delays 
exceeding 10 s, the grades of users tend to be significantly 
lower at a level of 2, which means that such long times are 
unacceptable for WWW users. 
103
International Journal on Advances in Internet Technology, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/internet_technology/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

2
4
6
8
10
12
14
16
18
20
Time [s]
0
1
2
3
4
5
Q [MOS]
 
Figure 12.  Subjective evaluation of WWW page opening times in MOS 
scale. 
The analysis of the results leads to the conclusion that 
users had a considerable problem with evaluating web page 
opening times with very high fluctuations. The measurement 
results obtained by the author are consistent with those 
presented in literature [22]. It can be noticed that users are 
willing to award very high grades for the service (MOS = 5) 
when opening times are under 2 s, while the lower grades 
(MOS less than 2) are given when opening times are 8 s and 
more. In individual cases the evaluation grades may differ 
significantly from the majority of the scores and thorough 
statistical analysis should therefore should be carried out. As 
can be seen in Fig. 12, the mean values for the specific page 
opening times were not only determined, but min and max 
values and standard deviation as well. 
The correlation between the opening times and the user 
grades achieved here is at a level of 80 %. The standard 
deviation is indicated by the boxes in Fig. 12, while  
whiskers represent the distances between the minimal and 
maximal values of the captured page opening times. This 
shows a high level of user uncertainty during the evaluation 
process. 
As it is known from the former experiments [22][27], 
during long waiting times many users begin to consider 
whether waiting for the page to open makes sense, and many 
of them resign. To find a precise relation between the 
captured values of web opening times and the quality 
experienced by users, a regression model was used. 
This model derived by the author can be described by the 
following formula: 
 
Q = 5
            for T < 1s,
Q = 4.84 – 2.63 log10T       for T 
(2)
' 
[1s; 1min], 
 
 
where: T is the web page opening time. 
 
The logarithmic line (Fig. 12) represents the Q value (in 
MOS scale) as a function of web opening times. The 
statistical analysis proved that the model fits the data very 
well, with the coefficient of determination (R2) above 0.9. It 
means that the obtained outcomes are replicated by the 
model in at least 90 % of the time. This model is valid for the 
page opening times T not exceeding 1 minute, which is even 
more than the longest times emulated in the experiments 
(20 s). Subjective evaluation however showed that web-page 
opening times longer than 10 s are not acceptable by the 
users, thus they may not be taken into account in further 
practical applications. 
A confirmation of the user’s QoE distribution, obtained 
in the paper, can be found in the analysis results presented by 
the above-mentioned ITU-T recommendation [22], where 
attention had also been drawn to the logarithmic nature of the 
relation between QoS and QoE in such a case. A possibility 
of determining the prospective MOS value by managing the 
opening times is very valuable and more convenient for the 
provider than performing the subjective evaluations, which 
are time consuming and more expensive. 
VII. CONCLUSION AND FUTURE WORK 
Internet Access Service is a key factor that influences a 
user’s perception of all the services provided on the Web. 
Thus, service providers have to do all their best to offer a 
good quality IAS. Moreover, they should monitor the 
network transmission parameters and be up to date with their 
values. Usage of the appropriate measurement methods is 
therefore very important. The methods can use different 
scenarios. In order to make the results credible and 
comparable with others, these scenarios should be clear and 
measurement interfaces and procedures have to be clearly 
defined. 
The paper shows the different measurement solutions that 
can be used. In the second part of the paper the author 
stressed the importance of subjective quality assessment 
methods, which are based on the experience of users and 
give more information about their perception. They assess 
the Internet Access quality through the quality of the services 
that they use. One of the most popular is the WWW service. 
Therefore, the author presented the example of a web 
browsing quality evaluation scenario, specified the key 
quality parameter and showed the results of measurements. 
At the end, the QoE model was proposed and discussed. The 
main conclusion is that the quality measurements should not 
only take into account the objective parameters, but 
subjective parameters as well. Obviously, the set of the 
parameters depends on the service. 
Future work will be devoted to WWW QoE model 
enhancement by specifying a wider set of parameters to be 
measured and to also build reference web pages that will be 
more representative for current Internet content. 
ACKNOWLEDGMENT 
The paper presents partial results of the statutory research 
carried out at Wroclaw University of Science and 
Technology, Poland. The author would like to express 
special thanks to Pawel Bardowski and Zbigniew Sałamacha 
for their contribution to the test-bed set-up and help during 
the editorial process. 
104
International Journal on Advances in Internet Technology, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/internet_technology/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

REFERENCES 
[1] J. H. Klink, “Selected Issues of Internet Access Service 
Quality Assessment,” ComputationWorld 2017. The Ninth 
International Conferences on Advanced Service Computing. 
Service Computation 2017 IARIA, February 19 - 23, 2017, 
pp. 31-36. 
[2] European Commission. EUROPE 2020 - A strategy for smart, 
sustainable and inclusive growth. [Online]. Available from: 
https : // ec.europa. eu/digital-single-market/en/europe-2020-
strategy, [retrieved: 12, 2016]. 
[3] European Commission. A Digital Agenda for Europe. 
[Online]. 
Available 
from: 
http  ://eur-lex.europa. eu/legal-
content/EN/TXT/PDF/?uri=CELEX:52010DC0245&from=E
N, [retrieved: 12, 2016]. 
[4] European Commission. Connectivity for a Competitive 
Digital Single Market - Towards a European Gigabit Society. 
[Online]. Available from: 
http : // ec.europa. eu/newsroom/dae/document.cfm?doc_id=171
82, [retrieved: 12, 2016]. 
[5] BEREC. How do consumers value Net Neutrality in an 
evolving Internet marketplace? [Online]. Available from: 
http : // www .berec.europa. eu/eng/netneutrality/, [retrieved: 12, 
2016]. 
[6] Official Journal of the European Union. Regulation (EU) 
2015/2120 of the European Parliament and of the Council of 
25 November 2015. [Online]. Available from: http  : // eur-
lex.europa. eu/legal-
content/EN/TXT/PDF/?uri=CELEX:32015R2120&from=en, 
[retrieved: 12, 2016]. 
[7] BEREC. Guidelines on Transparency. [Online]. Available 
from: https ://ec.europa. eu/digital-single-
market/en/news/berec-guidelines-transparency-scope-net-
neutrality-best-practices-and-recommended-approaches, 
[retrieved: 12, 2016]. 
[8] BEREC. The value of Network Neutrality to European 
Consumers. [Online]. Available from: 
http ://www.berec.europa. eu/eng/netneutrality/, [retrieved: 12, 
2016]. 
[9] ETSI. EG 202 057-4. Speech Processing, Transmission and 
Quality Aspects (STQ); User related QoS parameter 
definitions and measurements; Part 4: Internet access. 
[Online]. Available from: 
http ://www.etsi. org/deliver/etsi_eg/202000_202099/2020570
4/01.02.01_60/eg_20205704v010201p.pdf, 
[retrieved: 
12, 
2016]. 
[10] CISCO. White paper: Cisco VNI Forecast and Methodology, 
2015-2020, 
June 
2016. 
[Online]. 
Available 
from: 
http ://www.cisco. com/c/en/us/solutions/collateral/service-
provider/visual-networking-index-vni/complete-white-paper-
c11-481360.html, [retrieved: 12, 2016]. 
[11] ECC Report 195. Minimum Set of Quality of Service 
Parameters and Measurement Methods for Retail Internet 
Access Services, April2013. [Online]. Available from: 
http ://www.erodocdb. dk/Docs/doc98/official/pdf/ECCREP19
5.PDF, [retrieved: 12, 2016]. 
[12] Official Journal of the European Union. DIRECTIVE 
2009/136/EC of the European Parliament and of the Council, 
337/11, 25 Nov. 2009. [Online]. Available from: http  ://eur-
lex.europa. eu/legal-content/EN/TXT/?uri=celex:32009L0136, 
[retrieved: 12, 2016]. 
[13] ITU-T. Rec. Y.1541: Network performance objectives for IP-
based services. [Online]. Available from: 
https ://www.itu. int/rec/T-REC-Y.1541/en, 
[retrieved: 
12, 
2016]. 
[14] ITU-T. Rec. Y.1540: Internet protocol data communication 
service - IP packet transfer and availability performance 
parameters. [Online]. Available from: 
https ://www.itu. int/rec/T-REC-Y.1540/en, 
[retrieved: 
12, 
2016]. 
[15] R. Nunes, R. Pereira, Rui Valadas, and S. Parranc, “Agent-
Based Platform for Continuous Measurement of Internet 
Access 
Quality 
of 
Service,” 
16th 
International 
Telecommunications 
Network 
Strategy 
and 
Planning 
Symposium (Networks), Funchal, 2014, pp. 1-6, doi: 
10.1109/NETWKS.2014.6959251. 
[16] SamKnows. The global platform for internet measurement. 
[Online]. https ://www.samknows. com, [retrieved: 12, 2016]. 
[17] UKE. Memorandum QoS report (in Polish). [Online]. 
Available 
from: 
https ://www.uke.gov. pl/raport-koncowy-
memorandum-jakosci-13373, [retrieved: 12, 2016]. 
[18] ITU-T. Rec. G.1031: Multimedia Quality of Service and 
performance – Generic and user-related aspects. QoE factors 
in 
web-browsing. 
[Online]. 
Available 
from: 
https ://www.itu. int/rec/T-REC-G.1031/en, 
[retrieved: 
08, 
2017]. 
[19] M. Alreshoodi and J. Woods, “Survey on QoE/QoS 
Correlation Models for Multimedia Services,” International 
Journal of Distributed and Parallel Systems (IJDPS), 2013, 
vol. 4, No. 3, pp. 53-72, doi: 10.5121/ijdps.2013.4305. 
[20] D. Geerts, K. De Moor, I. Ketyko, A. Jacobs, J. Van den 
Bergh, W. Joseph, L. Martens, and L. De Marez, “Linking an 
Integrated Framework with Appropriate Methods for 
Measuring QoE,” Quality of Multimedia Experience 
(QoMEX), 2010 Second International Workshop on. IEEE, 
2010. pp. 158-163. 
[21] D. Strohmeier, S. Jumisko-Pyykkö, and A. Raake, “Toward 
task-dependent evaluation of web-QoE: Free exploration vs. 
who ate what?,” Globecom Workshops (GC Wkshps), 2012 
IEEE, pp. 1309-1313. 
[22] ITU-T. Rec. G.1030: Estimating end-to-end performance in 
IP networks for data applications. [Online]. Available from: 
https ://www.itu. int/rec/T-REC-G.1030/en, 
[retrieved: 
12, 
2016]. 
[23] APDEX. [Online]. Available from: https  ://www.apdex. org, 
[retrieved: 08, 2017]. 
[24] ITU-T. 
Rec. 
P.800.1: 
Mean 
opinion 
score 
(MOS) 
terminology. [Online]. Available from: 
https ://www.itu. int/rec/T-REC-P.800.1/en, 
[retrieved: 
08, 
2017]. 
[25] ITU-T. Rec. P.800.2: Methods for objective and subjective 
assessment of speech  and video quality. Mean opinion score 
interpretation and reporting. [Online]. Available from: 
http ://www.itu. int/itu-
t/recommendations/rec.aspx?rec=12973, [retrieved: 08, 2017]. 
[26] ETSI. Kepler reference web page. [Online]. Available: 
http ://docbox.etsi. org/STQ/Open/Kepler/, 
[retrieved: 
08, 
2017]. 
[27] P. Bardowski, J. Klink, and T. Uhl, “New metrics for WWW 
service quality assessment,” Przegląd Telekomunikacyjny (in 
Polish), No. 8-9, 2013, pp. 644-649. 
[28] BEREC. Guidelines for quality of service in the scope of net 
neutrality [Online]. Available from: 
http ://berec.europa. eu/eng/document_register/subject_matter/
berec/regulatory best practices/guidelines, 
[retrieved: 08, 2017]. 
 
105
International Journal on Advances in Internet Technology, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/internet_technology/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

