The Implementation of Noradrenaline in the NeuCogAr Cognitive Architecture
Max Talanov, Mariya Zagulova, Salvatore Distefano
Boris Pinus, Alexey Leukhin
Kazan Federal Universtity
ITIS
Russia
Email: max.talanov@gmail.com, mazagulova@stud.kpfu.ru,
salvatdi@gmail.com, bvpinus@gmail.com,
alexey.panzer@gmail.com
Jordi Vallverd´u
Universitat Autonoma de Barcelona, Catalonia
Spain
Email: jordi.vallverdu@uab.cat
Abstract—In this paper, we present a novel approach to model
and re-implement the noradrenaline inﬂuence in a bio-plausible
manner suitable for the modelling of emotions in a computational
system. We have upgraded our previous bio-inspired architecture
NEUCOGAR (Neuromodulating Cognitive Architecture) to cap-
ture a key aspect of cognitive processes: novelty detection and its
evaluation. With our model, we can computationally implement
a bioinspired cognitive architecture that uses neuromodulation
as a mechanism to identify signals, as well as to evaluate them
according to their novelty, taking into account the noradrenaline
concentration dynamics. At the same time, the values thus gen-
erated are stored in the system using the same neurotransmitters
model.
Keywords–spiking neural networks; artiﬁcial emotions; affective
computing.
I.
INTRODUCTION
After the revolution provided by new neuroscientiﬁc tools,
especially fMRI (functional magnetic resonance imaging), the
studies on cognition changed drastically the understanding of
the fundamental role of emotions [1]. When the sensorimotor
and embodied approaches to cognition [2] were identiﬁed
(even at robotic level [3]), the key functional role of emotions
was still unexplored. Artiﬁcial cognitivists specializing in
machine cognition started to consider the design and imple-
mentation of emotional architectures [4], as well as initiated
the ﬁelds of affective computing [5] or social robotics [6]. At
that point, the interest was to capture human affective modes to
implement them into machines, which humans should interact
with. During this process, a very important question emerged:
do machines need to have emotions, if we want to make
them cognitively powerful? This is the question that triggered
our research some years ago [7][8] and that oriented our
research towards biomimetic models [9]. The neurotransmitter
architecture of human brains controls the main cognitive and
emotional processes, indeed, acting as a twofold mechanism
[10]. Therefore, the role of emotions and their effect (only
including inborn basic emotional reactions) in the mammalian
cognition is considered to be signiﬁcant by several researchers
[11][12][13][14][15]. Even from the evolutionary perspective,
the key role of emotions in social design is of no doubt [16],
and also helps to explain moral behaviour [17].
For all the reasons above, the design of artiﬁcial architec-
tures through emotional values attracted interests, aiming at
providing the key to the existence of adaptive, creative, and
multiheuristic artiﬁcial architectures, by mimicking the most
successful characteristics of human cognition. Several attempts
to re-implement emotional aspects in artiﬁcial cognitive archi-
tectures have been performed as discussed in Section IV, but
the work of [18] represents the fundamental internal approach
to emotional robotics and AI (Artiﬁcial Intelligence). This way,
we started with the assumption that it could be beneﬁcial
to re-implement basic emotional mechanisms in a computa-
tional system gaining the richness of emotional appraisal and
behavioural strategies, as well as pain/pleasure reactions that
could be used in reinforcement learning. Following L¨ovheim
model of neurotransmitters [19], we propose a bio-inspired
artiﬁcial architecture called NEUCOGAR that implements
emotional-like mechanisms into machine data processing. In
Section II, we point out the mismatch between computational
resources available to current robotic systems and what is
required for neuronal simulation, introducing our concept of a
robotic system execution separated into day and night phases,
in order to bridge the gap between robotic systems and
supercomputers performing the simulation. In Section III, we
introduce the notion of bisimulation to answer the questions of
learning and mapping from realistic neural network to rules-
based control system. Section IV provides the information
about the actual topics in the ﬁeld of affective computing,
notable authors and research projects in this area. We sum up
the ideas presented in the paper and discuss the arose questions
in Section V.
II.
THE APPROACH
The key aspect for any living system is the skill to recog-
nize external and internal signals and to evaluate them [20].
On top of this basic feature, more complex operations can be
performed, such as the identiﬁcation of novel signals [21][22].
The novelty can be considered as the discrepancy between
what is known and what is discovered, by which activity and
exploration of the environment are elicited. Creativity is also
deeply related to this process [23].
Based on this consideration, we propose to implement
emotional mechanisms to manage processes such as attention,
resource allocation, goal setting, into our biomimetic architec-
ture NEUCOGAR. These mechanisms seem to be beneﬁcial
for dealing with informational systems in general (such as
living entities) and for AI and robotic systems in particular.
Indeed, classical approaches tend to be computationally de-
manding, as well as current cognitive-based ones, while the
10
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-531-9
COGNITIVE 2017 : The Ninth International Conference on Advanced Cognitive Technologies and Applications

Figure 1. A three-dimensional space of three basic neuromodulators
encapsulating basic emotions, mapped to computational system parameters.
proposed solution, NEUCOGAR, is quite promising, since it
adopts a higher level, mammalian neurotransmitter-like model
to implement a cognitive architecture for machine novelty-
detection and evaluation. This way, to implement the phe-
nomena related to emotions, we simulate the neurobiological
processes underlying emotional reactions, basically through
three neurotransmitters, which are active during brain cognitive
processes: noradrenaline (NA), dopamine (DA) and serotonin
(5HT). It is important to remark that several works identify the
noradrenaline as the main driver of neural response to novelty,
while this response is dampened by cholinergic transmission.
Later responses to novelty emanating from the frontal cortex
seem to be under the inﬂuence of the cholinergic system [24].
The selection of the neuro-plausible approach is based
on the assumption that the main mechanisms of neuro-
computations are similar to those of cellular level bio-chemical
reactions. We do not limit our approach to neuro-plausible
modelling, we established a link between psychological phe-
nomena, neuro-biological mechanisms and computational pro-
cesses. We started from the “cube of emotions” by Hugo
L¨ovheim [19], bridging psychological phenomena of “affects”
with neuro-biological phenomena of monoamines neuromod-
ulation, i.e., using NA, DA and 5HT, see Figure 1. We have
thus built a bio-plausible emulation of the dopamine pathways
and managed to emulate the “fear-like” state of the com-
putational system in [25][26]. Further developments include
the emulation of serotonin and noradrenaline. This paper is
focused on emulating the noradrenaline mechanisms through
the neurobiological simulator NEST [27] to reproduce in a
bio-plausible manner the psycho-emotional states identiﬁed by
dopamine and noradrenaline.
As the neuropsychological base for our cognitive archi-
tecture, we used a three dimensional monoamines neuro-
modulators model called “Cube of emotions” created by
Hugo L¨ovheim [19]. Three-dimensional space of three basic
neuromodulators: noradrenaline (NA), serotonin (5HT) and
dopamine (DA) encapsulates basic emotions or affects inher-
ited from work by Silvian Tomkins [28]. We have extended it
with mapping to computational system parameters: computing
utilization, computing redistribution, memory redistribution,
storage volume and storage, utilization.
III.
THE EXPERIMENTS
The proposed noradrenaline concentration dynamics model
is based on Izhikevich model for dopamine [29]. The state of
each synapse is described by two variables: synaptic weight w
and synaptic tag c, also called ”eligibility trace”. The eligibility
trace is a parameter used to control the “memory” of the algo-
rithm, associated with a given state, enabling the assignment
of some values to the data under analysis [30][31]. From a
biological perspective, it is either some enzyme activation, or
another relatively slow process that happens in the synapse,
if pre-synaptic and post-synaptic neurons ﬁre by the spike-
timing-dependent plasticity (STDP) rule. The eligibility trace
can modify the synaptic weight, but only in the presence of
extracellular neurotransmitter (noradrenaline), and only during
the timeframe of a few seconds. During that time interval, the
eligibility trace decays to zero. In a nutshell: the eligibility
trace controls the data evaluation in learning processes and is
directly involved in novelty detection, something that manages
temporal difference learning [32][33]. In this process, the
predictive role of dopamine is fundamental [34].
Consequently, we extend the Izhikevich equations for
dopamine [29], referring to interesting approaches such as [35]
or [36], to describe some governing equations and features
in the model of a neural network by noradrenaline. The key
aspect of this approach is that we are not just using some
kind of existing neural network, but the one implementing a
fundamental biomimetic model. Our approach allows to con-
sider classic neural networks adding a biomimetic meaning and
semantics to implement the mechanistic regulation operated
by neurotransmitters, especially dopamine as a modulator of
novelty detection and management [37].
We begin this process considering spiking network of
quadratic leaky integrate-and-ﬁre neurons [38]. The neuron
ratio is distributed as follows: a) 80% excitatory neurons, and
b) 20% inhibitory. The dynamics of each neuron is such that
the membrane potential v of each neuron at each moment (new
current potential ˙v) depends on abstract membrane recovery
variable u (new current value ˙u) [39]:
˙v = k(v − vrest)(v − vthresh) − u + I
(1)
˙u = a ∗ b ∗ (v − vrest) − u
(2)
if(v >= 30[mV ]) : {v = −65[mV ], u = u + 2[mV ]}
(3)
In our model, membrane voltage threshold vthresh and resting
potential vrest are constant, and the synaptic current input I
(the current ﬂowing in a neuron) has an exponential shape. The
spike occurs when the membrane potential is higher than -50
mV, and then the membrane potential recovers: v decreases to
-65 mV, u increases by 2 mV. We set a to 0.02, b to 0.2, k to
1.
11
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-531-9
COGNITIVE 2017 : The Ninth International Conference on Advanced Cognitive Technologies and Applications

Following Izhikevich, the STDP model [40] does not
change the synaptic weights directly, but instead it modulates
weights through a temporal eligibility trace (as it will be shown
in 6. The variation of the eligibility trace c (new current
eligibility trace ˙c) is described as follows:
˙c = − c
τc
+A+e
(tpre−tpost)
τ+
δ(t−tpost)−A−e
(tpre−tpost)
τ−
δ(t−tpre)
(4)
where tpre and tpost are the times of a pre- or post-synaptic
spike, A+ and A− are the amplitudes of the weight change,
τ+ and τ− are constant rates, δ(t) is the Dirac delta function
that step-increases the variable c. The eligibility trace decays
at the rate of τc.
The concentration of noradrenaline also impacts the mod-
ulation of synaptic weights [41][42], as shown in (6).
The noradrenaline concentration n decreases exponentially
with time (natural fade rate is τn), and increases depending on
salient, novel events:
˙n = − n
τn
+ pnovn(δ(t − tn)prew + δ(t − tn)ppun)
(5)
where ppunish is a punishment (stressor) event, prew is a re-
ward event, pnov is the probability of the event being novel and
unexpected (salient). The noradrenaline concentration cannot
go below zero: it increases with stressors, if pnov is bigger
than zero (a sudden stress), as well as with rewards, if prew
is bigger than zero (a surprise reward).
The excitatory synaptic weight w (new current value ˙w)
is not changed directly in the model. Instead, it is modulated
proportionally to relative concentration of noradrenaline n (to
its baseline level bn), multiplied by eligibility trace c:
˙w = c(n − bn)
(6)
The model was tested on MATLAB with the following
parameters:
•
Network of 1000 leaky neurons with STDP;
•
100 synapses per neuron;
•
Maximal synaptic strength = 5;
•
Initial synaptic strength (w) = 0;
•
Conduction delay = 1 [ms];
•
Membrane ground potential (v) = -65 [mV];
•
Coincidence interval for pre- and post-synaptic neu-
rons = 20 [ms];
•
Current level of NA concentration (n) = 0, as well as
5-HT and DA concentration;
•
Initial eligibility trace (c) = 0;
The results thus obtained from simulation, shown in Fig.
2, demonstrate that:
1)
Noradrenaline concentration was not affected whatso-
ever by predictable rewards with the novelty of zero.
Meanwhile, serotonin and dopamine concentration
were increased by reward - each of the three times
in the interval of ﬁrst 100 ms;
2)
Noradrenaline concentration was almost not affected
by predictable punishment with zero novelty while
serotonin fade rate was vastly increased by it, which
led to the serotonin concentration drop at the 90th ms
of the simulation run;
3)
Noradrenaline concentration was increased by every
unpredictable event, proportionally to the level of the
event’s saliency - it went much higher at the 180th
ms, when the reward’s novelty was 0.75, than at
380th ms, when the reward’s novelty was only 0.6.
Same reaction was demonstrated for the punishments
of different novelty, at the moments of 230 ms and
380 ms. However, dopamine and serotonin reaction to
reward and punishment events did not depend on how
unpredictable the events were: dopamine concentra-
tion was proportional to the frequency of the rewards
(of whatever novelty), serotonin concentration - to
both reward and punishment event frequency.
IV.
RELATED WORK
Since the last decade of 20th Century the interest towards
emotions and emotional representations in computational sys-
tems has been exponentially growing [43][44]. At the same
time, the industrial applications that could relate humans and
machines have required increased investments into Human-
Robot Interaction (HRI) studies, covering a big array of topics
[45][46][47], even ethical ones [48][49]. This rise of activity
was based on understanding of the role of emotions in human
intelligence and consciousness that was indicated by several
neuroscientists [50][51].
Starting from the seminal ideas of bioinspired neural net-
works of Stephen Grossberg in the 1970’s [8], in the following
decade a new vision on computational emotional architectures
was investigated by Aaron Sloman [52]. A few years later,
affective computing was born thanks to the book by Rosalind
Picard [5]. Social robotics was the natural evoluton of these
new trends, also at MIT by Cynthia Breazeal [6].
We could identify two main directions in the new research
ﬁeld of affective computing: emotion recognition and re-
implementation of emotions in a computational system, mostly
for HRI purposes. There are several cognitive architectures
that are capable of the re-implementation of emotional phe-
nomena, starting from ACT-R [53] to modern BICA [54],
among others. The interest in implementation of emotional
mechanisms is based on the fundamental role of emotions
in basic cognitive processes: colouring in appraisal, decision
making mechanisms, and emotional behaviour, as Damasio
showed in [1].
Our approach takes a step further on the road for neu-
robiologically plausible model of emotions [26]: Arbib and
Fellous [55][56] created the neurobiological background for
the direction to neurobiologically inspired cognitive architec-
tures; appraisal aspects were analyzed by Marsella and Gratch
researches [14][15], as well as in Lowe and Ziemke works
[13][57], or temporal and reinforcement learning [58][59].
As it was mentioned earlier in this paper, the processing
of the simulation took 4 hours of supercomputer’s processing
time to calculate 1000 milliseconds [60].
V.
CONCLUSION AND FUTURE WORK
In our paper, we have described a new approach for
augmentation of autonomous robotic systems with mechanisms
of emotional revision and feedback. We have modelled novelty
12
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-531-9
COGNITIVE 2017 : The Ninth International Conference on Advanced Cognitive Technologies and Applications

Figure 2. Transient evolution of eligibility trace c (cyan) and concentration of NA n (red), 5-HT (blue), DA (green), being exposed to reward (arrow) and
punishment (red circle) events with different levels of saliency (grey circles).
recognition and evaluation skills, which are useful for a broad
range of implementations: cognitive architectures, self-learning
models, HRI, among other possibilities. The implementa-
tion of a biomimetic cognitive architecture that captures the
basic neutrotransmitters roles (noradrenaline, dopamine and
serotonin), as well the noradrenaline concentration dynamics
model based on Izhikevich model for dopamine has made it
possible for our NEUCOGAR model to build reliable ways
to deal with cognitive novelty. This feature, novelty, is of the
outmost importance for a cognitive system, because it selects
and manages attention, modiﬁes memory resources and data,
stimulates responses, among other functions [61][62].
Despite of the good preliminary results, this research offers
also some important questions: a) ﬁrst of all, to deﬁne clearly
the input formats for realistic neural network; b) secondly, the
necessity of establishing reliable emotional revision thresholds;
c) ﬁnally, the clariﬁcation of the way by which we capture and
reproduce emotional equalizing (homeostasis) in a biomimetic
way (for ”average human” inspired architectures, as well as
for bioinspired but open ones).
On the one hand, different answers to these questions allow
us to adapt our model to a range of possible architectures
of robots’ control systems. These robotic architectures can
follow several scenario-demanding conditions (responses op-
timized by velocity, approximation, low computing demand,
etc.), which can be managed through the neurotransmitters
biomimetic model. The fundamental aspect of our model is that
it can follow human-like standard neurotransmitting mecha-
nisms; or the mechanisms can be modiﬁed, in order to optimize
other cognitive heuristics adapted to the real demands at that
speciﬁc time. On the other hand, we consider that the best way
to implement our model would be a software framework with
several pluggable adapters to accommodate the most popular
choices for robots’ ”brains”. This can be achieved using
an accepted programming language, at least for academics
(the barriers that create diverse manufactures employing own
languages are well known: ABB (Asea Brown Boveri Ltd.) has
its RAPID language, KUKA (Keller und Knappich Augsburg)
has KRL (Kuka Robot Language), Comau uses PDL2 (Pro-
cess Design Language 2), Yaskawa Electric Corporation uses
INFORM language, FANUC (Factory Automation NUmerical
Control) uses Karel language, etc.) [63][64]. Our idea is
that the power and simplicity of our model, as well as its
accessibility (offering all our data at free repositories), can help
to unify the ﬁeld. The beneﬁts of our bioinspired architecture
are evident: it allows to connect and manage modular systems
with a main but not dominant emotional architecture (like
our NEUCOGAR model). It can be seen as a cognitive net
that increases and empowers managing systems without the
necessity of reprogramming the whole architecture: it is a thin
global layer that coordinates sub-layers/modules activations,
allowing even a multi-heuristic system adapt to fast changing
demands.
ACKNOWLEDGMENTS
This work was funded by the subsidy of the Russian
Government to support the Program of competitive growth
of Kazan Federal University among world class academic
centers and universities. This paper has been partially funded
by Spanish Government DGICYT: Creatividad, revoluciones
e innovacin en los procesos de cambio cientﬁco (FFI2014-
52214-P).
REFERENCES
[1]
A. Damasio, Ed., Descartes’ Error: Emotion, Reason, and the Human
Brain.
Penguin Books, Jan. 1994.
[2]
O. Vilarroya, “Sensorimotor event: an approach to the dynamic, em-
bodied, and embedded nature of sensorimotor cognition,” Frontiers in
Human Neuroscience, vol. 7, 2014, p. 912.
[3]
R. Pfeifer and J. C. Bongard, How the Body Shapes the Way We Think:
A New View of Intelligence (Bradford Books).
The MIT Press, 2006.
[4]
A. Sloman, “Computational Modelling of Motive-Management Pro-
cesses,” in Proceedings of the Conference of the International Society
for Research in Emotions, N.Frijda, Ed. Cambridge: ISRE Publications,
1994, pp. 344–348.
[5]
R. W. Picard, Ed., Affective Computing.
Massachusets Institute of
Technology, 1997.
[6]
C. Breazeal, Ed., Emotion And Sociable Humanoid Robots.
Elsevier
Science, 2002.
[7]
J. Vallverd´u, Creating Synthetic Emotions through Technological and
Robotic Advancements. IGI Global, 2012, ch. Subsuming or Embody-
ing Emotions?, pp. IX–XIV.
13
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-531-9
COGNITIVE 2017 : The Ninth International Conference on Advanced Cognitive Technologies and Applications

[8]
J. Vallverdu, Ed., Handbook of Research on Synthesizing Human
Emotion in Intelligent Systems and Robotics.
Hershey, PA, USA:
IGI Global, 2015.
[9]
M.
Talanov,
J.
Vallverd´u,
S.
Distefano,
M.
Mazzara,
and
R.
Delhibabu,
“Neuromodulating
Cognitive
Architecture:
Towards
Biomimetic
Emotional
AI,”
in
2015
IEEE
29th
International Conference on Advanced Information Networking and
Applications,
vol.
2015-April.
IEEE,
mar
2015,
pp.
587–592.
[Online]. Available: http://www.scopus.com/inward/record.url?eid=2-
s2.0-84946224675&partnerID=tZOtx3y1
http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7098025
[10]
M. R. Zarrindast, “Neurotransmitters and Cognition,” EXS, vol. 98,
2006, pp. 5–39.
[11]
A. Hyungil and R. Picard, “Affective Cognitive Learning and Decision
Making: The Role of Emotions,” in The 18th European Meeting on
Cybernetics and Systems Research (EMCSR 2006), 2006.
[12]
R. W. Picard, E. Vyzas, and J. Healey, “Toward Machine Emotional
Intelligence: Analysis of Affective Physiological State,” vol. 23, no. 10,
2001, pp. 1175–1191.
[13]
T. Ziemke and R. Lowe, “On the Role of Emotion in Embodied
Cognitive Architectures: From Organisms to Robots,” Cogn Comput,
2009, pp. 104–117.
[14]
S. Marsella, J. Gratch, and P. Petta, Computational Models of Emotion.
Oxford: Oxford University Press, 2010, pp. 21–46.
[15]
J. Gratch and S. Marsella, “Evaluating a Computational Model of
Emotion,” Autonomous Agents and Multi-Agent Systems, vol. 11, 2005,
pp. 23–43.
[16]
F. De Waal, “Putting the Altruism Back into Altruism: the Evolution
of Empathy,” Annu. Rev. Psychol., vol. 59, 2008, pp. 279–300.
[17]
G. Rizzolatti and L. Craighero, “The Mirror-Neuron System,” Annual
Review of Neuroscience, 2004.
[18]
M. Minsky, The Emotion Machine: Commonsense Thinking, Artiﬁcial
Intelligence, and the Future of the Human Mind.
Simon and Schuster,
2007.
[19]
H.
L¨ovheim,
“A
New
Three-Dimensional
Model
for
Emo-
tions
and
Monoamine
Neurotransmitters,”
Medical
Hypotheses,
vol.
78,
no.
2,
feb
2012,
pp.
341–8.
[Online].
Available:
http://www.sciencedirect.com/science/article/pii/S0306987711005883
[20]
R. H. Wiley, Signal Detection, Noise, and the Evolution of Commu-
nication.
Berlin, Heidelberg: Springer Berlin Heidelberg, 2013, pp.
7–30.
[21]
E. Mather, “Novelty, Attention, and Challenges for Developmental
Psychology,” Frontiers in Psychology, vol. 4, 2013, p. 491.
[22]
S. J. and M. Meeter, “Short- and Long-Lasting Consequences of
Novelty, Deviance and Surprise on Brain and Cognition,” Neuroscience
and Biobehavioral Reviews, vol. 55, 2015, pp. 268–279.
[23]
A. J. Cropley, “Creativity and Cognition: Producing Effective Novelty,”
Roeper Review, vol. 21, no. 4, 1999, pp. 253–260.
[24]
W. T. Blows, “Neurotransmitters of the Brain: Serotonin, Noradrenaline
(Norepinephrine), and Dopamine,” J Neurosci Nurs., vol. 32, no. 4,
2000, pp. 234–8.
[25]
A. Leukhin, M. Talanov, I. Sozutov, J. Vallverd´u, and A. Toschev,
“Simulation of a Fear-Like State on a Model of Dopamine System
of Rat Brain,” vol. 449, 2016, pp. 121–126.
[26]
J. Vallverd´u, M. Talanov, S. Distefano, M. Mazzara, A. Tchitchigin,
and I. Nurgaliev, “A Cognitive Architecture for the Implementation
of Emotions in Computing Systems,” Biologically Inspired Cognitive
Architectures, 2015.
[27]
M. Gewaltig and M. Diesmann, “NEST (NEural Simulation Tool),”
Scholarpedia, vol. 2, no. 4, 2007, p. 1430.
[28]
S. Tomkins, Affect Imagery Consciousness Volume III : the Negative
Affects Anger and Fear.
New York: Springer Publishing Company,
1991.
[29]
E. M. Izhikevich, “Solving the Distal Reward Problem through Linkage
of STDP and Dopamine Signaling,” Cerebral Cortex, vol. 17, no. 10,
2007, pp. 2443–2452.
[30]
K. Katahira, T. Cho, K. Okanoya, and M. Okada, “Optimal Node
Perturbation in Linear Perceptrons with Uncertain Eligibility Trace,”
Neural networks : the Ofﬁcial Journal of the International Neural
Network Society, vol. 23, no. 2, Mar 2010, pp. 219–25.
[31]
M. Geist and B. Scherrer, “Off-Policy Learning with Eligibility Traces:
A Survey,” J. Mach. Learn. Res., vol. 15, no. 1, Jan. 2014, pp. 289–333.
[32]
A. Adam and M. White, “Investigating Practical Linear Temporal
Difference
Learning,”
in
Proceedings
of
the
2016
International
Conference on Autonomous Agents and Multiagent Systems, ser.
AAMAS ’16. Richland, SC: International Foundation for Autonomous
Agents
and
Multiagent
Systems,
2016,
pp.
494–502.
[Online].
Available: http://dl.acm.org/citation.cfm?id=2936924.2936997
[33]
C. Dann, G. Neumann, and J. Peters, “Policy Evaluation with
Temporal Differences: A Survey and Comparison,” Journal of Machine
Learning Research, vol. 15, 2014, pp. 809–883. [Online]. Available:
http://jmlr.org/papers/v15/dann14a.html
[34]
W. Schultz, “Predictive Reward Signal of Dopamine Neurons,” Journal
of neurophysiology, vol. 80, no. 1, 1998, p. 1.
[35]
H. M. Bayer and P. W. Glimcher, “Midbrain Dopamine Neurons Encode
a Quantitative Reward Prediction Error Signal,” Neuron, vol. 47, no. 1,
Jul 2005, pp. 129–41.
[36]
C. Yu, N.and Canavier, “A Mathematical Model of a Midbrain
Dopamine Neuron Identiﬁes Two Slow Variables Likely Responsible
for Bursts Evoked by SK Channel Antagonists and Terminated by
Depolarization Block,” Journal of Mathematical Neuroscience, vol. 5,
2015, p. 5.
[37]
M. Garcia-Garcia, I. Clemente, J. Dom´ınguez-Borr`as, and C. Escera,
“Dopamine transporter regulates the enhancement of novelty processing
by a negative emotional context,” Neuropsychologia, vol. 48, no. 5, Apr
2010, pp. 1483–8.
[38]
A. N. Burkitt, “Balanced Neurons: Analysis of Leaky Integrate-and-
Fire Neurons with Reversal Potentials,” Biological Cybernetics, vol. 85,
no. 4, Oct 2001, pp. 247–55.
[39]
T. Chou, L. D. Bucci, and J. L. Krichmar, “Learning Touch Preferences
with a Tactile Robot Using Dopamine Modulated STDP in a Model of
Insular Cortex,” Frontiers in Neurorobotics, vol. 6, no. 6, Jul 2015.
[40]
J. Lisman and N. Spruston, “Questions about STDP as a General Model
of Synaptic Plasticity,” Frontiers in Synaptic Neuroscience, vol. 2, 2010.
[41]
P. A. Baumann and W. P. Koella, “Feedback Control of Noradrenaline
Release as a Function of Noradrenaline Concentration in the Synaptic
Cleft in Cortical Slices of the Rat,” Brain research, vol. 189, no. 2, May
1980, pp. 437–48.
[42]
J. Ludwig, M. Gerlich, T. Halbr¨ugge, and K. H. Graefe, “The synaptic
noradrenaline concentration in humans as estimated from simultane-
ous measurements of plasma noradrenaline and dihydroxyphenylglycol
(dopeg).” Journal of Neural Transmission Supplementum, vol. 32, 1990,
pp. 441–5.
[43]
C. Breazeal, Designing Sociable Robots.
MIT Press, 2004.
[44]
R. W. Picard, What Does it Mean for a Computer to ”Have” Emotions?,
2001.
[45]
H. Admoni, “Nonverbal Communication in Socially Assistive Human-
Robot Interaction,” AI Matters, vol. 2, no. 4, 2016, pp. 9–10.
[46]
A. Esposito and L. C. Jain, “Modeling emotions in robotic socially
believable behaving systems,” in Toward Robotic Socially Believable
Behaving Systems (I), ser. Intelligent Systems Reference Library,
A. Esposito and L. C. Jain, Eds.
Springer, 2016, vol. 105, pp. 9–14.
[Online]. Available: http://dx.doi.org/10.1007/978-3-319-31056-5
[47]
J. Vallverd´u and G. Trovato, “Emotional affordances for human-robot
interaction,” Adaptive Behaviour, no. 5, pp. 320–334.
[48]
B. Lewandowska-Tomaszczyk and P. Wilson, Physical and Moral
Disgust in Socially Believable Behaving Systems in Different Cultures,
ser. Intelligent Systems Reference Library.
Springer, 2016, vol. 105,
pp. 105–132. [Online]. Available: http://dx.doi.org/10.1007/978-3-319-
31056-5
[49]
F. Operto, “Ethics in Advanced Robotics: ELS Issues in Advanced
Robotics,” IEEE Robotics and Automation Magazine, vol. 18, no. 1,
2011, pp. 72–78.
[50]
A. Damasio, The Feeling of What Happens : Body and Emotion in the
Making of Consciousness.
New York, 1999.
[51]
A. Murata, L. Fadiga, L. Fogassi, V. Gallese, V. Raos, and G. Rizzolatti,
14
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-531-9
COGNITIVE 2017 : The Ninth International Conference on Advanced Cognitive Technologies and Applications

“Object Representation in the Ventral Premotor Cortex (Area F5) of the
Monkey,” J Neurophysiol., vol. 78, no. 4, 1997, pp. 2226–30.
[52]
A. Sloman and R. Chrisley, “Virtual Machines and Consciousness,”
Journal of Consciousness Studies, 2003.
[53]
A. Harrison, “jACT-R: Java ACT-R,” in Proceedings of the 8th Annual
ACT-R Workshop, 2002.
[54]
A. V. Samsonovich, “Modeling Human Emotional Intelligence in Vir-
tual Agents,” in AAAI Fall Symposium - Technical Report, vol. FS-13-
03.
AI Access Foundation, 2013, pp. 71–78.
[55]
J. Fellous, “The neuromodulatory basis of emotion,” The Neuroscientist,
vol. 5, 1999, pp. 283–294.
[56]
M. Arbib and J. Fellous, “Emotions: from Brain to Robot,” Trends in
Cognitive Sciences, vol. 8(12), 2004, pp. 554–559.
[57]
R. Lowe and T. Ziemke, “The Role of Reinforcement in Affective
Computation Triggers, Actions and Feelings,” in IEEE Symposium
on Computational Intelligence for Creativity and Affective Computing
(CICAC), 2013.
[58]
R. Sutton, “Learning to Predict by the Methods of Temporal Differ-
ences,” Mach. Learn., vol. 3, no. 1, Aug. 1988, pp. 9–44.
[59]
S. P. Singh and R. S. Sutton, “Reinforcement learning with replacing
eligibility traces,” Machine Learning, vol. 22, no. 1-3, 1996, pp. 123–
158.
[60]
V.
Kugurakova,
M.
Talanov,
and
D.
Ivanov,
“Neurobiological
Plausibility
as
Part
of
Criteria
for
Highly
Realistic
Cognitive
Architectures,” in Procedia Computer Science, vol. 88, 2016, pp.
217–223. [Online]. Available: www.scopus.com
[61]
M. Kishiyama and A. Yonelinas, “Novelty Effects on Recollection and
Familiarity in Recognition Memory,” Memory and cognition, vol. 31,
no. 7, 2003, pp. 1045–1051.
[62]
T. Saigusa, T. Tuinstra, N. Koshikawa, and A. R. Cools, “High and Low
Responders to Novelty: Effects of a Catecholamine Synthesis Inhibitor
on Novelty-Induced Changes in Behaviour and Release of Accumbal
Dopamine,” Neuroscience, vol. 88, no. 4, 1999, pp. 1153–63.
[63]
S. Calinon, “Robot Programming by Demonstration,” in Springer Hand-
book of Robotics, 2008, ch. 59, pp. 1371–1394.
[64]
R. L. Wexelblat, History of Programming Languages. Academic Press,
2014.
15
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-531-9
COGNITIVE 2017 : The Ninth International Conference on Advanced Cognitive Technologies and Applications

