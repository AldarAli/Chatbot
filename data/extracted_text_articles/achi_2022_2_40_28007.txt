Relationship between 3D Eye-Gaze and the TrueDepth 
Measured by Vive Pro Eye 
Kenta Kato and Oky Dicky Ardiansyah Prima 
Graduate School of Software and Information Science 
Iwate Prefectural University 
152-52, Sugo, Takizawa, Iwate, Japan 
e-mail: g236s002@s.iwate-pu.ac.jp, prima@iwate-pu.ac.jp 
 
 
Abstract—The widespread availability of eye tracking devices 
has led to the active application of eye-gaze information, such as 
input interfaces, eye-gaze-based interaction with computers, 
and understanding of human visual information. More recently, 
various Head-Mounted Displays (HMDs) for Virtual Reality 
(VR) with built-in eye trackers have become commercially 
available. The Vive Pro Eye has been used for in-depth analysis 
of saccadic eye movements and in clinical ophthalmology. 
Unlike any other HMD-type eye tracker, the advanced slippage 
compensation in this device allows to maintain gaze accuracy 
and provides stable gaze measurement over a long period. We 
believe that this advantage may help in estimating accurate 
Three-Dimensional (3D) eye-gaze, and therefore it is necessary 
to investigate the accuracy of 3D gaze with the Vive Pro Eye. 
This study attempts to evaluate the accuracy of eye-gaze in two- 
and three-dimensions by measuring 3D eye-gaze when gazing at 
targets placed at different spatial positions with the Vive Pro 
Eye. Results showed that the relative position of the 3D eye-gaze 
to the 3D targets placed radially in 40-cm increments from 40 to 
200 cm was confirmed. The accuracy of 2D eye-gaze 
measurements tends to decrease as the viewing angle increases, 
and consequently the accuracy of the corresponding 3D eye-gaze 
measurements also decreases. The 3D eye-gaze to the centrally 
located visual targets increases linearly, while the rest of the eye-
gaze increases logarithmically. 
Keywords-3D eye-gaze; eye vergence; eye tracking; 3D 
perception; computer vision. 
I.  INTRODUCTION 
Two-Dimensional (2D) and Three-Dimensional (3D) 
contents are now accessible to consumers as Head-Mounted 
Display (HMD)-type Virtual Reality (VR) devices become 
available to the general consumers. Since these contents can 
be easily and cost-effectively created using VR, HMD-type 
VR is being used for applications that are difficult to 
reproduce in a real environment, such as product design and 
new training methods for sports [1]-[3]. Users can manipulate 
3D contents in VR mostly by using controllers or hand 
gestures. Recently, HMDs with an eye-tracking function has 
been introduced as an alternative method to control the 
contents. Since then, interactions based on eye tracking in VR 
have been actively developed [4]-[6]. In addition, with the 
commercialization of HMD-type eye trackers, the use of eye-
gaze information in VR environments is being explored in 
brain science, psychology, disease assessment, and behavioral 
analysis [7]-[9]. These eye trackers are expected to provide 
more accurate eye-gaze measurements because they block out 
ambient light. 
Stein et al. [10] evaluated several HMDs with built-in eye 
trackers, including Fove-0, Varjo VR-1, and the Vive Pro Eye. 
Their results showed that the Vive Pro Eye had the highest 
latency, even though it was the best in terms of field of view 
and tracking sampling rate. However, the results also 
indicated possibly due to data filtering within the Software 
Development Kit (SDK). To our knowledge, Vive Pro Eye is 
the only HMD with advanced slip compensation that handles 
headset motion to maintain accuracy and calibration. This 
solution allows users to move naturally throughout the 
experience without losing eye tracking performance. The 
Vive Pro Eye has been reported to be effective in performing 
saccadic eye movement assessment [11] and clinical 
ophthalmology [12].  
 The Vive Pro Eye outputs eye-gaze information in 3D 
coordinates, which could enable 3D eye-gaze estimation by 
crossing both extensions of the left and right eye-gaze raycasts 
without triangulation. This will allow for a simpler calculation 
for obtaining 3D eye-gaze than that based on vergence eye 
movements and is expected to lead to the analysis of various 
types of visual information using 3D eye-gaze. However, 
there is currently a lack of rigorous research investigating the 
accuracy of 3D eye-gaze with the Vive Pro Eye and the impact 
of gazing distance and direction on the accuracy. 
In this study, we use the Vive Pro Eye to collect eye-gaze 
information while gazing at targets placed at different spatial 
locations and analyze their distribution in two 2D and 3D. To 
characterize the eye-gaze at any given direction and distance, 
we place the visual targets radially on a plane at a given 
distance. Here, three seconds of fixation was performed to 
analyze the representative eye-gaze information during the 
fixation task, since small involuntary eye movements 
continuously change the eye-gaze position during the fixation. 
At the end, we will compare the characteristics of 3D eye-gaze 
measured with the Vive Pro Eye with those obtained with our 
previous experiments based on vergence eye movements to 
explore new insights. 
The rest of this paper is organized as follows. Section II 
describes related works on 3D eye-gaze measurements. 
Section III describes our experiments to characterize the 3D 
eye-gaze derived by Vive Pro Eye. Section IV summarizes our 
results. Finally, Section V concludes our study and discusses 
prospects. 
 
30
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-982-9
ACHI 2022 : The Fifteenth International Conference on Advances in Computer-Human Interactions

II. RELATED WORKS 
The 3D eye-gaze measurement relies on the relative 
position of the two eyes with respect to a given visual target. 
Vergence angle (the angle in the direction of the line of sight 
of both eyes) changes when the visual target moves to a 
certain distance from the viewer. Since our eyes never remain 
completely still as we try to align our eye-gaze with the object 
[13], 3D eye-gaze measurement is less stable than that of 2D 
eye-gaze. Small eye movements can cause changes in the 
position of both eyes, reducing the measurement accuracy. 
Kato & Prima [14] performed 3D eye-gaze measurements in 
an MR environment and confirmed that the relative size of the 
3D visual target and the surrounding physical environment do 
not affect the accuracy of 3D eye-gaze. 
Some studies have attempted to measure 3D eye-gaze 
without calibration in order to make such measurement easier. 
Palmero et al. [15] used recurrent Convolutional Neural 
Network (CNN) to automatically estimate 3D eye-gaze from 
still images using information from faces, eye regions, and 
facial landmarks. Liu et al. [16] proposed automatic 3D eye-
gaze estimation using an automatic calibration method that 
combines 3D salient pixels from RGB-D images and eye-gaze 
vectors. These attempts yielded plausible results, but their 
accuracies were not sufficient for the analysis of eye-gaze 
characteristics. 
Vive Pro Eye enables 3D eye-gaze estimation without the 
need for 3D calibration. It can record 3D eye-gaze origin and 
eye-gaze direction data estimated by constructing cones 
passing through the camera's focal point and pupil ellipses on 
the image plane and finding the circular intersection of these 
cones at a given distance. 
III. 3D EYE-GAZE MEASUREMENT USING VIVE PRO EYE 
In this study, we evaluate 3D eye-gaze measured with the 
Vive Pro Eye, which is currently the most popular eye 
tracking system for VR HMDs. Because the effect of vergence 
eye movements is not significant beyond 2m, many studies on 
vergence eye movements have conducted experiments on 
visual targets up to 2m [17][18]. For these reasons, our 
evaluation will be conducted by measuring eye-gaze up to 2m 
from the subject. The eye tracking accuracy of the Vive Pro 
Eye is 0.5° to 1.1° within a 20° Field of View (FoV). To 
evaluate the quality of 3D eye-gaze within and outside this 
FoV, we will measure the eye-gaze at broader FoV. 
A. Equipments 
Our experiment will be performed using Unity3D 
2019.4.31f1 and SteamVR 1.21.12 software to drive the Vive 
Pro Eye. Eye-gaze data will be acquired using SRanipal 
Runtime 1.3.2.0. The computer for the experiment features a 
Ryzen 9 3900 3.1Ghz, DDR4 64GB RAM, and a NVIDIA 
GeForce RTX 2060 Super graphics card.  
B. Visual Targets 
Visual targets are placed radially from 40 cm to 200 cm to 
the subject in 40 cm increments. Visual targets and their 
arrangement are illustrated in Figure 1.  
 
 
(a) Visual targets placed radially in eight directions. 
(b) Arrangement of planes containing the visual targets. 
Figure 1. Visual targets and their arrangement in this study. 
Horizontal (°)
Vertical (°)
 
Figure 2. Visual targets for the eye-gaze validation. 
 
 
Horizontal (°)
Vertical (°)
31
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-982-9
ACHI 2022 : The Fifteenth International Conference on Advances in Computer-Human Interactions

C. Procedure 
Subjects are provided with information about the 
experiment and then are asked to give informed consent to 
participate in the experiment. The subjects are then asked to 
answer an eye health questionnaire, and their visual acuity is 
measured using a Landolt ring placed three meters away from 
them. In addition, we give training on how to operate the Vive 
Pro Eye to ensure that the subject does not make any mistakes 
during the experiment. The subject is seated on a chair, 
wearing the Vive Pro Eye and its controller. The camera pose 
in the virtual space is fixed so that changes in the subject’s 
head pose do not affect the measurement. Our experiment is 
performed according to the following procedure.  
Step 1: Perform the Vive Pro Eye 5-point eye-gaze calibration. 
Step 2: Validate the eye-gaze accuracy using the 5-point 
validation target created for this experiment. If 
binocular eye-gaze accuracy is greater than 1°, return 
to Step 1. 
Step 3: Trigger 
the 
controller 
to 
perform 
eye-gaze 
measurements on each target for 3s. The experiment is 
terminated after 125 trials. 
The Step 2 is performed because the Vive Pro Eye's eye-gaze 
calibration does not provide the accuracy with numerical 
values. Figure 2 shows the placement of the visual targets to 
be used for the validation. Targets are placed 1m away from 
the subject and at 20° FoV in four directions. 
IV. EXPERIMENTS AND RESULTS 
Eight subjects (seven males, a female, mean age 23.4) 
participated in the experiment. They were tested for visual 
acuity using a Landolt ring to confirm that their vision 
achieved 1.0 or better. They were also asked to fill out a 
questionnaire to confirm that they had no health concerns. 
A. Pre-processing 
The Vive Pro Eye detects the opening and closing of the 
eyes, and the degree of eye opening is defined as 0 (closed) to 
1 (open). In this study, to obtain accurate eye-gaze data, we 
extracted only data in which the degree of eye opening was 
greater than 0.9 for both eyes of the subject. Eye opening at 
0.9 or less may result in false detection as the eyelid falls to 
hide some portion of the pupil. 
B. Eye-Gaze Accuracies and Precisions 
The accuracy and precision of the 3D eye-gaze depends 
on that of the 2D eye-gaze. The following equation was used 
in the calculations. 
𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦2𝐷 = √1
𝑛 ∑(𝑇𝑥𝑖 − 𝐺𝑥𝑖)2 + (𝑇𝑦𝑖 − 𝐺𝑦𝑖)
2
𝑛
𝑖=1
 
(1) 
𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛2𝐷 = √1
𝑛 ∑(𝐺𝑥𝑖+1 − 𝐺𝑥𝑖)2 + (𝐺𝑦𝑖+1 − 𝐺𝑦𝑖)
2
𝑛
𝑖=1
 
(2) 
Here, 𝑛 is the number of targets used for the measurement, 
𝑇𝑥𝑖, 𝑇𝑦𝑖,  and 𝐺𝑥𝑖, 𝐺𝑦𝑖 are the coordinates of the 𝑖-th target and 
the associated eye-gaze points. 
Table I shows the results of the 2D eye-gaze accuracies 
and precisions for visual targets placed at various distances, as 
shown in Figure 1. The numbers in bold indicate an accuracy 
TABLE I. 2D EYE-GAZE ACCURACIES (PRECISIONS) AT VARIOUS DISTANCES. 
UNITS: ° 
Subject 
40cm 
80cm 
120cm 
160cm 
200cm 
1 
1.34 (0.09) 
0.84 (0.10) 
0.91 (0.10) 
0.95 (0.10) 
0.83 (0.10) 
2 
0.63 (0.08) 
0.55 (0.08) 
0.56 (0.08) 
0.61 (0.09) 
0.53 (0.08) 
3 
0.47 (0.06) 
0.48 (0.06) 
0.45 (0.05) 
0.49 (0.06) 
0.74 (0.82) 
4 
0.49 (0.05) 
0.48 (0.05) 
0.57 (0.06) 
0.59 (0.04) 
0.60 (0.06) 
5 
0.78 (0.06) 
0.56 (0.06) 
0.85 (0.08) 
0.68 (0.09) 
0.75 (0.82) 
6 
1.25 (0.09) 
1.00 (0.10) 
1.20 (0.10) 
1.06 (0.09) 
0.90 (0.09) 
7 
1.61 (0.09) 
1.09 (0.07) 
1.04 (0.06) 
1.08 (0.08) 
1.11 (0.07) 
8 
1.60 (1.04) 
1.64 (0.83) 
1.05 (0.16) 
1.08 (0.08) 
1.00 (0.13) 
Mean 
1.02 (0.20) 
0.83 (0.18) 
0.83 (0.09) 
0.82 (0.10) 
0.81 (0.18) 
Std. Dev. 
0.451 (0.321) 
0.380 (0.270) 
0.254 (0.031) 
0.231 (0.054) 
0.182 (0.244) 
 
TABLE II. 2D EYE-GAZE ACCURACIES (PRECISIONS) AT VARIOUS ANGLES. 
UNITS: ° 
Subject 
0° 
10° 
20° 
30° 
1 
1.17 (0.11) 
0.95 (0.12) 
0.99 (0.09) 
1.01 (0.08) 
2 
0.51 (0.06) 
0.51 (0.10) 
0.63 (0.08) 
0.60 (0.07) 
3 
0.28 (0.06) 
0.36 (0.06) 
0.52 (0.06) 
0.70 (0.65) 
4 
0.46 (0.03) 
0.45 (0.04) 
0.54 (0.07) 
0.65 (0.05) 
5 
0.40 (0.06) 
0.67 (0.10) 
0.62 (0.06) 
0.91 (0.05) 
6 
0.55 (0.07) 
0.65 (0.08) 
0.95 (0.11) 
1.53 (0.09) 
7 
0.83 (0.09) 
0.79 (0.07) 
1.06 (0.08) 
1.65 (0.07) 
8 
0.92 (0.13) 
1.03 (0.15) 
0.81 (0.12) 
1.87 (1.10) 
Mean 
0.64 (0.08) 
0.68 (0.09) 
0.76 (0.08) 
1.11 (0.27) 
Std. Dev. 
0.283 (0.030) 
0.222 (0.031) 
0.201 (0.021) 
0.467 (0.367) 
 
32
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-982-9
ACHI 2022 : The Fifteenth International Conference on Advances in Computer-Human Interactions

of 1 degree or less, which accounts for 62.5% in total. A one-
way Analysis of Variance (ANOVA) revealed that there was 
not a statistically significant difference in mean accuracy 
score between at least five groups in distances (F(4, 35) = 
0.572, p = 0.685). The results for accuracies and precisions by 
angles are shown in Table II. The accuracy of the eye-gaze 
measurement tends to decrease as the viewing angle increases. 
ANOVA revealed that there was a statistically significant 
difference in mean accuracy score between at least four 
groups in angles (F(3, 28) = 3.379, p = 0.0321).  
C. 3D Eye-Gaze versus TrueDepth 
The TrueDepth of 3D eye-gaze is defined by the actual 
distance from the viewing point to the observer. As shown in 
Figure 3, the distribution of each subject's 3D eye-gaze 
increases with gazing distance. This trend was not observed 
from the accuracy of the 2D eye-gaze in Table I. However, 
this result is acceptable because, as mentioned earlier, 3D eye-
gaze measurement is less stable than 2D eye-gaze 
measurement because the eye-gaze is not completely still as 
we attempt to align our eye-gaze with the object. To further 
investigate the behavior of 3D eye-gaze in detail, we took the 
median values of all subjects' 3D eye-gaze for each viewing 
angle, as shown in Figure 4. The 3D eye-gaze to the centrally 
located visual targets increases linearly, whereas the rest of 
the eye-gaze shows logarithmic growth. Since the Vive Pro 
Eye uses a Fresnel lens, the estimated 3D eye-gaze results may 
be closer to the gazing subject as the viewing angle increases. 
However, since the scanpaths of the 3D eye-gaze obtained 
from dynamic visual cues measured in Kato & Prima (2021) 
also show such a curved trajectory [14], this phenomenon is 
still open for further study. 
 
 
Figure 3. Distribution of distance from 3D eye-gaze point to subject. 
Target Distance (cm)
Distance from the 3D Eye-Gaze Point to the Subject (cm)
 
Figure 4. Distribution of distance from 3D eye-gaze point to subject at each viewing angle. 
Viewing angle: 10
Viewing angle: 20
Viewing angle: 30
Target Distance (cm)
Target Distance (cm)
Target Distance (cm)
Distance from the 3D Eye-Gaze 
Point to the Subject (cm)
Center
Horizontal
Vertical
Left diagonal
Right diagonal
33
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-982-9
ACHI 2022 : The Fifteenth International Conference on Advances in Computer-Human Interactions

V. CONCLUSIONS 
This study evaluated the eye-gaze measurement capability 
of the Vive Pro Eye in terms of 3D eye-gaze measurement. 
Although this measurement was performed without 
triangulation and only by crossing the two extensions of the 
left and right eye-gaze raycasts, the resulting 3D eye-gaze 
point was found to be acceptable. The estimated distance from 
the 3D eye-gaze measurement point to the subject tends to be 
closer than the actual distance (TrueDepth). However, this can 
be corrected by using methods such as linear regression 
analysis. 
Small involuntary eye movements were found to affect the 
stability of the 3D eye-gaze measurement. The distribution of 
eye-gaze points was found to increase with gazing distance. 
We also found that 3D eye-gaze to a centrally located visual 
target increased linearly, while the rest of the eye-gaze 
increased logarithmically. 
From these findings, we can conclude that the Vive Pro 
Eye is capable of measuring 3D eye-gaze. However, users will 
need to construct their own measurement methods in order to 
reveal the accuracy and precision of the eye-gaze, although 
this type of library is commonly available in commercially 
available scientific eye trackers. 
 
REFERENCES 
[1] S. C. Mallam, S. Nazir, and S. K. Renganayagalu, “Rethinking 
maritime education, training, and operations in the digital era: 
Applications for emerging immersive technologies,” Journal of 
Marine Science and Engineering, 7(12), pp. 1–9, 2019. 
[2] F. Bellalouna, “New approach for industrial training using 
virtual reality technology,” Procedia CIRP, 93, pp. 262–267, 
2020 
[3] H. Ujiie et al., “Developing a virtual reality simulation system 
for preoperative planning of thoracoscopic thoracic surgery,” 
Journal of Thoracic Disease, 13(2), pp. 778–783, 2021. 
[4] P.Mohan, W. B. Goh, C. W . Fu, and S. K. Yeung, “DualGaze: 
Addressing the Midas Touch Problem in Gaze Mediated VR 
Interaction,” IEEE International Symposium on Mixed and 
Augmented Reality Adjunct (ISMAR-Adjunct 2018) , pp. 79–
84, 2018. 
[5] F. L. Luro and V. Sundstedt, “A comparative study of eye 
tracking and hand controller for aiming tasks in virtual reality,” 
Proceedings of the 11th ACM Symposium on Eye Tracking 
Research & Applications (ETRA '19), pp. 1–9, 2019. 
[6] L. Sidenmark, C. Clarke, X. Zhang, J. Phu, and H. Gellersen, 
“Outline Pursuits: Gaze-assisted Selection of Occluded 
Objects in Virtual Reality,” Conference on Human Factors in 
Computing Systems - Proceedings, pp. 1–13, 2020. 
[7] Y. Imaoka, A. Flury, and E. D. de Bruin , “Assessing Saccadic 
Eye Movements With Head-Mounted Display Virtual Reality 
Technology,” Frontiers in Psychiatry, 11(September), pp. 1–19, 
2020. 
[8] P. H. Yeh, C. H. Liu, M. H. Sun, S. C. Chi, and Y. S. Hwang, 
“To measure the amount of ocular deviation in strabismus 
patients with an eye-tracking virtual reality headset,” BMC 
Ophthalmology, 21(1), pp. 1–8, 2021. 
[9] M. Meißner, J. Pfeiffer, T. Pfeiffer, and H. Oppewal, 
“Combining virtual reality and mobile eye tracking to provide 
a naturalistic experimental environment for shopper research,” 
Journal of Business Research, 100(September), pp. 445–458, 
2019. 
[10] N. Stein et al., “A Comparison of Eye Tracking Latencies 
Among Several Commercial Head-Mounted Displays,” i-
Perception, 12(1), pp. 1–16, 2021. 
[11] Y. Imaoka, A.Flury, and E. D. de Bruin, “Assessing Saccadic 
Eye Movements With Head-Mounted Display Virtual Reality 
Technology,” Frontiers in Psychiatry, 11:572938, pp. 1–19, 
2020. 
[12] A. Sipatchin, S. Wahl, and K. Rifai, “Eye-Tracking for Clinical 
Ophthalmology with Virtual Reality (VR): A Case Study of the 
HTC Vive Pro Eye’s Usability,” Healhcare, 9, pp. 1-15, 2021. 
[13] J. Otero-Millan, S. L. Macknik, and S. Martinez-Conde, 
“Fixational Eye Movements  Binocular Vision,” Frontiers in 
Integrative Neuroscience, 8(52), pp. 1-10, 2014. 
[14] K. Kato and O. D. A. Prima, “3D Gaze on Stationary and 
Moving Visual Targets in Mixed Reality Environments,” 
International Journal on Advances in Life Sciences, 13(1&2), 
pp. 104-113, 2021. 
[15] C. Palmero, J. Selva, M. A. Bagheri, and S. Escalera, 
“Recurrent CNN for 3D Gaze Estimation Using Appearance 
and Shape Cues,” ArXiv, pp. 1-13, 2018. 
[16] M. Liu, Y. Li, and H. A. I. Liu, “3D Gaze Estimation for Head-
Mounted Eye Tracking System With Auto-Calibration 
Method,” in IEEE Access, 8, pp. 104207-104215, 2020. 
https://doi.org/10.1109/ACCESS.2020.2999633 
[17] A. Gibaldi and M. S. Banks, “Binocular eye movements are 
adapted to the natural environment,” Journal of Neuroscience, 
39(15), pp. 2877–2888, 2019. 
[18] C. Mestre, H. E. Bedell, F. Díaz-Doutón, J. Pujol, and J. 
Gautier, “Characteristics of saccades during the near point of 
convergence test,” Vision Research, 187, pp. 27–40, 2021. 
 
34
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-982-9
ACHI 2022 : The Fifteenth International Conference on Advances in Computer-Human Interactions

