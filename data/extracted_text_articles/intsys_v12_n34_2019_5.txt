Comparison of Single Image Processing Techniques and Their Combination for 
Detection of Weed in Lawns 
 
Lorena Parra (1), (2), Mar Parra (1), Virginia Torices (3), José Marín (3), Pedro V. Mauri (1), Jaime Lloret (2) 
(1) Instituto de Inv. para la Gestión Integrada de Zonas Costeras (IGIC), Universitat Politècnica de València (UPV). C/ 
Paranimf, 1, 46730 Grau de Gandia, Gandia 
(2) Instituto Madrileño de Investigación y Desarrollo Rural, Agrario y Alimentario (IMIDRA), Finca El Encin, Autovía 
del Noreste A-2, Km. 38.200, 28805 Alcalá de Henares, Madrid 
(3) Universidad Politécnica de Madrid. Escuela Técnica Superior de Ingeniería Agronómica, Alimentaria y de 
Biosistemas. Av. Puerta de Hierro, 2, 28040 Madrid 
Email: loparbo@doctor.upv.es, maparbo@epsg.upv.es, virtorices@gmail.com, jmarin@areaverde.es, 
pedro.mauri@madrid.org, jlloret@dcom.upv.es  
 
Abstract— The detection of weeds in lawns is important due to 
the different negative effects of its presence. Those effects 
include a lack of uniformity and competition for the resources. 
If the weeds are detected early the phytosanitary treatment, 
which includes the use of toxic substances, will be more effective 
and will be applied to a smaller surface. In this paper, we 
propose the use of image processing techniques for weed 
detection in urban lawns. The proposed methodology is based 
on simple techniques in order to ensure that they can be applied 
in-situ. We propose two techniques, one of them is based on the 
mathematical combination of the red, green and blue bands of 
an image. In this case, two mathematical operations are 
proposed to detect the presence of weeds, according to the 
different colorations of plants. On the other hand, we proposed 
the use of edge detection techniques to differentiate the surface 
covered by grass from the surface covered by weeds. In this case, 
we compared 12 different filters and their combinations. The 
best results were obtained with the Laplacian filter. Moreover, 
we proposed to use pre-processing and post-processing 
operations to remove the soil and to aggregate the data with the 
aim of reducing the number of false positives. Finally, we 
compared both methods and their combination. Our results 
show that both methods are promising, and its combination 
reduces the number of false positives (0 false positives in the 4 
evaluated images) ensuring the detection of all weeds. 
Keywords- Grass lawns; weeds; image processing; RGB 
bands; edge detection; drone. 
I. 
 INTRODUCTION  
In order to maintain a great appearance in grass surfaces, 
certain requirements need to be addressed. The use of 
technology can help in its monitoring [1]. Due to the activities 
that are carried out on the grass or around it, the grass suffers 
from compaction and the leaves are broken. Some of the 
activities performed on the lawns in residential areas or in 
public gardens are certain sports, entertainment, and 
enjoyment. The users of the lawns demand a series of 
requisites, being the most important one the visual aspect of 
the lawns. The visual aspect can be expressed as the 
uniformity of the lawn, the greenness of the grass and the 
absence of grass patches. Moreover, the lawns should be 
maintained with a low level of inputs [2]. 
The existence of weeds in the lawn is a problem. On the 
one hand, the weed presence implies a lack of uniformity on 
the surface. This lack of uniformity is the first cause of 
disappointment for users. On the other hand, the weeds will 
generate competition between them and the grass species. For 
this reason, it is necessary to carry out specific actions to solve 
the weed problem as soon as possible. Despite the fact many 
studies showed the benefits of spontaneous plants in the urban 
lawns, users still prefer the uniformity of the grass [3-5].  
It is crucial to detect the appearance of weed during the 
first days. Otherwise, the weed can infest huge areas of the 
lawn, and it will be difficult to eradicate them. Nowadays, the 
best available techniques to detect weeds are aerial images or 
the visual inspection of the lawns. The first option, the use of 
satellite images, offers multispectral images. Nonetheless, 
they have small spatial resolution and small temporal 
resolution. Thus, when we detect the weeds with the satellite 
image it may be too late and it would be necessary to apply 
the phytosanitary treatment to a large area. The second option, 
the visual inspection, is useful for small areas like a private 
garden. Nevertheless, for big areas like golf courses or big 
public gardens, this solution is not applicable. Therefore, the 
use of images obtained with drones and their analysis can be 
a solution for large surfaces [1]. The use of image processing 
is widely used in many different areas and for countless 
purposes. In agriculture, it has been used for illness detection 
[6] and for fruit maturity evaluation [7]. In aquaculture, it has 
been used for feed falling detection [8]. Moreover, it is used 
for face detection [9] and car license plate identification [10]. 
The aim of this paper is to present the use of image 
processing techniques for detecting the presence of weeds in 
lawns, which will be part of a system for garden monitoring 
described previously in [11]. Thus, a series of images were 
obtained from different lawns with the presence and absence 
of weed. The images were taken under different solar 
conditions. Different grass species and different weed species 
appear in the images. Part of the images will be used to 
evaluate the different techniques and methods included in our 
system and the rest of them to verify our findings. Two 
methodologies are tested, the Red-Green-Blue (RGB) band 
combination (or RGB methodology) and the edge detection 
filters. The goal is to use this methodology to automatize the 
177
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

monitoring of lawns in terms of weed detection. Therefore, it 
will be possible to detect the weed and apply the phytosanitary 
products only in the affected area. The operation of applying 
the phytosanitary product is not the focus of this paper. First, 
we test each methodology, including pre-processing to 
remove the soil from the analysis and post-processing to 
minimize the number of False Positives (FP). Then, we 
compare the results of both techniques and their combination.  
The rest of this paper is organized as follows. Section II 
presents the related work. Section III describes the proposal. 
The methods, band combination and edge detection are 
described in Section IV. Section V addresses the obtained 
results of each separated methodology and its combination. 
Section VI summarizes the conclusions and future works.  
II. 
RELATED WORK 
In this section, we are going to compare other techniques 
utilized to detect weed in different crops. 
The detection of weeds is an important issue for 
agriculture. Therefore, many scientists have been working on 
their identification based on images. The use of drones has 
increased the possibilities, and in recent years several papers 
have been published.  
The use of image processing to determine the presence of 
weeds in maize fields was presented by Burgos-Artizzu et al. 
in 2011 [12]. They described a computer vision system that 
can be used with videos. They tested their system under 
different light conditions. The system detected 95% of the 
weeds and 80% of the crops.  
Paikekari et al. presented in 2016 [13] an image processing 
methodology for weed detection. First, they used color to 
differentiate soil and grass. Then, the resultant image was 
converted into a greyscale image to apply an edge detection 
technique. Finally, the resultant image of edge detection was 
divided into 25 blocks. The analysis of each block determined 
if it contained weed with narrow leaves, weed with wide 
leaves, or crop.  
In 2018, Gao et al. [14] presented the use of aerial images 
with an ultra-high-resolution to detect intra and inter-row 
weed. They used a semi-automatic object-based image 
analysis with random forests. In addition, they used 
techniques to classify soil, weed, and crop. The authors 
applied this proposal to maize crop fields. The utilized images 
show the maize in the first days of growth. Their results have 
a coefficient of correlation of 0.895 and a mean squared error 
of 0.026.  
Marín et al. in 2017 applied simple image processing 
techniques in different publications to detect the grass 
coverage in lawns [15][16]. They worked with the histograms 
of the grass images to determine the weight of the grass and 
the level of coverage (high, low, very low).  
On the other hand, there are other types of studies focused 
on identifying different leaf affections. One example is the 
work developed by Khanaa and Thooyamani in 2017 [17]. 
They proposed an algorithm based on image processing. Their 
algorithm was able to detect different leaf diseases, such as 
bacterial pith necrosis, early blight, white trail, and target spot 
among others. 
Finally, Parra et al. in 2019 [1] showed the use of a new 
form of weed detection based on photographs taken from 
drones. In their article, they used the combination of pixel 
values in the three bands (RGB) to differentiate different types 
of surfaces (soil, grass, and weeds). Their results were 
promising and offer different types of formulas depending on 
the needs with different percentages of false positives (FP) and 
false negatives (FN). 
III. 
PROPOSAL 
In this section, we are going to detail the proposed system 
for lawn monitoring. The system is composed of a drone that 
flies over the lawn and takes photos. Then, the images are 
evaluated to determine where there are weeds in the lawn to 
program the application of phytosanitary products.  
A. Drone 
Our system uses a drone to take images of the lawn. Since 
we need a spatial resolution of 1mm we should select a drone 
with a camera that has a high spatial resolution and flies at 
high height altitude. Nevertheless, we can select a drone with 
a camera that presents lower spatial resolution and flies at a 
lower height. In order to calculate the flying height according 
to the camera resolution, we can use the equations proposed 
by Marin et al. [16]. We are going to use an Arduino camera 
with 640X480 pixels, and the flying height will be 2.3m.  
It is important to note that for our proposal we are going 
to use a drone with no camera. We will add the above-
mentioned camera connected to a Raspberry Pi 3 node. The 
Raspberry Pi 3 node will be in charge of taking images and 
analyzing them. Nonetheless, the flying issues will be 
operated by the drone processor, not by the Raspberry Pi 3 
node. Thus, we can split the task into different processors and 
our system can be adaptive to different situations.  
B. Operational principle 
Once the images will be gathered by the camera installed 
on the drone, the same node will analyze them. We need a fast 
analysis because the processor should analyze the data during 
the flight in order to trigger the sprinklers of the phytosanitary 
products. Thus, it is necessary to focus on simple image 
processing techniques and use a node with high processing 
capacity. Therefore, we propose to use a Raspberry 3 to 
analyze the data.  
Furthermore, we reduce our possibilities to the operations 
that involve only the RGB data of each pixel in the image. 
Therefore, we will avoid image recognition techniques. This 
type of technique, image recognition, offers accurate results. 
Nonetheless, they require higher processing capabilities and 
internet connection in some cases. On the other hand, the 
methods that use only the pixel values are common when we 
work with satellite images, which are multispectral images.  
Our challenge is to detect weeds in the lawns with the 
combination of only three image bands, red, green and blue 
(RGB). We can use two different options for detecting the 
weeds, the first option is the mathematical combination of the 
pixel values of the bands. Thus, operating with the pixel 
values of the RGB bands we can obtain a new image 
composed of pixels, whose values are a linear combination of 
178
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

the previous bands. Due to the fact that the soil, grass, and 
wild species have different coloration, this is a feasible option 
to differentiate the three surfaces.  
The second option is to use a combination of the pixel 
value and their neighbors from a single band. There are 
several techniques that use this method and are known as edge 
detection. It is important to note that the edge detection 
techniques are applied to one of the RGB bands. Therefore, 
they work with images in black and white. Edge detection 
techniques include different mathematical methods aimed to 
identify points in an image at which the brightness changes 
sharply. Since the aspect of grass and wild species are 
different, they will generate different patterns of brightness 
changes. The grass is composed of small and sharp leaves 
while most of the wild species have wide leaves. Therefore, 
the areas covered by grass will present more changes than the 
areas covered by wild species.  
The proposed system is shown in Figure 1, we can see the 
different bands obtained and their names. The red, green and 
blue bands of the image are also known as band 1, band 2 and 
band 3.  
C. Studied lawns 
The proposed system was tested in Finca El Encin, 
research facilities of the Instituto Madrileño de Investigación 
y Desarrollo Rural, Agrario y Alimentario (IMIDRA) in 
Spain. There are small experimental plots where other 
scientists are testing multiple grass combinations. During their 
research, different weeds appear in their lawns. We use their 
experimental plots to take images of different types of lawns 
with and without the presence of weeds.  
By using these experimental plots, we ensure that we will 
have lawns with different types of grass and under different 
environmental conditions. The plots used in the first step can 
be seen in Figure 2. 
In order to have verification, other images were taken in a 
different scenario. These images were gathered in Gandia, 
Valencia (Spain) in the gardens of Universitat Politécnica de 
Valencia (UPV). We intend to have a combination of images 
with and without the presence of grasses to test the system 
performance in terms of FP, FN, true negatives (TN) and true 
positives (TP). 
 
Figure 1.  System description. 
 
Figure 2.  Lawns image 
 
Combination
Band 3
Band 2
Band 1
New Image
179
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Moreover, we include images with different illumination 
conditions and with shadow areas to evaluate the possible 
negative effects. The characteristics of the used cameras are 
summarized in Table I. 
IV. 
METHODOLOGY 
In this section, the methodology for the image analyses is 
described. First, we describe the operations applied before the 
use of the proposed techniques, also known as pre-processing. 
Following, the technique of RGB combination is described. 
Subsequently, the edge detection techniques are detailed. 
Finally, post-processing is established.  
A. Image pre-processing 
In this subsection, the steps for image pre-processing are 
described in detail. The first step is the clipping of the image. 
The aim of this step is to ensure that all the pixels of the image 
are representing grass. This step is only used in the tests for 
evaluating the techniques. In the used images there are some 
external objects like architectonic elements (streets, park 
benches, and tarpaulins). Once the techniques are used in the 
real system, the gathered images will be only taken in the grass 
area of the garden and no other architectonic elements will 
appear. Therefore, this step is performed manually.  
The next step is to extract from the image the areas 
covered by dead grass or soil (areas of the garden without 
grass coverage). The objective is to avoid FP in the areas of 
soil. This is especially important in the case of edge detection. 
For this purpose, we are going to use the linear combination 
of RGB values of the pixels to differentiate the areas covered 
by healthy grass from the areas covered by soil or dead grass.  
As a result, we will obtain an image that solely contains 
the areas covered by healthy plants (grass or weed species). 
Now, the obtained image is ready for being processed.  
B. Image processing: RGB combination 
In this subsection, the details of the RGB combination for 
detecting the presence of weeds are described.  
The first issue to be considered is that it is not possible to 
work with threshold values of only one of the layers. Because 
these values are greatly affected by sun exposure, the presence 
of clouds, and even the day of the year. Thus, we need to work 
with a mathematical combination of different bands to avoid 
this problem.  
The second issue is related to the values of the pixels. Each 
pixel has a value between 0 and 255 in each one of the bands. 
The value is directly related to the brightness of the pixels. 
The pixels with higher values are represented in lighter colors. 
Meanwhile, the pixels with low values are displayed in darker 
colors. The areas with green color will have high values in the 
bands of green and lower values in the blue and red bands.  
The value of the pixel has no decimals and can only have 
a positive value. When we are applying the mathematical 
combinations, these rules are maintained. The resultant value 
of each pixel will be a positive value with no decimals. When 
mathematical operations are used, the maximum value can 
exceed the value of 255.  
The objective of this step is to obtain a new image where 
the values of pixels belonging to grass coverage are different 
from the values of pixels belonging to weed coverage. 
Therefore, we will explore the differences in the values of 
weed and grass in each band and find a simple mathematical 
expression that maximizes these differences in the resultant 
bitmap image. We will use different mathematical 
combinations of the bands to obtain a new image with low 
values in the areas covered by grass and high values in the 
areas covered by weeds.  
C. Image processing: Edge detection 
In this subsection, the information of the edge detection 
methodologies is described. There are many techniques for 
edge detection and we are going to describe the basics of the 
used ones. 
All the used filters can be used individually, but some of 
them offer better results when they are combined. For 
example, the gradient filters or the line detection filters. In this 
case, the four available filters are used individually. Then, the 
resultant image of each filter is combined (by adding the 
values of the individual images) having, as a result, a new 
image. 
The most important thing to know is the fact that these 
tools help us find the points of the photograph where there is 
a change in pixel values. Generally, these zones represent the 
edges of an object or, in our case, of a leaf. To detect this 
change, a mathematical operation is performed with the value 
of the pixel and its closest pixel, called neighbors. The 
operation to be performed will depend on the specific tool, or 
filter, used. Most of them use the value of that pixel (PI) and 
its 8 nearest neighbors (N1, N2, ..., N8) for the calculation of 
the new value assigned to this pixel, forming a 3x3 matrix, as 
can be seen in Figure 3. 
  
 
TABLE I.  
CHARACTERISTICS OF UTILIZED CAMERAS 
Characteristics 
Images in IMIDRA 
Images in Gandía 
Size of the image 
2048x1536 pixels 
4032x3024 pixels 
Horizontal and vertical resolution   
72 ppp 
72 ppp 
Bit Depth 
24 
24 
F point 
f/7.1 
f/1.7 
Focal distance 
5mm 
4mm 
Exposure time 
1/400 s 
1/100 s 
ISO Velocity 
ISO - 125 
ISO - 80 
180
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
 
Figure 3.  Use of filters in the image
Whichever filter is used, the result will be a new image in 
black and white where pixels that are not edges will have very 
low values, close to 0. Meanwhile, pixels that represent a zone 
of change, which is an edge, will have high values. There is 
no maximum value, the values will be higher or lower 
depending on the filter used. Our goal will be to find the areas 
of the image that have very low values. In the images taken, 
the areas covered by grass have numerous edges, while the 
areas where there are weeds are areas with greater uniformity 
in the pixels. Therefore, the areas with low values after the 
application of filters will represent the areas with weeds. 
Following, we detail the filters that have been used in this 
study.  
First, there are the edge detection filters, among which we 
find: the gradient filters, Laplacian filter, line detection filters, 
and Sobel filter. There are other edge detection filters but 
those are the ones we are going to use in the study.  
Gradient filters are the best when we want to detect edges 
in increments of 45º. Based on this type of filter we find the 
north, east, south, and west gradient filters.  
Secondly, we will use the Laplacian type filters. We will 
use only one of the variants, the one which uses a 3x3 matrix. 
This filter is useful for detecting edges, whatever the 
orientation of the edge. The Laplacian filter is recommended 
for the enhancement of linear features, especially in urban 
environments.  
The next filter used is the line detection filter, very similar 
to the gradient filter. There are four variants of this filter, 
according to the direction in which the edges are highlighted, 
vertical line, horizontal line, left diagonal line and right 
diagonal line.  
The last type of edge detection filter is the Sobel filter. 
Since the matrices used by these filters are identical to some 
used in gradient filters, Sobel filters are not included. All edge 
detection filters use a 3x3 matrix as can be seen in Figure 4. 
On the other side, there are the sharpening and smoothing 
filters. In our case, we will use only those of sharpening. The 
smoothing filters will be used later on for other purposes. The 
sharpening filters are recommended to be used so as to 
highlight the comparative difference of values with their 
neighbors. They allow us to enhance the boundaries between 
objects in the photographs. In this case, and despite the 
existence of other filters in our study, we have included only 
three of them: two filters that use a 3x3 matrix and a 5x5 
matrix, which can be seen in Figure 5. 
D. Post-processing 
Finally, to ensure the selected areas belong to wide leaves 
of weeds and minimize the FP, we apply an aggregation 
technique. These techniques are described in this subsection. 
Aggregation techniques allow, first of all, the combination 
of the value of a pixel and its neighbors, resulting in a new 
pixel; and secondly, increasing the size of the new pixel. The 
value of the new pixel, as well as its size compared to the 
previous pixels, will depend on the technique we use. There 
are different types of aggregation techniques. We can use 
different types of mathematical operators, such as maximum, 
minimum, median, mean, or even summation. Then, the size 
of the cell must be defined. The bigger the cell is, the higher 
the number of pixels will be used for the mathematical 
operator. Thus, the resultant pixels will be bigger than if we 
select a small cell.  
In the case of the RGB combination, the objective is to 
find a group of pixels with high values and avoid FP due to an 
isolated pixel with high value. Those isolated pixels with 
different values are generally related to light sparkles in the 
leaves of grass or due to errors in the image. As this type of 
pixels usually appears isolated, the possibles FPs are easily 
corrected with the aggregation technique, since their 
neighbors have regular values (belonging to grass or to 
weeds). Therefore, to detect the presence of a group of pixels 
with high value we will use as aggregation technique the 
mathematical operator of minimum, mean and median. Thus, 
if an isolated pixel has a high value (without belonging to 
weeds), once the mathematical operation is performed the 
resultant value will be lower due to the low values of its 
neighbors. However, when a group of pixels (belonging to 
weed leaves) have a high value, when the mathematical 
Image RGB
N1,  N2,  N3
N4,   PI,   N5
N6,  N7,  N8
Filter (Matrix)
Black and White Images (Bands)
Blue
Green
Red
Black and White 
Image with the 
edge detection
181
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

operation is done the resultant pixel will have a high value. 
We will test as aggregation cell value the sizes of 3, 5 and 10.  
In the case of edge detection, we seek to identify areas that 
have a group of pixels with low values. Thus, we will use the 
sum of all the pixels and the maximum value of the included 
pixels as an operation to calculate the value of the new pixel. 
As for the resulting pixel size, or cell size, we use the values 
of 3, 5 and 10. 
With the obtained image from the aggregation technique, 
threshold values must be taken to differentiate the pixels we 
consider positive (weeds) and negative (grass). There are 
different techniques to do it. In previous papers, the one which 
has shown a better result in changing lighting conditions has 
been the creation of classes based on statistical parameters. 
This option offered better results than taking a threshold value 
and applying them to all cases as was done in [10]. 
To sum up the whole process we have created a block 
diagram that represents all the steps carried out in this paper. 
The part of pre-processing is not included. The flow is 
presented in Figure 6. 
 
 
Figure 4.  Used edge detection filters 
 
Figure 5.  Used sharpening filters 
 
 
 
Figure 6.  Block diagram of the followed steps 
 
-1,
-2,
-1,
0,
0,
0,
1,
2,
1,
1,
0,
-1,
2,
0,
-2,
1,
0,
-1,
1,
2,
1,
0,
0,
0,
-1,
-2,
-1,
-1,
0,
1,
-2,
0,
2,
-1,
0,
1,
Gradiente norte
Gradiente este
Gradiente sur
Gradiente oeste
0,
-1,
0,
-1,
4,
-1,
0,
-1,
0,
-1,
-1,
-1,
2,
2,
2,
-1,
-1,
-1,
-1,
2,
-1,
-1,
2,
-1,
-1,
2,
-1,
-1,
-1,
2,
-1,
2,
-1,
2,
-1,
-1,
Laplaciano
Línea horizontal             Línea vertical    Línea diagonal derecha
2,
-1,
-1,
-1,
2,
-1,
-1,
-1,
2,
Línea diagonal izquierda
Laplacian
Vertical Line          Horizontal Line       Left Diagonal Line   
Right Diagonal Line   
North Gradient
East Gradient
South Gradient
West Gradient
-0,25,
-0,25,
-0,25,
-0,25,
3,
-0,25,
-0,25,
-0,25,
-0,25,
-1,
-1,
-1,
-1,
9,
-1,
-1,
-1,
-1,
Aumentar Nitidez
Nitidez 3x3                         Nitidez 5x5
-1,
-3,
-4,
-3,
-1,
-3,
0,
6,
0,
-3,
-4,
6,
21,
6,
-4,
-3,
0,
6,
0,
-3,
-1,
-3,
-4,
-3,
-1,
Increase Sharpness              Sharpness [3x3]               Sharpness [5x5]
Aggregation 
techniques
(Smoothing)
Obtaining the bands
Using the individual methods
Image RGB
Filter (Matrix)
Bands
Blue
Green
Red
Imagen B/N 
con los bordes
Combination of bands
New Image
Equation
Classifying
Combination
Final result
Positives (weeds)=Color
?
?
?
?
N1,  N2,  N3
N4,   PI,   N5
N6,  N7,  N8
Black and White 
Image with the 
edge detection
182
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

To evaluate the performance of the proposed methodology 
we will use the following parameters: (i) FN: we will consider 
how many weeds have not been indicated by any pixel after 
the analysis. (ii) FP: will be given as the total pixels that, 
according to the methodology used, indicate the presence of 
weeds although it is grass. (iii) TP: will be considered as the 
number of weeds that are indicated by one or more pixels. 
V. 
RESULTS 
In this section, we are going to show the obtained images 
and its processing to determine the presence or absence of 
weeds. First, we show the process to obtain the equations to 
detect the weed. Finally, we will present its verification.  
A. Image pre-processing: soil removal 
The image processing method is shown in this subsection. 
First, Figure 7 presents the RGB images in four different 
cases. The first one is a lawn with low grass coverage and with 
the presence of weeds at the top-center part. The weed has a 
darker coloration than the grass. Furthermore, it presents 
higher relative values in the blue band, compared with the rest 
of the grass. Image 2 is taken in a lawn with high grass 
coverage. There is a weed at the bottom-left of the image. As 
in the previous case, the weed has a more bluish coloration. 
In Image 3, we can see a lawn with low grass coverage and 
with the presence of the weed in the bottom-right of the image. 
In this case, the weed has a more yellowish coloration, 
compared with the grass. Finally, Image 4 represents typical 
lawns with no weeds; but, under light water stress. Thus, there 
are some parts of the grass that have a yellowish coloration 
due to the lack of water.  
The first issue that we can pay attention to is the fact that 
the soil has higher values of brightness in the red band than in 
the green band. Therefore, considering that the values of the 
pixels only can be positive and without decimals, we divide 
the green band by the red band obtaining a new image, which 
gives us information about the soil/plant coverage, see (1). 
The result of this mathematical relation between bands can be 
seen in Figure 6. The grass pixels have values higher than zero 
and are colored in green. The soil pixels have values of zero 
and are colored in yellow. Unfortunately, the portions of grass 
that have suffered from stress or have been strongly 
compacted, present a similar coloration than the soil. 
Consequently, those portions might be classified as soil. For 
our application, it is not a problem, because the important part 
for us is the green grass and green weeds.  
               (1) 
B. Image processing: weed recognition with RGB 
combination 
The next step is to find a mathematical relation, which 
gives, as a result, a new image with different values for pixels 
of grass and pixels of weed.  
We have two different types of weed, the ones with more 
bluish color, and the ones with more yellowish color than the 
grass. Consequently, we will need two different equations to 
detect the presence of weeds. One equation for the bluish 
weed, the ones which appear in RGB Image 1 and RGB Image 
2 of Figure 7. Another equation for yellowish weed, like the 
one which appears in RGB Image 3 of Figure 7, will be 
needed. The first equation, (2), will be used to detect the bluish 
weed. This resultant image after applying (2) will have high 
pixel values where there is a bluish weed. Thus, the equation 
has to maximize the data of pixels with higher relative blue 
values. Then, the data from the blue band should be divided 
by the data from the red and green bands. Since the dividend 
of the equation (blue brightness value of the pixel) has lower 
values than the divisor (green x red brightness values of 
pixels), and the pixels can only be a natural number, almost 
all the pixels have a value of zero.  
Thus, no differences were found. In order to increase the 
value of the dividend, we square it. Nevertheless, the value of 
the dividend is still lower than the value of the divisor in the 
majority of the cases and most of the pixels have a value of 
zero in the resultant image. Finally, we cube the divisor. Then, 
we obtain a new image with different values for different 
coverage surfaces. The obtained image combination that is 
used to detect bluish weeds can be seen in (2). 
On the other hand, we have an image with yellowish 
weeds. To detect them we should use the opposite steps than 
in the preceding paragraph, we have to use the data from green 
and red bands for the dividend and the data from the blue band 
for the divisor. As in this case, the values of the dividend are 
always higher than the values of the divisor, it is not necessary 
to neither square nor cube any of them. Therefore, the 
proposed formula, which can be used to detect the yellowish 
weed, is given by (3).  
 
Image nº 
1 
2 
3 
4 
RGB 
image 
 
 
 
 
Soil/Grass 
Coverage 
 
 
 
 
Figure 7.  Images utilized to obtain equations for weed detection 
𝑆𝑜𝑖𝑙 𝑟𝑒𝑚𝑜𝑣𝑎𝑙 = 𝐵𝑎𝑛𝑑 2 𝐵𝑎𝑛𝑑 1
 
 
183
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

    
                    (2) 
   
                     (3) 
The result of applying (2) and (3) to the RGB images of 
Figure 7 can be seen in Figure 8. We apply both formulas to 
all of the images to show the effectiveness of each formula for 
generating a new image that contains information about weed 
presence. The different colors represent different values in the 
image. The pixels with yellow tones have lower pixel values. 
On the contrary, the pixels with purple and blue colors have 
the highest values. In the RGB image, the presence of weed 
and its position are indicated with red circles. 
As it is expected, the pixels that contain bluish weeds 
(RGB Image 1 and RGB Image 2 in Figure 8), present higher 
values in the resultant image after applying (2) than the pixels 
that contain grass or soil. The pixels of the resultant image that 
have higher brightness values are represented in purple and 
blue colors. Meanwhile, the pixels with low brightness values 
are colored in yellow and light yellow. We can see that Image 
1 and the resultant image of (2) present higher pixel values, 
colored in blue, in the area where there are weeds. The 
resultant image of (3) presents higher values in the pixels that 
represent one of the grass species in Image 1. In Image 2, there 
is no specific area that contains pixels with high values.  
For Image 3, we can see that the pixels of the image 
obtained with (2), which have the highest values, are not 
related to the presence of weeds. However, in the image 
obtained with (3), we can clearly identify the presence of the 
weed. We can see that one of the grass species present in the 
lawn of Image 3 is giving high values (red color). But the 
purple and blue colors are only related to the weed presence.  
Finally, the resultant image of the image from the lawns 
without weed does not present any areas with high values. In 
the case of the resultant image of (2), there are some pixels 
with high values. Nevertheless, they appear scattered around 
the image, not joined in one area as in the other cases. 
Meanwhile, in the image of (3) almost all the pixels present 
low values and few pixels have high values. 
As the higher values indicate the presence of weeds, to 
evaluate the aggregation technique we are only going to 
consider the pixels with the highest values. We will use the 
natural breaks, jenks, to divide the pixels into 5 groups and 
only the last group will indicate the presence of weeds. 
One of the major advantages of the proposed system is that 
its results should not be affected by changes in solar 
exposition. Thus, we are going to test the aggregation 
technique with images gathered at another time period with 
different environmental conditions. Moreover, we are going 
to evaluate the use of a smoothing technique to reduce FP. 
The used images and the results of the analysis of the 
aggregation technique can be seen in Figure 9. Again, the 
position of weed is marked with a red circle in the RGB image. 
Image 5 of Figure 9 was gathered on a sunny day and 
represents a lawn with low grass coverage, with two types of 
soil (light and dark brown), and with the presence of a lot of 
weeds. Some of the weeds of Image 5 of Figure 9 are a bluish 
weed, then, the results are after applying (2). Image 6 of 
Figure 9 was taken on a day with less solar radiation. The 
image represents a lawn with some grass patches and the 
presence of yellowish weed at the bottom of the image. 
Therefore, the verification is done with (3). Finally, Image 7 
of Figure 9 represents a lawn with regular grass coverage on a 
cloudy day. In Image 7 of Figure 9, no weeds are present, the 
results are obtained with (2). We select (2) because it is the 
one that gives more FP in the previous test. The results with 
the cell value of 10 have not been presented, because they 
were not representative. We are going to present the results of 
a cell value of 5.  
 
Image nº 
1 
2 
3 
4 
RGB image 
 
 
 
 
Result of 
apply (2) 
 
 
 
 
Result of 
apply (3) 
 
 
 
 
Figure 8.  Images Obtained After Apply The Formulas Of (2) and (3) For Weed Detection 
 
𝑊𝑒𝑒𝑑 =  𝐵𝑎𝑛𝑑 33
 𝐵𝑎𝑛𝑑 2 × 𝐵𝑎𝑛𝑑 1
  ×  𝐵𝑎𝑛𝑑 2 𝐵𝑎𝑛𝑑 1
 
  
𝑊𝑒𝑒𝑑 =  𝐵𝑎𝑛𝑑 2 × 𝐵𝑎𝑛𝑑 1 𝐵𝑎𝑛𝑑 3
 
  ×  𝐵𝑎𝑛𝑑 2 𝐵𝑎𝑛𝑑 1
 
  
184
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Image nº 
5 
6 
7 
RGB 
image 
 
 
 
 
 
Aggregate 
data: 
Cell size 5 
Aggregation 
type: 
Mean 
 
 
 
 
Aggregate 
data: 
Cell size 5 
Aggregation 
type: 
Median 
 
 
 
 
Aggregate 
data: 
Cell size 5 
Aggregation 
type: 
Minimum 
 
 
 
 
Figure 9.  Original images and obtained images in the verification process 
First, we present the results of the aggregation technique, 
which uses the mean as a result. This technique is quite 
accurate in terms of identifying the leaves of the weeds. 
However, there are still some FP, which identify as a weed 
normal grass leaves, FP= 12, >40 and 22 in Images 5, 6 and 7. 
The FPs are more visible in the case of Image 7, where there 
was no weed. The number of FN is very low, FN= 1, 0 and 0 
in Images 5 to 7. Finally, the number of TP is considerably 
high compared with the FN, TP= 5 out of 6, 4 out of 4 and 0 
out of 0 in Images 5 to 7.  
The results of using an aggregation technique with the 
median have less FP (FP=9, 11 and 21 in Images 5 to 7). In 
terms of FN and TP, the results of using the median value are 
the same as those of using the mean value. 
Finally, if we use the minimum as a mathematical 
operator, the results show that FP=0 in all the images. 
Nevertheless, by utilizing this technique we have some FN 
(FN=3, 1 and 0 in Image 5, Image 6, and Image 7 of Figure 
8). 
Thus, depending on the application and the produced 
effects on the case of FP and FN, we can use one aggregation 
technique or other. For our application, since the objective is 
to maximize the grass quality by minimizing the phytosanitary 
products usage, we prefer to have FP than FN. Therefore, we 
propose to use the aggregation technique that uses the median 
as a result.  
185
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

C. Image processing: weed recognition with edge detection  
The results of applying the filters described in Figures 4 
and 5 are detailed in these paragraphs. To set-up of the system 
we have used different images, see Figure 10. The images 
were taken at the same height, some of them represent gardens 
with grass. Furthermore, we include an image, Image 4 in 
Figure 8 and Figure 10, which contains grass and weeds. 
 
Image with weeds (Image 1 in Figure 9) 
Images without weeds(Image 4 in Figure 9) 
Method 
Resultant image  
Weed detection   
Resultant image  
Weed detection   
 
 
A)  
B) 
C)  
D)  
Figure 10.  Image obtained after edge detection filters 
186
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

We analyze the effectiveness of each filter presented in the 
previous section and the best results are shown. First, the best 
aggregation technique for all cases has been the sum with a 
cell size equal to 5. It has also been observed that there are no 
differences in the results when the filters are applied to the 
different bands (RGB) of the image. Therefore, the results 
shown in this section correspond to the use of the filters in the 
red band. The presence of weeds in Figure 10 is indicated with 
yellow circles.  
Gradient filters, when used individually, have given very 
bad results. Despite applying aggregation techniques, the 
results did not clearly indicate the presence of weeds. 
However, when all the gradient filters are used together (each 
one applied separately and adding the 4 images obtained), the 
results markedly improve, see Figure 10 method A. The same 
behavior has been found with the line detection filters, by 
adding the images from the individual filters the results 
improve considerably (Figure 10 Method B).  
In both cases, the presence of dicotyledonous weeds has 
been detected. In the case of the line detection filter, a 
monocotyledonous weed has been detected in the image with 
weeds (TPs = 4 in both cases). Conversely, in both cases, two 
of the weeds have not been detected, FNs = 2. Therefore, we 
have FNs, which would cause the non-detection of a wild 
plant. There is no case FP in the image with weeds. Regarding 
the image without weeds, both filters give a considerably high 
number of FPs, 20 with method A and 24 with method B. 
In relation to the Laplacian filter (Method C in Figure 10), 
it has offered very good results without the need to be 
combined with other filters. Laplacian filter is the one that 
generates less FP when there are no weeds, FP = 2. In the case 
of the image with weeds, the results are equal to the previous 
filters, it has detected 4 out of the 6 plants, TP = 4 FN = 2. 
Finally, the sum of the gradient filters plus the line 
detection filters has a great capacity to detect weeds (Figure 
10 Method D). In the photograph with weeds, it is able to 
detect the presence of all of them, therefore it results in TP = 
6. However, in this photograph, the combination of filters 
indicates the presence of weeds where there is no weed in two 
cases, FP=2, both of them located in shadow areas. On the 
other hand, its result in photographs without wild plants shows 
that it is the worst option with a total of 39 FP. 
The sharpening filters have not given good results in any 
case, they give a high amount of FP and the TP are not as high 
as for the edge detection filters. Therefore, these filters have 
been excluded from the analysis. 
It is necessary to consider that up to this point we have 
worked with the option of classifying the resulting images 
according to the standard deviation of the image data. 
However, it has been observed that in this case, the use of a 
threshold value would be more appropriate. In Table II we 
present the minimum and maximum values of the class that is 
considered positive in Image 1 and Image 4 of Figure 10. 
Therefore, we could propose a threshold value depending on 
the method like the maximum value of pixels characterized as 
a weed in the image with weeds and minimum value of pixels 
characterized as a weed in an image without weed. The 
following thresholds 75, 100, 18, and 100 are proposed for 
methods A to D. However, we need to compare the use of 
threshold values with the standard deviation to classify the 
pixel values when the light conditions change. 
As the methodology that has given the best is C, Laplacian 
filter, we will check the results when using the threshold value 
proposed with the previous photographs to other new 
photographs obtained in Gandía. 3 out of 4 images have been 
taken in conditions of light similar to the photographs of the 
previous test (in IMIDRA) and the last one has been taken in 
conditions of lower light. Images 1, 2 and 4 have weeds, and 
Image 3 does not. 
TABLE II.  
MAXIMUM AND MINIMUM VALUES OF PIXELS 
CHARACTERIZED AS WEED  
Type of image 
Values 
Method 
A) 
B) 
C) 
D) 
Image without weeds 
Minimum  
96 
138 
19 
187 
Maximum  
147 
214 
26 
357 
Image with weeds 
Minimum  
0 
36 
10 
36 
Maximum  
67 
90 
19 
79 
 
In Table III we can see the results of the comparison of 
different classification options. In lighting conditions similar 
to the photographs used to obtain the threshold values, the use 
of the threshold value improves the results. The amount of FP 
is reduced in all cases by using the threshold value. The 
amount of FN has increased in one of the cases, this fact is not 
as worrying as the FP. We must consider that a FN in an image 
where the presence of weeds has already been detected has no 
repercussion since this area will be treated with the 
phytosanitary anyway. On the other hand, a FP in an image 
without weeds will cause an area to be treated without any 
need. 
However, analyzing the data in Photography 4, which has 
been taken in conditions of lower light, we observe that the 
results of classifying based on the standard deviation are better 
than the results of the threshold. When classifying with the 
established threshold value the number of FP is almost 4 times 
higher. Therefore, threshold values must be generated for 
different lighting conditions, or use the standard deviation as 
a classification method. 
TABLE III.  
COMPARISON OF CLASSIFICATION OPTIONS FOR METHOD C 
Method 
Parameter 
Image 
1) 
2) 
3) 
4) 
Standard  
deviation 
VP 
5 
8 
0 
4 
FP 
1 
≈ 40 
2 
≈ 60 
FN 
2 
4 
0 
0 
Threshold  
value 
VP 
5 
4 
0 
2 
FP 
0 
0 
1 
≈ 200 
FN 
0 
8 
0 
2 
D. Comparison of both techniques  
Finally, we are going to use four new images, two without 
weed presence and two with weed presence, taken in the same 
location than images 1-4 to compare the performance of both 
methodologies.  
With regard to the RGB methodology, we will present the 
most accurate results (from (2) or (3)) using the minimum as 
aggregation technique, with the objective of having no FP. On 
the other hand, regarding the edge detection, we are going to 
187
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

present the results using the Laplacian filter with the sum as 
the aggregation technique and using the threshold value 
obtained from Table II. A scheme of the combination of 
methods and techniques is presented in Figure 11. In this 
Figure, we can see the different steps carried out in order to 
obtain our results. First, the individual techniques are applied. 
Following, the aggregation technique is used, followed by the 
classification method. Finally, both images are joined. 
The technique of band combinations offered the following 
results. The method shows that in both images, the weeds are 
detected with the (3). The results of this methodology are 
FP≈45, TP=1, FN=0. In the second image with weed 
presence, it was not possible to detect the weed presence 
clearly with any of the RGB methods. With (2) we obtained 
the following results: FP=5, TP=0, FN=1 and with (3) 
FP>100, TP=3, FN=0. With the (3) it was possible to detect 
the presence of weed but the number of FP is very high, and 
we consider that none of the equations offer appropriated 
results. Finally, with the images without weed presence, the 
results of the first and second images are FP=6 and 10 with 
(2) and FP≈ 100 in both cases with (3).  
The results of using the edge detection method are the 
following ones. In the case of images with weed presence, the 
resultant images indicate the presence of weed in both cases 
the weeds are indicated TP= 1 and 3. Nonetheless, the results 
indicate the presence of weed in areas without a weed in one 
of the cases FP= 1 and 10. This method does not offer any FN. 
In the case of images without weed, the method offered in both 
image results in some FP, FP= 5 and 7 in each image. The 
resultant images of both filters and their combination in the 
images with weed presence are presented in Figure 12. First, 
the original images are shown and the presence of weed is 
indicated in red circles. Then the individual results of each 
technique are presented, the positive results (pixels identified 
as weeds) are in red. Finally, the results of combining both 
methodologies are presented. 
We can affirm that both methods (RGB and edge 
detection) are promising options for weed detection in grass 
gardens. Nonetheless, both methods need to be improved 
since a considerable number of FP are given. This fact is more 
relevant in the case of the RGB method with (3). 
Finally, we can join the data from both methods to 
improve the actuary. Therefore, if we combine the results of 
(2) and the Laplacian filter the weed detection improves 
considerably. The results are summarized in Table IV. The 
number of FP has been reduced. There is only one FP in Image 
2. The importance of the FP in an image when there is a TP, 
as in the case of Image 2, is low. In the images without weed 
presence, there is no FP. On the other hand, the weeds are 
correctly identified in the images with the presence of weed 
(Image 1 and Image 2). Thus, there is no FN in each image.  
VI. 
CONCLUSION 
In this paper, we have presented our proposal for weed 
detection in lawns using two image processing techniques. 
The objective is to detect the weeds to apply the phytosanitary 
products only to the affected area.  
We use a mathematical combination of the RGB bands 
and the edge detection filters to obtain new image data, which 
can be used to detect the weed. First, we found a formula that 
can be used to remove the soil from the images as pre-
processing. Then, after analyzing the RGB values of the 
weeds and the grass, we realize that there are two big groups 
of weeds. The ones with a bluish coloration and the ones with 
a yellowish coloration, compared with the grass. Thus, we 
need to use two different formulas to detect the weed. 
Moreover, several filters for edge detection have been 
compared and the Laplacian filter was the one that offered 
better results. Then, we apply aggregation techniques to 
minimize the number of FP in both methods. Finally, we 
compare and combine both methods, and observe the 
improvement of results when both methods are used together.  
By using the methodology described in this paper, it will 
be possible to detect weeds. This methodology is more 
effective for detecting dicotyledonous weeds, especially the 
ones with wide and big leaves. Nonetheless, in our results, 
some monocotyledonous leaves of weeds were detected. 
The future work will be related to the identification of 
different weed species using artificial intelligence and 
machine learning techniques. Those techniques will be 
applied not in the node itself, but in a cloud server. Moreover, 
we will work with images taken at a higher height and 
evaluate the benefits of using a thermal camera in conjunction 
with the RGB camera. Finally, and in order to estimate the 
reduction in phytosanitary product use, we will implement this 
methodology in golf courses. In those scenarios there is a huge 
area covered by grass and maintaining them without weeds is 
a key factor for the manager. 
 
Figure 11.  Block diagram of the process including the selected technics. 
 
 
Appling the 
aggregation 
techniques
Obtaining the bands
Using the individual methods
Image RGB
Filter (Laplacian)
Bands
Blue
Green
Red
Imagen B/N 
con los bordes
Combination of bands
New Image
Equation:
(2) or (3)
Cell size:
5
Aggregation type:
Sum
Cell size:
5
Aggregation type:
Minimum 
Classifying
Method: Natural breaks,
Nº of groups:5 groups
Threshold Value = 18.
Based on Table 2
Combination
Final result
Positives (weeds)=Color
0,   -1,    0
-1,    4,   -1
0,   -1,    0
Method: Natural breaks,
Nº of groups:5 groups
Positive results = last group
Threshold Value = 18.
Based on Table 2
Black and White 
Image with the 
edge detection
188
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

ACKNOWLEDGMENT 
This work is partially found by the Conselleria de 
Educación, Cultura y Deporte with the Subvenciones para la 
contratación de personal investigador en fase postdoctoral, 
grant number APOSTD/2019/04, by European Union through 
the ERANETMED (Euromediterranean Cooperation through 
ERANET 
joint 
activities 
and 
beyond) 
project 
ERANETMED3-227 SMARTWATIR, and by the European 
Union with the “Fondo Europeo Agrícola de Desarrollo Rural 
(FEADER) – Europa invierte en zonas rurales”, the 
MAPAMA, and Comunidad de Madrid with the IMIDRA, 
under the mark of the PDR-CM 2014-2020” project number 
PDR18-XEROCESPED. 
 
TABLE IV.  
COMBINATION OF RESULTS 
Method 
Parameter 
Image 
1) 
2) 
3) 
4) 
Band 
combination 
using (3) 
TP 
1 
3 
0 
0 
FP 
≈45 
>100 
≈ 100 
≈ 100 
FN 
0 
0 
0 
0 
Edge 
detection 
Laplacian 
TP 
1 
3 
0 
0 
FP 
1 
10 
5 
7 
FN 
0 
0 
0 
0 
Combination 
TP 
1 
3 
0 
0 
FP 
0 
0 
0 
0 
FN 
0 
0 
0 
0 
Image 
1) 
2) 
RGB image 
 
 
Image of RGB Band Operations using  (3) 
 
 
Image of Edge detection  
 
 
Resultant image of combinations: 
 
Blue pixels (positive results of 
RGB) 
 
Pink pixels (positive results of 
edge detection) 
 
Black pixels (positive results of 
combination)  
 
 
Figure 12.  Details of the combination of results in Figures with weed presence 
 
 
189
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

REFERENCES 
 
[1] L. Parra, V. Torices, J. Marín, P. V. Mauri, J. Lloret, "The Use 
of Image Processing Techniques for Detection of Weed in 
Lawns", The Fourteenth International Conference on Systems 
(ICONS 2019), Valencia, Spain, 24 – 28 March 2019, pp. 50-
55. 
[2] M. R. Barnes, K. C. Nelson, A. J. Meyer, E. Watkins, S. A. 
Bonos, B. P. Horgan, W. A. Meyer, J. Murphy, C. Yue, “Public 
land managers and sustainable urban vegetation: The case of 
low-input turfgrasses”, Urban forestry & urban greening, 2018, 
vol. 29, pp. 284-292. 
[3] A. Nagase, M. Kurashina, M. Nomura, J. S. MacIvor, “ 
Patterns in urban butterflies and spontaneous plants across a 
University campus in Japan”, The Pan-Pacific Entomologist, 
2019, vol. 94, no. 4, pp. 195-215. 
[4] Y. H. Hwang, Z. E. Jonathan Yue, “Intended wildness: 
Utilizing spontaneous growth for biodiverse green spaces in a 
tropical city”, Journal of Landscape Architecture, 2019, vol. 
14, no. 1, pp. 54-63. 
[5] S. B. Lerman, A. R. Contosta, J. Milam, C. Bang, “To mow or 
to mow less: Lawn mowing frequency affects bee abundance 
and diversity in suburban yards”, Biological conservation, 
2018, vol. 221, pp. 160-174. 
[6] R. Roscher, J. Behmann, A. K. Mahlein, J. Dupuis, H. 
Kuhlmann, L. Plümer, “ Detection of Disease Symptoms On 
Hyperspectral 
3D 
Plant 
Models. 
ISPRS 
Annals 
of 
Photogrammetry”, Remote Sensing & Spatial Information 
Sciences, 2016, vol. 3, no. 7. 
[7] P. D. Surya and K. J. Satheesh, "Assessment of banana fruit 
maturity by image processing technique", Journal of food 
science and technology, 2015, vol. 52, no 3, p. 1316-1327. 
[8] D. Li, L. Xu, H. Liu, “Detection of uneaten fish food pellets in 
underwater 
images 
for 
aquaculture”, 
Aquacultural 
Engineering, 2017, vol. 78, pp. 85-94. 
[9] H. Li, Z. Lin, X. Shen, J. Brandt, and G. Hua, "A convolutional 
neural network cascade for face detection", Proceedings of the 
IEEE 
Conference 
on 
Computer Vision 
and Pattern 
Recognition. 2015. pp. 5325-5334. 
[10] G. Maria, E. Baccaglini, D. Brevi, M. Gavelli, and R. 
Scopigno, "A drone-based image processing system for car 
detection in a smart transport infrastructure", Electrotechnical 
Conference (MELECON), 2016 18th Mediterranean. IEEE, 
2016. pp. 1-5.  
[11] L. Parra, J. Marín, P. V. Mauri, J. Lloret, V. Torices, A. 
Massager, “Scatternet Formation Protocol for Environmental 
Monitoring in a Smart Garden”, Network Protocols and 
Algorithms, 2018, vol. 10, no. 3, pp. 63-84. 
[12] X. P. Burgos-Artizzu, A. Ribeiro, M. Guijarro, and G. Pajares, 
"Real-time image processing for crop/weed discrimination in 
maize fields", Computers and Electronics in Agriculture, 2011, 
vol. 75, no 2, pp. 337-346. 
[13] A. Paikekari, V. Ghule, R. Meshram, and V. B. Raskar, "Weed 
detection using image processing", International Research 
Journal of Engineering and Technology (IRJET), 2016, vol. 3, 
no 3, pp. 1220-1222 
[14] J. Gao, W. Liaob, D. Nuyttensc, P. Lootensd, J. Vangeytec, A. 
Pižuricab, Y. Hee, J. G. Pietersa, "Fusion of pixel and object-
based features for weed mapping using unmanned aerial 
vehicle imagery", International journal of applied earth 
observation and geoinformation, 2018, vol. 67, pp. 43-53. 
[15] J. F. Marín Peira, , J. Rocher, L. Parra, A. Plaza, P. V. Mauri, 
J. Ruiz Fernández, S. Sendra, J. Lloret "Automation in the 
characterization of the cultivation Automatización en la 
caracterización del cultivo de céspedes en praderas urbanas ", 
Proccedings of the IX Congresso Ibérico de Agroengenharia, 
Braganza, Portugal, 4 – 9 Sept. 2017. 
[16] J. F. Marín Peira, L. Parra, J. Rocher, S. Sendra, J. Lloret, P. V. 
Mauri, A. Masaguer, "Urban Lawn Monitoring in Smart City 
Environments". Journal of Sensors, 2018, vol. 2018. 
[17] V. Khanaa and K. P. Thooyamani, "An Efficient Weed and Pest 
Detection System", Indian Journal of Science and Technology, 
2015, vol. 8, no 32. 
 
190
International Journal on Advances in Intelligent Systems, vol 12 no 3 & 4, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

