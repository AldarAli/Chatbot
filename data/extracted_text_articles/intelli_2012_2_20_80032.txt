The Design of a Self-Localization Estimation Method for Indoor Mobile Robots 
using an Improved SURF Algorithm  
 
 
Xing Xiong 
College of Information and Communication 
Daegu University 
Gyeongsan-City, Gyeongbuk, Korea 
e-mail: GaleWing@gmail.com 
Byung-Jae Choi 
School of Electronic Eng. 
Daegu University 
Gyeongsan-City, Gyeongbuk, Korea 
e-mail: bjchoi@daegu.ac.kr
 
 
Abstract— We present an improved self-localization estimation 
algorithm in this paper. The algorithm uses a modified SURF 
method to extract the interest points, using it to extract the 
orientation and a descriptor of the interest point in order to 
lessen the computation time. A robot using this method can 
estimate its indoor self-localization according to matched 
interest points. A number of intermediate results will also be 
discussed. The intermediate results show that the displacement 
method could correctly match the interest points in two images. 
Keywords-Ceiling Key Point Extraction; SURF (Speeded-Up 
Robust Features); DSP (Digital Signal Processor). 
I. 
 INTRODUCTION  
Mobile robot self-localization is a mandatory task for 
accomplishing full autonomy during navigation. Various 
solutions in the robotics community have been developed in 
order to solve the self-localization problem. The solutions 
can be categorized into two groups: relative localization 
(dead-reckoning) and absolute localization. Although very 
simple and fast, dead reckoning algorithms tend to 
accumulate errors in the system since these methods only 
utilize the information coming from proprioceptive sensors, 
such as odometer readings (e.g. incremental encoders on the 
robot wheels). Absolute localization methods are based on 
exteroceptive sensor information. This method yields a stable 
locating error but is more complex and costly in terms of 
computation time. Relative localization requires a high 
sampling rate in order to maintain an up-to-date pose, 
whereas absolute localization is applied periodically with a 
lower sampling rate to correct relative positioning 
misalignments [3]. 
With the furthering development of science and 
technology, visual positioning methods play an important 
role in the self-localization of autonomous mobile service 
robots working in indoor environments [5]. Generally, prior 
knowledge of an indoor environment can be used to 
determine the position and orientation of a mobile robot via 
visual positioning approaches. The features used by different 
approaches for mobile robot localization range from artificial 
markers, such as barcodes, to the placement and orientation 
of ceiling lights and tiles, for example. Indeed, the selected 
visual features have significant influence on the positioning 
approach performance. 
The remainder of this paper is organized as follows: 
Section II presents some of the related studies. Section III 
lays out the composition of the proposed algorithm. Section 
IV discusses some of the intermediate results. We draw our 
conclusions in Section V. 
II. 
RELATED WORK 
In the field of image processing, the Speeded Up Robust 
Features (SURF) algorithm [6] is an efficient and high-speed 
algorithm, which is considered to be an improved version of 
the Scale-invariant Feature Transform (SIFT) algorithm [10]. 
The SURF algorithm mainly consists of two parts: interest 
points extraction and an orientation and descriptor of the 
interest points extraction. For the interest point extraction, 
the SURF method uses an integral image and box filter to 
replace the Gaussian filter and the DoG (Difference of 
Gaussian) method found in the SIFT algorithm. This allows 
for a greatly reduced computation time.  
However, in the orientation and descriptor section the 
SURF method scans the neighborhood region twice. In the 
first scan the orientation of the interest point is extracted. 
The second scan, according to the orientation of the interest 
point, is used to extract the descriptor. In low-speed devices 
such as a DSP board, the two scans increase the amount of 
computation time. Furthermore, in the case of images that 
only rotate and move, a simpler method can be used to 
obtain the orientation and descriptor. 
In our paper, we use an alternative method to obtain the 
orientation and descriptor. This method only scans the 
neighborhood region interest points once. Our self-
localization estimation algorithm contains three parts: 
interest points extraction (using SURF), orientation and 
descriptor extraction (using the improved method), and the 
interest points matching and self-localization estimation. 
Because there is only one scan the necessary amount of 
calculation is reduced. 
III. 
THE COMPOSITION OF THE ALGORITHM 
In an indoor environment, the floor is assumed to be 
planar. The ceiling usually consists of a series of blocks that 
form a chessboard pattern parallel to the floor. In this study, 
a camera is mounted onto the top of the mobile robot 
working on the floor. The camera points to the ceiling, as 
shown in Figure 1. 
31
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-224-0
INTELLI 2012 : The First International Conference on Intelligent Systems and Applications

 
Figure 1.  Ceiling based visual positioning 
In our research, the SURF algorithm is used to extract the 
interest points. The SURF’s replacement method is used to 
extract the orientation and the descriptors of the interest 
points. The self-localization of the mobile robot is then 
estimated according to the different positions of the same 
interest points in two images. The flow chart of the algorithm 
is shown in Figure 2. The interest points extraction section is 
broken down in Figure 3. 
Simply put, in the rapid interest points detection method, 
the NMS (Non-Maximum Suppression) method used after 
obtaining the Fast-Hessian matrix in the conventional SURF 
algorithm is changed to a Non-minimum suppression method 
to obtain the feature points whose gray value is high. In 
addition, the conventional order of the box filter scale [6] is 
changed to 75, 51, and 99. Not only does this remove the 
impact of the image edge, reducing the amount of calculation, 
but also leads to an increase in the interest points. The 
interest points extraction results are shown in Figure 6. 
 
 
Figure 2.  The SURF algorithm flow chart  
 
Figure 3.  The interest points extration 
Regarding the orientation and descriptor extraction, our 
descriptor method is similar to that of the SIFT algorithm. 
The flow chart describing the replacement algorithm is 
shown in Figure 4. The details regarding this algorithm can 
be found in [11]. 
To date, in a simple environment, for the case of the 
translation and rotation of the image obtained from the 
ceiling, the replacement algorithm has been verified to be 
feasible. The results from the replacement algorithm are 
shown in Figure 7. 
 
Figure 4.  The modified algorithm flow chart 
32
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-224-0
INTELLI 2012 : The First International Conference on Intelligent Systems and Applications

The self-localization estimation method is illustrated in 
Figure 5. 
The two illustrations shown in Figures 5(a) and 5(b) 
show differences obtained over a small time interval. Figure 
5(a) illustrates a baseline before the camera is moved. After 
the camera is moved (5 seconds), Figure 5(b) illustrates the 
position and orientation differences. We assume that there 
are three interest points and a center point. The center point 
represents the self-localization of the mobile robot. One 
point amongst three interest points have two coordinates 
(Dash Line Coordinate System and Solid Line Coordinate 
System).  
 
 
(a) 
 
 
(b) 
 
Figure 5.  The self-localization estimation method 
The dashed line coordinates represent the image 
coordinates whereas the solid line coordinates represent the 
interest points. The X-axis of the solid line coordinate 
represents the orientation of the interest point.  
The center point’s coordinate (x, y) in the dashed line 
coordinate system can be changed to the solid line coordinate 
system 
( ,ˆ ˆ)
x y
by: 













 





x
y
x
y




cos
sin
sin
cos
ˆ
ˆ

As shown in Figure 5(b), there are two new coordinates 
( ˆ , ˆ )
xa ya
 and 
( ˆ , ˆ )
xb yb
. According to the characteristics of 
the invariant properties [10], 
( ˆ , ˆ )
xa ya
 and 
( ˆ , ˆ )
xb yb
 are in 
the same coordinate system. In fact, the location change of 
the mobile robot is from 
( ˆ , ˆ )
xa ya
 to 
( ˆ , ˆ )
xb yb
. The relative 
displacement of the mobile robot can therefore be expressed 
simply as: 
 
 
2
2
ˆ )
( ˆ
ˆ )
( ˆ
b
a
b
a
y
y
x
x
D




              (2) 
 
IV. 
THE INTERMEDIATE RESULTS 
In this section we discuss some intermediate results. 
Figure 6 shows the extracted interest points results. The 
black dots represent the interest points.  The captured image 
after camera moved is shown in Figure 6(b). Comparing the 
two images, most of the interest points are retained. 
 
 
(a) 
 
(b) 
Figure 6.  The extracted interest points simulation results: (a)  before and 
(b) after the camera moved 
33
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-224-0
INTELLI 2012 : The First International Conference on Intelligent Systems and Applications

Because the interest points being matched by the results 
from the DSP is not very intuitive, Figure 7 shows the results 
which were simulated using the same method in MatLAB. 
 
 
Figure 7.  Descriptor extraction and matching using our improved 
algorithm in MatLAB 
V. 
CONCLUSION 
In this study, we used Non-minimum suppression to 
replace Non-maximum suppression in interest points 
extraction. As a result, we present a modified SURF 
algorithm used to extract the orientation and descriptor of the 
interest points. The simulation results verify the modified 
algorithm has good interest point matching results. In future 
work, we will write a program to verify the proposed self-
localization estimating design in a DSP board. We will also 
address camera rotation in regards to the self-localization 
algorithm and verify it.  
 
 
ACKNOWLEDGMENT 
 
This work was supported in part by the Basic Science 
Research 
Program 
through 
the 
National 
Research 
Foundation of Korea (NRF) funded by the Ministry of 
Education, Science and Technology under Grant 2010-
0006588. 
REFERENCES 
[1] David C. K. Yuen and Bruce A. MacDonald: Vision-Based 
Localization Algorithm Based on Landmark Matching, Triangulation, 
Reconstruction, and Comparison, IEEE Transactions on Robotics, 
vol. 21, no. 2, pp. 217-226, April. 2005 
[2] Andreja Kitanov, Sanjin Biševac, and Ivan Petrovíc, “Mobile robot 
self-localization in complex indoor environments using monocular 
vision and 3D model”, IEEE/ASME international conference on 
Advanced intelligent mechatronics, pp. 1-6,  2007 
[3] Alexander Koenig, Jens Kessler and Horst-Michael Gross: A Graph 
Matching Technique for an Appearance-based, visual SLAM-
Approach using Rao-Blackwellized Particle Filters,” IEEE/RSJ 
International Conference on Intelligent Robots and Systems, pp. 
1576-1581, 2008 
[4] Kuan-Chieh Chen and Wen-Hsiang Tsai: “Vision-Based Autonomous 
Vehicle Guidance for Indoor Security Patrolling by a SIFT-Based 
Vehicle-Localization Technique”, IEEE Transactions On Vehicular 
Technology, Vol. 59, No. 7, pp. 3261-3271, 2010 
[5] De Xu, Liwei Han, Min Tan, and You Fu Li: “Ceiling-Based Visual 
Positioning for an Indoor Mobile Robot With Monocular Vision”, 
IEEE Transactions On Industrial Electronics, Vol. 56, No. 5, pp. 
1617-1628,  2009. 
[6] Herbert Bay, Tinne Tuytelaars, and Luc Van Gool, “SURF: Speeded 
Up 
Robust 
Features”, 
Computer 
Vision 
and 
Image 
Understanding(CVIU), Vol. 110, No. 3, pp. 346-359, 2008. 
[7] Paul Viola and Michael Jones, “Rapid Object Detection using a 
Boosted Cascade of Simple Features”, Proceedings of the 2001 IEEE 
Computer Society Conference on Computer Vision and Pattern 
Recognition, pp. I-511 – I-518, Kauai. HI. USA, 2001.  
[8] Han Bing and B. Boyd, "Direct Replacement Algorithms of Fast 
Computing Integral Image in SURF", Journal of Projectiles, Rockets, 
Missiles and Guidance, Vol. 31, No. 3, pp. 211-15, 2011. 
[9] Wang Jun-ben, LU Xuan-min and HE Zhao, "An Improved 
Algorithm of Image Registration Based on Fast Robust Features", 
Computer Engineering & Science, Vo1.33, No.2, pp. 112-118,  2011 
[10] David G. Lowe, “Distinctive Image Features from Scale-Invariant 
Keypoints”, International Journal of Computer Vision, Vol. 60, No. 2, 
pp. 91-110,  2004 
[11] Xing Xiong and Byung-Jae Choi, “A Replacement Algorithm of Fast 
Computing Interest Point’s Orientation and Descriptor in SURF”, 
International Conference on Advances in Electrical and Electonicas 
Engineeing, pp. 336-338,  Penang. Malaysia, 2012 
 
34
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-224-0
INTELLI 2012 : The First International Conference on Intelligent Systems and Applications

