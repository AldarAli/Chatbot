483
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Quality of Service Based Event Stream Processing Systems in Smart Grids
Epal Njamen Orleant
Grenoble INP, LIG
Saint Martin d’H`eres, France
Email: orleant.epal-njamen@imag.fr
Lourdes Martinez
Grenoble INP, LIG
Saint Martin d’H`eres, France
Email: martinez@imag.fr
Christine Collet
Grenoble INP, LIG
Saint Martin d’H`eres, France
Email: christine.collet@grenoble-inp.fr
Genoveva Vargas-Solar
CNRS, LIG-LAFMIA
Saint Martin d’H`eres, France
Email: genoveva.vargas@imag.fr
Christophe Bobineau
Grenoble INP, LIG
Saint Martin d’H`eres, France
Email: christophe.bobineau@grenoble-inp.fr
Abstract—This paper presents an approach for composing event
streams based on quality of service requirements (QoS) of smart
grids. The approach consists of an event stream model, compo-
sition strategies guided by QoS such as memory consumption,
event priority and notiﬁcation latency. Model and strategies are
implemented by a distributed event stream processing system
consisting of execution units that can be deployed across a
smart grid. The paper describes implementation issues and
experimental results.
Keywords–Complex event processing; Quality of service; Smart
Grids.
I.
INTRODUCTION
Smart grids are complex networks vastly instrumented with
intelligent electronic devices (sensors, smart meters, actuators,
etc.), network communication and information technologies.
Devices emanate huge amounts of data that can be exploited
for a wide range of applications like network trafﬁc analysis,
automation of operational control, prevention or detection
of dysfunctions, etc. Strategies to handle asynchronous data
collection, data transfer, and real-time data notiﬁcation and
processing are critical for achieving smart grid monitoring.
Those data can be considered as events that refer to hap-
penings of interest produced within the system environment.
The capacity to monitor and supervise a smart grid relies
on processing low level events in order to infer higher level
events semantically richer and more useful for end user appli-
cations [1]. This process includes events ﬁltering, aggregation,
correlation, windowing, etc. Infrastructures able to achieve
these computations on events are referred to as complex event
processing systems like [2–6].
For example, let us consider that a smart meter produces an
event of type CoverOpenAlert when its cover is opened, and a
sensor produces an event of type BadVoltage when it detects
an abnormal voltage on the electrical line. An application
may be interested in the sequence of CoverOpenAlert and
a BadVoltage occurring at the same place, within a two
minutes time window. This pattern detects suspicious activities
(MeterSuspected event type) on smart meters. The detection
of such a high level event includes event ﬁltering (type and
attribute based ﬁltering), windowing and temporal correlation.
In these situations, devices may notify events to a remote
Information System (IS) able to perform complex events
processing. The IS sends commands (with or without human
intervention) to certain devices for reacting to the reported
events. The dialog IS - devices may take considerable time,
thus hindering real-time requirements. An intuitive manner for
alleviating this problem is to inject certain intelligence into
devices, such that they can react to situations without some
external intervention. Thus, (total or partial) event processing
should be distributed among the smart grid devices. An inher-
ent consequence is the necessity to deploy event processing
systems in distributed architectures. The latter must efﬁciently
achieve event processing while adapting to their environment
in terms of the multiplicity of data sources (sensors, smart me-
ters, existing databases, etc.) and smart grid QoS requirements.
a) Multiplicity of data sources: Distributed systems
like smart grids consist of different types of components
that can act as event producers or consumers, with different
interaction modes (synchronous or asynchronous, push or pull
based style), as illustrated by sensors, smart meters, existing
databases. The diversity of interaction modes, coupled with the
difference in data formats make it difﬁcult to integrate events
from different producers for event processing purposes.
b) Quality of service (QoS): The need to detect and
notify complex events from basic events is sometimes corre-
lated with some quality of service requirements like memory
consumption, network occupancy, event priority, notiﬁcation
latency, etc. The extension of event models towards more ﬂex-
ible and QoS oriented event models requires an analysis and
the semantics that should be given to the events, and of their
associated processing strategies. This requires dissociating the
modeling of event and the application design and, the proposal
of methods that allow to deﬁne event types independently of
the management issues (detection, production, notiﬁcation).
Therefore, it is required to adapt the event models to smart
grid characteristics. On the other hand, those QoS requirements
generally constrain the way the event processing must be

484
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
achieved. More precisely, event processing must be achieved
on each device considering its memory availability.
Existing systems are limited in the sense that they do
not fully satisfy QoS requirements for event processing. The
problem we address in this paper can be summarized as
follows: given smart grid needs in terms of event composition
and QoS, how to provide the complex event processing system
that best fulﬁlls expected QoS requirements?
Our approach considers an event based abstraction of smart
grids functions and services. This abstraction allows to reason
on the smart grid in terms of event streams that are generated
by smart grid components. In order to identify relevant or criti-
cal situations (complex events) among those event streams, we
propose a distributed complex event processing architecture.
The event processing logic is implemented as a network of
operators executed by distributed event processing units. We
also propose strategies applicable to event processing units in
order to address the following QoS dimensions: event priority,
memory occupation and notiﬁcation latency.
The remainder of the paper is organized as follows: Section
II presents the related work. Section III presents the overview
of our approach for QoS based complex event processing in
smart grids. Section IV describes the proposed model and
system architecture for QoS based event processing. Section
V discusses how to specify QoS requirements and introduces
the QoS adoption strategies. These strategies are presented
in Section VI and Section VII. Section VIII discusses the
experimental results. Finally, Section IX concludes the paper.
II.
RELATED WORK
Many works have been achieved on event streams analysis
and composition, and many event processing systems have
been proposed so far [2–6], either for centralized or distributed
architectures.
In centralized architectures, produced events are pro-
cessed by a single node acting as an event processing server
[3][5][6][7][8]. In this approach, event streams must be routed
to the server node. This potentially increases the latency of the
event processing, and overloads the network and server, which
risks to become a point of failure. Therefore, this approach is
not suited for distributed contexts.
In distributed architectures, the event processing logic is
performed by a set of distributed communicating nodes, each
one achieving a part of the work. This offers a better scalability
and availability than centralized approaches. Some distributed
event processing systems are [2][4][9][10]. In this category, we
distinguish between clustered and in-network architectures. In
clustered architectures, the event processing is realized in a
clustered environment [4][11], whereas in-network architec-
tures allows to distribute the event processing over a large
number of nodes within a network topology [9][2]. This work
aims to propose an in-network event stream processing systems
for smart grid that deals with QoS.
Behnel et al. [12] and Appel et al. [13] identify some
QoS dimensions (latency, priority, etc.) relevant for distributed
event processing, but they do not propose mechanisms for
their adoption. However, some other systems provide QoS
support. They optimize the query processing according to
a particular objective, and differs from each other by the
adopted QoS dimensions. For example, [2] focuses on reducing
the network trafﬁc whereas [9] studies energy consumption.
In wide networking environments, it is not reasonable to
expect that all applications share the same objective. In our
approach, we identify a set of QoS properties relevant for event
processing in smart grids, and we study their adoption by the
event processing system.
A survey on the QoS requirements of smart grid communi-
cation systems is presented in [14]. It focuses on the function-
alities that have to be provided by smart grid communication
infrastructures in order to address application requirements.
Sun et al. [15] propose to add QoS by providing differentiated
service for data trafﬁc with different priority at the MAC (Me-
dia Access Control) layer. GridStat [16] is a publish-subscribe
middleware framework designed to meet the QoS requirements
for the electric power grid. It manages network resources to
provide low-latency, reliable delivery of information produced
anywhere on the network and sent to multiple other points.
In our work, we assume the existence of QoS support at the
networking layer (e.g, message priority) on which a complex
event processing system dealing with event priority, memory
occupation and notiﬁcation latency can be proposed for smart
grids.
III.
APPROACH OVERVIEW
Figure 1 summarizes our approach to integrate complex
event processing technologies into smart grids. It consists in
three layers of abstraction, namely smart grid, event streams,
and event processing network layers.
•
The smart grid layer consists in the real physical
smart grid architecture, which includes telecommuni-
cation based devices such as smart meters, sensors,
data concentrators, etc. Those devices are connected
by communication networks technologies including
power line, wireline or wireless communications [17].
The smart grid is described in terms of information
being used and exchange between functions, services
and components. This layer of abstraction is referred
to as the Information layer in the smart grid reference
architecture model [18]. In our approach, information
is seen as events that happen within the smart grid.
•
The event streams layer considers that data generated
by smart grids components are event streams. In this
layer, smart grid components act as sources, which
can generate different types of events in a continuous
manner. The event model considered in this work is
presented in Section IV.
•
The event processing network layer consists in a set
of distributed event processing units that are con-
nected by event channels. This network is created
according to complex event subscriptions. It may
be deployed across multiple distributed computers,
software artifacts and physical networks. The complex
event subscriptions are tagged with applications QoS
requirements such as event priority and notiﬁcation
latency. Those QoS requirements have to be translated
into constraints applicable to event processing units
at execution time. In addition to constraints derived
from applications requirements, inherent constraints to
the smart grid infrastructure also must be taken into
consideration, such as limitations on computational

485
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
resources (i.e., memory and CPU) and / or communi-
cation networks (i.e., network occupation).
Figure 1. Approach overview
IV.
MODEL AND ARCHITECTURE
This section presents the event model (event type and event
stream), and the runtime architecture of our approach (event
processing network).
A. Event model
1) Event type and event instance: An event type represents
a class of signiﬁcant facts (events) and the context under
which they occur. The deﬁnition of an event type includes
the attributes presented in Table I.
TABLE I. EVENT TYPE ATTRIBUTES
Name
Type
typeName
String
producerID
String
detectionTime
Number
productionTime
Number
notiﬁcationTime
Number
receptionTime
Number
priority
Number
context
Set<Attribute >
The typeName attribute refers to the name of the event
type. The producerID attribute refers to the id of the entity
who produced the event instance. The detectionTime attribute
refers to the time at which the event instance has been detected
by a source. The productionTime attribute refers to the time
at which the event has been produced (as a result of a
processing on others events) by an event processing unit. The
notiﬁcationTime attribute refers to the time at which the event
is notiﬁed to interested consumers. The receptionTime refers
to the time at which the event is received by an interested
consumer. The priority attribute represents the priority value
associate to the event instance. The context (context attribute)
of an event type deﬁnes all the attributes that are particular
to this event type. They represent the others data manipulated
by the producer, which are relevant to this event type. For
example, the context of a MeterMeasure event type generated
by a smart meter includes the voltage and current attribute.
An event type can be simple or composite. Simple event
types are event types for which instances are generated by
producers (sensors, smart meters, etc.). They are not generated
from the processing of other events. In the example considered
in Section I, BadVoltage and CoverOpenAlert are simple
event types. More generally in a smart grid, the event types
include Alarms, MeterMeasure and SensorMeasure generated
by electric devices and such as smart meters and sensors, and
Command, ControlOrder, ControlAction generated by utility
applications.
Complex (or composite) event types are event types for
which instances are generated as a result of event processing.
Reference [19] includes a set of operators applicable to events.
They capture particular situations (relevant or critical) that can
be inferred from occurrences of others events. Those situations
have to be notiﬁed to utility applications, such that the system
can be automatically or manually controlled. In the same
example, MeterSuspected is a complex event type. Complex
event types can also capture aggregated values, like the daily
electricity consumption of a household. This can be product of
the aggregation of the MeterMeasure event instances included
on a one-day window.
An event instance (or simply event) is an occurrence of
an event type. The event instance deﬁnes the value associated
to each attribute of the event type. For example, the event
occurrence e with attributes presented in Table II denotes an
event instance of type MeterMeasure, which has been produced
by producer meter1 at time 1, notiﬁed at time 2, received at
time 3, which has a priority value 3, and for which the voltage
and current values are 220 and 3, respectively.
TABLE II. EVENT INSTANCE
Name
Type
typeName
’MeterMeasure’
producerID
’meter1’
detectionTime
1
productionTime
1
notiﬁcationTime
2
receptionTime
3
priority
3
voltage
220
current
3
2) Event stream: An event stream is a continuous, append-
only sequence of events. We note Stream(s,T) the stream of
events of type T generated by the source s. If S is a set of
sources, then {Sstream(s,T),s ∈ S} deﬁnes a stream of events
of type T, denoted Stream(T).
B. Event processing network
As introduced in Section III, the event processing logic
is implemented by the event processing units. The runtime
deployment of event processing units with associated event
channels is called the event processing network [20][21]. This
is illustrated in Figure 2.
The general vision of our QoS based complex event pro-
cessing system can be brieﬂy described as follows: applications
subscribe to composite events by issuing complex event pat-
terns to the system, this must also include the speciﬁcation of
the associated QoS requirements. The system then deploys a
set of distributed event processing units, which apply different
strategies to meet QoS requirements during event processing.
Complex events produced by the event processing units are
notiﬁed to consumers. In a smart grid, such an infrastructure
can act as a middleware on which utility applications rely

486
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
for detecting interesting or critical situations (sensors errors,
alarms, etc.) over the electrical grid, and at the same time, rely
on some QoS guarantees (e.g., priority, notiﬁcation latency,
etc.).
EPU	  
EPU	  
EPU	  
EPU	  
Event  
Producers 
Event 
Consumers 
Event processing network 
Event channels 
Figure 2. Event processing network
1) Event processing unit: An event processing unit can be
deﬁned by three types of components (see Figure 3):
•
a set of input queues, on which parts of input event
streams are maintained.
•
an operator, which implements a three step event
processing logic: fetch-produce-notify. In the ﬁrst step
(fetch), some events are selected from the input queues
and marked as ready to be used to produce new
composite events. In the second step (produce), the
events selected at the ﬁrst step are used to produce new
composite events according to the operator semantic.
The produced complex events are stored in the output
queue. In the third step (notify), events in the output
queue are notiﬁed either, to another event processing
units or to the interested consumers.
•
an output queue, which contains events to be notiﬁed.
produce 
Stream 1 
notify 
fetch 
Input queue 1 
Output 
 stream 
Stream 2 
Input queue 2 
output queue 
 
 
Figure 3. Event processing unit
2) Event channel: Event processing units communicate
through event channels. Event channels are means of convey-
ing events [22]. This can be done via standard tcp or udp
connections, or higher level communication mechanisms like
publish/subscribe [23] or group communication [24] provided
by a middleware layer.
C. Architecture
The architecture of the proposed QoS based event pro-
cessing system is depicted at Figure 4. It consists of four layers
described as follows.
•
the application layer consists of two types of compo-
nents: event producers (sensors, smart meters, etc.),
Figure 4. System architecture
and event consumers that subscribe to complex event
patterns having speciﬁc QoS requirements.
•
the event processing network layer consists of a set of
distributed event processing units that communicate
among them via event channels.
•
the middleware layer provides a high level communi-
cation mechanism to event processing units. This can
be publish/subscribe [23][16] or group communication
services [24]. It relies on the underlying network layer.
•
the network layer ensures messages delivery from one
destination to another.
V.
QOS SUPPORT IN EVENT PROCESSING
The need to detect and notify complex events from basic
events is sometimes correlated with some QoS requirements.
The QoS dimensions we address in this paper are event
priority, notiﬁcation latency and memory occupation. Those
QoS requirements are either imposed by smart grid applica-
tions (event priority, notiﬁcation latency), or by the execution
environment (memory occupation).
1) Event priority: Event priority deﬁnes a priority order
between events. In some contexts, events may have different
priorities that have to be captured at event processing runtime.
For example, in a smart grid, a BadVoltage event can be

487
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
higher priority than a CoverOpenAlert event. Events that have
a higher priority have to be processed and notiﬁed earlier than
less priority events.
2) Memory occupation: Smart grid devices may have dif-
ferent memory capacity. To adapt event processing to the
memory capacity of devices, it must be a way to specify the
maximum memory occupation incurred by an event processing
unit at execution time. The memory occupation constraint
gives an upper bound of the number of events that an event
processing unit can maintain at execution time.
3) Notiﬁcation latency: In the common practice for power
device protection, the circuit breaker must be opened imme-
diately if the voltage or current on a power device exceeds
the normal values. The notiﬁcation latency of an event is the
time elapsed between its production and its notiﬁcation to
interested consumers (end users or event processing units). The
notiﬁcation latency constraint imposed on an event processing
unit deﬁnes an upper bound on the notiﬁcation latency of
events produced by that event processing unit.
A. QoS expressions
Each QoS requirement is associated to a speciﬁc value
domain. Below we specify the value domains corresponding
to the introduced QoS requirements:
•
Dlatency denotes the notiﬁcation latency domain. La-
tency is a measure of time that adopts a numeric value
expressed as either, a positive integer or a positive
fraction. Therefore, a latency value belongs to the
domain of real numbers R+. Thus, we can say that
Dlatency ⊆ R+. We also assume that the arithmetic
and comparison operations that can be applied on real
numbers also can be applied among values belonging
to Dlatency. For instance, intuitively a low latency is
preferable than a high latency, thus it can be desir-
able to compare latency values using the comparison
operators less than(<), and less than or equal to (≤).
•
Dpriority denotes the event priority domain. An event
instance is associated to a priority level that varies
according to the event type. A priority level is rep-
resented with a positive integer value. Therefore, we
consider that a priority value belongs to the domain of
natural numbers N; thus, Dpriority ⊆ N ≤ n. We assume
that we can use comparison or arithmetic operators
on latency values. The priority is a heavily restricted
bounded QoS requirement, priority = 1 denotes the
highest priority and priority = n denotes the lower
priority. The equal to (=) operator is required to
associate an event to a priority level.
•
Dmemocc denotes the memory occupation domain. We
express the memory occupation in terms of number
of events, for this reason, such a requirement adopts
an integer positive value thus belonging to the domain
of natural numbers N. We state that Dmemocc ⊆ N ≤
m. Where the comparison operator less than or equal
to (≤) speciﬁes an upper bound and m speciﬁes the
maximum memory capacity of the current device.
Let us assume that D is the set of the considered QoS
domains, thus D = Dlatency
S Dpriority
S Dmemocc. Given a
domain DQ, we assume a function name(DQ) that returns the
domain name, a function operator(DQ) that returns the set of
related operators, and a function value(DQ) that returns the set
of possible values.
For instance, let us consider the domain Dlatency, thus:
•
name(DQ) = notiﬁcation latency
•
operator(DQ) = greater than (>), greater than or equal
to (≥), less than (<), less than or equal to (≤), equal
to (=), not equal to (̸=)
•
value(DQ) = R+, this is the set of all positive real
numbers
1) Atomic QoS expression: An atomic QoS expression α
speciﬁes a QoS requirement. It is of the form (n, Θ, v), where
•
n denotes a domain DQ , where DQ ∈ D
•
Θ ∈ operator(DQ) and,
•
v ∈ value(DQ)
For instance, the atomic QoS expression (notiﬁcation la-
tency, ≤, 2000 ms) speciﬁes that the latency for notifying an
event must be equal than or less to 2000 milliseconds.
2) Complex QoS expression: A complex QoS expression ε
speciﬁes multiple QoS requirements. Assuming that an atomic
QoS expression speciﬁes a QoS requirement, thus a complex
QoS expression results from the conjunction of two or more
atomic QoS expressions. The deﬁnition of a complex QoS
expression is as follows:
•
If α1 and α2 are atomic QoS expressions then α1
S
α2 is a complex QoS expression ε1.
•
Let us suppose that the complex QoS expression ε2
results from the conjunction α1
S α2
S α3 of atomic
expressions.
•
Thus, ε2 results from the conjunction ε1
S α3.
•
A complex QoS expression results from the conjunc-
tion of two or more QoS atomic expressions, or other
complex expressions.
The QoS expression (notiﬁcation latency, ≤, 2000 ms) S
(event priority, =, 1) speciﬁes that the notiﬁcation latency must
be less than or equal to 2000 milliseconds, and in addition, the
highest priority level (i.e., priority = 1) is required.
B. QoS adoption
QoS expressions are translated into constraints that have to
be satisﬁed by the runtime environment. In order to address
those QoS requirements, we propose:
•
an event processing units placement algorithm that
ensures load balance between the available processing
devices while minimizing the end to end latency.
For simplicity, we will refer to this problem as the
operators placement problem, since the placement of
an event processing unit is the same as the placement
of the operator it implements.
•
a strategy applicable to event processing units al-
lowing to ensure that high priority events will be
processed and notiﬁed earlier than less priority events.

488
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
VI.
OPERATOR PLACEMENT
Event stream processing operators can be deployed in
several ways on smart grid devices. Operators placement
may considerably impact the quality of service. For instance,
deploying operators on a single node may potentially minimize
the latency of events processing, since it avoids the time spent
to communicate among several nodes. However, concentrating
the process on one node may overﬂow its memory capacity,
thus resulting in the violation of a QoS requirement (i.e.,
memory occupation). This section presents a QoS adoption
strategy that addresses the operator placement problem.
A. Problem deﬁnition
Operators placement refers to the (close to) optimal selec-
tion of the physical nodes hosting the operators in an event
processing network in order to satisfy a predeﬁned global cost
function. Operators placement is an instance of a more general
task-assignment problem that addresses the (close to) optimal
assignment of m tasks to n processors in a network, which
has an O(nm) complexity. The operator placement problem is
NP-complete.
The operator placement algorithm takes as input a speci-
ﬁcation of a physical network topology T = {N,E}, which
consists in a set of computing nodes N and their links E.
The operator placement also requires a speciﬁcation of the
resources (i.e., memory and CPU) available on each node,
and the latency of communication links. Figure 5 shows an
example of network topology that comprises 9 computing
nodes, each communication link being labeled with its cor-
responding latency. Table III shows the resources availability
on each computing node. In order to specify the exact value
of CPU rate available on each node, we specify a coefﬁcient
that indicates how fast is that node compared to a reference
node for which the CPU coefﬁcient is 1. For example, node
n1 is two times slower than node the reference node n7, and
node n8 is three times faster than node n7
n2 
n3 
n4 
n5 
n6 
n7 
n8 
n9 
n1 
2 
2 
2 
2 
2 
1 
1 
0.5 
Figure 5. A physical network topology
The operator placement algorithm also takes as input an
event processing graph EPG =< θ,A >, which consists in a
set of event streams producers P ∈ θ, a set of stream processing
operators O ∈ θ and a set of event stream consumers C ∈ θ.
A represents the set of edges that connect the operators in
O. Figure 6 shows an example of an event processing graph,
where P1 and P2 are two producers, C1 is a consumer, o1,o2,o3
and o4 are stream processing operators. The operators are
TABLE III. RESOURCES AVAILABILITY ON NETWORK NODES
Node
Memory
CPU coefﬁcient
n1
10
1/2
n2
10
1/2
n3
15
1/2
n4
12
1/2
n5
10
1/2
n6
10
1/2
n7
50
1
n8
60
3
n9
30
2
associated with measures or estimates of demand, such as
the memory and CPU time that each operator expects for
processing a single input event. Table IV shows the estimates
associated to operators o1,o2,o3 and o4.
P2 
P1 
o1 
o2 
o3 
o4 
C1 
Figure 6. An event processing graph
TABLE IV. ESTIMATES OF THE OPERATORS RESOURCES REQUIREMENTS
Operator
Memory
Execution time
o1
8
4
o2
12
5
o3
10
6
o4
20
9
The output of the operator placement algorithm is a map-
ping function λ that associates to each operator the node on the
network topology in which it should be hosted. Figure 7 shows
a possible operator placement, where operators o1,o2,o3 and
o4 are mapped to nodes n6,n4,n8 and n8, respectively.
P1 
P2 
C1 
o1 
o2 
o3 
o4 
2 
2 
2 
2 
2 
1 
1 
0.5 
Figure 7. Example of operators placement.
We assume that each producer and each consumer is
restricted to a permanent physical network node. Operators can
be placed on arbitrary nodes having enough available resources
for their execution. In general, a placement algorithm assigns

489
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
operators to processing nodes in a way that satisﬁes a set of
speciﬁed constraints and optimize a given objective function.
In our setting, the constraint is to ensure that no processing
node is overloaded beyond its memory capacity. The objective
function is the expected end-to-end latency between producers
and consumers.
B. Problem formalization
In order to formally deﬁne the issue of operators placement,
let us consider the notations presented in Table V.
TABLE V. NOTATIONS
Operator
Execution time
o
event processing operator
n
network node
init
initial mapping of producers and consumers
time(o)
execution time of o on a reference node
mem(o)
memory required by operator o
p(o,n)
execution time of o on node n
cpuCoe f(n)
CPU coefﬁcient of node n
amem(n)
memory available on a node n
lat(e)
latency of the network link e
netPath(ni,nj)
the network path between nodes ni and nj
c(a)
latency of the communication between operators
connected by the edge a
λ(o)
the mapped location of operator o
We formalize the operator placement problem as follows:
minimize
λ
cost(λ) = ∑
o∈θ
p(o,λ(o)+ ∑
a∈A
c(a))
(1)
subject to:
λ(o) = init(o), if o ∈ P∪C
(2)
∀n ∈ N ∑
o:λ(o)=n
mem(o) ≤ amem(n)
(3)
where
p(o,n) =
time(o)
cpuCoef(n)
(4)
c(a) =

0
if for a = (oi,oj), λ(oi) = λ(o j)
β(a)
otherwise
(5)
a = (oi,oj), β(a) =
∑
ei∈netPath(λ(oi),λ(o j))
lat(ei)
(6)
Equation (1) states the cost of an operator mapping λ,
which is the estimated end-to-end latency incurred by λ. It
is calculated as the sum of the latency due to event processing
(ﬁrst part) and the latency due to the network communication
(second part). Equation (2) states that the mapping should be
consistent with respect to the initial mapping of producers and
consumers. Equation (3) states that the mapping should be
deﬁned such that no processing node is overloaded beyond
its memory capacity. Equation (4) shows the formula that
allows to compute the processing time of a mapped operator.
Equations (5) and (6) show how to compute the network
latency incurred by inter operator communications. By using
these formulas, we can compute the cost of the operators
mapping presented in Figure 7.
First, note that this mapping is valid, since it does not
violate (2) and (3). Following (4), we compute p(o,λ(o)) for
operators o1 to o4 as 8, 10, 2 and 3, respectively. The latency
of event processing is then 23.
Now let us compute the latency due to inter-operator
communications. For the edge (P1, o1), it equals 2. For the
edge (P2,o2), it also equals 2. For the edge (o1,o3), it equals 1.
For the edge (o2,o3), it equals 2+1, so 3. For the edge (o3,o4)
it equals 0. For the edge (o4,C1), it equals 0.5. The latency
incurred by inter operator communication is then 7.5. Thus,
the total cost of the operator mapping is cost(λ) = 23+7.5 =
30.5.
C. Brute force approach
The operator placement problem can be modelled as a
constraint satisfaction problem (CSP). CSPs are mathematical
problems deﬁned as a set of objects whose state must satisfy
a number of constraints. The constraints that we consider are
deﬁned by (2) and (3), and are similar to the constraint deﬁned
by the bin packing problem, where items of different volumes
must be packed into a ﬁnite number of bins, each with a
given volume. For the purpose of operator placement, the bins
represent the processing nodes, and their size represents their
memory capacity. The items represent the operators, and their
volume represents their memory occupation. We can now rely
on a CSP solver to ﬁnd the set of valid mappings according
to the bin packing constraint. The optimal mapping is the one
with the minimum cost among the set of valid mappings, as
shown in the following algorithm.
OpPlacement(EventProcessingGraph epg, NetworkTopol-
ogy topo, InitialMapping init)
λopt ← null;
solver ← BinPackingSolver();
solver.constructBinPackingConstraint(epg, topo, init);
if solver.hasSolution() then
λ ← solver.nextSolution();
c ← cost(λ);
λopt ← λ;
while solver.hasSolution() do
λ ← solver.nextSolution();
c2 ← cost(λ);
if c2 < c then
c ← c2;
λopt ← λ;
end if
end while
end if
return λopt;
D. Greedy approach
The OpPlacement algorithm browses the whole space of
correct solutions (with respect to the bin packing constraint)
in order to ﬁnd the optimal one. Then, it follows a brute
force approach. Because of its exponential complexity, the
OpPlacement algorithm fails to produce a result in an ac-
ceptable period of time for large event processing graphs and
network topologies. In order to deal with such large inputs, we
propose a greedy approach for operator placement. The idea
of this approach is to incrementally map parts of the event
processing graph on speciﬁc parts of the network topologies,
combining found solutions, till all operators are mapped. There
are two main aspects that have to be considered here in order
to apply this approach. First, it should be speciﬁed how to

490
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
compute parts of the event processing graph. Then, it should
be speciﬁed how to compute the part of the network topology
where a computed part of the event processing graph should
be mapped. In order to do that, we rely on the following
hypothesis on event processing graph and network topology
respectively:
•
Hypothesis 1: there is one consumer for each input
event processing graph. This reduces the complexity of
the problem, since considering many consumers in the
event processing graph will lead to multi optimization
with respect to each consumer, especially when some
consumers share the same part of the event processing
graph.
•
Hypothesis 2: the network topology has a tree struc-
ture. This is consistent with electrical grid topologies,
which are generally designed under a tree structure.
1) Computing subgraphs of the event processing graph:
Given the original event processing graph, a subgraph will
consist of intermediates operators that are reachable from a
given producer to the consumer c. Therefore, they will be the
same number of subgraph than the number of producers in
the original graph. In the following, we assume the existence
of a function subgraph(EPN,Pi) that computes the subgraph
associated to the producer Pi. For example, considering the
event processing graph in Figure 8, the result of the function
subgraph(EPN,P2) is the subgraph that consists of the set
of nodes θ′ = {P2,o2,o3,o4,c} and the set of edges A′ =
{(P2,o2),(o2,o3),(o2,o4),(o3,c),(o4,c)}.
2) Computing a subgraph of the network topology: Once
we compute a subgraph subgrap(EPN,Pi) of an event pro-
cessing graph for a given producer Pi, we need to compute the
subgraph of the network topology where it should be mapped.
In order to do that, we consider the mapped location of the
producer Pi and the one of consumer c as deﬁned by the initial
mapping init. The resulting subgraph is the one that includes
the nodes in the path between init(Pi) and init(c). Since the
network topology is a tree, there is only one path between
init(Pi) and init(c). Then, the size of the subgraph is of the
order of O(log(n)), where n corresponds to the number of
nodes in the original network topology. We assume that this
subgraph is computed by the function subgraphTopo(T,ni,nj).
P0 
P1 
o2 
o3 
o4 
o1 
C 
P2 
Figure 8. Event processing graph
For example, considering the network topology in Figure
9, and assuming that the producer P2 and the consumer c are
initially mapped at nodes n6 and n10, respectively, the result
of the function subgraphTopo(T,n6,n10) is the subgraph that
consists in the set of nodes N′ = {n6,n8,n9,n10} and the set
of edges E′ = {(n6,n8),(n8,n9),(n9,n10)}.
n5 
n2 
n6 
n7 
n8 
n9 
n10 
n3 
200 
200 
100 
100 
100 
100 
25 
n0 
n1 
n4 
200 
200 
200 
Figure 9. Network topology
3) Greedy algorithm: The greedy version of the algorithm
is presented as follows.
OpPlacementGreedy(EventProcessingGraph epg, Network-
Topology topo, InitialMapping init)
λ ← init;
for each producer Pi in epg do
epg′ ← subgraph(epg,Pi);
topo′ ← subgraphTopo(topo,init(Pi),init(c));
λ′ ← OpPlacement(epg′,topo′,λ);
if λ′ != null then
λ ← λSλ′;
for each operator o in epg′ do
if o is not mapped then
mark o as mappped;
update the availble memory in λ(o);
end if
end for
else
return null;
end if
end for
return λ;
The OpPlacementGreedy algorithm achieves local opti-
mization for each computed subgraph of the original event
processing graph. At each step, the solution is combined with
the previously found solutions and the result is used like
the initial mapping for others iterations. As it ﬁnds solutions
during subgraph mappings, it marks all non-mapped operators
as mapped, and continues till all subgraphs are mapped. If the
mapping of a subgraph of the original event processing graph
fails, the algorithm stops and the mapping is considered as
failed.
VII.
DEALING WITH EVENT PRIORITY
The QoS requirements concerning memory occupation and
latency have already been addressed by the operators place-
ment algorithm presented in the previous section. However,

491
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
the event priority still remains for being attended, this section
presents a proposal to deal with this requirement.
As stated in Section IV, any instance of an event type has
a priority attribute to which an integer value must be assigned
(See Table I). The priority value of a simple event is deﬁned
by its producer, whereas the priority value of a composite
event is computed as the maximum priority of its operand
events. The higher is the priority value associated to an event
instance, the higher is the event priority. Events are inserted
into input and output queues according to their priority. Input
and output queues are priority-based FIFO structures with
limited capacity. The priority relation ≺ is deﬁned as follows:
ei ≺ e j → ei.priority < ej.priority∨ei.priority = e j.priority∧
e j.detectionTime ≤ ei.detectionTime
The ≺ relation ensures that high priority events will be no-
tiﬁed early compared to less priority events. As consequence,
the notiﬁcation of a less priority event can be postponed for
a signiﬁcant amount of time. This issue, that we refer to as
the starvation problem, is stated more precisely as follows: an
event in the output queue may suffer the starvation problem
with respect to the notiﬁcation step, if after a signiﬁcant
number of notiﬁcations k, the event is still in the output queue,
due to its priority that is less compared to that of inserted
events.
To solve the starvation problem, we associated to each
event in the output queue a time to live value ttl that is
initialized to an integer k. At each notiﬁcation step, the ttl
value of each event decreases and the events for which the ttl
value equals zero are notiﬁed. For the event priority deﬁned
by applications to be really effective, there are also some
assumptions that have to be made on the underlying layers of
the event processing runtime. More precisely, the middleware
layer must provide a FIFO delivery mechanism, allowing to
convey events while preserving their notiﬁcation order such as
in [24] [25].
VIII.
EXPERIMENTAL EVALUATION
We focused our experiments to the evaluation of the
operator placement algorithm. We developed our algorithm
using Java programming language. We rely on the Jacop
CSP solver [26] to implement the bin packing constraint.
For our experiments, we deﬁned different types of devices
(smart meters, data concentrators, sensors, etc.) with different
resource proﬁles. A resource proﬁle is deﬁned by a memory
capacity and a CPU coefﬁcient. Based on this, we generated
network topologies with various sizes, and containing devices
with different deﬁned proﬁles. The latency of the communi-
cation links among the different devices was ﬁxed too. We
followed the same idea with operators. We deﬁned different
kind of operators with memory and CPU time requirements.
We generated event processing graphs of different sizes, and
comprising the speciﬁed operator types.
We conducted a ﬁrst experiment to compare the results of
the greedy algorithm with those of the brute force algorithm.
More precisely, we focused on the algorithm execution time,
and the quality of resulting operator placement, which is
captured by its cost. We generate 20 different inputs for
the algorithm, each consisting in a network topology and
an event processing graph. Each network topology consisted
in 15 nodes, and the number of operators in each event
processing graphs ranged from 7 to 10. For each input, we
executed the OpPlacement algorithm (brute force) and the
OpPlacementGreedy. We choose to run this experiment over a
small network topology and small event processing graphs in
order to make sure that the optimal solution can be calculated.
We compared ﬁrst the execution time of the algorithms.
The result is depicted at Figure 10, which presents for each
of the 20 executions (x axis), the time duration (y axis)
of the brute force algorithm, and the time duration of the
greedy algorithm. Clearly, the greedy algorithm performs faster
than the brute force algorithm, being in average one order of
magnitude faster.
0 
200 
400 
600 
800 
1000 
1200 
1400 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 
Time dura*on 
Execu*on n°  
Time brute force  
Time Greedy 
Figure 10. Operator placement execution time: comparison between brute
force and greedy algorithm
Figure 11 compares the cost of operator placement com-
puted by the greedy algorithm with the optimal one, computed
by the brute force algorithm. We can observe that the cost
of the operator mapping computed by the greedy algorithm
is generally close to the optimal one. Even more interesting,
for this experiment, the accuracy of the greedy approach
(computed as the percentage of optimal solutions that were
found) was 55%.
0 
200 
400 
600 
800 
1000 
1200 
1400 
1600 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 
Cost  
Execu+on n° 
Cost brute force 
Cost Greedy 
Figure 11. Cost of operator placement: comparison between brute force and
greedy algorithm
We conducted another experiment in order to test how the
greedy algorithm behaves on large event processing graphs.
We execute the algorithm over a network topology consisting
in 50 nodes. The size of event processing graphs ranged from
15 to 110 nodes. It is worth to mention that the brute force
approach was not able to compute the optimal result here, due
to its time complexity. Figure 12 presents the result of this
experiment. We notice that the time duration of the greedy
algorithm does not necessarily increases when the size of
the event processing graph growths. In fact, the structure of
the event processing graph is another factor that impacts the
performance of the algorithm. In event processing graphs for
which operators are highly connected, the subgraph associated
to a producer can have a high number of operators. Therefore,
the time to compute the mapping of that subgraph can be
longer. For example, in the experiment, the event processing
graphs having size 45 and 60 were dense, this explains the
peaks we observed in the duration time.

492
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
0 
20000 
40000 
60000 
80000 
100000 
120000 
140000 
15 
20 
25 
30 
35 
40 
45 
50 
55 
60 
65 
70 
75 
80 
90 100 105 110 
Time dura*on 
Size of event processing graph 
Time Greedy 
Time Greedy 
Figure 12. Scale up of the greedy algorithm
IX.
CONCLUSION
This paper shows that monitoring of smart grids can be
done using an event based approach where event streams
generated by distributed sources are processed by distributed
event processing units. Such units may produce complex
events indicating situations of interest that are notiﬁed to
consumers. Since the invocation of business, critical processes
is now triggered by events. The QoS of the event processing
infrastructure becomes a key issue. We have identiﬁed key
QoS dimensions relevant to smart grids, namely event priority,
memory occupation and notiﬁcation latency. We proposed a
brute force algorithm for deploying event stream operators in a
network topology, considering memory occupation and latency.
To overcome the time complexity of the brute force approach,
we propose a greedy algorithm for operator placement. The
experiments shown that, while performing faster than the brute
force approach, the greedy algorithm provides good quality
solutions. We also proposed a strategy to deal with event
priority.
We are currently developping a simulation platform to
demonstrate our approach. The simulation platform allows
to represent a smart grid topology and an event processing
network. In addition, it implements the proposed strategies for
QoS adoption. On the other hand, we are working on the
speciﬁcation of a real smart grid use case. The simulation
platform will leverage the implementation and validation of
the proposed use case.
Network occupation is another QoS dimension relevant to
smart grids that was not addressed in this work. As future
work, it would be interesting to integrate network occupation
as another constraint in our model. The proposed QoS based
event stream processing approach can be associated with
a language for describing complex event composition with
related QoS. This will also be studied in future works.
ACKNOWLEDGMENT
This work was carried out as part of the SOGRID project
(www.so-grid.com), co-funded by the French agency for En-
vironment and Energy Management (ADEME) and developed
in collaboration between participating academic and industrial
partners.
REFERENCES
[1] O. Epal, C. Collet, and G. Vargas, “Towards a Quality
of Service Based Complex Event Processing in Smart
Grids,” in Proceedings of the 5th International Conference
on Smart Grid, Green Communication and IT Energy-
aware Technologies (ENERGY). Internatonal Academy,
Research and Industry Association, May 2015, pp. 1–4.
[2] G. Cugola and A. Margara, “Raced: An adaptive middle-
ware for complex event detection,” in Proceedings of the
8th International Workshop on Adaptive and Reﬂective
Middleware, ser. ARM ’09. New York, NY, USA: ACM,
2009, pp. 5:1–5:6.
[3] “Homepage of Esper,” 2015, URL: http://esper.codehaus.
org/ [accessed: 2015-03-27].
[4] “Homepage of TIBCO StreamBase,” 2015, URL: http:
//www.streambase.com/ [accessed: 2015-03-27].
[5] D. Gyllstrom, E. Wu, H.-J. Chae, Y. Diao, P. Stahlberg,
and G. Anderson, “SASE: complex event processing over
streams,” in Proceedings of the 3rd Biennial Conference
on Innovative Data Systems Research (CIDR), 2007, pp.
407–411.
[6] “Homepage of Oracle CEP,” 2015, URL: http://www.
oracle.com/ [accessed: 2015-03-26].
[7] A. J. Demers, J. Gehrke, B. Panda, M. Riedewald,
V. Sharma, and W. M. White, “Cayuga: A general
purpose event monitoring system.” in Proceedings of
the 5th Biennial Conference on Innovative Data Systems
Research (CIDR).
www.cidrdb.org, January 2007, pp.
412–422.
[8] D. Luckham, “Rapide: A Language and Toolset for
Simulation of Distributed Systems by Partial Orderings
of Events,” Stanford University, Tech. Rep., 1996.
[9] O. Saleh and K.-U. Sattler, “Distributed complex event
processing in sensor networks,” in Proceedings of the
2013 IEEE 14th International Conference on Mobile
Data Management - Volume 02, ser. MDM ’13.
IEEE
Computer Society, June 2013, pp. 23–26.
[10] P. R. Pietzuch, B. Shand, and J. Bacon, “A framework for
event composition in distributed systems,” in Proceedings
of the ACM/IFIP/USENIX International Conference on
Middleware, ser. Middleware ’03, vol. 2672.
Springer-
Verlag New York, Inc., 2003, pp. 62–82.
[11] “Storm: Distributed and fault-tolerant real-time com-
putation,” 2013, URL: http://storm.incubator.apache.org/
[Accessed: 2015-11-10].
[12] S. Behnel, L. Fiege, and G. M¨uhl, “On quality-of-service
and publish-subscribe,” in Proceedings of the Interna-
tional Conference on Distributed Computing Systems,
2006, pp. 1–6.
[13] S. Appel, K. Sachs, and A. Buchmann, “Quality of
service in event-based systems,” in Proceedings of the
CEntral EURop Workshop (CEUR), vol. 581, 2010, pp.
1–5.
[14] Y.-h. Jeon, “QoS Requirements for the Smart Grid Com-
munications System,” Journal of Computer Science and
Network Security, vol. 11, no. 3, 2011, pp. 86–94.
[15] W. Sun, X. Yuan, J. Wang, D. Han, and C. Zhang, “Qual-
ity of Service Networking for Smart Grid Distribution
Monitoring,” in Proceedings of the 1st IEEE International
Conference on Smart Grid Communications, 2010, pp.
373–378.
[16] H. Gjermundrø d, D. E. Bakken, C. H. Hauser, and
A. Bose, “GridStat: A ﬂexible QoS-managed data dis-
semination framework for the power grid,” IEEE Trans-
actions on Power Delivery, vol. 24, no. 1, 2009, pp. 136–
143.

493
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[17] W. Wang, Y. Xu, and M. Khanna, “A survey on the
communication architectures in smart grid,” Computer
Networks, vol. 55, no. 15, Oct. 2011, pp. 3604–3629.
[18] Smart Grid Coordination Group, “Smart grid reference
architecture,” 2012, URL: http://ec.europa.eu/ [accessed:
2015-03-27].
[19] G. Cugola and A. Margara, “Processing ﬂows of infor-
mation: From data stream to complex event processing,”
ACM Computing Surveys, vol. 44, no. 3, 2012, pp. 15:1–
15:62.
[20] L. Perrochon, W. Mann, S. Kasriel, and D. C. Luckham,
“Event Mining with Event Processing Networks,” pp.
474–478, 1999.
[21] G. Sharon and O. Etzion, “Event-processing network
model and implementation,” IBM Systems Journal,
vol. 47, no. 2, 2008, pp. 321–334.
[22] “Event processing glossary
version 2.0,” 2011, URL:
http://www.complexevents.com [accessed: 2015-03-27].
[23] P. T. Eugster, P. A. Felber, R. Guerraoui, and A.-M.
Kermarrec, “The many faces of publish/subscribe,” ACM
Computing Surveys, vol. 35, no. 2, 2003, pp. 114–131.
[24] G. V. Chockler and R. Vitenberg, “Group Communication
Speciﬁcations : A Comprehensive Study,” ACM Comput-
ing Surveys, vol. 33, no. 4, 2001, pp. 427–469.
[25] A. Malekpour, A. Carzaniga, G. T. Carughi, and F. Pe-
done, “Probabilistic FIFO Ordering in Publish/Subscribe
Networks,” in Proceedings of the 10th International Sym-
posium on Network Computing and Applications.
Ieee,
augst 2011, pp. 33–40.
[26] “Homepage of JaCoP,” 2015, URL: http://jacop.osolpro.
com [accessed: 2015-03-26].

