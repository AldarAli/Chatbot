Possibility of Gait Analysis with MediaPipe and Its Application in Evaluating the Effects 
of Gait-assist Devices 
 
 
 
Yasutaka Uchida 
Dept. of Life Science 
Teikyo University of Science 
Adachi-ku, Tokyo, Japan 
e-mail: uchida@ntu.ac.jp 
Tomoko Funayama 
Dept. of Occupational therapy 
Teikyo University of Science 
Uenohara-shi, Yamanashi, Japan 
e-mail: funayama@ntu.ac.jp 
 
Yoshiaki Kogure 
Professor Emeritus 
Teikyo University of Science 
Adachi-ku, Tokyo, Japan 
e-mail: kogure@ntu.ac.jp 
 
 
Abstract—The use of free software in motion analyses in the 
medical and healthcare fields could contribute to the collection 
of improved data through rehabilitation and daily health 
management. The possibility of gait analyses using moving 
images is examined using the free software, MediaPipe. As a 
preliminary experiment for applying this software in the 
rehabilitation field, we attempt a timed up-and-go test and 
obtain detailed ankle trajectories. Additionally, considering the 
limitations of the camera installation during measurement, we 
examine the differences in the camera position when capturing 
the gait characteristics. Consequently, the characteristics 
captured were almost similar, although some discrepancies 
were observed between the data from the front and oblique 
directions. The detection of the ankle angle was possible. 
However, a motion analysis using the gait velocity will be 
required for the correct placement of objects. We analyzed the 
data obtained from the application of the Orthobot, a gait aid 
device, for the measurement of gait. The detection of the 
differences in gait before and after the application of the 
Orthobot would significantly contribute to the gait assessment. 
The data were compared with those obtained using ORPHE 
ANALYTICS. Because MediaPipe only provides relative 
coordinate values for 33 different target body parts, data 
interpretation requires correction. However, it proved to be a 
tool that provided a lot of information by allowing researchers 
to incorporate the necessary formulas. 
 
Keywords-Gait analysis; MediaPipe; detection of ankle 
angle; health care; walking aid device. 
 
I. 
 INTRODUCTION 
The measurement of the lower limb function is useful in 
assisting the prevention of falls. To date, medical and 
welfare professionals such as rehabilitation and nursing care 
staff have been responsible for providing support to prevent 
falls. In recent years, devices for measuring the lower limb 
function have become widespread. However, the equipment 
used in rehabilitation medicine and sports requires detailed 
data and specialized knowledge of the equipment operations. 
Decisions related to health conditions in daily life are 
difficult to make. Lower limb dysfunction can lead to 
serious accidents, such as falls. Stumbling and falling 
accidents are common social issues [1]–[8]. 
Wearable devices are now applied in daily life. They can 
collect various information, such as a runner's running route 
and speed, as well as their pulse rate. This information can 
be used as management records by connecting it to the 
Internet. Daily health-related data managed by servers can 
be very useful for the elderly. Internet of Things (IoT) 
devices have been developed for many applications. An IoT 
device can help prevent falls and stumbling by measuring 
the ankle joint data. Previously, we measured the gait of 
hemodialysis patients; however, the analysis required 
specialized knowledge of machine learning [9]–[12]. 
MediaPipe is a free software from Google. Numerical 
data related to faces can be obtained using this software, 
which specializes in facial data and poses corresponding to 
the entire body. It is also possible to display three-
dimensional (3D) skeletons from two-dimensional (2D) 
detection on a screen. The ability to see images of the 
skeleton as it is projected onto the physique can be easily 
implemented in rehabilitation facilities [13]–[17]. 
This software provides 3D coordinates that increase its 
effectiveness. Specifically, if the ankle angles can be 
obtained from images, it could be a promising alternative 
for determining physical condition changes based on the 
experience of physical and occupational therapists. Long-
term ankle angle data would also be useful for the early 
44
International Journal on Advances in Life Sciences, vol 15 no 1 & 2, year 2023, http://www.iariajournals.org/life_sciences/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

detection of physical condition changes due to illness or 
other causes. 
Image-based video analyses have long been used in 
rehabilitation and other medical and healthcare fields, such 
as the joint research field. Despite the ongoing research, it is 
impossible to state that image analysis is applied in daily 
rehabilitation support for patients. The demonstration of the 
application of video analysis in rehabilitation at a low cost, 
would cause many people to use it [18]–[22]. 
Therefore, we examined the possibility of gait analysis by 
video using MediaPipe. Motion analysis using free software 
could lead to the rapid spread of video analysis in the 
medical and healthcare fields. 
We adopted this software to conduct a basic analysis of 
how gait changes using Orthobot, an assistive device for 
walking that was not considered previously, to determine 
the extent to which it can be applied in the field of 
rehabilitation [23].  
If the range of motion of the ankle joint is narrow, even in 
the lower limbs, the toes do not rise, making it is easy to 
stumble and fall. We inferred that walking involved not only 
the lower limb functions but also the entire body. 
Considering the gait from an inverted pendulum model, 
an initial experiment was conducted to determine how the 
effect of wearing the assistive device would manifest and 
whether the effect would be sustained by examining the 
change in the neck angle from the direction perpendicular to 
the center of the body [24][25]. 
This research was approved by the Ethics Committee of 
Teikyo University of Science. 
 
II. 
EXPERIMENTS 
The subjects were two men in their 60s and 70s, 
respectively. The two gait events differed in terms of the 
ankle restrictions. The supporter restricted the ankle joint 
motion. For the elderly patient experience set, the subject 
wore glasses that did not restrict the ankle joint motion.  
The corresponding locations of the 33 landmark data 
locations on the body output by MediaPipe are listed in 
Table I. 
We used arrays with previously reported pressure 
sensors to compare the accuracy of the comma-separated 
value (CSV) data obtained from MediaPipe skeletal 
certification. The resistance of the pressure sensors changed 
depending on the pressure, ranging from 100 to 1 MΩ. A 1 
kΩ resistor was connected in series with this sensor, and the 
voltage change of the resistor was used as the input signal. 
Each sensor measured the voltage at 1 kHz. Eight sensors 
were arranged parallel to the travel direction. The pressure 
sensor data were transferred to an Arduino Mega 2560 R3 
connected to a personal computer. The connection between 
the sensors and the Arduino is shown in Figure 1. 
 
 
 
TABLE I. Pose Landmark of MediaPipe. 
 
Pose Landmark 
0. nose 
1. left_eye_inner 
4. right_eye_inner 
2. left_eye 
5. right_eye 
3. left_eye_outer 
6. right_eye_outer 
7. left_ear 
8. right_ear 
9. mouth_left 
10. mouth_right 
11. left_shoulder 
12. right_shoulder 
13. left_elbow 
14. right_elbow 
15. left_wrist 
16. right_wrist 
17. left_pinky 
18. right_pinky 
19. left_index 
20. right_index 
21. left_thumb 
22. right_thumb 
23. left_hip 
24._right_hip 
25. left_knee 
26. right_knee 
27. left_ankle 
28. right_ankle 
29. left_heel 
30. right_heel 
31. left_foot_index 
32. right_foot_index 
 
The output signals of sensor numbers A0–A7 and the 
distance between each sensor were used to calculate the 
walking speed. 
 
 
Figure 1. Connection of sensors and Arduino. 
 
A    Accuracy check of CSV data outputed by MediaPipe  
We evaluated the possibility of using CSV data output 
by MediaPipe to perform gait analysis considering the 
elderly patient experience set. This measurement indicates 
the accuracy of the quantification of the ankle position. 
Because the assessment was performed during gait, we used 
VCC
P0
Sensor : P0
1k
Mega2560
+5V
A0
A7
 
45
International Journal on Advances in Life Sciences, vol 15 no 1 & 2, year 2023, http://www.iariajournals.org/life_sciences/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

images from the timed up-and-go measurement, which is 
used as a basis for the evaluation of falls experienced by the 
elderly, to conduct the analysis in MediaPipe. 
Figure 2 shows the trajectory of the timed up-and-go 
measurements. The trajectory was similar to that of the left 
ankle movement, which was assumed from being seated in 
the chair to approximately 3 m away and being seated in the 
chair again. A detailed ankle trajectory was obtained. The 
video analysis of the timed up-and-go test confirmed the 
maintenance of the integrity of the specifications [24]–[28]. 
 
Figure 2. Trajectory of timed up-and-go analyzed by MediaPipe. 
 
B       Results from the front angle 
Gait videos taken from the front under two different 
conditions, without motion restriction and with motion 
restricted by a knee supporter, were analyzed using 
MediaPipe. Figure 3 shows the skeleton analysis of the 
motion without/with restrictions using a video from the 
front. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3. Skeleton analysis of motion (a) without and (b) with restrictions 
using video from front. 
 
The values of z in Figure 4, which represent the heights 
of the left and right ankle joints, were plotted against the 
presence and absence of motion restriction, respectively.  
It can be deduced that the time that the heel is on the 
floor is short because the average of the integrated values of 
the z values of the foot that applies the restriction is large. 
 
 
 
Figure 4. Values of z that represent the ankle height. 
 
C         Results from an oblique upward angle  
In this analysis, the image was obtained from an oblique 
upward angle to enhance the z-axis length ratio. Peaks 
corresponding to the left and right toes were also observed. 
Differences owing to the angle of filming were analyzed 
from the images obtained from the front and diagonally 
above the angles. 
Figure 5 shows the image without/with restrictions 
using the video from an oblique angle. The sheet on the 
floor consisted of the pressure sensors described in Figure 1. 
The separately conducted results of the ankle angle 
measurements indicate that the subjects’ left and right feet 
have different flexibilities. The results are presented in 
Table II. The left ankle joint was more restricted than the 
right ankle joint, but there was no significant left-right 
difference. Therefore, we considered the ankle-to-knee and 
ankle-to-toe lines as vectors and obtained the angle between 
them from the inner product. The images were captured in 
two different ways while the subjects were walking and then 
analyzed. 
 
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.000
0.100
0.200
0.300
0.400
0.500
0.600
z-axis
Time[s]
R
L
No restriction
0.000
0.050
0.100
0.150
0.200
0.250
0.300
0.000
0.200
0.400
0.600
0.800
1.000
1.200
1.400
z-axis
Time[s]
R
L
Restriction
 
satrt
Returning 
point
x axis
y axis
z axis
 
 
46
International Journal on Advances in Life Sciences, vol 15 no 1 & 2, year 2023, http://www.iariajournals.org/life_sciences/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 5. Skeleton analysis of motion (a) without and (b) with restrictions 
using video from oblique upward angle. 
 
 
TABLE II. Range of Motion. 
 
Direction of motions 
R / L Side 
Joint angle [deg] 
Plantar flexion 
R 
60 
L 
50 
Dorsi flexion 
R 
10 
L 
5 
 
 
 
 
Figure 6. Results of ankle angle from the front and oblique upward angle 
 
Based on these results, the ankle angles that significantly 
affected gait were determined. The results of this analysis 
are shown in Figure 6. The changes in the left and right 
ankle angles were almost identical with and without motion 
restriction. However, in both cases, the change in the right 
ankle angle was smaller. It is unclear whether this was a 
feature of the subject's gait or a software problem. Further 
studies with different subjects are necessary to determine 
the cause. 
 
D        Gait speed 
The gait speed was examined. Because the coordinates 
are those of the projection from the camera, correction was 
required [31]–[34]. Although it is best to correct the 
coordinates from a 3D viewpoint, in this case, the correction 
is based on the walking trajectory. Therefore, we compared 
the walking speeds based on measurements for which 
specific lengths were known. 
For the gait speed, we compared the data from the 
camera with the data from the pressure sensor and 
determined the points that should be analyzed to obtain 
accurate results based on the software. We inferred that it 
would be difficult to determine the walking speed when 
shooting from an oblique direction because the screen was 
moved in an oblique direction. However, data could be 
 
47
International Journal on Advances in Life Sciences, vol 15 no 1 & 2, year 2023, http://www.iariajournals.org/life_sciences/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

obtained for comparison if the same conditions were used. 
The problem with the images captured from the front was 
that the size of the subject varied depending on the 
measurement data point. 
Therefore, we considered the part of the image that 
moved as slightly as possible on the screen, which was the 
shoulder area, because it was close to the central part. 
Figure 7 shows the plot of the right shoulder, which had the 
largest slope. The obtained value was approximately 0.17, 
and this value was equal to 0.67 km/h.  
 
 
Figure 7. Right shoulder position as a function of time. 
 
Figure 8 shows a 3D display of the trajectory of the 
right shoulder position. Because the slope of the change in 
the right shoulder position is approximately 45o, it was 
deduced that using the correction value for the direction of 
motion on the screen, a walking speed of 1.4 km/h, which is 
almost the same as the 1.3 km/h obtained from the mat, 
could be obtained. 
 
 
 
 
Figure 8. 3D display of the trajectory of the right shoulder position. 
 
E        Orthobot 
The Orthobot employed in this study is a gait-assist 
device that supports walking by estimating the gait phase 
from the thigh posture and generating torque. The Orthobot 
can be attached to a conventional knee-ankle-foot orthosis 
to control an individual's knee. 
 
 
 
Figure 9. Photograph of the Orthobot attached. 
 
 
 (a) 
 
 (b) 
 
 (c) 
Figure 10. Results of calculated knee angle from MediaPipe.  
48
International Journal on Advances in Life Sciences, vol 15 no 1 & 2, year 2023, http://www.iariajournals.org/life_sciences/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

It automatically assists in the flexion and extension of the 
knee joint at the appropriate time. The motion state of the 
leg wearing the aid was measured using drone measurement 
technology by considering the wearer's swing phase as a 
pendulum. The torque generated was calculated by 
estimating the gait phase from the thigh posture to assist 
walking. Figure 9 shows a photograph of the attached 
Orthobot. 
Orthobots can be attached to general walking aids and 
are considered highly versatile. The driving device is 
located in the knee portion, and signals from a controller 
attached to the back portion of the device move the assistive 
device, allowing the paralyzed person to experience walking 
motion, thereby restoring the function. 
Figures 10(a)–(c) show the changes in the knee joint 
during walking before, during, and 5 min after wearing the 
Orthobot, respectively. The change in the angle of nearly 
100° is due to the change in direction. The view of the knee 
joint angle is not significant during walking, and the 
machine assists with the swing of the knee. Five minutes 
after use, the change in the knee joint decreases. 
 
 F       Neck tilt angle for the subject wearing the walking 
assist device 
Walking affects the entire body and not just the lower 
extremities. In this section, we focus on the head and neck 
parts of the body. We used an inverted pendulum model for 
walking. We calculated how much the neck part was tilted 
from the axis of the center of the torso during walking, 
based on the coordinate information obtained from 
MediaPipe. As shown in Figure 11, the angle of the neck 
was defined as the angle between the line connecting the 
coordinates of the midpoints of the left and right shoulders 
and the coordinates of the midpoints of the left and right 
hips, and the line connecting the coordinates of the 
midpoints of the left and right shoulders and the tip of the 
nose, calculated using the formula for the interior angle of a 
vector.  
The 
analysis 
software 
ORPHE 
ANALYTICS 
manufactured by ORPHE was also used to obtain the neck 
tilt angle, which was used for confirmation. The neck angle 
obtained from this software depends on the direction of gait; 
therefore, absolute values are used because they are positive 
or negative depending on the gait. 
 
 
 
Figure 11. Neck angle definition. 
 
Figure 12 shows the results of the analysis when walking 
without an aid. It also shows changes in the left and right 
ankles. The angle of the neck corresponds to the left-side 
axis, whereas the angles of the left and right heels 
correspond to the right axis. The measurement started before 
the movement from the starting point; hence, the walk 
began facing left approximately 2 s later. At approximately 
10 s, the direction changed 180° to a rightward walk. The 
data started with a leftward walk. At approximately 10 s, the 
data shows a 180-degree turn around and a rightward walk. 
Neck movement during walking is in the form of a slowly 
changing wave with a higher-frequency component. The 
orange line in the figure shows the left heel change, whereas 
the gray line shows the right heel. The values are larger at 
farther distances from the camera. The vertical movement of 
the heel changed in response to the neck tilt angle signal. 
 
 
Figure 12. Results of the analysis when walking without aid. 
 
49
International Journal on Advances in Life Sciences, vol 15 no 1 & 2, year 2023, http://www.iariajournals.org/life_sciences/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 13. Results obtained when a walking aid was used. 
 
 
Figure 14. Results obtained approximately 5 min after using aid. 
 
Figure 13 shows the results obtained when a walking aid 
was used. The tilt angle of the neck is also indicated by the 
blue line. 
Figure 14 shows the measurement taken approximately 
5 min after the aids were removed. This is a short time 
measurement because MediaPipe could not continuously 
capture the arm movements during this measurement, and 
the data stopped at 20 s. 
 
 
 
Figure 15. Change in neck tilt obtained using ORPHE ANALYTICS. 
 
Figure 16. Absolute values of neck tilt before Orthobot use. 
 
 
Figure 17. Absolute values of neck tilt during Orthobot use. 
 
 
Figure 18. Absolute values of neck tilt 5 min after Orthobot use. 
 
Figure 15 shows the change in the neck tilt obtained 
using the ORPHE ANALYTICS. This measurement was 
performed before the use of the Orthobot. 
Figure 16 plots the absolute values for comparison with 
MediaPipe. This measurement was also conducted before 
the use of the Orthobot. Figure 17 shows the tilt of the neck 
while using the Orthobot. Figure 18 shows the measured 
neck tilt approximately 5 min after using the Orthobot. In 
Figure 16, the high-frequency signal with a relatively small 
amplitude is superimposed on the low-frequency signal as in 
the calculation with MediaPipe. For assisted aids, the high 
frequencies with large amplitudes have a noticeable number 
component. This trend is also observed in Figure 18, which 
 
50
International Journal on Advances in Life Sciences, vol 15 no 1 & 2, year 2023, http://www.iariajournals.org/life_sciences/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

shows 
results 
of 
approximately 
5 
min 
after 
the 
supplementation with the Orthobot, with large amplitude 
high-frequency components. 
 
 G       Discrete Fourier-transformation analysis for stride 
variability 
The risk of falling is closely related to stride variability. 
Therefore, we focused on the variability and examined the 
frequency intensity using discrete Fourier-transformation 
(DFT) analysis. Figures 19-22 show the analysis results 
from the MediaPipe software, and Figures 23-25 show those 
from the ORPHE ANALYTICS. The DFT spectra were 
measured before, during, and 5 min after wearing the 
Orthobot walking assist device. Only 22 s of signal were 
used for the DFT evaluation, until the MediaPipe lost sight 
of a landmark point and stopped working properly when 
measured 5 min after removing the Orthobot.  
The spectra of the neck angle changes before, during, 
and after using the assistive device obtained from ORPHE 
ANALYTICS are shown in Figures 23-25, with large peaks 
obtained in the low-frequency region below 0.5 Hz. The 
low-frequency peaks were particularly strong in the case of 
Figure 23 without the assistive device. The peak at 
approximately 1.6  
 
 
 
Figure 19. Spectrum before using Orthobot. 
 
Figure 20. Spectrum when using Orthobot. 
 
Figure 21. Spectrum after using Orthobot 
 
Figure 22. Sepctrum of heel using Orthobot. 
 
 
Figure 23. Spectrum before using Orthobot analyzed data obtained by 
ORPHE ANALYTICS. 
 
 
Figure 24. Spectrum when using Orthobot analyzed data obtained by 
ORPHE ANALYTICS. 
 
 
 
 
 
51
International Journal on Advances in Life Sciences, vol 15 no 1 & 2, year 2023, http://www.iariajournals.org/life_sciences/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
 
Figure 25. Spectrum of heel using the Orthobot analyzed data obtained by 
ORPHE ANALYTICS. 
 
Hz decreased after the use of the assistive device, which 
may be due to the characteristics of the subject's gait. 
 
III. 
DISCUSSION 
A     Accuracy check of CSV data outputed by MediaPipe 
The analysis using MediaPipe reproduced the left ankle 
trajectory in the timed up-and-go measurements, as shown 
in Figure 2. The z-axis values corresponding to the vertical 
motion are small owing to the screen settings; therefore, the 
z-axis values are emphasized. Consequently, it is necessary 
to make a prior reference measurement and correction for an 
accurate evaluation. Detailed ankle trajectories were 
obtained. Video analysis of the timed up-and-go test 
confirmed that the specifications remained consistent.  
B     Skeleton analysis of without/with restrictions using 
video from front and oblique upward angle 
As shown in Figures 4 and 6, it was possible to 
determine the ankle angle as gait condition data, although 
we did not calculate this timed up-and-go measurement. 
Comparing the independently measured range-of-motion 
angle data of the ankle joint and comparative ankle joint 
range-of-motion angles obtained from the video, slight 
differences were observed owing to the camera angles. The 
angular change in the right foot was almost the same, 
regardless of the camera angle. In contrast, the angular 
change in the left leg tended to be smaller. For the subject’s 
gait, another measurement showed that the joint change in 
the left foot was smaller than that in the right foot. Further 
investigation is required in another experiment with a 
different subject. 
C     Gait speed 
We considered the parts of the image that were 
considered to move as slightly as possible on the screen. In 
this image, the shoulders were close to the center of the 
image, so this was considered. In the walking speeds 
obtained 
by 
walking 
on 
the 
mat, 
differences 
of 
approximately 2.1 km/h and 1.3 km/h were obtained with 
and without the motion restriction, respectively. The values 
obtained from MediaPipe, however, were approximately an 
order of magnitude lower. 
Although it is desirable to correct the coordinates from 
a three-dimensional perspective, in this case, the correction 
was based on the gait trajectory. Therefore, we compared 
the walking speeds based on measurements with known 
specific lengths. We examined the points that could be 
analyzed to obtain accurate results based on software 
principles. We inferred that it would be difficult to 
determine the gait speed when shooting from an oblique 
direction because the screen is moved in an oblique 
direction. However, we believe that, under the same 
conditions, we could obtain data for comparison. Obviously, 
the images taken from the front had a problem in that the 
size of the subject differed from one measurement data point 
to another. 
Figure 8 shows a three-dimensional display of the 
trajectory of the right shoulder position. Because the slope 
of the change in the right shoulder position is approximately 
45o, it was found that using the correction value for the 
direction of motion on the screen, a walking speed of 1.4 
km/h was obtained, which was almost the same as the 1.3 
km/h obtained from the mat. 
Because the walking speed can be corrected by the 
choice of the detection point, it is necessary to be creative 
when capturing videos, for example, by shooting parallel to 
the direction of motion. 
D     Tilt angle of neck calculated by Mediapipe and 
ORPHE ANALYTICS 
As shown in Figure 12, the tilt angle of the neck, 
indicated by the blue line, does not show a gradual change 
compared to the case without the aid, and a higher-
frequency component can be observed. The change in the 
heel shape corresponded to the change in the vertical 
movement of the heel. 
As shown in Figure 13, the tilt angle of the neck does 
not exhibit a gradual change compared with the case without 
the aid. A higher-frequency component can be observed in 
the change in the shape of the heel corresponding to the 
vertical movement of the heel. 
Figure 14 shows a measurement taken approximately 5 
min after the aids were removed. Although long-period 
waves were observed, high-frequency waves corresponding 
to the same up-and-down heel movements as when the 
assistive device was used were also observed, suggesting 
that the effect of the assistive device was still present. 
In Figure 16, a high-frequency signal of a relatively 
small amplitude is superimposed on a low-frequency signal, 
as in the calculations with MediaPipe. In the assisted case, 
high species with large amplitudes have a noticeable 
number of components. This trend is also observed in 
Figure 19, which shows approximately 5 min after Orthobot 
replenishment and includes a high-frequency component of 
a large amplitude. 
52
International Journal on Advances in Life Sciences, vol 15 no 1 & 2, year 2023, http://www.iariajournals.org/life_sciences/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 E       DFT analysis for stride variability 
In the spectrum before mounting shown in Figure 19, 
the peak change was gradual, as observed in the waveform, 
and the peak spectra were observed at 0.3, 0.6, and 
approximately 1 Hz. A small peak was also observed at 
approximately 1.7 Hz. Many fine peaks were observed in 
the knee joint flexion and extension movements when the 
subject wore the walking assist device because of the 
assisted movement. A peak at approximately 0.8 Hz was 
observed, although it was not a clear peak compared to the 
peak before the assist device was attached. A peak at 
approximately 1.6 Hz was also observed. Five minutes after 
the assist device was removed, not only a peak at 
approximately 0.8 Hz but also 0.9 Hz was observed, 
whereas a peak at approximately 1.6 Hz was observed; 
however, its amplitude was smaller. Figure 22 shows the 
results of the spectral analysis of the right heel of the right 
foot while wearing the assistive device, with peaks at 
approximately 0.4 Hz and 0.8 Hz. This suggests that these 
two peaks were caused by leg motion. 
F      Advantages and disadvantages of software 
implementation 
Because this software can be installed on tablets and 
smartphones, we believe that the skeleton analysis screen 
can be effective as a simple check tool at rehabilitation sites. 
In the case of a detailed numerical analysis, there are 
differences in the numerical values obtained owing to 
differences in the camera angles, necessitating the use of a 
camera with a sufficiently wide angle at the time of 
measurement or having the camera fixed to eliminate 
shaking of the camera during movement. The current 
experiment only shows the results of the analysis of one 
subject with and without pseudo limitations of movement. 
Data from two subjects of different ages and genders 
measured simultaneously are currently being analyzed.   
Based on the above, we believe that the conditions 
necessary for using this software in the field can be 
determined by accumulating more data and adapting it to 
subjects with gait disorders. 
 
IV. 
CONCLUSION AND FUTURE WORK 
 
With the widespread use of smartphones, it is very easy 
to record videos of a person’s walking condition and to ask 
for a diagnosis from a medical professional. The ability to 
obtain skeletal displays and numerical data, similar to this 
software, is expected to rapidly improve the potential of 
video analysis in the medical insurance field. 
However, the limitations of shooting conditions when 
introducing this software should be considered. For example, 
the shooting angle and location on which the analysis 
should be focused are important. In the future, we will 
improve the optimization of the video shooting conditions 
and correction methods for all shooting angles. In addition, 
these corrections will be made and adapted for each subject. 
 We compared the foot movements of the Orthobot, an 
assistive device, before, during, and after 5 min of using 
MediaPipe and ORPHE ANYTICS. It was deduced that 
MediaPipe could obtain data over a considerable area. 
However, there are many areas where it is difficult to obtain 
the desired data through programming and to interpret the 
data; therefore, it is necessary to clarify the purpose of data 
collection for use in the field. 
ACKNOWLEDGMENT 
 
This work was supported by JAPS KAKENHI (grant 
number JP20K11924).  
REFERENCES 
 
[1] Y. Uchida, T. Funayama, Y. Kogure, “Investigation of the 
Application of MediaPipe to Gait Analysis,” pp. 1-6, IARIA, 
GLOBAL HEALTH 2022. ISBN: 978-1-61208-995-9.  
[2] L. G-Villanueva, S. Cagnoni, and L. Ascari, “Design of a 
Wearable Sensing System for Human Motion Monitoring in 
Physical Rehabilitation,” Sensors, vol. 13, pp. 7735-7755, 
2013. 
[3] Y.-L. Zheng, X.-R. Ding, C. C. Y. Poon, B. P. L. Lo, H. 
Zhanf, and G-Z. Yang, “Unobtrusive Sensing and Wearable 
Devices 
for 
Health 
Informatics,” 
IEEE 
Transactions 
Biomedical Engineering, vol. 61, pp. 1538-1554, 2014. 
[4] M. M. Alam and E. B. Hamida, “Surveying Wearable Human 
Assitive Technology for the Life and Safty Critical 
Applocations: Standards, Challenges and Opportunities,” 
Sensors, pp. 9153-9209, 2014. 
[5] M. J. Deen, “Information and Communications Technologies 
for Elderly Ubiquitous Healthcare in a Smart Home,” 
Personal and Ubiquitous Computing, pp. 573-599, 2015. 
[6] S. Hong and K. S. Park, “ Unobtrusive Photoplethymographic 
Monitoring Under the Foot Sole while in a Standing Posture,” 
Sensors, 3239, 2018. 
[7] V. Bucinskas, et al., “Wearable Feet Pressure Sensor for 
Human Gait and Falling Diagnosis,” Sensors, vol. 21, 5240, 
2021. 
[8] P. M. Riek, A. N. Best, and R. Wu, “Validation of Inertial 
Sensors to Evaluate Gait Stability,” Sensors, vol. 23, 1547, 
2023. 
[9] Y. Uchida et al., “Feature Value Extraction for Body 
Condition Change Measurement System Using Pressure 
Sensor Array,” Human Interface Society in Japanese, vol. 24, 
No.1, pp. 79-82, 2022, ISSN 2188-6652. 
[10] Y. Uchida, T. Funayama, K. Hori, M. Yuge, N. Shinozuka 
and Y. Kogure, “Possibility of Detecting Changes in Health 
Conditions using an Improved 2D Array Sensor System,” 
Sensors & Transducers, vol. 259, pp. 29-36, 2022.  
[11] Q. Zou, Y. Wang, Q. Wang, Y. Zhao, and Q. Li, “Deep 
Learning-Based gait Recognition Using Smartphones in the 
Wild,” IEEE Transactions on Information Forensics and 
Security, pp. 1-15, 2020, arXiv:1811.00338v3 [cs.LG].  
[12] F. Wang, A. Dong, K. Zhang, D. Qian, and Y. Tian, “A 
qualitative 
Assessment 
Grading 
Study 
of 
Balance 
Performance Based on Lowe Limb Dataset,” Sensors, vol. 23, 
33, 2023.  
[13] V. Bazarevsky et al., “ BlazePose: On-device Real-time Body 
Pose tracking,” arXiv:2006.10204v1 [cs.CV] 2020.  
53
International Journal on Advances in Life Sciences, vol 15 no 1 & 2, year 2023, http://www.iariajournals.org/life_sciences/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[14] G. Kaur, G. Jaju, D. Agawal, K. Lyer, and C. M. Prashanth, 
“Implementation of Geriatric Agility Detection Using 
MediaPipe Pose,” International Journal of Recent Advances 
in Multidisciplinary Topics, vol. 3, 119, 2022, ISSN:2582-
7839.  
[15] J.-L. Vhung, L.-Y. Ong, and M-C. Leow, “Comparative 
Analysis of Skelton-Based Human Pose Estimation,” Future 
Internet, vol.14, 380, 2022.  
[16] J.-W, Kim, J.-Y. Choi, E.-J. Ha, and J.-H. Choi, ”Human Pose 
Estimation Using MediaPipe Pose and Optimization Method 
Based on Humanoid Model,” Applied Sciences, vol. 12, 2700, 
2023. doi.org/10.3390/app13042700.  
[17] Q. Wang, g. Kurilo, F. Ofli, and R. Bajcsy, “Evaluation of 
Pose tracking Accuracy in the First and Second Generations 
of Microsoft Kinect,” arViv:1515.04134v1 [cs.CV] 2015. 
[18] P. Plantard, E. Auvinet, A. S. Le Pierres, and F. Multon,”Pose 
Estimation with a Kinect for Ergonomic Stuidies: Evaluation 
of the Accuracy Using a Virtual Mannequin,” Sensors, vol. 15,  
pp. 1785-1803, 2015. 
[19] R. A. Clark, B. F. Mentiplay, E. Hough, and Y. H. Pus, 
“Three-Dimensional Cameras and Skeleton Pose Tracking for 
Physical Function Assessment: A Review of Use, Validity, 
Current Developments and Kinect Alternatives,” Gait & 
Postture, vol. 68, pp. 193-200, 2019.  
[20] Y. Ma, K. Mithratatne, N. Wilson, Y. Zhang, and X. Wang, 
“Kinect v2-Based Gait Analysis for Children with Cerebral 
Palsy: Validity and Reliability of Spaial Margin of Stability 
ad Spationtemporal Vaiables,” Sensors, vol. 21, 2104, 2021. 
[21] D. Imoto, S. Hirano, M. Mukaino, E. Saitoh, and Y. Otaka, 
“A Novel Gait Analysis System for Detecting Abnormal 
Hemiparetic Gait Patterns during Robo-assisted Gait 
Training : A Criterion Validity Study among Healthy Adults,” 
Frontiers in Neurorobotics, 16:1047376, 2022.  
[22] L. Buker, V. Quinten, M. Hackbarth, S. Hellmers, R. 
Diekmann, and A. Hein, “How the Processing Mode 
Influences Azure Kinect Body Tracking Results,” Sensors, 
vol. 23, 878, 2023.  
[23] K. Shihomi, K. Ohata, T. Tsuboyama, Y. Sawada, and Y. 
Higashi, “Development of New Rehabilitation Robot Device 
that Can be Attached to the Conventional Knee-Ankle-Foot-
Orthosis for Controlling the Knee in Individuals After 
Stroke,” 2017 International Conference on Rehabilitation 
Robotics, pp. 304-307, 2017. 
[24] A. L. Hof, M. G. J. Gazendam, and W. E. Sinke, “the 
condition for dynamic stability,” Journal of Biomechanics, 
vol. 38, pp. 1-8, 2005. 
[25] R. M. Magnani, S. M. Bruijn, J. van Dieen, and M. F. Vieira, 
“Head Orientation and Gait Stability in Young Adults, 
Dancers and Older Adults,” Gait & Posture, vol. 80, pp. 68-73, 
2020. 
[26] J. Choi, S. M. Parker, Y. Gwon, and J. Youn, “Wearable 
Sensor-Based Prediction Model of Time up and Go Test in 
Older Adults,” Sensors, vol. 21,  6831, 2021. 
[27] J. Beyea, C.A. McGibon, A. Sexton, J. Noble, and C. 
O’Connell, “Covergent Validity of a Wearable Sensors Sytem 
for Measuring Sub-Task Performance during the Timed Up-
and-Go test,” Sensors, vol. 17, 934, 2017. 
[28] J. P. Monteiro, A. T. Magalhaes, and H. P. Oliveira, “Human 
Pose Estimation, Anthropomorphism and Gamification in 
Promotion of Physical Activity Among Breast Cancer 
Surviviors,” International Journal on Advances in Life 
Sciences, vol. 11, pp. 118-127, 2019. 
[29] F. Buisseret et al., “Time Up and Go and Six-Minute Walking 
Test with Wearable Inertial Sensor: One Step Futher for 
Prediction of the Risk of Fall in Elderly Nursing Home 
People,” Sensors, vol. 20, 3207, 2020. 
[30] A. L. M. Frangakis, E. D. Lemaire, and N. Baddour, “Subtask 
Segmentation Method of the Timed Up and Go test and L 
Test Using Inertial Measurement Units-A Scoping Review,” 
Information, vol. 14, 127, 2023. 
[31] Z. Li, R. Zhang, C. H. Lee, and Y. Lee, “An Evaluation of 
Posture Recognition Based on Intelligenct Rapid Entire Body 
Assessment 
System 
for 
Determing 
Musculoskeletal 
Disorders,” Sensors, vol. 20, 4414, 2020.  
[32] Y. Ono, O. D. A. Prima, and K. Hosogoe, “Evaluation and 
Application of Partial Body Joint Model in 3D Human Pose 
Estimation from Signal Image,” International Journal on 
Advances in Life Sciences, vol. 13, pp. 114-123, 2021. 
[33] I. Crombrugg et al., “Accuracy Assessment of Joint Angles 
Estimated from 2D and 3D Camera Measurements,” Sensors, 
vol. 22, 1729, 2022.  
[34] X. Yu, J. Baar, and S. Chen, “Joint 3D Human Shape 
Recovery and Pose Estimation from a Signal Image with 
Bilayer Graph,” arXiv:2110.8472v2 [cs.CV], 2021.  
 
 
 
54
International Journal on Advances in Life Sciences, vol 15 no 1 & 2, year 2023, http://www.iariajournals.org/life_sciences/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

