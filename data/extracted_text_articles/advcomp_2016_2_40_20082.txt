Study of Search Optimization Opportunities of Heuristic Algorithms for Solving 
Multi-Extremal Problems 
Rudolf Neydorf, Ivan Chernogorov, Victor Polyakh 
Orkhan Yarakhmedov, Yulia Goncharova 
Department of Software Computer Technology and 
Automated Systems and Department of Scientific-
Technical Translation and Professional Communication 
Don State Technical University 
Rostov-on-Don, Russia 
Email: ran_pro@mail.ru, hintaivr@gmail.com, 
silvervpolyah@gmail.com, orhashka@gmail.com, 
jl.goncharova@gmail.com 
Dean Vucinic 
Department of Mechanical Engineering and  
Department of Electronics and Informatics 
Vrije Universiteit Brussel 
Brussel, Belgium 
Email: dean.vucinic@vub.ac.be 
 
 
Abstract— The investigated objective of this paper is the search 
optimization task of multiextremal objects, which is considered 
to be more complicated than the optimization tasks of mono-
extremal objects. This work postulates that in order to achieve 
this goal, the heuristics algorithms are the only ones able to 
provide suitable solutions. Therefore, 3 of the most popular 
and devised approaches have been considered: (1) the method 
of swarming particles, (2) evolutionary-genetic approach and 
(3) ant algorithm. The conducted research has established the 
common test environment for comparing the multi-extremal 
Rastrigin function, with the 3 investigated methods. It is 
clearly shown that all of these 3 methods are quite appropriate 
for solving the multiextremal tasks. However, in each of the 
addressed heuristic algorithms, we have applied their own 
specific characteristics to solve the problem of detection and 
identification of the global and local extrema. These 
approaches have been combined together due to the general 
need of data clustering. It is illustrated that, when solving an 
extremal task, each of these methods can provide the desired 
solution for a fairly wide range of imposed accuracies and 
available resource times. 
Keywords: searching optimization; multi-extremal; genetic 
algorithm; swarm algorithm; ant algorithm 
I. 
 INTRODUCTION 
The most advanced state-of-the-art issues in science, 
technology, economics, military affairs and other applied 
modern trends are somehow connected with the solving tasks 
of achieving an optimum in designs, technologies, models 
and environments, through the possibility of controlling the 
dynamic and static states, as well as, other requirements put 
forward in the specifications of the design objects. In other 
words, the developers have to solve the problems of 
searching optimization (SO) [1][2][3]. It is very typical that 
most of the current known SO methods are developed and 
effectively used to find only one extremum, which is often 
the global one [3][4]. However, many design tasks in solving 
complex technological systems and transportation problems 
require optimization. Especially, the objects of discrete 
nature are characterized by multiextremal (ME) properties 
[4][5][6][7][8][9][10][11]. A significant distinctive property 
for solving such tasks requires specific methods to reach the 
solution. It is unlikely that these methods should be sought in 
the class of the SO deterministic methods, though such 
attempts are already well known. These methods are too 
sensitive to the sign variation of discontinuous functions 
within their continuum response factor spaces. However in 
the discrete factor spaces, they are described as the NP-
complete algorithms. For solving real optimization problems, 
it has been common to apply methods marked “heuristics”. 
These methods are, according to the authors, the most 
perspective to obtain solutions for the multiextremal 
problems [5][6][7][8][9][10][11]. 
A. Formulation of the problem 
As mentioned above, the motivation is to research the 
most common heuristic SO methods in an environment of a 
more typical, universal and complex ME problem. The 
performed research revealed the possibility of finding, some 
or all, extremes by applying each of the chosen methods. 
Along with this qualitative evaluation, it is necessary to 
numerically assess the accuracy of determining the extremes 
values, as well as their coordinates. Therefore, in the first 
stage of this research, we suggest to choose the ME test 
function that might provide a common environment for all 
the methods when solving ME tasks. In the second stage of 
this research, the exact heuristic approaches are chosen, 
which determine both, the well-known methods of solving 
ME tasks, and their implementation algorithms. 
B. Choosing multiextremal test function and a preliminary 
analysis of its properties 
The most common and effective test functions for 
developing and analyzing the SO methods are the 
Rosenbrock, Himmelblau and Rastrigin functions. The 
Rastrigin function (RF) is the most applied ME function 
between all of them. This universal function is not convex, 
and already proposed in 1974 by Rastrigin [12]. The 
equation of N function arguments is:
 


 







n
i
i
i
x
A
x
A n
x
f
1
2
)
cos(2
( )

, (1) 
44
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-506-7
ADVCOMP 2016 : The Tenth International Conference on Advanced Engineering Computing and Applications in Sciences

where: x=(x1,…,xn)T – vector; A=10. 
The global minimum of this function is at the point 
(0,0)=0. It is difficult to find a local minimum of this 
function, because it has many local minimums. The 
isolation and evaluation of extremais a complex task. 
In Section 2, the 3 most popular approaches of finding 
the set of extremaproblem are discussed for the 2-
dimensional Rastrigin function. Section 3 describes the 
related work. In Section 4, the conclusion of the conducted 
research is given. 
II. 
SELECTING A GROUP OF HEURISTIC METHODS 
In this article, the authors settled on 3 most relevant tasks 
that are common in practice, when solving various search 
optimization tasks. 
A. RF using swarming particles method 
The essence and reasons in using the method of 
swarming particles (MSP) in SO tasks are well known 
[13][14][15][16][17]. The classic MSP algorithm simulates 
the real behavior patterns of insects, birds, fishes, many 
protozoa, etc. However, ME objects require to know some 
specific properties of this algorithm. 
The authors [18][19][20] and other students of R. 
Neudorf [7][8][9][10][11] have significantly reworked the 
canonical MSP version. In particular, a new modified 
version of this algorithm was developed for solving the ME 
tasks, which is based on a model of the mechanical 
principles of the particle movement, and complemented by 
the mechanisms borrowed from the biological laws, as well 
as, the method of adaptation mechanisms, as property of the 
ME task. 
The Mechanical Movement Model (MMM) of particles 
[20] in MSP was significantly modified and refined: 

t
V
X
X
t i
t
t i
t
ti





)
(
)
(




t
A
V
V
t i
t
t i
t
ti





)
(
)
(






tri
pi
i
A
A
A







where: X(t-∆t)i – i-th particle previous position; Xti – i-th 
particle current position; Vti – i-th particle velocity at the 
current time; V(t-∆t)i – i-th particle current velocity; A(t-∆t)i – 
particle previous acceleration in previous time; ∆t – 
integration interval; Api – acceleration caused by the particles 
biologically action attractive forces; Atri – slowing under the 
action of friction forces. 
To improve the searching properties, the stochastic blur 
parameter was introduced: 
 
5.0 ))
)1(
(
2
1(
( )





 rnd

 
, 
(5) 
where: λξ(ε) – fluctuating parameter value by tact; ε – 
distorted relative deviation parameter from nominal value; 
rnd(1) – random number in the range [0, 1]. 
For particles, the natural clustering mechanisms were 
proposed and tested: 
 
gradient, based on particles sensitivity to change the 
velocity changing sign [9][10][11]; 
 
potential, based on the introduction in MMM 
attractive forces at all local extrema, which detected 
by swarming and scanning the search space: 
 
C
pi
L
pi
G
pi
pi
A
A
A
A







, 
(6) 
where: AG
pi - particles attraction to global extremum; AL
pi - 
particles attraction to the local extremum; AC
pi - particles 
attraction to the cluster center. 
The ME MSP algorithm showed good selectivity by 
localization extremaareas, but the clustering and clusters 
localization of mechanisms (finding values of extremaand 
their coordinates) require substantial structural and 
parametric improvements. 
This mechanism does not break the swarm into multiple 
clusters. It only saves the particles position that entered into 
the cluster. This allows the particles to be attracted, at all 
times to the global, local and cluster extrema, and does not 
stop them within their cluster. 
In this research, we have introduced and verified the 
following modifications: 
 
mechanism for dropping out "bad" clusters was 
introduced by certain criteria (the worst for a given 
number of iterations); 
 
mechanism for combining similar clusters was 
introduced at each step; 
 
parametrical 
settings 
were 
introduced 
for 
conditional attraction to the nearest cluster center; 
 
clusters areas localization mechanism and a 
mechanism finding local extremaparameters in them 
were added. 
The modification of the dynamic clustering mechanism 
allows reducing the time and increasing the search accuracy. 
However, in the follow up studies the authors suggest a 
modification, which might reduce the processing time to 
drop out the "bad" cluster’s members and to combine the 
clusters by several criteria. 
The testing modifications effectiveness was carried out 
for RF in coordinate range (x,y) ϵ [-1.5, 1.5]. In this area, RF 
has 9 local minimums, including one global. Fig. 1(a), 1(b) 
and 1(c) show extremaareas localization process and 
creation corresponding clusters. 
Fig. 1(a), 1(b) and 1(c) show that the particles are 
initially attracted to the resulting cluster, which is located in 
the global extremum area. This is due to the overall 
prevalence of the global attraction power over the local 
forces of attraction. Some peripheral particles might find the 
45
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-506-7
ADVCOMP 2016 : The Tenth International Conference on Advanced Engineering Computing and Applications in Sciences

 
 
a) 
b) 
c) 
 
 
d) 
e) 
f) 
Figure 1.  Extremaareas localization of (a – the 1st iteration, b – the 15th iteration, c – the 50th iteration). Local identification of one local extremum of (d – 
the 1st  iteration, e – the 33rd iteration, f – the 50th iteration)
local extrema, which are attracted to them, and gathered in 
clusters. In strict clusters areas, the ME MSP algorithm (in 
case of having less isolated and significant extrema) is 
repeated. This process is iteratively repeated until the 
desired accuracy of the local and global extremaparameters 
is achieved. 
Within an unlimited time for fulfilling the algorithm of 
each cluster, a quite stable dynamic equilibrium of particles 
is set. The calculations, for the modelling activity, make 
obvious, that the average number of the particles is 
correlated with the value of the extremum. The degree of 
correlation depends on the ME MSP algorithm settings. 
In order to improve the accuracy of any extremum 
parameters estimation, the repetition of ME MSP algorithm, 
for the contracted areas of the defined clusters, is applied. 
This process can be iteratively repeated until the desired 
accuracy is achieved in respect to all the local and global 
extrema. 
The examples in Fig. 1(d), 1(e) and 1(f) demonstrate the 
fragments of the iterative identification of the local 
extremum, which is located at the point [-1, 1]. TABLE I 
shows the results obtained by the localization in all areas. 
The table presents the coordinates x=x1 and y=x2, and the RF 
values obtained by applying the equation (2). The increase 
of number of iterations (and the search time) increases the 
estimation accuracy. 
TABLE I.  
RESULTS OF THE EXPERIMENT 
Standard 
Extremum evaluation item 
x 
y 
f (x, y) 
Coordinates 
Value 
x 
y 
f (x, y) 
-1 
1 
2 
-0,9957 
0,9953 
1,9901 
-1 
0 
1 
-0,9949 
0,0001 
0,995 
-1 
-1 
2 
-0,9951 
-0,9947 
1,9899 
0 
1 
1 
-3,20*10-5 
0,9948 
0,995 
0 
0 
0 
9,85*10-5 
-6,49*10-6 
1,94*10-6 
0 
-1 
1 
0,00017 
-0,995 
0,995 
1 
1 
2 
0,9949 
0,995 
1,9899 
1 
0 
1 
0,995 
0,00011 
0,995 
1 
-1 
2 
0,9952 
-0,9951 
1,9899 
 
Thus, we can conclude that ME MSP is an effective tool 
for solving the ME tasks. 
B. RF using evolutionary-genetic algorithm 
The Evolutionary-Genetic Algorithm (EGA) is one of 
the most popular tools for solving optimization tasks 
[21][22][23][24]. The structure and basic operators of EGA 
46
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-506-7
ADVCOMP 2016 : The Tenth International Conference on Advanced Engineering Computing and Applications in Sciences

are well known, and the specific parametric features depend 
on the application. In particular, the use of EGA for solving 
ME tasks [25][26][27][28] requires the addition of the 
classic EGA with the tools of extremaselection by type (max 
or min), by the value and by the object’s coordinates in the 
factor space. This paper develops the approach for the 
extremaselection, based on the use of one sample Student’s 
t-test [27][28][29]. Its essence lies in the consistent use of 
EGA with further clustering values, which are obtained in 
its generations of the final results. Latter on, they are 
separated, as coordinate groups, in order to test the null 
hypothesis for each of them. 
The arithmetic model of the present clustering method 
involves the consistent comparison of vectors with the 
middle value of vectors group v={∆vi=vi–v0 | i ϵ{1;n}}, 
where n – quantity of vectors. Regarding the specified 
probability, the decision on the set membership of vector v 
is taken into account. To clarify, for the set membership, it 
is necessary to calculate the average value of the group 
vectors lengths, used for their comparison: 
 
   

n
i
v n
v
1
/
. 
(7) 
Then, we calculate the standard deviation of the vectors 
lengths of already identified cluster: 
 
 


 

n
i
v
n
v
v
S
1
2
{ }
)1
) /(
(
, 
(8) 
 
n
S
S
v
v
} /
{
}
{



. 
(9) 
Using the calculated values, the experimental values of 
one-sample Student’s t-test are counted: 
 
}
{
0
/
v S v
v
t

   
. 
(10) 
If the determined experimental t0 value does not exceed 
the table tr value [30] at n freedom degrees and a chosen 
level of confidence probability P, we can assume that t0 
belongs to this group of objects.  
This method has proven to be well adapted to study the 
ME dependencies [27][28][29][30][31]. 
By following this approach, the algorithm and respective 
software tool (ST) were developed. By using ST, we studied 
RF in the same range, as we described in the previous 
section of this paper, while investigating RF by the 
algorithm of the swarming particles.  
The structure of the EGA parameters input, which was 
used in the RF investigation, includes the generations of 
EGA individuals = 10, in each generation = 1000, the 
probability of crossover = 95% and probability of mutation 
= 30%. It should be noted that the search area parameter is 
the same, as in the previous section, and the accuracy of the 
research in this area = 7 digits, after the decimal point. 
Consequently, it becomes possible to allocate 9 clusters, 
whose minimums can correlate with those that came into the 
study area. 
Fig. 2 shows the graphs of sequential detection of RF 
values and their different coordinates (X and Y), as well as 
the corresponding values of the objective function (F(X, Y)
≈2), which are in descending order (for clusters formed 
around minimums with (-1,1), (1,-1), (1,1), (-1,-1) values).  
Eight peripheral clusters characterize local minimums, 
and the central cluster contains the results approaching the 
global minimum of the function (see Fig. 3(a). It clearly 
shows, that close (and in some cases equal) to the value of 
the 
function 
objectives, 
which 
contain 
significant 
differences in the coordinate parameters (i.e., parameters of 
the objective function, that provide values close to the 
minimum are unlike). The ME of the studied object 
confirms this fact. 
The results of the function study in terms of global and 
local minimums are shown in TABLE II. Their actual 
values are written down under the data in the table. The 
values of the objective function, adjusted for the second 
iteration, as well as their corresponding coordinates are 
shown in TABLE III.  
Based on the data presented in TABLE II, it can be 
mentioned that extremavalues and their coordinates are not 
very accurate. 
 
Figure 2.  Clusters allocation in the experiment.  
TABLE II.  
FOUNDED PARAMETERS OF THE OBJECTIVE FUNCTION AT 
THE FIRST ITERATION (IN CLUSTERS) 
Standard 
Extremum evaluation item 
x 
y 
f(x,y) 
Coordinates 
Value 
x 
y 
f(x,y) 
0 
0 
0 
0,00188 
0,00015 
0,00071 
-1 
0 
1 
-0,98932 
0,00073 
1,00137 
0 
-1 
1 
0,00824 
-1,00043 
1,01436 
1 
0 
1 
0,99948 
-0,01328 
1,03398 
0 
1 
1 
0,01403 
1,00665 
1,0611 
1 
-1 
2 
0,99146 
-0,99314 
1,993 
1 
1 
2 
0,99702 
1,00467 
2,00947 
-1 
-1 
2 
-0,9897 
-1,01397 
2,06707 
-1 
1 
2 
-1,00528 
1,00077 
2,01775 
TABLE III.  
FOUNDED PARAMETERS VALUES OF THE OBJECTIVE 
FUNCTION AT THE SECOND ITERATION 
Values 
2nd cluster 
4th cluster 
8th cluster 
x 
-0,999996 
0,999992 
-0,999996 
y 
0,000005 
-0,000008 
-1,000005 
f(x,y) 
0,999997 
0,999989 
1,999991 
47
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-506-7
ADVCOMP 2016 : The Tenth International Conference on Advanced Engineering Computing and Applications in Sciences

 
 
a) 
b) 
c) 
Figure 3.  Extremalocalization areas of (a - the selected RF clusters). Forming clusters in the localized region of (b - the 100th generation, c - the 110th  
generation). 
If the obtained values are not satisfying the required 
accuracy, we can find a value that is more accurate in the 
next RF minimum, and which is found within each cluster. 
The evidence of this, as example is presented in the research 
of 2nd, 4th and 8th cluster, according to Table II. The authors 
have developed the approach to localize search in the 
extreme areas [29]. This approach is based on EGA using 
[27][28], where close minimum values of second cluster can 
be observed in Fig. 3(b)), with the best extreme estimation 
highlighted by a red circle. By using the localized search, 
another search was carried out in the area around the 
highlighted extreme (see Fig. 3(c)). 
C. RF using ant colony optimization 
The Ant Colony Optimization (ACO) is another group 
of methods used in solving different optimization tasks. The 
ACO distinctive feature is that the key behavioral 
characteristics of real ants are simulated [32]. Commonly, 
ACO is mostly applied to minimize the path in graph tasks 
[33], but the given algorithms also show good results in 
other domains [34][35]. In this paper, the classical ACO is 
applied to optimize ME RF benchmark task [12]. 
The described method, based on the classic ACO 
realization, is applied for solving graph problems [35], 
however with some additions. 
Similar to the classic ACO, in this modification, we can 
distinguish such steps as “initialization and arrangement”, 
“moving of ants”, “updating of pheromone” and “breakpoint 
checking”. 
For example, a RF fragment for the range (x,y) ϵ [-1.5, 
1.5] was examined. It is divided into nxn fragments, each of 
them associated with function value in the center and some 
pheromone level. The specified amount of ants is placed on 
each fragment. As all the fragments are equal, the size of the 
fragment can be calculated by the following formula: 
 
n
X
X
m
/)
(
min
max 

. 
(11) 
Thus, the set of fragments is defined by the matrix 
B=(Ii,j)n,n
i=q,j=1.  
When an ant is moving from fragment Ii,j, it is 
calculating the moving probabilities towards the adjacent 
fragments, by using the following formula: 
 



















.0
)
,
(
)
,
(
,
)
,
(
)
,
(
)
(
1
,1
1
,1
,
,
*
1
,1
1
,1
,
,
,
j
i
j
i
i j
j
i
j
i
j
i
i j
j
i
k
ij
y
f x
y
x
f
Q
y
f x
y
x
f
t
P
. (12) 
where: Q*=Q(τi+1,j+1, τij, ηi+1,j+1, ηij, α, β,t) - dependence 
function of pheromone number in fragments τi+1,j+1, τij on the 
algorithm parameters within the task. In the quality of the 
function algorithm, we consider: ηi+1,j+1, ηij = |f(xij, yij) – 
f(xi+1,j+1, yi+1,j+1)|-1 - weight (virtual distance) between 2 
fragments; α - pheromone influence changeable coefficient; 
β - weight influence changeable coefficient; t - iteration 
number. 
On the basis of the described algorithm and the model 
(see (11) and (12)) a software tool (ST) that implements the 
search of local and global extremawas developed. As an 
example, Fig. 4(a), 4(b) and 4(c) show the search results of 
RF global and local minimums. To solve the task, RF search 
area borders similar to the ones accepted in the previous 
sections were selected. The selected area was initially 
divided with a step of 0.25, and 2 ants were placed on each 
fragment. Coefficients are α=1, β=0.5, ρ=0.5, K=1 and τ=1. 
Fig. 4(a), 4(b) and 4(c) shows separate stages of work for 
ST. 
For example, let us consider the higher area of 
subdivisions with the smaller fragments. This algorithm is 
iteratively applied to the localized fragments until the 
required accuracy is achieved. The operation results of ACO 
are presented by Fig. 5(a), which shows the obtained results 
of localization and two clarifications of global extremum 
with division into 100x100 fragments situated at point (0, 
0). 
48
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-506-7
ADVCOMP 2016 : The Tenth International Conference on Advanced Engineering Computing and Applications in Sciences

 
 
a) 
b) 
c) 
Figure 4.  Visualization of software work stages of (a – initialization, b – the 3rd iteration, c - the final result). 
 
 
a) 
b) 
c) 
Figure 5.  The results of the location and clarification in the 100x100 division area of (a - selection of all local extrema, b - the selection of the best local 
extremum, c - clarification of the global extremum). 
The localization resulted in 4 extremain 4 central 
fragments (see Fig. 5(a)). In their centers, distant 0.015 apart 
from the point (0,0), the value of the function is equal to 
0.089210707938399. This enables to suggest that the 
extremum is located at the joining point of these fragments. 
For more accurate solutions ACO is applied for one of the 
fragments x ϵ [-0.03, 0], y ϵ [0, 0.03]. Fig. 5(b) shows that 
the ants tend to move to the lower right corner and 
accumulate in the fragment x ϵ [-0.0003, 0], with assessed 
value 8,92764330373552*10-6. The ACO application (see 
Fig. 5(c)) specifies the value of the extremum to be 
8,92761420345778*10-10, and its coordinates to be 1,5*10-6. 
D. Computational resources and performance 
Searching 
the 
extremaby 
swarming 
particles, 
evolutionary-genetic and ant colony algorithms on 2-
dimensional Rastrigin function is carried out on a PC with 
processor AMD Phenom II P960 with 6 GB of RAM. 
To achieve the accuracy 10-3, the time was in range 20-
100 sec. Additional search within each area was required in 
range 20-110 sec. for one area. 
III. 
RELATED WORK 
In the design optimization process, we are often 
confronted with problems facing the multiextremal 
conditions. Such situation requires decisions, which take 
into consideration several identical or close extrema, and the 
best choice in-between them has to be made. The classical 
theory of schedules gives examples, where several identical 
optimums and identical suboptimums, close to them exist 
[2][3][4][7][8][36]. The majority of discrete, integer and 
combinatory programming problems differs in such 
property [37][38][39], in particular, when finding solution 
for graphs [40][41][42][43]. The finite number (though very 
big) of admissible decisions requires considering the 
multiextremal solutions for the discrete environment 
optimization. It is important to have a complete solution of 
the multiextremal task, because the criterion is usually a 
numerical expression related to the optimized object. 
However, there are many additional conditions, which can 
help to choose the extrema, equivalent or close in size, and 
satisfy both, the numerical criteria estimates and the 
49
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-506-7
ADVCOMP 2016 : The Tenth International Conference on Advanced Engineering Computing and Applications in Sciences

heuristic ideas. Therefore, the choice, of the most effective 
methods and algorithms, is an extremely important step to 
find such solution of the multiextremal task. 
However, not all the search methods provide the 
successful solution for the multiextremal task. It is well 
known that the determinate methods are sensitive to the 
sign-variable, so-called "gullied" surfaces, which define the 
real variables in the factor space. The solution of discrete 
tasks by such methods leads to the nondeterministic 
polynomial, in order to define for the complete problem in 
time. The methods of the accidental search are poorly 
predictable, since it is impossible to control the time 
expenditure, and even the basic decision, which heuristic 
method to apply, when having a real search optimization 
problem. In particular, in Russia, in the last years, the quite 
intensive research is conducted, to find appropriate solutions 
for the many optimization problems. Among these methods, 
it is important to mention the swarming particles algorithm 
[13][14][15][16][17][18][19][20] the ant colony algorithm 
[31][32][33][34][35] 
and 
the 
evolutionarily 
genetic 
algorithm 
[21][22][23][24][25][26][27][28]. 
These 
algorithms were investigated, as the traditional optimization 
tasks, and in relation to find the solution of the 
multiextremal tasks. For the last case, they have been 
significantly modified, by experimenting with different 
heuristic methods, which research was conducted earlier by 
the authors [9][10][11]. Therefore, the presented work 
brings forward a peculiar theoretical result, and trace the 
roadmap for the future research in this direction. 
IV. 
CONCLUSION 
The analysis of the application of the 3 heuristic 
algorithms for solving the ME tasks showed that these 
methods are efficient, effective, and bring some essential 
features to the described solutions.  
The specific approaches to solve the task for each of 
these particular cases is determined through the analysis of 
the algorithms features; the detection and identification of 
local extrema, clustering methods and subsequent operations 
for the results analysis. However, in all these cases the 
modifications of algorithms is connected with the data 
clustering necessity, which was proved to be essential. Also, 
all the methods showed adequate performance.  
To conclude, all the 3 methods, studied in this paper, are 
considered to be relevant and promising for future 
applications. The specific choice of the algorithm tool for 
solving ME tasks depends on the experience and personal 
researcher preferences, as well as on the special features of 
the subject research area. 
In this paper, the task of finding the set of extremafor 2-
dimensional Rastrigin test function was examined. In future 
research, it is advisable to study the problem of higher 
dimension (3 or more) in order to assess the impact of 
algorithms’ parameters on time and search accuracy, and to 
enable algorithms modifications for the mathematical 
models of any problem dimension. 
 
REFERENCES 
[1] S. Boettcher and A. G. Percus, "Extremal optimization: 
methods derived from co-evolution", Proceedings of the 1999 
Genetic and Evolutionary Computation Conference (GECCO 
’99), pp.825-832, 1999. 
[2] C. A. Floudas and P. M. Pardalos, "Encyclopedia of 
optimization, 2nd Edition", Springer, New York: Springer 
Scince+Dusiness Media, LCC, 2009. 
[3] K. B. Jones, "Search engine optimization, 2nd edition", 
Indianapolis: Wiley Publishing, 2010. 
[4] R. 
Shreves, 
"Drupal 
search 
engine 
optimization", 
Birmingham: Packt Publishing LTD, 2012. 
[5] I. M. Vinogradov, "Mathematical encyclopedia", Soviet 
Encyclopedia, vol.4, 1977-1985, pp.135-140. 
[6] R. G. Strongin, "Algorithms for multi-extremal mathematical 
programming problems", pp.357-378, 1992. 
[7] R. A. Neydorf, A. V. Filippov, and Z. H. Yagubov, 
"Commute 
algorithm 
of 
biextreme 
solutions of 
the 
homogeneous distribution problem", Herald of DSTU, 
№5(56), vol.11, pp.655-666, 2011. 
[8] R. A. Neydorf and A. A. Zhikulin, "Research of properties 
solutions of multi distribution problems", System analysis, 
management and information processing: Proceedings of the 
2nd International Scientific Seminar, Rostov-on-Don: IC 
DSTU, pp.377-380, 2011. 
[9] R. A. Neydorf and А. А. Dereviankina, "The methodology of 
solving problems of the modified method of multi swarming 
particles", 
Innovation, 
ecology 
and 
resource-saving 
technologies at the enterprises of mechanical engineering, 
aviation, transport and agriculture, Proceedings of the IX 
International Scientific and Technical Conference, Rostov-on-
Don: IC DSTU, pp.328-330, 2010. 
[10] R. A. Neydorf and А. А. Dereviankina, "Decision of multi 
tasks by dividing swarms", Herald of DSTU, №4(47), vol.10, 
pp.492-499, 2010. 
[11] R. A. Neydorf and А. А. Dereviankina, "The solution of 
problems of recognition by swarming particle swarm 
division", News of SFU. Technical science. Special Issue 
"Intellectual CAD", Taganrog: Publisher TTI SFU, №7(108), 
pp. 21-28, 2010. 
[12] L. A. Rastrigin, "Systems of extremal control", Nauka, 
Moscow (in Russian), 1974. 
[13] R. C. Eberhart and J. Kennedy, "New optimizer, using 
particle swarm theory", Proceedings of the Sixth International 
Symposium on Micromachine and Human Science, Nagoya, 
Japan, pp.39-43, 1995. 
[14] J. Kennedy and R. Eberhart, "Particle swarm optimization", 
Proceedings of IEEE International Conference on Neural 
Networks IV, pp. 1942-1948, 1995. 
[15] Y. Shi and R. C. Eberhart, "A modified particle swarm 
optimizer", 
Proceedings 
of 
the 
IEEE 
Congress 
on 
Evolutionary Computation, Piscataway, New Jersey, pp.69-
73, 1998. 
[16] M. Clerc and J. Kennedy, "The particle swarm-explosion, 
stability, and convergence in a multi-dimensional complex 
space", IEEE Transactions on Evolutionary Computation, 
pp.58-73, 2002. 
[17] Mendes, J. Kennedy, and J. Neves, "The fully informed 
particle swarm: simpler, maybe better", Evolutionary 
Computation, IEEE Transactions on 8(3), pp.204-210, 2004. 
[18] R. A. Neydorf and I. V. Chernogorov, "Parametric 
configuration of the algorithm of searching optimization by 
swarming 
particles 
using 
experimental 
planning", 
International Institute of Science "Educatio", №2(9), vol.4, 
pp.44-49, 2015. 
50
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-506-7
ADVCOMP 2016 : The Tenth International Conference on Advanced Engineering Computing and Applications in Sciences

[19] R. A. Neydorf and I. V. Chernogorov, "Increased 
functionality of the method of swarming particles by 
kinematic and dynamic modification of the algorithm of its 
realization", 
LTD 
"Aeterna", 
International 
Journal 
"Innovative science", №6, vol. 1, pp. 24-28, 2015. 
[20] R. A. Neydorf and I. V. Chernogorov, "A parametric research 
of the algorithm of swarming particles in the problem of 
finding the global extremum", Mathematical methods in 
technique and technologies – MMTT-28: Proceedings 
XXVIII International Scientific Conference, YA.6, Saratov: 
SSTU, pp.75-80, 2015. 
[21] A. Fraser, "Computer models in genetics", New York: 
McGraw-Hill, 1970. 
[22] D. Goldberg, "Genetic algorithms in search, optimization and 
machine learning", Addison Wesley, 1989. 
[23] H. Mühlenbein, D. Schomisch, and J. Born, "The parallel 
genetic algorithm as function optimizer", Parallel Computing, 
vol. 17, pp.619-632, 1991. 
[24] N. A. Barricelli, "Esempi numerici di processi di evoluzione", 
Methodos, pp.45–68, 1954. 
[25] S. Boettcher, "Extremal optimization - heuristics via co-
evolutionary 
avalanches", 
Computing 
in 
Science 
& 
Engineering 2, pp.75–82, 2000. 
[26] S. Boettcher, "Extremal optimization of graph partitioning at 
the percolation threshold", pp.5201–5211, 1999. 
[27] R. A. Neydorf and V. V. Polyakh, "Method of multisearch 
using evolutionary genetic algorithm and sample t-test", LTD 
"Aeterna", International Journal "Innovative science", №3, 
vol.1, pp.135-140, 2015. 
[28] R. A. Neydorf and V. V. Polyakh, "Study of multi 
dependencies using an evolutionary genetic method and one 
sample Student's t-test", Mathematical methods in technique 
and 
technologies 
– 
MMTT-28: 
Proceedings 
XXVIII 
International Scientific Conference, YA.6, Saratov: SSTU, 
pp. 83-87, 2015. 
[29] R. A. Neydorf and V. V. Polyakh, "Localization search 
scopes evolutionary genetic algorithm for solving problems of 
multi nature", Science.Technology.Production, №6, vol.2, 
pp.18-22, 2015. 
[30] M. Lovric, "International encyclopedia of statistical science", 
Springer-Verlag Berlin Heidelberg, 2011. 
[31] A. Kazharov and V. Kureichik, "Ant colony optimization 
algorithms for solving transportation problems", Journal of 
Computer and Systems Sciences International, №1, vol.49, 
pp.30–43, 2010. 
[32] M. Dorigo and L. M. Gambardella, "Ant colony system: a 
cooperative learning approach to the traveling salesman 
problem", IEEE Transactions on Evolutionary Computation, 
№1, vol.1, pp.53-66, 1997. 
[33] X. Liu and H. Fu, "An effective clustering algorithm with ant 
colony", Journal of Computers, №4, vol.5, pp.598-605, 2010. 
[34] M. D. Toksari, "Ant colony optimization for finding the 
global minimum", Applied Mathematics and Computation 
176, pp.308–316, 2006. 
[35] R. A. Neydorf and O. T. Yarakhmedov, "Development, 
optimization and analysis of parameters of classic ant colony 
algorithm in solving travelling salesman problem on graph", 
Science. Technologies. Production, №3, vol.2, pp.18-22, 
2015. 
[36] Michael L. Pinedo Scheduling Theory, Algorithms, and 
Systems Fourth Edition ISBN 978-1-4614-1986-0 e-ISBN 
978-1-4614-2361-4 
DOI 
10.1007/978-1-4614-2361-4 
Springer 
New 
York 
Dordrecht 
Heidelberg 
London 
Mathematics Subject Classification (2010): Library of 
Congress Control Number: 68Mxx, 68M20, 90Bxx, 90B35. 
[37] https://www.encyclopediaofmath.org/index.php/Discrete_pro
gramming (September 29, 2016). 
[38] Donald E. Knuth - The Art of Computer Programming. 
Volume 4, Fascicle 0: Introduction to Combinatorial 
Algorithms and Boolean Functions (vi+240pp, ISBN 0-321-
53496-4). 
[39] http://www.cs.utsa.edu/~wagner/knuth/ (September 29, 2016). 
[40] GRhttp://diestel-graph-theory.com/index.html (September 29, 
2016). 
[41] Keijo Ruohonen. Graph theory (Translation by Janne 
Tamminen, Kung-Chung Lee and Robert Piché) 2013. 
[42] Christopher Griffin, Graph Theory: Penn State Math 485 
Lecture Notes Version 1.4.2.1 2011-2012. 
[43] Paul Van Dooren Graph Theory and Applications Université 
catholique de Louvain Louvain-la-Neuve, Belgium Dublin, 
August 2009. 
 
51
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-506-7
ADVCOMP 2016 : The Tenth International Conference on Advanced Engineering Computing and Applications in Sciences

