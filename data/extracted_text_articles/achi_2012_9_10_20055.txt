Emotion Recognition Through ANS Responses Evoked by Negative Emotions 
Emotion Recognition based on Machine Learning Algorithms 
Eun-Hye Jang, Byoung-Jun Park, Sang-Hyeob 
Kim, Chul Huh 
BT Convergence Technology Research Department 
 Electronics and Telecommunications Research Institute 
Daejeon, S. Korea 
cleta4u@etri.re.kr; bj_park@etri.re.kr; 
shk1028@etri.re.kr; chuh@etri.re.kr 
Yeongji Eum, Jin-Hun Sohn 
Department of Psychology/Brain Research Institute 
Chungnam National University 
Daejeon, S. Korea 
 Yeongji_Eum@gmail.com; jhsohn@cnu.ac.kr
 
Abstract—Emotion recognition using physiological responses is 
one of the core processes to implement emotional intelligence 
in human-computer interaction (HCI) research.  The purpose 
of this study was to investigate emotion-specific ANS responses 
and test recognition rate using classification algorithm when 
negative emotion such as fear, surprise, and stress was evoked. 
The results of one-way ANOVA toward each parameter, there 
were significant differences among three emotions in skin 
conductance response (SCR), number of SCR (NSCR), skin 
temperature (SKT), and high frequency of HRV (HF). Results 
of emotion recognition applied to statistical method, i.e. linear 
discriminant analysis (LDA) and 4 machine learning algorithm, 
i.e. classification and regression tree (CART), self organizing 
map (SOM), Naïve Bayes and support vector machine (SVM) 
for emotion recognition showed that an accuracy of emotion 
classification by SVM was the highest and by LDA was the 
lowest.  This can be helpful to provide the basis for the emotion 
recognition technique in HCI as well as contribute to the 
standardization in emotion-specific ANS responses. 
Keywords-emotion recognition; machine learning algorithm; 
ANS responses 
I. 
INTRODUCTION 
Emotion plays an important role in contextual 
understanding of messages from others in speech or visual 
forms. In advanced human-machine interaction, for affective 
communication between user and computer, it has to 
consider how emotions can be recognized and expressed 
during human-computer interaction and emotion recognition 
is one of the key steps towards emotional intelligence. 
Emotion recognition is one of the core processes to 
implement emotional intelligence in human-computer 
interaction (HCI) research [1]. Particularly, in important HCI 
applications such as computer aided tutoring and learning, it 
is highly desirable (even mandatory) that the response of the 
computer takes into account the emotional or cognitive state 
of the human user [2]. Emotion recognition has been studied 
using facial expression, gesture, voice, and physiological 
signal [3-7]. Physiological signal may happen to artifact due 
to motion, and have difficulty mapping emotion-specific 
responses pattern, but this has some advantages which are 
less affected by environment than any other modalities as 
well as possible to observe user’s state in real time. In 
addition, they also can be acquired spontaneous emotional 
responses and not caused by responses to social masking or 
factitious emotion expressions. Finally, measurement of 
emotional responses by multi-channel physiological signals 
offer more information for emotion recognition, because 
physiological responses are related to emotional state [8]. 
Many previous studies on emotion have reported that 
there is correlation between basic emotions such happiness, 
sadness, anger, etc. and physiological responses [9-15]. Also, 
experimental studies have been performed to distinguish 
specific emotions by autonomic nervous system (ANS) 
response and reported the emotion-specific ANS responses 
[10]. For example, in research reviewed 134 studies about 
ANS activity [11], ANS responses related to anger are a 
modal response pattern of reciprocal sympathetic activation 
and increased respiratory activity, particularly faster 
breathing. Studies on sadness report a heterogeneous pattern 
of sympathetic–parasympathetic coactivation and ANS 
responses of fear point to broad sympathetic activation, 
including 
cardiac 
acceleration, 
increased 
myocardial 
contractility, vasoconstriction, and increased electrodermal 
activity. Recently, emotion recognition using physiological 
signals has been performed by various machine learning 
algorithms, e.g., Fisher Projection (FP), k-Nearest Neighbor 
algorithm (kNN), Linear Discriminant Function (LDF), 
Sequential Floating Forward Search (SFFS), and Support 
Vector Machine (SVM). Previous works conducted a 
recognition accuracy of over 80% on the average seems to be 
acceptable for realistic applications [3-7]. Picard, Vyzas & 
Healey [3] classified 8 kinds of emotions (neutral, anger, 
grief, sadness, platonic love, romantic love, joy, & respect) 
by using kNN and it was verified 81.3% of accuracy. Haag, 
Goronzy, Schaich and Williams [4] applied MLP to 
categorize dimensions of arousal and valence in each 
emotion, and then it was reported as 80% of average 
accuracy. Also, Calvo, Brown and Scheding [14] reported 
42% of accuracy by using SVM to differentiate 8 kinds of 
emotions (neutral, anger, grief, sadness, platonic love, 
romantic love, joy, & respect).  
However, Wagner, Kim and Andre [1] mentioned that it 
can be clearly observed that the accuracy strongly depends 
on the data sets which were obtained in laboratory conditions. 
That is, the results were achieved for specific users in 
specific contexts and it is very difficult to label emotion 
classes in physiological signals (waveforms) without 
uncertainty. Therefore, it is needed to recognize emotion 
218
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

using manifold data sets obtained from different contexts and 
select the most optimal algorithm for emotion recognition. 
And in order to apply more elaborate feedback in HCI, it is 
necessary to discriminate the similar and vague emotions 
which are hard to be sorted. However, past studies is not a lot 
about discrimination of similar emotions under positive 
emotion or negative emotion likewise.  
In this paper, to improve the limitation that it is result in 
specific context, we used 10 different emotional stimuli to 
induce one emotion under the same context conditions. And 
we verified the specific ANS responses of each emotion 
when negative emotions such as fear, surprise, and stress 
were evoked. The reason for selection of negative emotion 
was that in theory of evolution, it plays an important role in 
adaptation of living and surviving the evolution of human 
[16]. In particular, fear is associated with defensive 
aggression and is a kind of attempt to escape and people in 
fear emotion would attack only if escape is impossible [17-
19]. Main function of surprise is to interrupt ongoing action 
and orient people to a possibly significant event. It has one 
core 
appraisal—appraising 
something 
as 
novel 
and 
unexpected—although other appraisals can shift the 
subjective feeling of surprise or shift the emotion from 
surprise to another emotion [20]. Stress are “constraining 
force or influence,” “a physical, chemical, or emotional 
factor that causes bodily or mental tension and may be a 
factor in disease causation,” and “a state resulting from 
stress-especially one of bodily or mental tension resulting 
from factors that tend to alter existent equilibrium [21].” 
Finally, we identified the optimal algorithm being able to 
classify three negative emotions. For this, we used a 
statistical method, linear discriminant analysis (LDA) which 
is one of the linear models, and 4 different machine learning 
algorithms, i.e., classification and regression tree (CART) of 
decision tree model, self organizing map (SOM) of Neural 
Network, Naïve Bayes of probability model, and SVM of 
non-linear model, which are used the well-known emotion 
algorithms.  
 
II. 
METHODS 
A. Participants 
A total of 12 college students (6 males 20.8 years±1.26 
and 6 females 21.2 years±2.70) participated in this study. 
They reported that they hadn’t had any history of medical 
illness or psychotropic medication and any kind of 
medication due to heart disease, respiration disorder, or 
central nervous system disorder. A written consent was 
obtained before the beginning of the study from the 
participants and they were also paid $20 USD per session to 
compensate for their participation. 
B. Emotional stimuli 
Thirty emotional stimuli (3emotions x 10sets) which are 
the 2-4 min long audio-visual film clips captured originally 
from movies, documentary, and TV shows were used to 
successfully induce emotions (fear, surprise, and stress) in 
this study (TABLE 1). Fear-inducing films were the scene 
which had tense and dreary atmosphere. Surprise clips were 
a section in which startling accident occurred and stress clip 
was TV adjustment scene that was mixture of black and 
white with white noise sound; you may easily see that when 
after all daily programs ended.  
TABLE I.  
THE EXAMPLES OF EMOTIONAL STIMULI 
Emotion 
Contents 
Examples 
Fear 
ghost, haunted 
house, scare, 
etc. 
 
Surprise 
sudden or 
unexpected 
scream etc. 
 
Stress 
audio/visual 
noise on screen, 
etc. 
 
 
The used audio-visual film clips were examined their 
suitability and effectiveness by preliminary study which 22 
college students rated the category and intensity of their 
experienced emotion on emotional assessment scale after 
they were presented each film clip. The suitability of 
emotional stimuli means the consistency between the 
experimentor’s intended emotion and the participanats’ 
experienced emotion (e.g., scared, surprise, and annoying). 
The effectiveness was determined by the intensity of 
emotions reported and rated by the participants on a 1 to 11 
point Likert-type scale (e.g., 1 being “least surprising or  
least surprising or not surprising” and 11 being “most 
surprising”).  
 
TABLE II.  
THE SUITABILITY AND EFFECTIVENESS OF EMOTIONAL 
STIMULI 
 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
M 
Fe
ar 
75 
(10) 
100 
(9.9) 
83 
(9.8) 
92 
(9.6) 
92 
(9.7) 
92 
(9.7) 
83 
(9.6) 
100 
(9.3) 
100 
(9.3) 
75 
(8.7) 
89 
(9.6) 
Su
rpr
ise 
75 
(9.3) 
92 
(9.7) 
100 
(9.7) 
100 
(9.9) 
83 
(9.6) 
83 
(9.6) 
100 
(9.5) 
83 
(9.4) 
83 
(8.6) 
75 
(10.3) 
89 
(9.5) 
Str
ess 
92 
(9.3) 
100 
(9.1) 
100 
(8.8) 
100 
(8.9) 
100 
(9.3) 
100 
(8.8) 
92 
(9.3) 
100 
(9.3) 
100 
(9.1) 
100 
(9.3) 
98 
(9.1) 
above: suitability (%), below (  ): effectiveness (point) 
219
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

 
The result showed that emotional stimuli had the 
suitability of 89% and the effectiveness of 9.1 point on 
average. The suitability of each stimulus was ranged from 75 
to 100% and from 8.6 to 10.3 point in the effectiveness 
(TABLE 2). 
C. Procedure 
Prior to the experiment, participants were introduced to 
detail experiment procedure and had an adaptation time to 
feel comfortable in the laboratory’s environment. Then an 
experimentor attached electrodes on the participants’ wrist, 
finger, and ankle for measurement of physiological signals. 
Physiological signals were measured for 60 sec prior to the 
presentation of emotional stimulus (baseline) and for 2 to 4 
min during the presentation of the stimulus (emotional state), 
then for 60 sec after presentation of the stimulus as recovery 
term. Participants rated the emotion that they experienced 
during presentation of the film clip on the emotion 
assessment scale (Figure 1). This procedure was repeated 3 
times for elicitation of 3 differential emotions. Presentation 
of each film clip was count-balanced across each emotional 
stimulus. This experiment was progressed by the same 
procedures over 10 times. 
 
 
 
Figure 1.  Experiment procedures 
D. Experimental Settings 
The laboratory was a sound-proof (lower than 35dB) 
room of 5m x 2.5m size where any outside noise or artifact 
was completely blocked. A comfortable chair was placed in 
the middle of the laboratory and 38 inch TV monitor for 
presentation of emotional stimuli was placed in front of the 
chair. An intercommunication device was located to the right 
side of chair for participant to communicate with an 
experimenter. A CCTV was installed on the top of the 
monitor set to observe participant’s behaviours and their 
behaviours were storage through the monitor and a video 
cassette recorder outside the laboratory. 
E. Physiological measures and data analysis 
The physiological signals were acquired by the MP100 
system (Biopac System Inc., USA). The sampling rate of 
signals was fixed at 256 samples for all the channels. EDA 
was measured from two Ag/AgCl electrodes attached to the 
index and middle fingers of the non-dominant hand. ECG 
was measured from both wrists and one left ankle (reference) 
with the two-electrode method based on lead I. PPG and 
SKT were measured from the little finger and the ring finger 
of the non-dominant hand, respectively. Appropriate 
amplification and band-pass filtering were performed. 
The signals were acquired for 1minute long baseline state 
prior to presentation of emotional stimuli and 2-4 minutes 
long emotional states during presentation of the stimuli. The 
obtained signals were analyzed for 30 seconds from the 
baseline and the emotional state by AcqKnowledge (Ver. 
3.8.1) software (USA) (Figure 2). The emotional states were 
determined by the result of participant’s self-report (scene 
that emotion is most strongly induced during presentation of 
each stimulus).  
Features extracted from the physiological signals and 
were used to analysis are as follows: meanGSR, meanSCR, 
NSCR, meanSKT, maxSKT, meanPPG, Mean RR(s), 
STD(s), Mean HR(1/min), RMSSD(ms), NN50(count), 
pNN50(%), SD1(ms), SD2(ms), CSI, CVI, RR tri index, 
TINN(ms), FFTap_LF, FFTap_HF, ARap_LF, ARap_HF, 
FFTnLF, FFTnHF, FFTL/Hratio, ARnLF, ARnHF, and 
ARL/Hratio. 
 
 
Figure 2.  Analysis of physiological signals 
270 physiological signal data (3 emotions x 10 stimuli x 
9 cases) except for severe artifact effect by movements, 
noises, etc. were used for analysis. And differences of 
physiological signals among 3 emotions (alpha level at .05) 
were analyzed by one-way ANOVA (SPSS ver. 15.0). Also, 
to identify the emotion recognition algorithm being able to 
best recognize 3 different emotions by physiological signals, 
statistic method, LDA and 4 machine learning algorithms, 
i.e., CART which is a robust classification and regression 
tree, unsupervised SOM, Naïve Bayes classifier based on 
density, and SVM with the Gaussian radial basis function 
kernel were selected.  
LDA, which is a statistical method to classify data 
signals by using linear discriminant functions, provides 
extremely fast evaluations of unknown inputs performed by 
distance calculations between a new sample and mean of 
training data samples in each class weighed by their 
covariance matrices [22]. CART is one of decision tree and 
nonparametric technique that can select from among a large 
number of variables those and their interactions that are most 
important in determining the outcome variable to be 
explained [23]. CART integrates the various information 
sources together for final decision. SOM, called Kohonen 
map, is a type of artificial neural networks in the 
220
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

unsupervised learning category and generally present a 
simplified, relational view of a highly complex data set [24]. 
The Naive Bayes algorithm is a classification algorithm 
based on Bayes rule and particularly suited when the 
dimensionality of the inputs is high [25]. SVM finds a 
hyperplane based on support vector to analyse data and 
recognize patterns. The complexity of the resulting classifier 
is characterized by the number of support vectors rather than 
the dimensionality of the transformed space [26]. Features’ 
differences between emotional states and baseline extracted 
from physiological signals were used to apply these 
algorithms. 
 
III. 
RESULTS 
A. Verification of the differences in ANS responses among 
emotions by one-way ANOVA 
The results of one-way ANOVA using difference value 
of signals subtracting emotional states from baseline, there 
were statistically significant differences among three 
emotions in NSCR, mean SCR, mean SKT, max SKT and 
FFT ap_HF (which is value to integrate an absolute value 
power of HF extracted from FFT) (TABLE III).  
TABLE III.  
THE RESULT ON ONE-WAY ANOVA TOWARD EACH 
PARAMETERS 
ANOVA 
SS 
df 
MS 
F 
dNSCR 
100.398 
2 
50.199 
20.886*** 
dmeanSCR 
7.363 
2 
3.681 
6.242** 
dmeanSKT 
94.884 
2 
47.442 
5.827** 
dmaxSKT 
91.563 
2 
45.781 
5.744*** 
FFTap_HF 
2,322.00 
2 
1,161.00 
3.833* 
* p < .05, ** p < .01, *** p < .001 
 
To verify the difference among three emotions in detail, 
data were analyzed by LSD post hoc test. Figure 3 shows the 
result. There were significant differences of NSCR among all 
emotions and mean SCR between fear and stress, and 
between surprise and stress. SCR and NSCR, which are 
extracted from EDA decreased while all emotions were 
evoked, compared to baseline. Also, mean and max SKT 
distinguished between fear and surprise and between fear 
and stress. SKT decreased during fear induction and 
increased during surprise and stress from baseline. Finally, 
significant difference between fear and surprise was in FFT 
ap_HF. There were an increase of FFT ap_HF in fear and 
decreases of FFT ap_HF in surprise and stress.  
 
 
 
 
 
 
 
 
Figure 3.  The results of LSD post-hoc test (*p<.05, **p<.01, **p<.001) 
B. The results of emotion recognition by machine learning 
algorithm 
28 features extracted from physiological signals were 
applied to 5 algorithms for emotion recognition of fear, 
surprise and stress. LDA, CART, SOM, Naïve Bayes and 
SVM were tested to confirm emotion recognition rate. The 
result of emotion recognition is like TABLE IV. 57.3% of 
originally grouped cases were correctly classified by LDA, 
87.2% by CART, 59.5% by SOM, 80.9% by Naïve Bayes, 
and 100.0% by SVM. Three emotions, i.e., fear, surprise and 
stress were classified by SVM optimally. 
TABLE IV.  THE RESULT OF EMOTION RECOGNITION BY SVM 
Algorithm 
Accuracy (%) 
Features (N) 
LDA 
57.3 
28 
CART 
87.2 
28 
SOM 
59.5 
28 
Naïve Bayes 
80.9 
28 
SVM 
100.0 
28 
 
The more detail results of emotion recognition accuracy 
by each algorithm are like from TABLE V to IX. In analysis 
of LDA, accuracy of each emotion had range of 49.5% to 
62.0%. Fear was recognized by LDA with 60.6%, surprise 
49.5%, and stress 62.0% (TABLE V). 
TABLE V.  THE RESULT OF EMOTION RECOGNITION BY LDA 
 
Fear 
Surprise 
Stress 
Total 
Fear 
60.6 
20.2 
19.1 
100.0 
Surprise 
22.2 
49.5 
28.3 
100.0 
Stress 
16.0 
22.0 
62.0 
100.0 
 
CART provided accuracy of 87.2% when it classified all 
emotions and the recognition rate of each emotion was 
range of 84.0% to 92.2%. In fear, recognition rate of 92.2% 
221
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

was achieved with CART, 85.4% in surprise, and 84.0% in 
stress (TABLE VI). 
TABLE VI.  THE RESULT OF EMOTION RECOGNITION BY CART 
 
Fear 
Surprise 
Stress 
Total 
Fear 
92.2 
5.0 
3.0 
100.0 
Surprise 
8.8 
85.4 
5.8 
100.0 
Stress 
6.0 
10.0 
84.0 
100.0 
 
The result of emotion recognition using SOM showed 
that accuracy to recognize all emotions was 59.5%. 
According to orders of fear, surprise, and stress, recognition 
rates of 71.3%, 59.2%, and 48.0% were obtained by SOM 
(TABLE VII). 
TABLE VII.  THE RESULT OF EMOTION RECOGNITION BY SOM 
 
Fear 
Surprise 
Stress 
Total 
Fear 
71.3 
19.8 
8.9 
100.0 
Surprise 
26.2 
59.2 
14. 6 
100.0 
Stress 
30.0 
22.0 
48.0 
100.0 
 
The accuracy of Naïve Bayes algorithm to classify all 
emotion was 80.9%. And each emotion was recognized by 
Naïve Bayes with 83.2% of fear, 67.0% of surprise, and 
93.0% of stress (TABLE VIII).  
TABLE VIII.  THE RESULT OF EMOTION RECOGNITION BY NAÏVE 
BAYES 
 
Fear 
Surprise 
Stress 
Total 
Fear 
83.2 
4.9 
11.9 
100.0 
Surprise 
15.5 
67.0 
17.5 
100.0 
Stress 
4.0 
3.0 
93.0 
100.0 
 
Finally, accuracy of SVM was 100.0% and classifications 
of each emotion were 100.0% in all emotions (TABLE IX). 
TABLE IX.  THE RESULT OF EMOTION RECOGNITION BY SVM 
 
Fear 
Surprise 
Stress 
Total 
Fear 
100.0 
0.0 
0.0 
100.0 
Surprise 
0.0 
100.0 
0.0 
100.0 
Stress 
0.0 
0.0 
100.0 
100.0 
 
IV. 
CONCLUSION 
This study was to identify the difference among fear, 
surprise and stress emotions using physiological responses 
induced by these emotional stimuli and to find the optimal 
emotion recognition algorithm for classifying these three 
emotions. In our results, there were the differences of NSCR, 
mean SCR, mean SKT, max SKT, and FFT ap_HF among 
emotions by one-way ANOVA. EDA index, i.e., NSCR and 
mean SCR, is signal that represents the activity of the 
autonomic nervous system (activity of sweat glands) [27]. 
SKT variation reflects ANS activity and is effective indicator 
of emotional status. Variations in SKT mainly come from 
localized changes in blood flow, which is caused by vascular 
resistance or arterial blood pressure. The mechanism of 
arterial blood pressure variation can be described by a 
complicated model of cardiovascular regulation by the 
autonomic nervous system. Features of FFT ap_HF extracted 
from ECG reflect the activity of cardiac activity. The sino-
atrial (SA) node, which acts as pacemaker of cardiovascular 
activity, receives inputs from both branches (sympathetic and 
parasympathetic) of the autonomic nervous system. The 
activity level of the sympathetic nervous system is presented 
to the SA node by a postganglionic fibre, and that of the 
parasympathetic nervous system is given by a vagal nerve. 
The SA node can be thought of as a spike train generator 
whose inter-spike interval is modulated by the integration of 
the activity levels of the sympathetic and parasympathetic 
nervous system [12]. 
Our result showed that SVM is the best algorithm being 
able to classify fear, surprise and stress emotions. SVM is 
designed for two class classification by finding the optimal 
hyperplane where the expected classification error of test 
samples is minimized [28]. The SVM shows a recognition 
ratio much higher chance probability, i.e. 100.0% for three 
emotion categories, when applied to physiological signal 
databases. This was utilized as a pattern classifier to 
overcome the difficulty in pattern classification due to the 
large amount of within-class variation of features and the 
overlap between classes, although the features were 
carefully extracted [12]. However, LDA and SOM had the 
lowest accuracy in emotion recognition. We think that this 
result in variability of physiological signals. The basic 
assumption that different emotions have a more or less 
unique and person-independent physiological response 
remains questionable. This could be reflected in the fact that 
the recognition rate falls off with the number of emotion 
categories [12]. These uncertainties could be an important 
cause that deteriorated the recognition ratio and troubled the 
model selection of the LDA or SOM. 
Although some algorithm showed lower accuracy of 
emotion recognition, our results led to better chance to 
recognize human emotions and to identify the optimal 
emotion recognition algorithm by using physiological 
signals. In particular, SVM algorithm for classification of 
emotions can be helpful to provide the basis for the emotion 
recognition technique such as realization of elaborate and 
emotional man-machine interaction and will be applied to 
play an important role in several applications e.g., the 
human-friendly personal robot or other devices needed for 
various emotions recognition including how to develop 
effective robot control or adaptation behavior pattern using 
recognized emotion and product natural avatar’s emotional 
behavior for interaction. 
However, for more accurate and realistic applications, a 
novel method to identify not only basic emotions but also 
more various emotions such as boredom, frustration, and 
222
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

love, etc. must be devised before it is mentioned that 
emotion recognition based on physiological signals is a 
practicable and reliable way of enabling HCI with emotion-
understanding capability. Although, various physiological 
signals offer a great potential for the recognition of 
emotions in computer systems, in order to fully exploit the 
advantages of physiological measures, standardizations of 
experimental methods have to be established on the 
emotional model, stimulus used for the identification of 
physiological patterns, physiological measures, parameters 
for analysis, and model for pattern recognition and 
classification [29]. Finally, more research is needed to 
obtain stability and reliability of this result compare with 
accuracy of emotion classification using other algorithms. 
ACKNOWLEDGMENT 
This research was supported by the Converging Research 
Center Program funded by the Ministry of Education, 
Science 
and 
Technology 
(No. 
2011K000655 
and 
2011K000658).  
REFERENCES 
[1] J. Wagner, J. Kim, and E. Andre, “From physiological signals 
to emotions: Implementing and comparing selected methods 
for feature extraction and classification,” 2005 IEEE 
International 
Conference 
on 
Multimedia 
and 
Expo, 
Amsterdam, pp. 940-943, July 2005. 
[2] N. Sebe, I. Cohen, and T.S. Huang, “Multimodal emotion 
recognition,” in Handbook of Pattern Recognition and 
Computer 
Vision, 
Amsterdam: 
Publications 
of 
the 
Universiteit van Amsterdam, 2005, pp. 1-23. 
[3] R. W. Picard, E. Vyzas, and J. Healey, "Toward machine 
emotional intelligence: Analysis of affective physiological 
state," IEEE Transaction on Pattern Analysis and Machine 
Intelligence, vol. 23, pp. 1175-1191, 2001. 
[4] R. Cowie, E. Douglas-Cowie, N. Tsapatsoulis, G. Votsis, S. 
Kollias, W. Fellenz and J. G. Taylor, “Emotion recognition in 
human computer interaction,” IEEE Signal Process. Mag., vol. 
18, pp. 32-80, January 2001. 
[5] A. Haag, S. Goronzy, P. Schaich, and J. Williams, "Emotion 
recognition using bio-sensors: First steps towards an 
automatic system," Affective Dialogue Systems, vol. 3068, pp. 
36-48, 2004. 
[6] J. A. Healey, "Wearable and automotive systems for affect 
recognition from physiology," Doctor of Philosophy, 
Massachusetts Institute of Technology, Cambridge, MA, 2000. 
[7] F. Nasoz, K. Alvarez, C. L. Lisetti, and N. Finkelstein, 
"Emotion recognition from physiological signals for user 
modeling of affect," International Journal od Cognition, 
Technology and Work-Special Issue on Presence, vol. 6, pp. 
1-8, 2003. 
[8] P. D. Drummond, and S. H. Quah, “The effect of expressing 
anger on cardiovascular reactivity and facial blood flow in 
Chinese and Caucasians,” Psychophysiology, vol. 38, pp. 
190-196, 2001. 
[9] G. Stemmler, "The autonomic differentiation of emotions 
revisited: 
convergent 
and 
discriminant 
validation," 
Psychophysiology, vol. 26, pp. 617-632, 1989. 
[10] P. Ekman, R. W. Levenson, and W. V. Friesen, "Autonomic 
nervous system activity distinguishes among emotions," 
Science, vol. 221, p. 1208, 1983. 
[11] S. D. Kreibig, "Autonomic nervous system activity in 
emotion: A review," Biological psychology, vol. 84, pp. 394-
421, 2010. 
[12] K. H. Kim, S. W. Bang, and S. R. Kim, “Emotion recognition 
system using short-term monitoring of physiological signals,” 
Medical & Biological Engineering & Computing, vol. 42, 
pp.419-427, 2004. 
[13] J. N. Bailenson, E. D. Pontikakis, I.B. Mauss, J. Gross, M. E. 
Jabon, C. A. C. Hutcherson, C. Nass, and O. John, "Real-time 
classification of evoked emotions using facial feature tracking 
and physiological responses," International journal of human-
computer studies, vol. 66, pp. 303-317, 2008. 
[14] R. Calvo, I. Brown, and S. Scheding, "Effect of experimental 
factors on the recognition of affective mental states through 
physiological measures," AI 2009: Advances in Artificial 
Intelligence, vol. 5866, pp. 62-70, 2009. 
[15] C. Liu, K. Conn, N. Sarkar, and W. Stone, "Physiology-based 
affect recognition for computer-assisted intervention of 
children with Autism Spectrum Disorder," International 
journal of human-computer studies, vol. 66, pp. 662-677, 
2008. 
[16] C. Darwin, The expression ofthe emotions in man and 
animals. London: John Murray, 1872. 
[17] D. C. Blanchard, and S. N. Takahashi, "Affect and 
aggression: An animal model applied to human behavior," 
Advances in the Study of Aggression, vol. 1, pp. 1-62, 1988. 
[18] K. M. J. Lagerspetz, "Aggression and aggressiveness in 
laboratory mice," in Aggressive behavior, S. Garattini and E. 
B. Sigg, Eds., ed New York: Wiley, 1969, pp. 77-85. 
[19] K. E. Moyer, The Psychobiology of aggression. New York: 
Harper & Row, 1976. 
[20] K. R. Scherer, "Appraisal considered as a process of 
multilevel sequential checking," in Appraisal processes in 
emotion: Theory, methods, research, K. R. Scherer, et al., 
Eds., ed New York: Oxford University Press, 2001, pp. 92-
120. 
[21] Merriam-Webster. 
(2001, 
Februry 
22). 
WWWebster 
Dictionary 
[Online]. 
Available: 
http://www.m-
w.com/dictionary.htm 
[22] M. 
Murugappan, 
R. 
Nagarajan, 
and 
S. 
Yaacob, 
“Classification of human emotion from EEG using discrete 
wavelet transform,” Journal of Biomedical Science and 
Engineering, vol. 3, pp. 390-396, April 2010. 
[23] J. R. Quinlan, C4.5 Programs for Machine Learning, San 
Mateo, CA: Morgan Kaufmann, 1992. 
[24] F. Fdez-Riverola, E. L. Iglesias, F. Diaz, J. R. Mendez, and J. 
M. Corchado, “SpamHunting: an instance-based reasoning 
system for spam labeling and filtering,” Decision Support 
Systems, vol. 43, pp. 722-736, 2007. 
[25] D. W. Aha, D. Kibler, and M. K. Albert, “Instance-based 
learning algorithms,” Machine Learning, vol. 6, pp. 37-66, 
1991. 
[26] P. D. Wasserman, Advanced Methods in Neural Computing, 
New York, Van Nostrand Reinhold, pp. 35–55, 1993. 
[27] W. Boucsein, “Electrodermal activity,” Plenum Press, 
NewYork, 1992. 
[28] K. Takahashi, “Remarks on emotion recognition from bio-
potential 
signals,” 
2nd 
International 
Conference 
on 
Autonomous Robots and Agents, Palmerston North, pp. 186-
191, December, 2004. 
[29] J. Arroyo-Palacios, and D. M. Romano, “Towards a 
standardization in the use of physiological signals for 
affective recognition systems,” Proceedings of Measuring 
Behavior 2008, 2008. 
223
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

