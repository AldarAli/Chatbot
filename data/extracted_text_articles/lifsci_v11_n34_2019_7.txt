A System for Collecting Motion Data for Use in Quantitatively 
Evaluating Activities of Daily Living 
 
Yoshitoshi Murata, Oky Dicky Ardiansyah Prima, Rintaro 
Takahashi 
Graduate School of Software and Information Science 
Iwate Prefectural University 
Takizawa, Japan 
e-mail: {y-murata, prima}@iwate-pu.ac.jp, 
g231r019@s.iwate-pu.ac.jp 
Yukihide Nishimura, Hiroyuki Tsuboi, 
Department of Rehabilitation Medicine 
Iwate Medical University 
Morioka, Japan 
e-mail: ynishi@iwate-med.ac.jp, hiroyuki.tsuboi@j.iwate-
med.ac.jp 
 
Abstract— A system is needed for quantitatively evaluating the 
activity recovery level of functional disable people. Although 
functional recovery is administered to hemiplegic patients 
during rehabilitation, some patients who have recovered 
function in a rehabilitation facility are still unable to perform 
daily activities at home. Therefore, recovering activities of 
daily living (ADL) has become more important than functional 
recovery. Since existing ADL recovery level indices are based 
on responses to questionnaires, judgment of recovery level is 
easily affected by an evaluator’s subject. We have developed a 
system for collecting and storing motion data on daily life 
activities for use in quantitatively evaluating ADL recovery 
levels. Evaluation of the system using data measured for a 
healthy participant with restricted movement and two actual 
hemiplegic patients demonstrated that slight differences in 
disability levels can be detected. This system is thus well suited 
for quantitative ADL assessment for patients with a disability. 
Keywords-rehabilitation; functionary recovery; activities in 
daily living; ADL; BLE beacon; Google Firebase. 
I. 
 INTRODUCTION 
Most patients suffering from cerebrovascular disease 
have paralysis on one side of the body, and their bodies lean 
and twist to the paralyzed side. Also, because of unusual 
muscle strain, their hands and feet become stiff. In some 
cases, muscles of the upper body go into convulsions. 
Functionary recovery is administered to hemiplegic patients 
as rehabilitation. However, some patients are not always to 
live less inconveniently in their home. Some patients who 
recover hand and arm functionality better in a rehabilitation 
facility cannot eat meals better in their home. Therefore, 
recovering Activities of Daily Living (ADL) has recently 
become more significant than recovering functionaries. We 
proposed a system to collect motion data on patient’s ADL 
in IARIA eTELEMED 2019 [1]. 
The Barthel Index, which is based on questionnaires, is 
popularly used to quantitatively evaluate ADL recovery 
levels [2][3]. With questionnaires, however, recovery level 
judgments easily change in accordance with the evaluator’s 
subject. Each recovery level is digitized to a few levels. For 
example, answers for feeding include “unable,” “needs help 
cutting, spreading butter, etc., or requires modified diet” and 
“independent.” Each answer is scored 0, 5, or 10. However, 
the recovery level for feeding with help ranges from “a 
patient eating food directly from dishes without using a 
spoon or fork” to “a patient eating a meal with a knife and 
fork in almost the same way as a healthy person.” Also, it 
takes too much time to ask and observe whether a patient can 
do an activity independently without needing help. 
Functional Independence Measure (FIM) [4] and Katz 
Index [5]-[7] scores are also used to evaluate ADL. FIM 
scores cover not only functional disease but also mental 
disease. Scores are broken down into seven levels for each 
activity, including feeding. Katz Index scores are usually 
applied to cure elder patients or those suffering from chronic 
disease.  
The question formats for these evaluation methods are 
basically the same, and an evaluator needs much time to ask 
questions and observe a patient. We think that a quantitative 
evaluation system with a computer is needed to evaluate 
patients objectively without needing to ask them any 
questions and/or observe them.  
Judging ADL recovery levels is based on whether 
patients can do tasks, such as eating, getting dressed, bathing, 
washing, and discharging bodily waste by themselves. 
Therefore, a system that collects motion data of patients in 
daily life needs to not only measure and collect the motions 
of body parts but also detect which activities are performed. 
However, it is very difficult to estimate these merely from 
changes in acceleration and/or gyro sensor data obtained 
from devices attached to body parts. Therefore, we estimate 
activities by using information about places, such as a dining 
table, bathroom, dressing room, or bedroom. We used the 
BLE beacon [8] to detect places in this system.  
Most surgeons also think that postoperative patient 
functions assessed by ADL and quality of life have become 
especially important ways to measure surgical treatment 
outcomes for the elderly [9]. 
In this study, we developed a system to collect and store 
patients’ motion data to quantitatively judge the recovery 
level of activities in daily living. The system can use up to 
seven sensors for simultaneously measuring the motions of 
seven body parts. A patient’s name, measured location, 
sensor-attached body parts and time-stamps are described as 
the file names for each measured data file in this system.  
The system only requires that recognized medical doctors 
or physiotherapists can access measured data to maintain 
security. To ensure this, we developed a data collecting 
system based on Google Firebase [10]. Since the Firebase 
160
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

application can be independently implemented for any 
organization, high level security can be maintained. 
To confirm whether this cloud-based system can 
distinguish between normal and restricted movements, we 
first had a healthy participant rotate both lower arms and 
then extend them forward to ensure that the system measured 
these movements correctly. We then restricted movement of 
the person’s elbows and collected movement data during 
teeth brushing, face washing, and eating.  
Next, we applied this system to tow actual hemiplegic 
patients. Drinking and walking motions were measured.  
The measurement data differed slightly depending on the 
level of movement restriction or disability; this system is 
thus suitable for quantitatively assessing the ADL level of 
patients with a disability. 
After introducing related work in Section II, we describe 
the system’s design concept and its implementation in 
Sections III and IV. Confirmation of its performance for a 
healthy participant with restricted movement is presented in 
Section V, and that for actual hemiplegic patients is 
presented in Section VI. Section VII concludes with a 
summary of the key points and a mention of future work.  
II. 
RELATED WORK 
To develop a quantitative evaluation system for the 
recovery level of activities in daily living of hemiplegic 
patients, we have to know how to evaluate ADL 
quantitatively, existing life log systems and healthcare 
information cloud service. 
A. Evaluation index for function level 
Three indexes to evaluate function level in daily living 
are widely used: the Barthel Index, the FIM and the Katz 
Index. They are basically questionnaires for daily life 
activities, such as feeding. The Barthel Index and FIM are 
popularly 
applied 
to 
evaluate 
function 
levels 
for 
rehabilitation patients, such as those afflicted with 
cerebrovascular disease.  There are ten question items in the 
Barthel Index: Feeding, Moving from wheelchair to bed and 
return, Personal toilet (washing face, combing hair, shaving, 
cleaning teeth), Getting on and off the toilet (handling 
clothes, wiping, flushing), Bathing self, Walking on level 
surfaces, Ascending and descending stairs, Dressing 
(includes tying shoes, fastening fasteners), Controlling 
bowels and Controlling bladder [2] [3]. A score of 
independently doing an activity is usually 10 points, doing it 
with help is usually 5 points, and not doing it is 0 points.  
FIM evaluates not only physical functions but also social 
abilities, such as communication or social recognition [3]. 
The number of questions covers 18 issues; 13 for physical 
functions and five for social abilities. Questions about 
physical functions are more segmentized. For example, the 
dressing function is divided into dressing the upper body 
and the lower body, moving activities are divided into the 
moving between a wheelchair and a bed/chair, and sitting on 
a toilet seat and moving to a bathtub. Scores are given on a 
seven-point system. Independently doing an activity gets 
seven points, doing it with full help gets one point, and 
doing it with partial help gets scores ranging from two to six 
points. 
The Katz Index is usually applied to elder patients or 
those suffering from chronic disease in a variety of care 
settings [4 - 6]. The index ranks adequacy of performance in 
six activities: bathing, dressing, toileting, transferring, 
continence, and feeding. Clients are scored yes/no for 
independence in each of the six functions. 
Every three indexes evaluate whether a patient can do 
activities in daily living. Therefore, our proposed system 
must know what kinds of activities a patient tries to do. 
In addition, one of the most widely recognized and 
clinically relevant measures of body function impairment 
after stroke is the Fugl-Meyer (FM) assessment. Of its 5 
domains (motor, sensory, balance, range of motion, joint 
pain), the motor domain, which includes an assessment of 
the upper extremity (UE) and lower extremity (LE), has 
well-established reliability and validity as an indicator of 
motor impairment severity across different stroke recovery 
time points. Consistently, greater motor severity as 
indicated by lower UE and LE FM motor scores is 
correlated with lower functional ability, such as spontaneous 
arm use for feeding, dressing and grooming, or walking at 
functional gait speeds. [11]. 
B. Life log system 
Over the years, many researchers have tried to estimate 
daily life human activities, such as walking and sitting up 
and down from acceleration and/or gyro sensor data 
obtained from wearable devices and/or smartphones. In this 
paper, we refer to the research done respectively by Zhan et 
al. and Wang et al. [12] [13]. Only a few motions were 
given in this research; distinctions among activities were not 
recognized. In contrast, Debraj et al. tried to recognize 19 
daily living activities [14]. They collected environment 
information, such as that for temperature and location in 
addition to activity information. They used GPS and BLE 
beacons to identify places. However, they did not consider 
the Barthel Index or other indices and consequently their 
target activities did not correspond to activities in the index 
of function recovery levels. 
C. Healthcare cloud service 
Zhang et al. developed a cyber-physical system for 
patient-centric healthcare applications and services [15]. 
They called it Health-CPS. It was built on cloud and big 
data analytics technologies.  It consisted of a data collection 
layer, a data management layer and an application service 
layer to collect and follow up on many kinds of big data. It 
used a security tag to maintain security.  
Doukas et al. proposed a mobile system that enables 
electronic healthcare data storage, update and retrieval using 
cloud computing [16]. A mobile application was developed 
using Google’s Android OS and Amazon’s S3 to provide 
management of patient health records and medical images. 
161
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

We developed a cloud service whose collecting function 
for medical data is basically the same as that for the above 
systems. However, our system is specialized so that it can 
collect activity and place information to functionally 
evaluate recovery levels that correspond to existing 
evaluation methods, such as the Barthel Index. In this paper, 
we show how we implemented the system with Eri 
BLM620 [17] as the sensor node, as well as Android 
smartphone, BLE beacon, and Google Firebase. 
III. 
SYSTEM DESIGN CONCEPT 
We designed the proposed system so that it could not 
only evaluate ADL for a patient, but also develop 
algorithms for detecting whether a patient can do a 
designated activity. The system collects and stores sensor 
data and video data synchronously and allows appropriate 
persons to access stored data. We designed the system while 
taking the following issues into consideration: 
1) Suppressing battery consumption for wearable sensor 
devices, 
2) Suppressing recorded data and collecting necessary 
data, 
3) Maintaining security. 
 
Google Firebase service provides many functions, 
including authentication and real-time database functions, to 
enable systems to be managed effectively, such as through 
the means of allowing access to authorized persons. Since 
any organization can independently implement Firebase 
applications, it becomes possible to maintain high level 
security. This is why we implemented our data collecting 
system on Google Firebase.  
The image of a data collecting system that collects data 
about the motions that a patient performs daily is shown in 
Figure 1. The system we propose consists of sensor devices, 
a sensor relay unit (smartphone), BLE beacons, and Google 
Firebase. A smartphone is used as the sensor relay unit that 
controls sensor devices and temporarily stores and forwards 
measured data to the Firebase. 
BLE beacons are placed in various locations: under a 
dining table, on top of a toilet, in a bathroom, in a bedroom, 
in a closet. When the smartphone receives a BLE beacon 
signal level that exceeds the threshold level, it sends a 
message to sensor devices to start measuring data. And 
when the smartphone receives a receiving signal level lower 
than the threshold level, it sends a message to sensor devices 
telling them to stop measuring data. Sensor devices and 
smartphones are managed by the Realtime Database on 
Google Firebase. Security is maintained by enabling only 
authorized persons using the system, including patient, 
readers, such as medical doctor and installation personnel, 
such as nurse are also managed by the Realtime Database is 
used to maintain security. In this system, measured data are 
downloaded for pre-registered persons from the web server.  
 
 
Figure 1. Image of the data collecting system for patient’s daily life 
motions. 
IV. 
SYSTEM IMPLEMENTATION 
We developed a PatientApp program that works on the 
sensor relay unit and a DataCollectionServer program that 
works on Firebase. The PatientApp manages sensor devices, 
gets measured data from sensor devices and uploads the data 
file to the DataCollectionServer.  
A. PatientApp 
This time, we developed a PatientApp program based on 
the Android Framework. With this program, a developer 
must first access the Firebase and download a configuration 
file. An Android application package file (Apk File) is then 
made as a building application and is connected to Firebase. 
This makes it possible to securely download the Apk File 
for each organization. 
Before starting to measure sensor data and/or video data, 
it is necessary to enter a patient’s name, bind a sensor with a 
body part, bind a BLE beacon with a place of activity and 
select a video recording on/off function. Therefore, we 
designed a transition diagram of UI pages as shown in 
Figure 2. There were three alternatives for a user name at 
the login; the patient’s name, the medical worker’s name 
with measuring devices set up, and the medical 
professional’s name with measured data analyzed. For the 
latter two cases, a patient’s name must be entered after the 
login. Therefore, we decided on the first one, login with a 
patient’s name. 
After login, a “List of setting up” page is presented. An 
example of this page is shown in Figure 3. With it, a user 
can confirm a state of setting. When the “Change” button is 
clicked, the page will change to the “Sensor” page to bind a 
sensor with a body part. When the “Next” button is clicked, 
the page will change to the “Beacon” page to bind a BLE 
beacon with a place in activity. When the “Next” button is 
clicked, the page will change to the “Video” page to select 
video ON/OFF. When the “Next” button is clicked, the page 
will change to the “List of setting up” page. When the 
“Next” button is clicked in the “List of setting up” page, the 
162
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

page will change to the “Measuring” page.  When the 
“Start” button on this page is clicked, the PatientApp sends 
a message to the sensor messages to start measuring, and the 
“Start” button changes to the “Stop” button. When the 
“Stop” button is clicked, the PatientApp sends a message to 
the sensor messages to stop measuring, and the “Stop” 
button changes to the “Start” button. When the “End” button 
is clicked, the PatientApp finishes. 
When a sensor receives a BLE beacon signal, it starts 
measuring, and, when a sensor loses a BLE beacon signal, it 
stops measuring. After clicking the “Stop” button, measured 
data are changed to a measured data file. Its file name is 
“Patient name_place_body part_timestamp” to recognize its 
properties. The file is uploaded to the storage in Firebase. 
 
 
Figure 2. Transitions of UI pages in the PatientApp. 
 
 
Figure 3. Example of setting up page list. 
We developed the following six packages of classes to 
achieve the above proceedings: 
- 
Beacon: receiving beacon signals and handing their 
information to other classes. 
- 
Mobile2wear: controlling a sensor device and 
receiving measured data. 
- 
Camera: managing a video camera. 
- 
Firebase: converting measured data and transferring 
the data to the Firebase storage. 
- 
View: managing transition of pages 
- 
Viewmodel: listening events on buttons or input 
boxes and handing, such information to other 
classes. 
B. DataCollectionServer 
The DataCollectionServer has the following functions; 
- 
Data upload function: The sensor relay unit 
temporarily stores measured data and forwards them 
to the server. 
- 
Data download function: Authorized persons, such 
as 
medical 
doctors 
can 
access 
the 
DataCollectionServer and download measured data 
files securely. 
 
It consists of the Storage and WebSite. The WebSite 
collaborates with the Storage and provides a file download 
function to a medical professional through the Web browser. 
In this subsection, we mainly introduce how to upload 
and download measured data file. 
1) Data upload function (Figure 4) 
After a measured file has been made, the PatientApp 
uploads the file to the storage server in Firebase as shown in 
Figure 4. The storage server generates the file download 
URL, which is managed in the Realtime Database. 
 
 
Figure 4. Sequence flow to upload measured files. 
 
2) Measured data download function (Figure 5) 
Supervisors input the access account of medical 
professionals from the management page in Firebase. The 
163
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

sequence flow with which medical professionals download 
their patients’ files is shown in Figure 5. When medical 
professionals access the Website, they log in with their 
assigned ID and password on the page of Figure 6 (a).  
 
 
Figure 5. Sequence flow to download measured files. 
 
 
 
(a) Login page 
 
 
 
(2) File list page 
 
Figure 6.  WebSite user interface. 
 
After login, the Website application accesses the 
Realtime Database to get information related to nurses and 
patients. The Website application also gets meta-data such 
as an access path to a stored file. When a medical 
professional clicks a file on the page of Figure 6 (b), the 
Website application accesses the indicated file on the 
Storage through the access path. Finally, the indicated file is 
downloaded. 
 
C. Wearable device 
We initially used a SONY Smart Watch III [18] as the 
wearable device, as reported at eTELEMED 2019. However, 
SONY no longer produces this device, so we worked with 
Eri, Inc. [17] to develop the BLM620 wearable sensor to 
ensure a stable supply. 
Its appearance and configuration are shown in Figures 7 
and 8. It contains a 3D digital accelerometer and a 3D 
digital 
gyroscope 
packaged 
together 
(LSM6DSL, 
STMicroelectronics [19]) and a Bluetooth and CPU module 
packaged 
together 
(HRM1062, 
Hosiden 
[20]). 
Its 
acceleration and gyro axes are shown in Figure 9. The 
maximum number of simultaneous connections is seven.  
Its connection performance was measured using an 
Android terminal wirelessly connected to seven wearable 
devices, as shown in Figure 10, for two types of connection: 
multi-thread and sequential. The flow for each type is 
shown in Figure 11. The data were measured in lower and 
higher radio interference environments. The interference in 
the latter one was generated by a nearby 2.8 GHz WiFi 
access point. There was no such interference source in the 
former one. The terminal connected to each device 30 times. 
The connection error rate (CER) is shown in Figure 12. 
While there were differences in the CER between devices, 
the CER was generally higher in the higher radio 
interference environment than in the lower one. It was also 
higher for the multi-thread connections than for the 
sequential connections. Therefore, we used sequential 
connections in this application program. 
 
 
Figure 7. Appearance of the developed wearable device 
 
Figure 8. Configuration of the developed wearable device 
164
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 9. Acceleration and gyro axis 
 
 
Figure 10. A scene of experiment 
 
 
(a) Multi-thread connection 
 
 
(b) Sequential connection  
 
Figure 11. Connection flow 
 
 
 
Figure 12. Connection error rate 
V. 
COMFIRMATION OF SYSTEM PERFORMANCE 
Prior to collecting motion data for actual hemiplegic 
patients, we collected motion data for a healthy participant 
with and without elbow restrictions to confirm that the 
proposed system can detect differences between normal and 
restricted joint movement.  
A. Simple motions 
We started with simple motions for which it is easy to 
confirm the accuracy of measured data. We first had the 
participant rotate both lower arms 90°, as shown in Figure 
13, five times. The measured acceleration and yaw/roll/pitch 
angle data are shown in Figure 14. The acceleration along 
the X and Z axis basically changed from 0 to 1 G alternately 
(Figure 14 (a)) five times. The acceleration along the X axis 
changed from 0 to −1 G while that along the Z axis changed 
from 0 to 1 G alternately (Figure 14 (c)) five times.  
The roll angles for the two arms (Figures 14 (b) and (d)) 
were symmetrically opposite due to their symmetrical 
motions. The acceleration along the Z axis when both 
thumbs were in the “right up” position (Figures 14 (a) and 
(c)) was not zero. This reason is caused by over actions of 
the arms. The yaw/roll/pitch angles in Figures 14 (b) and (d) 
include the drift error. 
 
 
                       (a) Start                                            (b) End 
Figure 13. Rotating the lower arm 
 
165
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 14. Measured data of rotating the lower arm 
 
The participant raised both lower arms from the straight 
down position to the forward position, as shown in Figure 
15, five times. The measured acceleration and yaw/roll/pitch 
angle data are shown in Figure 16. The acceleration along 
the Y axis for the straight down position was roughly −1 G 
(Figures 16 (a) and (c)) since the sensors simply measured 
gravity. The acceleration along the X axis corresponded to 
the centrifugal force. The symmetric differences in yaw 
angle between Figures 16 (b) and (d) were due to the 
symmetrical motion. The yaw/roll/pitch angles in Figures 16 
(b) and (d) include the drift error, the same as in Figures 14 
(b) and (d). The measured data in Figures 14 and 16 
basically represent the changes in motion accurately. 
 
 
                                  (a) Start                      (b)End 
Figure 15. Rising the lower arm forward 
 
 
Figure 16. Motion data of rising the lower arm forward 
B. Restricted motions 
To confirm whether the proposed system can detect 
differences between different motion restrictions, we 
measured the participant’s motions during eating, face 
washing, and teeth brushing under three conditions; 
a. Bending of the right elbow was restricted by placing it 
in a plaster cast (Figure 17), wrapping it in a bandage, 
and fixing it to his upper body with a bandage, 
b. Bending of the right elbow was restricted by placing it 
in a plaster cast and wrapping it in a bandage, without 
fixing it to anything. 
c. No restriction. 
 
Wearable devices were attached to the head, the mid-
lumbar region, both lower arms, and both upper arms, as 
shown in Figure 18. Under conditions a and b, the 
participant brushed his teeth with his right hand, as shown 
in Figure 19 (a). Under condition c, he brushed his teeth 
with his left hand since he usually brushes with his left hand. 
The acceleration data for the lower arms and head are 
presented in Figure 20. The other data are not presented as 
they did not have any particular features of interest. Since 
there was a lot of right and left or up and down motion and 
little rolling motion in brushing teeth, the angle data for the 
tooth-brushing arm had little variation. There were big 
166
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

differences in the data between conditions a and b, as shown 
in Figures 20 (a-2) and (b-2) while there was little 
difference between conditions b and c, as shown in Figures 
20 (b-2) and (c-1). There was little head movement under 
any condition, as shown in Figures 20 (a-3), (b-3), and (c-3).   
 
 
Figure 17. Plaster cast    
 
 
Figure 18. Participant with sensors and restrictions 
 
 
(a)Brushing teeth       (b)Washing face          (c)Eating food 
Figure 19. Restricted motions 
The participant washed his face with his right hand 
under conditions a and b, as shown in Figure 19 (b). He 
washed his face with both hands under condition c. The 
acceleration data for the lower arms and head are presented 
in Figure 21. The other data are not presented as they did 
not have any particular features of interest. Since there was 
a lot of up and down motion and little rolling motion in 
washing face, the angle data for the face washing arm had 
little variation. There were not any big differences in the 
data between conditions a and b, as shown in Figures 21 (a-
2) and (b-2). There was a big difference in the data between 
condition c and the other two conditions: the acceleration 
data for the lower arms varied widely, as shown in Figures 
21 (c-1) and (c-2) due to using both hands. There was little 
head movement under any condition, as shown in Figures 
21 (a-3), (b-3), and (c-3). 
The participant ate curry rice with his right hand under 
all three conditions, as shown in Figure 19 (c). The 
acceleration and angle data for the right lower arm are 
presented (Figure 22), since eating food with a spoon 
involves much rolling motion. The angle of head for the 
direction of gravity is also presented (Figure 22 (a-3), (b-3), 
and (c-3)). The range of change in the acceleration Y, Z, and 
pitching of his right hand are bigger, as there was less 
motion restriction. The angle of head for the direction of 
gravity during eating is bigger, as there was less motion 
restriction. The participant had to close his face to curry and 
was hard to roll his hand during eating in condition a. 
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
17
22
27
32
Time (sec.)
加速度X
加速度Y
加速度Z
Acceleration (G)
(a-1) Acceleration (left lower arm)
(a-2) Acceleration (right lower arm)
Acceleration (G)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
17
22
27
32
Time (sec.)
加速度X
加速度Y
加速度Z
(a-3) Acceleration (head)
Acceleration (G)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
6
11
16
21
26
Time (sec.)
加速度X
加速度Y
加速度Z
(b-1) Acceleration (left lower arm)
Acceleration (G)
(b-2) Acceleration (right lower arm)
Acceleration (G)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
6
11
16
21
26
Time (sec.)
加速度X
加速度Y
加速度Z
(b-3) Acceleration (head)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
5
10
15
20
Time (sec.)
加速度X
加速度Y
加速度Z
Acceleration (G)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
5
10
15
20
Time (sec.)
加速度X
加速度Y
加速度Z
(c-1) Acceleration (left lower arm)
(c-2) Acceleration (right lower arm)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
7
9
11
13
15
17
Time (sec.)
加速度X
加速度Y
加速度Z
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
17
22
27
32
Time (sec.)
加速度X
加速度Y
加速度Z
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
5
10
15
20
Time (sec.)
加速度X
加速度Y
加速度Z
(c-3) Acceleration (head)
Acceleration (G)
Acceleration (G)
Acceleration (G)
Brushing
Brushing
Brushing
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
 
(a) Condition a                                                           (b) Condition b                                                       (c) Condition c 
 
Figure 20. Data collected during teeth brushing. 
 
167
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
7
9
11
13
15
17
Time (sec.)
加速度X
加速度Y
加速度Z
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
4
6
8
10
12
14
16
18
Time (sec.)
加速度X
加速度Y
加速度Z
Acceleration (G)
(a-1) Acceleration (left lower arm)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
4
6
8
10
12
14
16
18
Time (sec.)
加速度X
加速度Y
加速度Z
(a-2) Acceleration (right lower arm)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
4
6
8
10
12
14
16
18
Time (sec)
加速度X
加速度Y
加速度Z
(a-３) Acceleration (head)
Acceleration (G)
Acceleration (G)
Acceleration (G)
(b-1) Acceleration (left lower arm)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
7
9
11
13
15
17
Time (sec.)
加速度X
加速度Y
加速度Z
Acceleration (G)
(b-2) Acceleration (right lower arm)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
7
9
11
13
15
17
Time (sec.)
加速度X
加速度Y
加速度Z
Acceleration (G)
(b-３) Acceleration (head)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
4
6
8
10
12
14
Time (sec.)
加速度X
加速度Y
加速度Z
(c-1) Acceleration (left lower arm)
Acceleration (G)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
4
6
8
10
12
14
Time (sec.)
加速度X
加速度Y
加速度Z
(c-2) Acceleration (right lower arm)
Acceleration (G)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
4
6
8
10
12
14
Time (sec.)
加速度X
加速度Y
加速度Z
Acceleration (G)
(c-３) Acceleration (head)
Washing
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
X
Y
Z
Washing
Washing
 
(a) Condition a                                                          (b) Condition b                                                       (c) Condition c 
 
Figure 21. Data collected during face washing. 
 
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
4
9
14
19
24
29
Time (sec.)
加速度X
加速度Y
加速度Z
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
12
17
22
27
32
37
Time (sec.)
加速度X
加速度Y
加速度Z
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
4
9
14
19
24
29
34
Time (sec.)
加速度X
加速度Y
加速度Z
(a-1) Acceleration (right lower arm)
Acceleration (G)
Acceleration (G)
(b-1) Acceleration (right lower arm)
(c-1) Acceleration (right lower arm)
Acceleration (G)
X
Y
Z
X
Y
Z
X
Y
Z
Angle (degree)
(a-2) Angle (right lower arm)
(b-2) Angle (right lower arm)
(c-2) Angle (right lower arm)
-180
-130
-80
-30
20
70
120
170
4
9
14
19
24
29
34
Time (sec.)
ヨー…
ロー…
ピッ…
-180
-130
-80
-30
20
70
120
170
12
17
22
27
32
37
Time (sec.)
ヨー…
ロー…
ピッ…
-180
-130
-80
-30
20
70
120
170
4
9
14
19
24
29
Time (sec.)
ヨー…
ロー…
ピッ…
Angle (degree)
Angle (degree)
Y
R
P
Y
R
P
Y
R
P
(a-３) Angle for the gravity (head)
Angle (degree)
(b-３) Angle for the gravity (head)
(c-３) Angle for the gravity (head)
0
20
40
60
80
100
4
9
14
19
24
29
Time (sec)
0
20
40
60
80
100
12
17
22
27
32
37
Time (sec)
Time (sec)
0
20
40
60
80
100
4
9
14
19
24
29
34
Angle (degree)
Angle (degree)
 
(a) Condition a                                                           (b) Condition b                                                       (c) Condition c 
 
Figure 22. Data collected during eating. 
168
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

These results demonstrate that measured data for lower 
arm motions are effective for detecting differences in 
motion restriction levels. Although it impossible to detect a 
difference using data for a single activity, such as teeth 
brushing or face washing, it is possible to detect one using 
data for a combination of activities, such as teeth brushing, 
face washing, and/or eating. 
VI. 
MEASUREMENT FOR HEMIPLEGIC PATIENTS 
 We collected and analyzed data for the walking and 
drinking motions of two hemiplegic patients and three 
healthy participants who wore seven wearable devices for 
collecting data. Their placements for each motion are shown 
in Figure 23. Data were collected for three stable walking 
cycles and for one drinking motion on the paretic side. The 
UE and LE functionalities of the two hemiplegic patients 
were assessed on the basis of FMA by physical and 
occupational therapists. Hemiplegic patient A had severe 
impairment on the paretic side (FMA UE score: 25; LE 
score: 14) while hemiplegic patient B had mild impairment 
on the paretic side (FMA UE score: 58; LE score: 26). 
The data were collected safely and smoothly for both the 
hemiplegic patients and healthy participants. The walking 
and drinking motions during collection were the same as 
their usual motions. The periods were longer for the patients 
due to their severe impairment. Since the period of time 
during walking and drinking and the acceleration and angle 
data for every healthy participant were similar, data for a 
typical healthy participant were presented in this paper. 
Figure 24 shows the raw acceleration and angle data for 
the paretic-side lower leg for hemiplegic patients A (a-1 and 
2) B (b-1 and 2), and for the left lower leg for the healthy 
participant (c-1 and 2) for the walking motion. While it is 
difficult to recognize walking gait cycles from the 
acceleration data for hemiplegic patients B and the health 
participant, the walking gait cycles are clearly recognized in 
the yaw angle data for all participants. The yaw angle 
indicates forward movement in the lower leg. The range for 
the healthy participant is biggest in three participants. The 
range is smaller for the hemiplegic patients due to their 
severe impairment. 
Figure 25 shows the raw acceleration and angle data for 
the paretic-side lower arm and for the head for hemiplegic 
patients A (a-1, 2, and 3) and B (b-1, 2, and 3), and for the 
left lower arm and head for the healthy participant (c-1, 2, 
and 3) for the drinking motion. The data indicate a larger 
forward movement of the head for the hemiplegic patients 
than for the healthy participant. And, the range of yaw angle 
of the lower arm of patient A is smaller than that of patient 
B and the healthy participant. This difference is attributed to 
the severe impairment and compensatory movements of the 
patients. 
This experiment demonstrated that this device and 
system can safely and smoothly collect motion data for 
hemiplegic patients as well as healthy individuals. They are 
thus suitable for quantitative assessment of ADL for 
hemiplegic patients. 
  
 
(a) Drinking a cup of water                            (b) Walking 
Figure 23. Experimental scenes with a hemiplegic patient 
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
17
19
21
23
25
27
29
Time(sec)
X
Y
Z
Acceleration (G)
Angle (degree)
-180
-130
-80
-30
20
70
120
170
17
19
21
23
25
27
29
Time(sec)
Y
R
P
1 cycle
(a-1) Acceleration (lower leg on paretic side)
(a-2) Angle (lower leg on paretic side)
Acceleration (G)
Angle (degree)
(b-1) Acceleration (lower leg on paretic side)
-180
-130
-80
-30
20
70
120
170
12
13
14
15
16
17
Time(sec)
Y
R
P
(b-2) Angle (lower leg on paretic side)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
12
13
14
15
16
17
Time(sec)
X
Y
Z
1 cycle
Acceleration (G)
Angle (degree)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
12
13
13
14
14
15
15
16
16
Time(sec)
X
Y
Z
-180
-130
-80
-30
20
70
120
170
12
13
13
14
14
15
15
16
16
Time(sec)
Y
R
P
(c-2) Angle (left lower leg)
(c-1) Acceleration (left lower leg)
1 cycle
 
(a)  Hemiplegic patient A                                           (b) Hemiplegic patient B                                        (c) Healthy participant 
Figure 24. Data collected walking 
169
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

VII. CONCLUSION AND FUTURE WORK 
Existing evaluation indexes for activities in daily living 
(ADL) recovery levels such as the Barthel Index are based 
on responses to questionnaires. Therefore, the judging of 
recovery levels can be easily affected by an evaluator’s 
subject. We have presented a system for collecting and 
storing motion data about daily life activities for use in 
quantitatively evaluating ADL recovery levels. The system 
was developed on the basis of Google Firebase. We used 
information about places such as a dining room and a 
bathroom to estimate the type of activity. The places are 
detected using Bluetooth beacons.  
Measurement results obtained for a healthy volunteer 
with restricted movement demonstrated that it is possible to 
detect slight differences in the restriction level. However, it 
is difficult to estimate whether the motions can be 
performed without help.  
Through the experiment measuring for hemiplegic 
patients, the proposed system can collect motion data safely 
and smoothly.  Measurement results obtained from two 
hemiplegic patients whose severity of impairment were 
different shows that it is possible to detect slight differences 
in the severity. 
Planned improvements to the proposed system include 
uploading video and GPS data to a cloud server. GPS data 
will enable measurement of motion during walking or 
running outdoor.  
Our goal is to develop a new index for evaluating ADL 
recovery levels on the basis of big motion data measured for 
people performing various activities. 
ACKNOWLEDGEMENT 
The authors extend thanks to Mr. Kazuhiro Yoshida, Mr. 
Fumiaki Yamaguchi, and Mr. Shunpei Okimura for the help 
he provided in performing this research. The research and 
development 
was 
supported 
by 
the 
MIC/SCOPE 
#181602007. 
REFERENCES 
[1] R. Takahashi, Y. Murata, and O. D. A. Prima, “A System for 
Collecting Motion Data on Patients’ Activities of Daily Living,” 
IARIA, Proceedings of eTELEMED 2019, pp. 7-12, 2019. 
[2] The Barthel Index; 
 http://www.strokecenter.org/wp-content/uploads/2011/08/barthel.pdf 
[retrieved: November, 2019]. 
[3] F. I. Mahoney and D. Barthel, “Functional evaluation: The Barthel 
Index.”, Maryland State Medical Journal 1965, vol.14, pp. 56-61, 
1965. 
[4] D. Chumney et al., “Ability of Functional Independence Measure to 
accurately predict functional outcome of stroke-specific population: 
Systematic review,” Departmentof Veterans Affairs, Journal of 
Rehabilitation Research & Development, Volume 47, Number 1, pp. 
17-29, 2010. 
[5] M. Shelkey and M. Wallace, “Katz index of independence in activity 
of daily living (ADL),” https://www.semanticscholar.org/paper/Katz-
Index-of-Independence-in-Activities-of-Daily-Shelkey-
Wallace/fb433f328b79f56d82a52551960c93da74469baa  
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
10
30
50
70
Time(sec)
X
Y
Z
Acceleration (G)
-180
-130
-80
-30
20
70
120
170
10
30
50
70
Time(sec)
Y
R
P
Angle (degree)
(a-1) Acceleration (lower arm on paretic side)
(a-2) Angle (lower arm on paretic side)
0
20
40
60
80
100
120
10
30
50
70
Angle (degree)
(a-3) Angle (head)
Time (sec)
Time (sec)
Acceleration (G)
Angle (degree)
Angle (degree)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
9
11
13
15
17
19
Time(sec)
X
Y
Z
Acceleration (G)
Angle (degree)
Angle (degree)
-180
-130
-80
-30
20
70
120
170
9
11
13
15
17
19
Time(sec)
Y
R
P
0
20
40
60
80
100
120
140
9
11
13
15
17
19
(b-1) Acceleration (lower arm on paretic side)
(b-2) Angle (lower arm on paretic side)
(b-3) Angle (head)
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
9
10
11
12
13
14
15
16
17
Time(sec)
X
Y
Z
-180
-130
-80
-30
20
70
120
170
9
10
11
12
13
14
15
16
17
Time(sec)
Y
R
P
0
20
40
60
80
100
120
140
9
10
11
12
13
14
15
16
17
Time (sec)
(c-1) Acceleration (left lower arm)
(c-2) Angle (left lower arm)
(c-3) Angle (head)
Drinking
Drinking
Drinking
 
(a)  Hemiplegic patient A                                           (b) Hemiplegic patient B                                        (c) Healthy participant 
Figure 25. Data collected drinking 
170
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[retrieved: November, 2019]. 
[6] S. Katz et al., “Progress in development of the index of ADL,” 
Gerontologist 1970, vol. 10, pp. 20 –30, 1970. 
[7] M. Shelkey, and M. Wallace, “Katz Index of Independence in 
Activities of Daily Living (ADL),” The Hartford Institute for 
Geriatric Nursing, New York University, College of Nursing, Issue 
Number 2, 2012. 
[8] Bluetooth 
Technology; 
https://www.bluetooth.com/bluetooth-
technology/radio-versions, [retrieved: November, 2019]. 
[9] T. Amemiya et al., “Activities of Daily Living and Quality of Life of 
Elderly Patients After Elective Surgery for Gastric and Colorectal 
Cancers,” Lippincott Williams & Wilkins, Annals of Surgery, 
Volume 246, Number 2, pp. 222-228, 2007. 
[10] Google Firebase Cloud Messaging, 
https://firebase.google.com/docs/cloud-messaging/?hl=en,  
 [retrieved: November, 2019]. 
[11] K. J. Sullivan et al., “Fugl-Meyer assessment of sensorimotor 
function after stroke: standardized training procedure for clinical 
practice and clinical trials.”  Stroke, vol. 42, pp.  427-432, 2011 
[12] K. Zhan, S. Faux, and F. Ramos, “Multi-scale Conditional Random 
Fields for First-Person Activity Recognition on Elders and Disabled 
patients,” ELSEVIER, Pervasive and Mobile Computing, Volume 16, 
Part B, pp. 251-267, 2015.. 
[13] L. Wang, T. Gu, X. Tao, H. Chen, and J. Lu, “Recognizing Multi-
User Activities Using Wearable Sensors in a Smart Home,” 
ELSEVIER, Pervasive and Mobile Computing, Volume 7, Number 3, 
pp. 287-298, 2011. 
[14] D. Debraj, B. Pratool, K. D. Sajal, and C. Sriram, “Multimodal 
Wearable Sensing for Fine-Grained Activity Recognition in 
Healthcare,” IEEE, Internet Computing, pp. 26-35, 2015. 
[15] Y. Zhang et al., “Health-CPS: Healthcare Cyber-Physical System 
Assisted by Cloud and Big Data,” IEEE, Systems Journal, Volume 11, 
Number 1, pp. 88-95, 2017. 
[16] C. Doukas, T. Pliakas, and I. Maglogiannis, “Mobile Healthcare 
Information Management utilizing Cloud Computing and Android 
OS,” IEEE, 2010 Annual International Conference of the IEEE 
Engineering in Medicine and Biology, pp. 1037-1040, 2010. 
[17] Eri, Inc., https://www.erii.co.jp/en/, [retrieved: November, 2019]. 
[18] SONY Smart Watch 3, 
https://www.sonymobile.com/global-en/products/smart-
products/smartwatch-3-swr50/#gref, [retrieved: November, 2019]. 
[19] LSM6DSL, STmicroelectronics, https://www.st.com/en/mems-and-
sensors/lsm6dsl.html, [retrieved: November, 2019]. 
[20] HRM1062, Hosiden, 
https://www.hosiden.co.jp/news/product/hrm1062.html 
         [in Japanese, retrieved: November, 2019]. 
 
 
 
 
 
 
171
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

