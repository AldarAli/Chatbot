81
International Journal on Advances in Intelligent Systems, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org
Reporting and Analyzing Student Behavior in 3D Virtual Worlds 
 
 
 
 
 
Aliane Loureiro Krassmann 
Graduate Program of Informatics in Education 
Universidade Federal do Rio Grande do Sul (UFRGS) 
Porto Alegre/RS â€“ Brazil 
alkrassmann@gmail.com 
 
Felipe Becker Nunes 
Liane Margarida Rockenbach Tarouco 
Graduate Program of Informatics in Education 
Universidade Federal do Rio Grande do Sul (UFRGS) 
Porto Alegre/RS â€“ Brazil 
liane@penta.ufrgs.br 
 
Magda Bercht 
Graduate Program of Informatics in Education 
Universidade Federal do Rio Grande do Sul (UFRGS) 
Porto Alegre/RS â€“ Brazil 
nunesfb@gmail.com  
 
Tito Armando Rossi Filho 
Graduate Program of Informatics in Education 
Universidade Federal do Rio Grande do Sul (UFRGS) 
Porto Alegre/RS â€“ Brazil 
rossitito@hotmail.com 
 
 
Abstractâ€”Virtual Worlds are open 3D environments capable of 
simulating a variety of educational practices, thus reducing 
risks and costs with physical laboratories. However, its freedom 
characteristic can cause dispersion and make it difficult to 
navigate and focus. Aiming at improving user navigation, this 
paper analyzes a Heads Up Display (HUD) solution that keeps 
sensing the locations visited by the user, and presents it in the 
form of a â€œheat mapâ€. The main contribution has two sides: 1) 
a reporting system is presented, which allows teachers to easily 
keep up with studentsâ€™ behavior in the environment; 2) an 
analysis of experimental data has been performed, focusing on 
the extent and intensity of content observation, with the 
purpose of presenting the potential of the HUD to act as a 
guidance tool in educational Virtual Worlds. 
Keywords-virtual 
worlds; 
heads 
up 
display; 
student 
interaction. 
I. 
INTRODUCTION 
This paper is an extended version of [1], which proposed 
the use of Heads Up Display (HUD) device working as a heat 
map, to create a context-aware Virtual World (VW), coming 
to the conclusion that it helped on studentsâ€™ navigation. The 
HUD could be attached to any userâ€™s screen by touch, and it 
would keep dynamically inferring its context, changing 
colors according to the locations visited and the frequency 
(or duration) of visitation.  
VW are 3D open environments where users, represented 
by their own avatars, can move around, meet and interact 
with other avatars [2]. This technology is capable of 
simulating whole environments, thus greatly decreasing 
costs and risks of conducting experiments in physical 
laboratories [3].  
Graduate Program of Informatics in Education 
Universidade Federal do Rio Grande do Sul (UFRGS) 
Porto Alegre/RS â€“ Brazil 
bercht@inf.ufrgs.br 
 
 
 
 
 
 
 
 
Also, according to Englund [4], it enables to move away 
from traditional classroom learning and to design activities 
with an emphasis not on â€œlearning aboutâ€, but with focus on 
â€œlearning by beingâ€ or â€œlearning by doingâ€. Mastrokoukou 
and Fokides [5] highlight that although the development of 
these environments is quite a lengthy process, long term 
benefits of its use may arise, since it can be reused several 
times. 
Chow [6] explains that a VW is characterized by being 
more exploratory, active and participatory, rather than 
centralized in listening and absorbing information. 
Multiusers are encouraged to navigate freely through 
different locations within the environment, to develop their 
own learning processes, according to their own demand [7].  
Due to the great diversity of didactic materials that can 
be inserted in VW, such as texts, images, videos and 
presentation slides, different spaces or rooms can be created, 
separated by, for example, subject or type/category of 
content. Simsek and Can [8] assert that giving students the 
freedom to choose the type of learning material to explore, 
makes them more active individuals in their learning process. 
As the ones who spend more time inside it tend to interact 
more with educational objects [9], it is desirable for the user 
to spend long times navigating the VW. Studies have 
described that the total number of visits to a learning object 
may indicate student interest [10].  
However, these characteristics of discovery-based 
environments, which offer the greatest potential to promote 
learning, at the same time represent the biggest challenge: 
the complexity of the learning experience [11]. According to 
Mayer [12], environments designed to make users discover 

82
International Journal on Advances in Intelligent Systems, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org
materials completely on their own are harder to use. GÃ¼tl 
[13] discovered that if users spend too much time learning to 
use a complex interface they might leave the environment. 
This leads to several educational implications, as 
engagement hindrance or demotivation, as users may be 
distracted by numerous functions and simulated scenes in the 
VW, disturbing their attention from the learning contents [3]. 
For example, Ijaz, Bogdanovych and Trescak [14] found, 
in an unsupervised experiment, that participants did not 
properly explore the VW: important areas were left 
unexplored. Also, some students faced technical issues and 
did not fully achieve the learning objective; in consequence, 
scored low in the exam. In their study, Griol, Molina and 
Callejas [15] found that the amount of options and tools 
available in the VW had a negative effect in some students, 
who felt disoriented. They suggest this happened especially 
to players of video games, as they are used to follow a script, 
with predeï¬ned outcomes.  
This way, Christensen, Maraunchak and Stefanelli [16] 
suggest that the educational use of VW must be carefully 
articulated and organized by the teacher. Csikszentmihalyi 
[17] emphasizes that activities stimulate more flow if they 
embody certain rules and clearly state what the users should 
do.  
Moreover, for immersive learning environments to act as 
it is expected, with students having great flexibility while 
faced with numerous learning opportunities, intelligent real-
time support and guidance is required [14]. This means that, 
in accordance with TÃ¼zÃ¼n and Ã–zdinÃ§ [18], being informed 
about the objects and locations in the environment plays a 
key role in getting to know about other paths. Baydas et al. 
[19] exemplified how reflective guidance, directive signs, 
symbols, footprints and notice boards within the VW can be 
helpful in achieving the learning goals, getting some positive 
results.  
However, one of the most complicated aspects inside 
VW is precisely automatic scaffolding or guidance, since it 
is very large and flexible [18]. As stressed by Soliman and 
Guetl [20], it is not unusual to see the lack of autonomous 
support in VW, and learners find themselves alone with no 
guidance.  
The usual approach to provide automatic guidance on 
VW is concentrated on virtual agents. According to Johnson, 
Rickel and Lester [21] animated agents that can serve as 
guides are an important instructional aid, so students wonâ€™t 
become disoriented and lost in virtual reality environments. 
Xie and Luo [22] identified that students performed better 
and in less time because they could find the destinations 
quickly with the help of virtual agents. Also, they felt more 
satisfied. 
In the last decades, ubiquitous computing techniques 
have been used aimed at improving student performance, and 
consequently, beneficiating institutional cost effectiveness 
[23]. In line with this trend, and as an alternative from the 
virtual agentsâ€™ scenario, several researches have benefited 
from the use of HUD device capabilities, available to 
implement in most of the VW platforms, as OpenSimulator 
and Second Life, to personalize and dynamize VW in 
different ways.  
Extending the work of [1], in the current research we 
intend to: a) establish a way to enable teachers to easily 
extract reports of studentâ€™s behavior in the environment, in 
order to help monitoring educational activities; and b) 
analyze differently the records from the experiment 
previously performed, to verify if the HUD can influence in 
the extent and in the intensity of didactic content observation 
in the environment. Thus, we will try to answer the following 
main research question: how is it possible to (1) report and 
(2) analyze student behavior inside Virtual Worlds? We 
will discuss on how these two aspects can be useful for 
student assessment and pedagogical improvements in 
educational VW. 
The article is organized as follows: Section II presents the 
related work; Section III explains the research method; 
Section IV presents the developed report system; Section V 
shows the analysis performed with the data, discussing 
results found; ending with Section VI, which presents the 
conclusions and future research. 
II. 
RELATED WORK 
In this section, we present some examples of how HUD 
and heat map devices have been used towards optimizing 
user experience.  
Using Second Life platform, Shah, Bell and Sukthankar 
[24] implemented a recommendation system that suggests 
places to visit, personalized with the userâ€™s destination 
preferences. To acquire data on usersâ€™ travel patterns, they 
developed a custom tracker object using the Linden Scripting 
Language (LSL), which periodically prompts the user to 
enter information describing and evaluating its current 
location. The HUD could be worn on the right or left side of 
the screen, and it monitor the avatar current location (x, y, z 
coordinates).  
In the study of Keelan et al. [25] each participant was 
given a HUD that allowed them to indicate up to eight 
emotional states throughout the Second Life visitation, four 
positive and four negative. The goal was to identify and 
analyze which aspects invoked emotional responses, and 
what kinds of information were considered trustworthy or 
untrustworthy by the users.  
One of the promising VW applications that seem to 
demand such a device is the visit of virtual museums. In this 
field, Sookhanaphibarn and Thawonmas [26] emphasize that 
personalization can play a key role for increasing the number 
of return visitors. They mention the idea of using HUD to 
show personalized recommendations in VW, like to what has 
already been implemented for physical museums, but with 
the advantages of requesting simple implementation and no 
additional cost.  
Likewise, Ward and Sonneborn [27] implemented a 
HUD that provides subtitles of dialogue in many languages, 
including English, French, German, Spanish, Italian, and 

83
International Journal on Advances in Intelligent Systems, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org
Portuguese. Also, the HUD records the avatarâ€™s position so 
users can know where they are in the build and receive audio, 
pictorial and textual information about what they are seeing 
on their visit. 
In the field of displaying or highlighting locations to 
situate the student, the Virtual Learning Environment (VLE) 
MOODLE in more recent versions (2.7 onwards) has a 
plugin that implements the â€œheat mapâ€ concept to help user 
navigation, using a color scheme (yellow, orange and red) to 
represent the â€œheatingâ€. The heat map highlights areas as 
well as components that highly attracted studentsâ€™ attention 
by counting the number of clicks.  
Rakoczi [28] developed a similar system, but tracking the 
studentâ€™s eye movements to identify areas â€œmore lookedâ€, 
that is, which captured more attention, as shown in Figure 1. 
 
Figure 1. Heat map of MOODLEâ€™s calendar [28].  
 
Similarly to the studies presented, Krassmann et al. [1]  
showed the initial results of the development and application 
of a context-aware HUD that works as a heat map, â€œheatingâ€ 
(changing colors) as the locations in the VW are visited more 
often, allowing the user to be aware of his/her own 
navigation behavior. The authors explored how this device 
could help on improving engagement and interaction time, 
getting some good results. 
In this extended version, we present the development of 
a system that allows teachers to extract reports from userâ€™s 
behavior in the Virtual World, enabling to see patterns of 
studentsâ€™ access in a simple and intuitive way, facilitating 
monitoring and assessment, without the need for the teacher 
to be in person observing the activity. Also, we analyze some 
of the data gathered from the experiment performed in [1], 
using statistical techniques to investigate new hypothesis, as 
the impact of the HUD in the extent and intensity of content 
observation, and in face of the difficulty level of accessing 
locations in the virtual environment. 
III. 
MATERIALS AND METHOD 
The research is an exploratory quasi-experimental study, 
with a convenient sample of individuals who had a minimum 
level of computer skills. A region in the Virtual World from 
AVATAR Project [29] (an acronym in Portuguese that 
means Virtual Learning Environment and Remote Academic 
Work) was used. This project intends to investigate, test and 
promote the training and the use of virtual laboratories in 
immersive 
environments, 
using 
the 
open-source 
OpenSimulator platform. A set of regions are implemented 
in this VW, within different subjects as Physics, Electricity, 
Chemistry, among others. 
Students enrolled in courses at the authorsâ€™ university 
and colleagues that work on the project were invited to 
participate in the experiment, which took place on the 
university facilities. Singularity [30] and Firestorm [31] 
viewers were used to enter the VW, being those free 
softwares 
capable 
of 
rendering 
the 
3D 
graphical 
environment appropriately. 
To explain more in detail the method of research, we 
have created subsections regarding the VW development, the 
heat map HUD implementation and the experiment design 
and execution. 
A. The Virtual World 
Two virtual laboratories, in one region from AVATAR 
Project, were used: Waves and Wireless Networks, which 
are introduced on Krassmann et al. [32]. According to the 
authors, in these environments students from Secondary or 
Technical education have the opportunity to visualize the 
practical side of some abstract concepts that are part of their 
daily life, as the propagation of radio waves and Wi-Fi 
communication.  
To improve the organization of content and provide a 
clear distribution, these two teaching contents were divide 
into 12 topics, distributed along 12 specific locations in the 
two laboratories, which are presented in Table I.  
TABLE I. 
LOCATIONS AND TOPICS DISTRIBUTION 
Number 
Content topic/subject 
1 
Wave Characteristics 
2 
AM and FM Radio Waves 
3 
Wave Phenomena 
4 
Electromagnetic Spectrum 
5 
Introduction to Wireless Networks I 
6 
Introduction to Wireless Networks II 
7 
Wireless Networks Topologies 
8 
Infrared and Bluetooth 
9 
Range of Wireless Networks I 
10 
Range of Wireless Networks II 
11 
Range of Wireless Networks III 
12 
Material interference in propagating wireless networks 
 
In each of the 12 locations, different didactic materials 
such as videos, presentation slides, images, texts, animated 
digital media, audios, web pages embedded in QR (Quick 
Response) code and simulations were implemented, 
according to the location subject. Each one was identified as 
to their type through luminous plaques and with short 

84
International Journal on Advances in Intelligent Systems, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org
instructions displayed on the bottom, seeking to provide an 
intuitive and independent navigation for users.  
Figure 2 presents a screenshot of the environment 
entrance. It can be seen that a control panel was placed at the 
beginning of the path, containing buttons that give the user 
introductory information, for example, on how to move 
around, use the didactic materials and what is expected in 
this visitation. Also, thereâ€™s a green button where the user 
can attach itself the HUD. In this case, the user have already 
pushed the button and the HUD is on the right side the 
screen. 
 
Figure 2. Waves and Wireless Networks Laboratories entrance. 
 
To help on student guidance, Figure 3 shows plaques 
simulating wooden material with arrows pointing the 
directions to each location. The aim of this signalization was 
to ensure that users without the HUD could also navigate the 
environment and visit all the locations available.  
 
Figure 3. Plaques with arrows pointing the directions to each location. 
B. The heat map HUD 
The HUD is composed of a numerical map of the 
environment. It can be attached by the user by touching one 
time on the corresponding button, and it goes to its top right 
screen. It works sensing the places visited, recording into a 
database and retrieving this information in real time.  
The HUD is composed of 12 prims (primitives â€“ 3D 
object unit) that are linked. Each prim has its own texture that 
identifies the number and the topic of one location, and its 
own scripts to change its color from white to red, â€œheatingâ€ 
according to the frequency of access or time elapsed on 
visitation. To do this, the classification presented in Table II 
was idealized and adopted. 
TABLE II. 
HEAT MAP CLASSIFICATION ON HUD 
Color 
Tag 
 Frequency 
Time elapsed 
Yellow 
Weak 
   Second time 
2 minutes 
Orange 
Medium 
   Third time 
3 minutes 
Red 
Strong 
    Fourth time 
4 minutes 
 
In this sense, if the user has remained at one of the 12 
locations for at least two minutes, according to our 
classification, it is assumed he/she is visiting this location for 
the second time, so the prim on the HUD that represents this 
location turns yellow; after three minutes it turns orange, and 
after four minutes it turns red. The sensor checks every five 
seconds for the presence of an avatar and consults in the 
database if this specific user has already visited the place, 
registering it only after every minute (60 seconds), in an 
incremental way. The prim also has the ability, by touching 
it, to tele transport users to the respective location. 
Figure 4 shows the heat map following the userâ€™s avatar 
at two different locations in the VW. It can be seen, for 
example, that this user has visited Location 5 very often 
(red), but Location 3 lacks visiting, as it is still white (top 
screen). It also shows that Location 8 is now changed from 
yellow to red (bottom screen). So it can be concluded that 
this user got back to that location twice more and/or has spent 
more two minutes in the same spot (from yellow â€“ 2 minutes; 
to red â€“ 4 minutes). 
 
Figure 4. HUD following the student in two different locations. 
The identification of locations inside the VW were 
signalized with circles on the floor, with sensors 
programmed to identify avatars presence in a radius of eight 
meters. Figure 5 shows a screenshot of Location 4 
â€œElectromagnetic Spectrumâ€, with the gray circle on the 
floor identifying it (â€œL4â€). 

85
International Journal on Advances in Intelligent Systems, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 5. Screenshot of Location 4 â€œElectromagnetic Spectrumâ€. 
Besides LSL programming language, OpenSimulator 
Scripting Language (OSSL) was used to program the HUD. 
To capture data from each user in real time, the sensors 
collect data and send it through HTTP requests. All this 
procedures are managed by a WAMP system (Windows, 
Apache, MySQL, PHP). 
More specifically, the function llSensor was used to 
create an invisible monitoring field, defining the area of the 
sweep (eight meters). This sensor is activated every 60 
seconds, through the use of llSetTimerEvent(60) function, 
whose call is carried out by the instruction. In this way, the 
sensor checks if there are users in its coverage range every 
60 seconds. If so, the avatar name is verified and stored, 
along with the information about the current location.  
The script which performs this sensing operation in the 
VW environment works in the following way (written in 
pseudocode).  
 
1. Set the time: llSetTimerEvent(60) 
 
2. When time reaches, activate sensor: 
llSensor("", NULL_KEY, AGENT, 8, PI) 
 
3. When sensor activates, search for avatar name:  
avatar_name = llDetectedName(x) + avatar_name 
    
4. Once avatar name is captured, gather the data: 
string hud = 
avatar_name+location_id+location_name+time    
     
5. Pass the data to PHP file: 
llHTTPRequest("http://server/heatmap.php?dados
_user="+hud, [HTTP_METHOD,"GET"],"") 
 
6. Get the answer from server: 
http_response(key request_id, integer status, 
list metadata, string hud) 
 
As shown in the pseudocode presented, the information 
is sent through the function llHTTPRequest. The function 
HTTP_METHOD â€œGETâ€ is the one which enables the PHP 
file in the server to receive the data. The file receives it and 
â€œexplodesâ€ it in an array, separating location id, location 
name and time the user remained in that location. The names 
of each user that were inside the sensor area at the moment 
of data collection are separated and organized. Another 
function works registering time records in which this 
occurred. After all these treatments, data are ready to be sent 
to MySQL database, where they are stored.  
Data are stored in the â€œheat mapâ€ table of the database, 
as follows: a) userâ€™s name; b) name and ID of the location 
visited; c) time user remained in that location (60, 120, 180 
or 240 seconds); d) the current heat map status for the user at 
that location (white, yellow, orange or red); e) time records. 
When visiting a location for the first time, a new complete 
record is inserted in this table, so time and current heat map 
status attributes are subsequently updated, according to an 
incremental analysis of time elapsed.  
Immediately after this procedure, the avatar_name 
attribute has to be cleaned, so it can be received again and 
compared in the table. The http_response then brings the 
answer, which is passed through the channel 225 (selected 
by us) to update the HUD, if necessary. 
This process can occur simultaneously for several users, 
receiving all interactions occurred from the sensors inserted 
inside the environment, allowing the sensing of multiple 
users in different locations, without competition problems. 
C. The experiment 
Data from an experiment performed in Krassmann et al. 
[1] is analyzed. As described by the authors, on the occasion 
16 individuals, divided into control and experimental groups, 
were informed about the experiment goals, the voluntary 
aspect of their participation and the complete confidentiality 
of any data gathered about them. Each one received an 
individual login to access the 3D environment. They were 
instructed to freely and intuitively navigate in the VW, 
without any pedagogical path or visitation time previously 
defined. The purpose of this orientation was to provide them 
with freedom to interact in places they considered 
appropriate, visiting the desired materials and remaining in 
each location as long as they were interested. 
Immediately after the session, that lasted for an average 
of approximately 33 minutes, a questionnaire was 
administered, containing demographic questions and items 
regarding the navigation in the environment, including the 
impressions about the heat map (HUD) for the experimental 
group. The main findings are presented in the original paper 
[1]. In this extended version we focus on creating a reporting 
system and analyzing student interaction in a more profound 
way, which corresponds to the two next sections. 
IV. REPORTING STUDENT INTERACTION 
As mentioned by Balderas et al. [33], VWs developed 
using open-source software â€” such as OpenSimulator â€” 
allow developers and teachers to access student logs and 
retrieve valuable information on learnersâ€™ in-world behavior 
and interaction. This possibility, explored in this research, is 
important not only in terms of assessment: it also facilitates 
the identification of learner profiles and VW behavior 
patterns, which can help improving the environment, as it 
allows the accomplishment of different types of actions to 
assist the students during their interaction [27]. 

86
International Journal on Advances in Intelligent Systems, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org
Duncan, Miller and Jiang [34] corroborates that having a 
good understanding of the userâ€™s in-world behavior can help 
on improving the educational use. They suggest that, as 
students virtually participate, it may be hard for the teachers 
to monitor the educational process, being difficult to tell 
whether the students are actually learning or playing in the 
VLE.  
However, a high degree of dependence on the teacher or 
his/her constant intervention in the activity is also 
undesirable. Ijaz, Bogdanovych and Trescak [14] discovered 
that it decreases interactivity and immersion of participants: 
users became less engaged in the experience and were keen 
to finish it quickly. 
In order to improve and facilitate student monitoring and 
evaluation, by the pedagogic point of view and in an 
autonomous way, a reporting web-system was developed. Its 
objective is to facilitate the process of analysis of studentâ€™s 
interactions inside the 3D VLE without the need of the 
teacher assistance. The system was basically developed with 
the PHP programming language and the connection to the 
MySQL database, with the previously described â€œheat mapâ€ 
table, which stores all user interactions received from the 
HUD. 
With the data of each user, it is possible to identify which 
places were visited in the environment, since in these places 
sensors are triggered by the presence of a user and record this 
information in the database. In this sense, based on the data 
collected from students interactions in the two laboratories 
(12 locations), we have implemented six different types of 
reports, described as follows.  
1. 
Student Activity Report: the data of a specific 
user, selected by the teacher, are presented for an individual 
assessment, showing locations the student visited, how long 
he/she remained on each one, and the tags related to each 
time. An example is presented in Figure 6. 
2. 
Activity Report by Location: in this report all 
interactions occurring in a specific location are extracted, 
allowing the teacher to see an overview of places that have 
been visited the most, and, on the other hand, which need to 
be more stimulated to visitation. For instance, it might be a 
warning for the teacher that a specific location lacks 
attractiveness. Figure 7 shows a clipping of an example of 
this report, showing all user presence captured in Location 8 
â€œInfrared and Bluetoothâ€. 
3. 
Activity Report by Time: the teacher has the 
possibility to investigate, in this report, the interaction that 
occurred in different intervals of time, covering all locations 
and students. For example, it can show all the places and 
users with a 180 seconds tag (visited three times or for three 
minutes). It can be useful for the teacher, for instance, to 
immediately verify places more accessed (time = 240 
seconds) and, on the other hand, places that were never 
visited (time = 0 seconds). 
 
 
Figure 6. Example of User Activity Report (Report 1). 
 
 
Figure 7. Example of Activity Report by Location (Report 2). 
4. 
Activity Report by Color: similar to the previous 
report, in this case it is possible to perform the analysis of 
student interaction according to the color tags defined in the 
heat map (white, yellow, orange and red), covering all 

87
International Journal on Advances in Intelligent Systems, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org
locations. In this case, teacher can use the color tag to 
identify places more and less visited. 
5. 
Detailed Activity Report: seeking to provide the 
teacher with more details of each student behavior, this 
report presents the summarized data of a selected user, as it 
can be seen in the clipping of example presented in Figure 8. 
It shows the total number of visits in each location, how long 
it was the total visit duration on each place, and the number 
of heat map tags received for each location. In this sense, this 
report allows the teacher to see where a specific student have 
been in the VLE and for how long, allowing, for example, to 
evaluate him/her. 
 
Figure 8. Example of Detailed Activity Report (Report 5). 
6. 
Full Report: this report aims to provide the teacher 
with all the information stored in the database in a 
summarized way. It enables to have a panorama of the whole 
class interaction in the VW, and to do filtered searches in a 
diversity of ways, seeking to analyze more specific data. It 
also allows, for instance, the teacher to evaluate the activity, 
to analyze if all the locations projected for learning were used 
(or useful). 
  
Each report is ordered decreasingly chronologically, and 
it can be generated in three different periods: weekly, 
monthly and complete, by selecting an option in field â€œselect 
an intervalâ€. In addition, all the reports have the option of 
being exported in Portable Document Format (PDF), or can 
be downloaded in the form of customizable worksheets, so 
the teachers have the freedom to manipulate and store the 
reports according to their preference or need.  
Through this web system, teachers can perform activities 
with a group of students in the Virtual World without the 
need of being present to observe the procedure all the time, 
consequently influencing in the student freedom and feelings 
of immersion [14]. Also, this way, giving proper 
instructions, students can access the environment from 
home. 
The data are easily available on the internet, through any 
device. It can be used to assist the teacher on the self-
evaluation, the analysis and/or the assessment of the whole 
class or each student individually, at any time and from 
anywhere. 
V. ANALYZING STUDENT INTERACTION 
This section aims to complement the analysis presented 
in Krassmann et al. [1], investigating data from the 
experiment performed by the authors in a more thorough 
way.  
The original article did some inferences based mostly on 
studentsâ€™ self-report, that is, based on subjective opinions 
about the VW, which implicates on individuals personal 
aspects, as personality or mood. Focusing on making a more 
objective analysis, aiming to identify patterns from the 
experimental group (using the HUD), and compare it with 
the control group (that did not use the HUD), data from 
students interactions in the Virtual World were analyzed by 
the light of statistical inference tests, using the software 
Minitab version 17.  
A sample composed of 10 individuals, being six from the 
experimental group and four from the control group was 
selected. This low sample is because not all participantsâ€™ 
records were properly registered in the database, due to 
adjustments done in the scripts by the researchers during the 
experiments period.  
The following new research questions (RQ) have driven 
this data analysis:  
ï‚· RQ1 - Is there any impact of the HUD in the 
extension of content observation inside the Virtual World? 
ï‚· RQ2 - Is there any impact of the HUD in the 
intensity of content observation inside the Virtual World? 
ï‚· RQ3 - Is there any impact of the HUD in the 
difficulty level to find locations inside the Virtual World, 
regarding the extension and the intensity of content 
observation?  
To investigate RQ1, it was created a formula that 
identifies the degree of student experimentation of all 
locations, which we named ECO (Extension of Content 
Observation), since each location relates to a topic content, 
calculated using (1). 
âˆ‘
ğ‘„ğ‘¢ğ‘ğ‘›ğ‘¡ğ‘–ğ‘¡ğ‘¦ğ‘œğ‘“ğ´ğ‘ğ‘ğ‘’ğ‘ ğ‘ ğ‘’ğ‘‘ğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ ğ‘ğ‘¦ğ‘ ğ‘¡ğ‘¢ğ‘‘ğ‘’ğ‘›ğ‘¡â€²ğ‘–â€²
ğ‘›
ğ‘–=1
ğ‘„ğ‘¢ğ‘ğ‘›ğ‘¡ğ‘–ğ‘¡ğ‘¦ğ‘œğ‘“ğ´ğ‘£ğ‘ğ‘–ğ‘™ğ‘ğ‘ğ‘™ğ‘’ğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ Ã—ğ‘›
     (1) 
                                                                  n=total of assessed students 
 

88
International Journal on Advances in Intelligent Systems, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org
As result, the ECO of control group had an average of 
0.75, while the value obtained for the experimental group 
was 0.66. It means that, overall, students from control group 
accessed 75% of locations at least once, and the students 
from experimental group accessed a bit less, about 65%.  
Thus, we can answers RQ1 with a yes, there is some 
impact of the HUD in the extension of content observation 
in the VW, but not as we expected: the users with the heat 
map device visited a lower number of locations. In other 
words, higher level of content observation (locations) was 
covered by control group. Some inferences trying to explain 
this fact are made on RQ2 explanation. However, t-tests 
performed to compare ECO of both groups could not reject 
the null hypothesis of equality, with p=0.57 at confidence 
level of 95%. 
RQ2 is concerned with the intensity of access of 
locations, considering to the heat map classification (Table 
II). It is here called ICO (Intensity of Content Observation), 
and is calculated according to (2). 
âˆ‘
ğ‘„ğ‘¢ğ‘ğ‘›ğ‘¡ğ‘–ğ‘¡ğ‘¦ğ‘œğ‘“4ğ‘¡â„ğ‘¡ğ‘–ğ‘šğ‘’ğ´ğ‘ğ‘ğ‘’ğ‘ ğ‘ (
)ğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘‰ğ‘–ğ‘ ğ‘–ğ‘¡â€²ğ‘–â€²
ğ‘›
ğ‘–=1
ğ‘„ğ‘¢ğ‘ğ‘›ğ‘¡ğ‘–ğ‘¡ğ‘¦ğ‘œğ‘“ğ´ğ‘£ğ‘ğ‘–ğ‘™ğ‘ğ‘ğ‘™ğ‘’ğ¿ğ‘œğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ Ã—ğ‘›
  (2) 
                                                                 n= total of assessed students 
 
For this measure, instead of considering all locations 
visited by users, it was considered only locations that were 
accessed at least four times (or 4 minutes â€“ strong/red tag).  
As result, the ICO for the control group was 0.25 and for 
the experimental group 0.28. This answers RQ2, showing 
that yes, there is an impact, although small, of the HUD in 
the intensity of content observation in the VW: individuals 
from experimental group visited locations with a bit higher 
frequency. However, the null hypothesis that the ICO of both 
groups is equal has not been rejected, with p=0.82.  
The results for RQ2 indicate a positive impact of the heat 
map in the Virtual World activity and complement RQ1. It 
shows that, although students using the heat map visited less 
locations, they visited it with more intensity (with more 
frequency or stayed for more time). Among the reasons for 
this fact, we speculate that maybe they felt more compelled 
to achieve the heat map completeness (turn red locations on 
the HUD). 
One of the potential advantages of using this concept of 
heat map in VW is to highlight areas that have not been 
explored yet by the users, especially places that may be more 
difficult to find in the 3D virtual space, in consequence to the 
environment design. We investigated this usefulness in RQ3. 
First, we assigned a difficulty level of access for each 
location in the Virtual World, considering researchersâ€™ 
experience while observing student difficulty to find them 
when navigating the 3D VLE. So, it was created the 
classification displayed in Table III.  
 
 
TABLE III.   DIFFICULTY CLASSIFICATION OF LOCATIONS 
Location number 
Difficulty to find 
1, 4, 5, 6, 7, 8, 10 
Easy 
2, 3, 9 
Moderate 
11, 12 
Hard 
 
Easy locations are the ones considered more visible, with 
no obstacles to reach it. Moderate locations are a little 
hidden, requiring students to go inside rooms and/or to climb 
stairs. Hard locations are the ones in different buildings or in 
more hidden places, as behind walls, for example. Figure 9 
shows an example of a moderate to find location, as the user 
had to climb the stair on the right side of the screen to be able 
to see the wireless propagation simulation (Location 9). 
 
Figure 9. Screenshot of Location 9 â€œRange of Wireless Networks Iâ€. 
Following this classification, ECO and ICO metrics were 
calculated for each level of difficulty and compared between 
control and experimental groups. The results are shown in 
Table IV. 
TABLE IV.    ECO AND ICO ACCORDING TO ACCESS DIFFICULTY 
Location 
classification 
ECO 
ICO 
Control 
Exp. 
Control 
Exp. 
Easy 
0.78 
0.76 
0.46 
0.40 
Moderate 
0.83 
0.61 
0.08 
0.22 
Hard 
0.50 
0.41 
0.00 
0.17 
 
This result indicates a clear impact of the heat map, 
especially in ICO metric for the â€œmoderateâ€ and â€œhardâ€ 
location classifications, since the difference of values 
between groups are bigger (0.14 and 0.17). The data show 
that students from experimental group accessed for much 
more time (with more intensity) the locations classified as 
hard or moderate to find than students from the control 
group. 
Therefore, RQ3 can also be answered with a yes, there is 
an impact, small but positive, of the HUD in the difficulty 
level of access of locations in the Virtual World, regarding 
the intensity (frequency) of access. In this sense, again it may 
be inferred that the heat map have motivated students to turn 
locations red on the HUD, even the ones harder to find, 
frequenting it more. This highlights the benefit of a little of 
gamification implemented in the activity, as the students 

89
International Journal on Advances in Intelligent Systems, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org
sought to complete their HUD while using it. Still, the t-test 
did not reject the null hypothesis of equality between groups.  
To sum up, these new research questions (RQ1, RQ2, 
RQ3) showed more objective results, which could not be 
obtained only with students self-reports. This justifies the 
need and the importance of automatically keeping track of 
studentsâ€™ interactions in the VW, recording it properly into 
databases and making it accessible to teachers in an 
organized way.  
However, in spite of some noticeable difference between 
groups, in all cases all p-values were higher than 0.05, not 
rejecting the null hypothesis at confidence level of 95%. So 
a caution must be taken to expand the conclusions of this 
research to a population of students, due to the small sample 
size analyzed in this study. 
VI. CONCLUSIONS AND FUTURE WORK 
Virtual Worlds are tools that simulate the real world in 
3D, providing teachers with many educational possibilities, 
as the creation of virtual laboratories [7]. But the lack of 
autonomous support, while learners are interacting in the 
environment, might prejudice the experience [19].   
In order to contribute with this theme, we have presented 
a solution that takes advantage of usersâ€™ context information 
to present a real-time heat map, using the HUD device 
available in most VW platforms. The goal is to help on user 
navigation in the VLE, highlighting places visited according 
to the frequency of access, keeping students aware of their 
activities (places visited), and at the same time, personalizing 
their 
experience. 
First 
results 
of 
this 
application 
demonstrated that it can increase engagement and interaction 
time [1].  
In this paper we have tried to answer our main research 
question: how is it possible to (1) report and (2) analyze 
student behavior inside Virtual Worlds?  
To answer (1) we have introduced a web system that 
allows the teacher to easily extract reports from studentsâ€™ 
behavior inside the VW, retrieved from sensors implemented 
using LSL, OSSL and PHP programming languages. This 
way, the educator does not need to stay monitoring students 
to evaluate the activity progress, and in consequence, it 
minimizes possible negative influences of his/her presence 
on studentsâ€™ immersion and interactivity. Six different types 
of reports were constructed, allowing to see, for example, 
locations less visited, which may, in result, indicate the need 
for adjustments in the environment to improve visitation in 
those places. 
To investigate (2), we have performed a deeper analysis 
of data from a previous experiment [1], to identify the 
usefulness of the heat map HUD in providing guidance inside 
the VW, in order to help the students to reach the learning 
objectives. Three new research questions were investigated, 
which using statistical techniques, demonstrated the 
existence of an impact of the HUD in the extension (number 
of places visited) and in the intensity (frequency of location 
visitation) of educational content observation inside the 
environment. Overall, the results have shown how the 
contribution of the gamification aspect of the HUD device 
motivated students to achieve the â€œredâ€ tag on the heat map, 
even in places more difficult to find. In this sense, we have 
also presented some possibilities of data analysis in 
educational Virtual Worlds.  
As the main contribution, we showed that, concerning 
student guidance, intelligent agents are not the only solution; 
other types of autonomous support may be helpful. The HUD 
has as advantages being flexible, as it can be attached to any 
particular user, and it functions individually, different from 
common agents that usually are not personalized for each 
user. In addition, the device is different from common heat 
maps, which highlight items or places visited by all users. All 
the tools used are open source, allowing researchers and 
educators from around the world to reproduce the same or 
better solutions.  
As future works, regarding (1), we plan to integrate the 
ECO and ICO formulas to the report system, to automatically 
obtain the levels of student interaction in the VLE, regarding 
extension (the number of locations/topics visited) and 
intensity (the frequency of location/topic visit). In the same 
manner, we intend to include a function to attribute notes for 
student performance, measured by visit duration or coverage, 
allowing them to see their own reports after the experience. 
 Concerning (2), we will apply the VW with the HUD and 
the reporting system with more teachers, from different areas 
and environment designs, to compare the results and 
optimize the tool, gathering data that can be analyzed to 
increase the validity of results. Based on these new results, 
we will construct a model to improve studentâ€™s unsupervised 
learning process inside Virtual Worlds. 
REFERENCES 
[1] 
A. L. Krassmann, F. B. Nunes, T. A. Rossi Filho, L. M. R. 
Tarouco, and M. Bercht, â€œHeads Up Displays (HUD) as a Tool 
to Contextualize the User in 3D Virtual Worldsâ€, The 
Eleventh International Conference on Mobile Ubiquitous 
Computing, 
Systems, 
Services 
and 
Technologies 
(UBICOMM 2017), IARIA, Nov. 2017, pp. 169-175, ISBN: 
978-1-61208-598-2. 
[2] 
D. J. H. Burden, â€œDeploying embodied AI into virtual 
worldsâ€, Knowledge-Based Systems vol. 22, no. 7, pp. 540- 
544, 2009. 
[3] 
D. Liu, K. K. Bhagat, Y. Gao, T. W. Chang, and R. Huang, 
â€œThe Potentials and Trends of Virtual Reality in Educationâ€, 
In Virtual, Augmented, and Mixed Realities in Education, pp. 
105-130, Springer, Singapore, 2017. 
[4] 
C. Englund, â€œExploring approaches to teaching in three-
dimensional virtual worldsâ€, The International Journal of 
Information and Learning Technology, vol. 34(2), pp. 140-
151, 2017. 
[5] 
A. Mastrokoukou and E. Fokides, â€œDevelopment and 
Evaluation of a 3D Virtual Environment for Teaching Solar 
System's Conceptsâ€, International Journal of Education and 
Information Technology, vol. 1(5), pp. 148-154, 2016, ISSN: 
2381-7410 (Print); ISSN: 2381-7429 (Online). 
[6] 
M. Chow, â€œDeterminants of presence in 3D virtual worlds: A 
structural equation modelling analysisâ€, Australasian Journal 
of Educational Technology, vol 32(1), pp. 1-18, 2016. 
[7] 
M. Rico, J. Rodriguez, D. RiofrÃ­o-Luzcando, and M. Berrocal-
lobo, â€œA Cost-Effective Approach for Procedural Training in 
Virtual Worldsâ€, Journal of Universal Computer Science, vol. 
23(2), pp. 208-232, 2017, doi: 10.3217/jucs-023-02-0208. 

90
International Journal on Advances in Intelligent Systems, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org
[8] 
I. Simsek,and T. Can, â€œThe Design and Use of Educational 
Games in 3D Virtual Worldsâ€, Society for Information 
Technology & Teacher Education International Conference, 
AACE, Mar. 2016, pp. 611-617. 
[9] 
J. Cruz-Benito, R TherÃ³n, F. J. GarcÃ­a-PeÃ±alvo, and E. P. 
Lucas, â€œDiscovering usage behaviors and engagement in an 
Educational Virtual Worldâ€, Computers in Human Behavior, 
vol. 47, pp. 18-25, 2015. 
[10] L. P. Macfadyen and S. Dawson, â€œMining LMS data to 
develop an â€˜early warning systemâ€™ for educators: A proof of 
conceptâ€, Computers & Education, vol. 54(2), pp. 588-599, 
Feb. 
2010, 
doi: 
https://doi.org/10.1016/j.compedu.2009.09.008. 
[11] R. Moreno, R. E. Mayer, H. A. Spires, and J. C. Lester, â€œThe 
case for social agency in computer-based teaching: Do 
students learn more deeply when they interact with animated 
pedagogical agents?â€, Cognition and Instruction, vol. 19(2), 
pp. 
177-213, 
2001, 
doi: 
https://doi.org/10.1207/S1532690XCI1902_02. 
[12] R. E. Mayer, â€œMultimedia learningâ€, Psychology of Learning 
and Motivation, vol. 41, pp. 85-139, 2002. 
[13] C. GÃ¼tl, â€œThe support of virtual 3D worlds for enhancing 
collaboration in learning settingsâ€, In Techniques for fostering 
collaboration in online learning communities: Theoretical and 
practical perspectives, pp. 278-299, 2011, doi: 10.4018/978-
1-61692-898-8.ch016. 
[14] K. Ijaz, A. Bogdanovych, and T. Trescak, â€œVirtual worlds vs 
books and videos in history educationâ€ Interactive Learning 
Environments, 
vol. 
25(7), 
904-929, 
2017, 
doi: 
https://doi.org/10.1080/10494820.2016.1225099. 
[15] D. Griol, J. M. Molina, and Z. Callejas, â€œAn approach to 
develop intelligent learning environments by means of 
immersive virtual worldsâ€, Journal of Ambient Intelligence 
and Smart Environments, vol. 6(2), pp. 237-255, 2014. 
[16] I. Christensen, A. Maraunchak, and C. Stefanelli, â€œAdded 
value of teaching in a virtual worldâ€, In The Immersive 
Internet, Hampshire: Palgrave Macmillan, pp. 125-137, 2013. 
[17] M. Csikszentmihalyi, â€œFinding flowâ€, vol. 131, New York: 
Basic Books, 1997.  
[18] H. TÃ¼zÃ¼n and F. Ã–zdinÃ§. â€œThe effects of 3D multi-user virtual 
environments on freshmen university students' conceptual and 
spatial learning and presence in departmental orientationâ€, 
Computers & Education, vol. 94, pp. 228-240, 2016. 
[19] O. Baydas, T. Karakus, F. B. Topu, R. Yilmaz, M. E. Ozturk, 
and Y. Goktas, â€œRetention and flow under guided and 
unguided learning experience in 3D virtual worldsâ€, 
Computers in Human Behavior, vol. 44, pp. 96-102, 2015. 
[20] M. Soliman and C. Guetl. â€œIntelligent pedagogical agents in 
immersive virtual learning environments: A reviewâ€, The 
33rd international convention MIPRO, IEEE, May 2010, pp. 
827-832. 
[21] W. L. Johnson, J. W. Rickel, and J. C. Lester, â€œAnimated 
pedagogical agents: Face-to-face interaction in interactive 
learning environmentsâ€. International Journal of Artificial 
Intelligence in Education, vol. 11(1), pp. 47-78, 2000. 
[22] T. Xie and L. Luo, â€œImpact of Prompting Agents on Task 
Completion in the Virtual Worldâ€, International Journal of 
Online Engineering (iJOE), vol. 13(6), pp. 35-48, 2017. 
[23] V. Kellen, A. Recktenwald, and C. Bumgardner, â€œPâ€“An Open 
Source Personalization Platform for 
Higher 
Educationâ€, 
University of Kentucky, Lexington-USA. [Online]. Available 
from: 
https://pdfs.semanticscholar.org/1e5b/8023cbfa9d281a2ce4e 
d71577d2eadc0b4ce.pdf  2018.06.09. 
[24] F. Shah, P. Bell, and G. Sukthankar, â€œA Destination 
Recommendation System for Virtual Worldsâ€, Twenty-Third 
International Florida Artificial Intelligence Research Society 
Conference (FLAIRS 2010), 2010, pp. 475-476. 
[25] J. Keelan, L. B. Ashley, D. Morra, V. Busch, K. Atkinson, and 
K. Wilson, â€œUsing virtual worlds to conduct health-related 
research: Lessons from two pilot stuedis in Second Lifeâ€, 
Health Policy and Technology, vol. 4 (3), pp. 232-240, 2015, 
doi: https://doi.org/10.1016/j.hlpt.2015.04.004. 
[26] K. Sookhanaphibarn and R. Thawonmas, â€œDigital Museums 
in 3D Virtual Environmentâ€, Handbook of Research on 
Methods and Techniques for Studying Virtual Communities: 
Paradigms and Phenomena, IGI Global, vol. 1, 2011, doi:  
DOI: 10.4018/978-1-60960-040-2.ch042. 
[27] T. B. Ward and M. S. Sonneborn, â€œCreative expression in 
virtual worlds: Imitation, imagination, and individualized 
collaborationâ€, Psychology of Popular Media Culture, vol. 1, 
pp. 32-47, 2011. 
[28] G. Rakoczi, â€œCast your eyes on moodle: An eye tracking study 
investigating learning with Moodleâ€, The 4th International 
Conference Moodle.si, May 2010. 
[29] AVATAR Project. Universidade Federal do Rio Grande do 
Sul. [Online]. Available from: http://www.ufrgs.br/avatar/. 
2018.06.09. 
[30] Singularity Viewer Official website. [Online]. Available 
from: http://www.singularityviewer.org/ 2018.06.09. 
[31] Firestorm Viewer Official website. [Online]. Available from: 
http://www.firestormviewer.org/ 2018.06.09. 
[32] A. L. Krassmann, T. A. Rossi Filho, L. M. R. Tarouco, and M. 
Bercht, â€œInitial Perception of Virtual World Users: A Study 
about Impacts of Learning Styles and Digital Experienceâ€, 
International Journal for Innovation Education and Research, 
vol. 5(5), pp. 95-112, 2017. 
[33] A. Balderas, A. Berns, M. Palomo-Duarte, J. M. Dodero, and 
I. Ruiz-Rube, â€œRetrieving Objective Indicators from Student 
Logs in Virtual Worldsâ€, Journal of Information Technology 
Research (JITR), vol. 10(3), pp. 69-83, 2017. 
[34] I. Duncan, A. Miller, and S. Jiang, â€œA taxonomy of virtual 
worlds usage in educationâ€, British Journal of Educational 
Technology, 
vol. 
43(6), 
pp. 
949-964, 
2012, 
doi: 
https://doi.org/10.1111/j.1467-8535.2011.01263.x. 

