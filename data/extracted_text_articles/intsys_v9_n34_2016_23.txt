496
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Old Habits as a Resource for Design:  
On Learning and Un-learning Bodily Knowledge
Tone Bratteteig 
Department of Informatics 
University of Oslo 
P.B. 1080, 0316 Oslo, Norway 
tone@ifi.uio.no 
 
Guri Verne 
Department of Informatics 
University of Oslo 
P.B. 1080, 0316 Oslo, Norway 
guribv@ifi.uio.no 
 
 
Abstract—There are many reasons why artifacts and systems 
are difficult to use in practice. In this paper, we investigate 
such difficulties as a basis for design for ease of use. Difficulties 
may stem from the artifact or system itself, or from the artifact 
or system in use in its real use context. Technology introduces 
new tasks, and both learning new tasks and unlearning old 
habits can be challenging. We discuss how users’ previous 
knowledge and habits can be used to understand how and why 
an artefact is difficult to use. This understanding is useful for 
designing artefacts that are easy to use. We end the paper with 
presenting a conceptual framework for design for coherence 
and simplicity from the users’ perspective, where users’ habits 
and bodily knowledge act as resources for design.  
Keywords—usability; 
habits; 
automated 
behaviour; 
automation;  participatory design. 
I. 
 INTRODUCTION 
Usability is often defined as the ease of use and 
learnability of an artifact, sometimes narrowed down to 
specific users in a specified use context having specific 
achievement goals (e.g., ISO 9241). But what does “ease of 
use” mean more precisely? We have tried to find out what it 
is that makes some artifacts difficult to use for some users. 
This paper builds on an earlier paper [1] and expands the 
empirical material as well as the depth of discussion of 
possible reasons why some things turn out to be difficult to 
use. Our aim is that knowledge about how a piece of 
technology is difficult to use can be used as a basis for 
designing solutions that are easy to use.  
Much of the research on artefacts that are easy – or 
difficult – to use is based on Nielsen [2], who lists five 
aspects of usability: learnability, efficiency, memorability, 
low error rate, and satisfaction. A more elaborate list is given 
by [3], who present eight aspects: consistency, universal 
design, feedback, closure of dialogs, reversal of action, 
control, error prevention, and memory load. Except for 
universal design, all the aspects are general and concern the 
design of the artifact seen as a stand-alone context-
independent thing. Our research shows, however, that it is 
difficult to achieve a total independence of contextual design 
elements – it is impossible and even unwanted: “All products 
make some reference to either products extant during 
previous generations or products from different companies or 
product families.” [4]. Such references are important to build 
on when trying to understand how to use the product. Even 
well-designed stand-alone artifacts can be difficult to use for 
users not sharing the contextual competence pre-supposed in 
the design. We have seen this in our and our colleagues’ 
research, where we focus on elderly people and the 
technological support that is supposed to enable them to live 
independently in their homes longer [5].  
The paper is structured as follows: Section II gives a 
review of literature about problems in using technologies. In 
Section III, we present two studies of use of technology: the 
use of public services like tax, and the use of common home 
artifacts like remote controls or mobile devices that need 
charging. Section IV summarizes the challenges we have 
identified in our research. In Section V we discuss the 
competencies users need to use an artifact, and how such 
competencies are experienced and embodied. Section VI 
summarizes what we have found to make things difficult to 
use. In Section VII, we turn to design for ease of use: we 
discuss how we can go from knowing about the difficulties 
people have using an artifact to design of an artifact that is 
easy for them to use. We divide the discussion in two parts, 
addressing first how designing with users can end up with 
design results that are easy to use, and lastly we discuss a 
more general approach to automation that addresses how the 
design itself creates user problems and how these can be 
resolved. Section VIII concludes the paper.  
II. 
PROBLEMS WHEN USING TECHNOLOGY 
A close study of people using IT artifacts reveals that 
they often find technology difficult to use (e.g., [6]). A 
classic study is Suchman’s study of use of a Xerox copy 
machine [7][8] demonstrating how operating a copy machine 
was difficult due to the difference between the scripted 
“plan” in the copy machine and the users’ (situated) 
understanding of copying. Another classic is Gasser’s study 
of how people work around computer systems that do not fit 
the work they need to do, which shows that people carry out 
their jobs also with non-supporting artifacts [9]. Even when 
an IT system works well, it may not work well together with 
other systems [10][6]. Just using more than one system can 

497
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
create problems as they are often not designed as parts of a 
larger coherent system or network [11].  
A different set of studies shows that an artifact can be 
used in different ways, e.g., Barley’s classic study [12] of the 
introduction of a CT scanner into the radiology departments 
at two different hospitals. Although the same technology was 
introduced, the cooperation and social organisation of the 
radiology work developed differently. In one department the 
radiology work became more decentralised with delegated 
responsibility; in the other, responsibilities became unsettled 
and the relation between the radiologists and the technicians 
became less close. This study shows that the same artifact 
can be part of very different socio-technical practices.  
For designers, it is particularly interesting to study the 
non-users of an artifact. They are, however, very difficult to 
get hold of (unless they can be located in a particular place, 
e.g., an organization). Orlikowski [13] and Star and Ruhleder 
[14] describe how people are not using a computer system 
with good reasons, indicating that contextual matters (like 
reward systems) may offer good reasons for not using a 
system – irrespective of the usability aspects of the system 
itself. If the system appears to hamper the career of its users 
by having them share things that are important for their own 
careers, they will not do that. Even a small uncertainty about 
how data can be used and by whom may result in not sharing 
those data [15].  
As a way to get access to non-users of the public service 
web pages of the tax authorities, Verne [16] studied people 
calling the tax authorities’ call centre. She found that even if 
tax rules are complicated most of the questions concern 
relatively simple tax issues and that the callers’ problems are 
concerned with interpreting and applying the rules to their 
own life. Similarly, [17] studied single parents’ use of 
mandatory online services for communicating with the 
public service and found that some single parents believe 
that the civil servants do not inform them of the benefits they 
are eligible to. This causes the single parents to interact with 
the case handlers through traditional channels such as the 
telephone or personal meetings. In this example, lack of trust 
in the relationship with the civil servants led to non-use of a 
mandatory online service.   
Several studies of assistive technology in the homes of 
elderly people have been carried out, see e.g., [1][18]. Noting 
that much of the technology is not used, Greenhalgh et al. 
focus on the subjective opinions and experiences from the 
elderly’s own technology use. They call for a different 
design approach in order to develop technology that supports 
the elderly in achieving what matters to them and enhances 
the quality of their life [19]. Many of the current solutions 
aimed at elderly users are imported from other application 
areas and not designed specifically for an elderly user group, 
e.g., touch screens [20].  
We also see that the level of automation of some of the 
tasks seem to confuse people. Cummings [21] describes 
automation with reference to human control (decision-
making) and information: at the lowest level of automation 
the computer offers no assistance and the human takes all 
decisions and actions. At the highest level of automation, the 
computer decides everything “and acts autonomously, 
ignoring the human” (p. 2). Fully automated systems may 
seem like a tempting solution to making systems easy to use 
but artefacts that act autonomously can pose problems even 
when they are not used in any active sense – in particular 
when errors occur [22][23][24].  
We know a great deal about systems and artifacts that are 
not easy to use, but what is less clear is how to get from 
knowing what is difficult to designing a solution that is easy 
to use. In this paper, we have set out to do this: we analyse a 
set of studies of difficult-to-use-technologies in order to 
arrive at design ideas for easy-to-use solutions.  
We report from a set of qualitative interpretive case 
studies [25] aimed at developing new knowledge on how to 
design technology [26] that will be experienced as useful and 
easy to use in practice. As we have been interested in finding 
out why and how artefacts are difficult to use, hence we have 
chosen a qualitative rather than quantitative approach to 
evaluate technologies. Studies of use in situ give a better 
basis for answering these questions than usability studies 
where a test person is given a set of pre-defined tasks to 
solve outside of the real use context. 
III. 
DIFFICULT-TO-USE 
Investigating people’s reasons for not using an artifact is 
very instructive for designers: there may be a range of logical 
and sensible reasons for not using an artifact or using it in 
“wrong” ways. In this section, we report from our studies of 
users and non-users of computer technology.  
A. Badly designed Systems and Artifacts 
Some artifacts are difficult to use because of the design. 
Verne’s [22] study of citizens’ calls to the tax information 
call centre showed that many callers had tried to use the 
online tax self-service without succeeding. Listening in to 
474 telephone calls over a period of 22 months gave a basis 
for understanding the callers’ problems. Examples of 
problems ranged from not finding their PIN-code to more 
specific questions like a woman receiving welfare benefits 
and had tax deducted from her pension, but being aware that 
welfare pension was tax-free she asked for help in correcting 
the tax deduction. From eight in-depth semi-structured 
interviews with call advisors and their managers we learned 
about their work practices and their experiences of the 
callers’ issues. The call centre advisors often walk the callers 
through the self-service web site and commented to us that 
the online services were not user-friendly. To callers who do 
not know which numbers in their tax card they need to 
change, there is no difference between filling out a paper 
form and reporting online. But online tax self-services may 
introduce additional complexity for the citizens [22]. 
Tax in Norway is almost fully automated. Throughout the 
year, employers deduct tax from their employees’ wage 
payments and forward to the tax collector. This deduction is 
specified in the tax card, which is produced by the Tax 
Administration based on last year’s tax return form and 
information provided by the citizen if needed. The tax return 
form 
is 
produced 
semi-automatically 
by 
the 
Tax 
Administration based on input from employers, other public 
agencies and the citizen [27]. 

498
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Because tax laws and regulations vary a lot between 
countries, examples from the tax area are often complicated. 
We therefore offer a similar but simpler case: online student 
registration for classes [28]. New students at the University 
of Oslo are assigned a personal online account when they 
register. At first this account contains no services or 
information; the student can only use it for paying the 
entrance fee to the university. When the fee is paid, the status 
of the student is changed to “active student” in the system, 
and services such as signing up for classes become available. 
Many students do not understand that more services become 
available after they have paid the fee, and report the non-
availability of services and information as an error [28].  
A second set of examples can illustrate our point further. 
The examples are taken from an evaluation study of IT 
technology for independent living in an apartment building 
adapted to elderly people [5], involving sensors, alarms and a 
tablet connected to the Internet. Our investigations started in 
2012 and include a number of studies carried out by 
colleagues and students in our research group. The studies 
document that many of the technologies do not function well 
in everyday use. The tablet, for example, has a wall-mounted 
charger station designed to charge while showing the time 
(Fig. 1 upper). However, the slot for positioning the charger 
in the right position is narrow and difficult to see, and many 
users do not manage to mount it right and do not discover 
this until the battery is empty [29]. Also the very common 
stove alarm is difficult to use for people in wheel chairs or 
people who find it difficult to hold the turn-off-switch while 
stretching and bending over the stove to turn the alarm off 
(Fig. 1 lower).  
These examples illustrate that artifacts and technology 
themselves can create problems for their users.  
B. The Artifact in Use  
Some artifacts are difficult to use because of the use 
context and the use situation. Verne’s [22] study of callers 
found that many people call because they need help with 
matching the rules and regulations with events and 
circumstances in their life, not because tax regulations and 
rules are complicated. Her data includes several examples of 
simple tax rules that may represent problems when applied to 
a person’s life situation.  
* When citizens move, they are required to send a 
notification of address to the Population Register. A citizen 
called to ask if he needed to send a notification to the tax 
authorities when he changed his job. (The answer is no.)  
*A newly retired citizen needed guidance on how her 
new status affected her personal economy and on which of 
her different types of incomes are subject to which taxes.   
*A house owner who earned money from renting her 
house asked if renovating costs could be deducted from her 
tax. She rented the apartment to her son, and wondered how 
the rules were applied in this case.  
In all three examples, the life situation or circumstances 
of the citizen triggered the phone call. In the first example, 
the caller’s life situation was irrelevant to the tax regulation 
in question, but in the two others the life situation needed to 
be matched with the rules and regulations by a tax expert.  
Again our second set of examples is everyday 
technologies used by elderly people in their homes. We 
found that these types of difficulties arise when people use 
technologies that they do not have previous experience with. 
One example is an active woman, approximately 85 years 
old, who uses a hearing aid. She is well organised, educated, 
and has had an active work life, and she uses everyday 
technologies like her TV effortlessly. Her occupational 
therapist has tried to teach her how to use an amplifier for 
her hearing aid: a wireless microphone that amplifies sounds 
and submits to her hearing aid. 
 
 
 
Figure 1.  Welfare technology: Tablet charging (above), stove alarm 
(below). 
The “accessory pen” is easy to use once fitted to the hearing 
aid: the manufacturer says that it is “zero hassle” because it 
is “completely simple to use, with one-click connection of 
receivers and fully automated settings” [30]. Using the pen 
involves pushing one small button in addition to charging it. 
However, the old woman finds the pen difficult to use. She 
does not remember how to use it from one therapist visit to 
the next. She wants to charge it before she uses it, but 
forgets. The occupational therapist (whose job it is to adapt 
support devices to individual users) has suggested that she 
instead can charge it after she has used it, and that she can 
keep it in the charger until the next time she needs it. But in 
the “old days”, keeping devices in the charger could be 
dangerous, and the old woman therefore does not want to do 
this – even if the therapist assures her that with this 
equipment there is no danger. The old woman often finds her 
hearing aid amplifier not charged when she needs it.  
A lady aged 70-something said that she was “not very 
experienced with technology” when we interviewed her 
about her use of technology. During the interview, she told 
us about her use of her TV with several remote controls, her 
iPad, and a variety of apps, including an app for buying 
online bus tickets and one for cloud storage of family 
pictures. She used FaceTime on her iPhone but considered 

499
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Skype to be too difficult. Skype was installed on her PC and 
she considered everything concerned with the PC to be too 
cumbersome. She avoided using it, but used her iPad and 
iPhone every day.  
C. Other’s Doings 
Some technology problems are caused by factors outside 
the user’s control, e.g., by actions or errors made by third 
parties. Some callers to the tax information call centre had a 
problem having their welfare support reduced because the 
welfare agency “tidied up their systems” and deducted 50 % 
of the benefits because of a missing tax card. The tax 
authorities receive many calls from people who have not 
received a tax card in the mail, but this is often their own 
doing (or rather: not doing). However, in one case the street 
address had been changed by the municipality, and since the 
caller had not moved she was not aware that she needed to 
send a notification of change of address.  
A more complicated case was a young man who had 
received a bill for penalty tax for underreporting his income 
two years ago. His employer had gone bankrupt and his 
reported income was disputed. There was no employer who 
could confirm the callers’ claims, and he had no 
documentation of his version of what had happened. In 
principle, he needed to document the non-event of not 
underreporting income. The advisor helped him by 
suggesting steps to take to retrieve documentation and 
proceed with his claims in his case with the tax authorities.   
The smart home technologies in the apartment building 
for elderly people had automatic electricity saving. However, 
the first winter everybody experienced that the apartments 
were very cold, and the elderly people (who normally need 
higher indoor temperatures because they do not move much) 
had to get help from the janitor service to correct the 
temperature. It took a long time to find out that some of the 
basic calculations for the electricity system were wrong 
resulting in faulty temperature regulation in the individual 
apartments [23]. We (the authors) work in a smart building 
ourselves and have experienced similar difficulties when 
trying to identify the reasons for bad temperature regulation 
mechanisms. When using artifacts that are part of a larger 
complex system, the problems that a user experiences may 
very well be the result of other people’s activities or errors.  
IV. 
DIFFERENT CHALLENGES 
Difficulties using artifacts can have several sources: the 
artifact itself, the artefact-in-context, and shared artifacts that 
others use and interact with. The users are often unable to 
distinguish between these sources.  
Difficulties that stem from the artifact or system itself 
pose challenges for users, that are afraid to make errors or 
reluctant to use cumbersome technology. Such challenges 
can be met with various practical measures to stimulate and 
enhance use, such as moving the technology to a place where 
it is easier to reach, as in the case of the turn-off switch for 
the stove alarm, which is difficult to reach and the 
positioning of the tablet charger (see Fig. 1). Users can be 
trained in using online services, another practical measure 
towards the challenges posed by difficult technology (see 
e.g., [31]).  
Difficulties that stem from the artifact-in-context or in-
interaction pose a different set of challenges. Difficulties 
stemming from the artifact-in-context originate in challenges 
with relating the technology to the users’ own life situation 
or circumstances. In order to do their own taxes in a 
competent way citizens need to learn and to understand the 
tax rules and regulations and understand how their life 
situation matches or not matches with concepts from the 
rules. Active use of an accessory hearing aid requires that the 
user establishes a new practice that fits into her life and that 
she can follow up without help from the occupational 
therapist. To address such challenges, a user may need 
external help to explain and interpret rule systems or 
technologies.  
Difficulties that stem from others’ actions and 
interactions are the hardest challenges to meet. It seems that 
errors that stem from other people’s actions are particularly 
difficult to understand as they often surface in unexpected 
ways and need some kind of “debugging” to be 
comprehensible. This kind of debugging requires special 
competence and can be time-consuming.  External help is 
often needed to disentangle difficulties that stem from 
complex interactions [27]. And often there is not one best 
solution [14]. 
We sum up the kinds of difficulties in Table I, and 
indicate what kinds of challenges they pose.  
TABLE I.  
DIFFERENT KINDS OF DIFFICULTIES WITH ARTIFACTS AND 
SYSTEMS, AND THE CHALLENGES THEY POSE 
What is 
difficult? 
Kinds of difficulties  
Artifact  
Context 
Activities by 
others 
Examples: 
Holding the 
turn-off 
switch. 
Positioning of 
the charger. 
Online tax self 
services 
Personal economy 
when retiring. Tax 
deductions for 
renting out a house 
to family. 
Tax card when 
starting a new job  
Bankrupcy by an 
employer. Welfare 
agency “tidies up 
their systems”. 
Errors made by 
subcontractors.  
Challenges:  
Practical 
measures: 
moving a 
charger,   
teaching.  
Matching artifact 
with own life 
situation or 
circumstances 
Disentangling 
interactions and 
complexities 
 
Even though the challenges that meet the users are 
different, the general feature is that users need experience 
from previous similar situations in order to be able to 
differentiate between approaches to resolving the difficulties. 
The competence for addressing problems can be gained in 
many ways.   
V. 
COMPETENCE 
Competence, as the ability to do something successfully 
or efficiently, is important for using technology. The 
examples in Section III show that competence can concern 
the design that makes the operation of the technology 

500
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
difficult (III.A) as well as the adaptation of the technology to 
the actual situation (III.B). In both cases, the users have to do 
fitting work [9] in order to use the technology 
A. What we Know  
A usability test of a video conferencing system showed 
that users who did not have the same technological 
experience as the designers (which in this case was an 
iPhone) did not understand the interaction mechanisms and 
had problems operating the system [32]. Langdon et al. [4] 
discuss this problem on a more general level, showing that 
“similarity of prior experience to the usage situation was the 
main determinant of performance, although there was also 
some evidence for a gradual, age-related capability decline.” 
(p. 179). They conclude that in their test of driving a new car 
“there was … some clear evidence that experience may be 
more influential than age” (p. 189). Docampo [33] has 
identified four technology generations: electro-mechanical 
period, remote control era, use of displays, and use of 
layered menus, basically distinguishing between before and 
after 1960. The generations affect how people learn new 
technology and are visible as a discontinuity of errors and 
task timings between the generations. 
Previous experience is a salient feature that builds self-
efficacy [34]. According to self-efficacy theory for human 
agency, belief in one’s own competence and mastery is 
important for succeeding. In their study of the effects of 
training programs in computer use for older adults, Wild et 
al. [35] found that after one year of consistent computer use 
the participants reported reduced levels of anxiety and 
increased self-confidence in their abilities to use computers. 
Participants with mild cognitive impairments were less likely 
to demonstrate increased efficacy and competence. This is in 
line with our own empirical findings. We interviewed an 
occupational therapist, who had the experience that elderly 
people with mild cognitive impairments were able to learn 
new practices, but they would need much training and 
follow-up from her.  
Langdon et al. [4] suggest that “prior experience with 
similar products and product features is a strong predictor 
of the usability of products over the wider range of 
capabilities. This similarity results from experience with 
same brand, or functionally and perceptually differing 
products, provided that key functional features and visual 
appearances are maintained. . … In particular, in the 
absence of prior experience of a product interaction 
interface, or with the appearance of product features, users 
of all age groups apparently resorted to a means-end or trial 
and error based approach that was slow, repetitive and 
error prone.” (p. 190). Hurtienne and Langdon [36] suggest 
a continuum of knowledge sources starting with 1) innate 
knowledge like reflexes and 2) sensorimotor experiences like 
speed, gravity (early childhood learning), 3) culture 
(everyday life), and 4) expertise acquired in a profession or 
hobby. Knowledge about tools crosses these “levels” of 
knowledge. They suggest that knowledge residing on the 
sensorimotor level of the continuum is basic to most people 
and is acquired early in life. Knowledge from culture or 
professional life differs.  
B. How we Know 
Langdon et al. found that previous experience provided 
guidance on how to carry out their tests: “Memories relating 
to the experience of products will be stored in the long term 
memory and the ability of the central executive to find the 
relevant knowledge will depend on the cues provided and the 
level of previous experience.” [4:182]. They conclude that 
their older test-participants were not able to use the 
technology, which “is consistent with the idea that they had 
no previous experience to provide guidance on how to 
complete the trials, rather than being of lower cognitive 
capability as a result of ageing.” [4:190].   
Using technology is also a bodily experience. Höök [37] 
discusses bodily ways of knowing in her study of the 
challenges she experienced when learning the English style 
of horseback riding based on her background in riding 
Icelandic style. Competence in and experience from 
horseback riding resides in the body and is expressed by 
more or less automatic bodily reactions and responses to 
external events. She uses her experience from learning a new 
riding style as a basis for reflections on how to design for 
bodily experiences.  
There are subtle differences in how the rider interacts 
with the horse within these riding schools. Communication 
with a horse is mainly bodily as the rider gives signals with 
her legs and hands, but also less explicitly with body posture 
and movements. The horses are trained to react differently to 
signals (from the legs, hands, body posture) from the rider. 
In the English riding style, the rider aims to not disturb the 
horse with her movements because the horse is trained to 
move independently based on previously given signals, for 
example to trot in a circle. The rider aims to sit in a “loose” 
way on the back of the horse. In the Icelandic style, the rider 
will need to push forward with her bodily movements and 
put tension into the horse to enable an unusual gait such as 
the tölt.  
Höök [37] describes how she needed to practice again 
and again with constant feedback from the instructor to be 
able to learn the new movements, positioning and 
interactions. Even though she cognitively knew and 
understood how she was supposed to move and position her 
body, it was difficult to do/perform the new movements at 
the right time.  
C. Learning and Un-learning 
Learning new movements and ways of communication 
implies unlearning the old ways [37]. Unlearning bodily 
ways of knowing implies consciously and deliberately 
practicing not doing the usual activity and instead practice 
something new. Having learnt how and when to perform a 
new movement is different from practicing the old habits. 
Unlearning bodily knowledge requires conscious cognitive 
work before it becomes a habitual and automated practice.  
Höök’s movements for performing Icelandic horse riding 
were automated while the new riding style was not. The 
transition required that she spent conscious effort to unlearn 
the old and learn the new.  
Automatic thoughts and behaviour occur without any 
need for conscious effort as “[m]ost of our thoughts and 

501
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
behaviors tend to be automatic or have automatic 
components, and for good reason. These processes are fast, 
allowing us to do things like drive to work without having to 
think about how to turn the steering wheel each time we get 
into a car” [38: 991]. Our conscious attention can be directed 
towards issues that need it more. Such “automaticity” is a 
result of practicing and repeating an activity over and over 
again, often coupled with an external event that will later 
trigger the automatic thought or behaviour. Automaticity 
occurs on low cognitive levels.   
For our purposes in this paper, automaticity and habit 
plays the same role in describing repeated behaviour that 
does not require any conscious attention or deliberation. 
Habitual activities may be triggered by environmental and 
contextual cues [39]. If a situation requires flexibility and 
change, strong habits may often emerge as errors. Conscious 
change away from habitual behaviour is demanding, and 
people act according to old habits when they are distracted, 
under time pressure and with limited ability. Older adults 
were less able to modify habitual behaviour [39]. 
An example of deep automaticity may happen when 
using modern hearing aids, where the wearer can train his or 
her brain to filter out noise from the sound that s/he wants to 
hear in order to get the most out of the hearing aid. The brain 
needs some years to re-adjust, and middle-aged people will 
benefit from starting to use the hearing aids before it is 
strictly necessary. People who do not start using them until 
their 70ies may experience that their brains will be very slow 
in adjusting and they may experience the hearing aid as 
insufficient and unpleasant. The brain needs time to allow for 
automation that enables the filtering activity to take place 
outside of the conscious brain activity [40].  
As an example of automation of symbolic interaction we 
will refer to a woman in her seventies, who told us about her 
technology use. Our informant is retired, and in periods of 
her life she has been seriously ill and received treatment. But 
now she is active in her community with activities and 
organisations and she is active in her home. She does not 
have a smartphone and often experience problems when 
writing sms-es. She asks her husband to finish her sms if she 
needs help. However, she is the one who masters the remote 
control for the TV. She says (with a smile) that she has to, 
because her husband rarely watches TV. Her son gave her a 
simplified remote control for her birthday, which she never 
uses – she took it to be a prank and has not taken it as a 
serious artifact. She has no problems using the usual TV 
remote control (Fig. 2).  
Changes in rules and regulations as well as in the 
technology for doing taxes introduce new tasks for the 
citizens. In 2008 submitting the tax return form was made 
optional in that Norwegian citizens could just accept the 
figures that was already gathered by the tax authorities and 
presented in a pre-completed form. Accepting was done by a 
non-action: by not making changes in the pre-completed 
form. Hence, learning to differentiate and understand when 
to report changes has become a separate task. Many of the 
callers were not aware that they did not have to send in a 
paper form, and that they could report online [16]. In practice 
it can be difficult to differentiate between learning new tasks 
and unlearning old tasks, but we argue that analytically they 
create different kinds of challenges.   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Wu et al. [41] present a participatory design project with 
people with anterograde amnesia, aimed at developing a 
“memory aid” for and with them. They base their design on 
the fact that “amnestics rely heavily on external memory 
aids, such as a calendar or an action item list.” (p. 217). Their 
design provides a “tool [that] will assist amnestics when 
they feel lost or disoriented by providing information as to 
their whereabouts and their intent for being where they are. 
A person having amnesia will typically follow familiar 
routines in their daily life, such as the same route home, 
because deviating from this path will often result in 
disorientation. Our tool enables an amnestic to grow 
increasingly confident and independent in exploring new 
locations and situations – a feat that is very difficult in 
current practice.” [41, original emphasis]. 
The tool was based on the fact that amnestics’ procedural 
memory to a large extent remains intact; therefore, it was 
possible to train new routines and skills for using the tool. 
“Interestingly, the overall similarity of products that has been 
experienced before does not have to be high to allow 
effective learning” [4].  
Occupational therapists working with elderly people have 
told us that people often install electric water heaters in the 
homes of their old relatives in order to avoid that they start a 
fire if they forget the kettle on the stove. However, if the 
elderly person has a “bad day” and is particularly forgetful, 
s/he may put the water heater on the stove as a bodily habit, 
and this may cause fire. 
VI. 
WHAT IS DIFFICULT – SEEN FROM THE USER 
Looking closer at what is difficult suggests a distinction 
between learning and un-learning tasks. We found that the 
sources for the difficulties were the tasks to learn and the old 
tasks to unlearn: the two different processes are experienced 
in different ways both in cases where the artifact is difficult 
itself and when it is the fitting of the technology to the 
situation that appears to be difficult. We came across 
 
Figure 2. A retired woman just laughed about using her 
large-sized and simplified remote control for her TV set 
(normal remotes to the left). 

502
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
examples of actions and errors made by third parties, such as 
vendors, employers, other public agencies and other 
technologies. In these cases, the situation was experienced as 
unpredictable and confusing and not possible to explain by 
the user unless s/he had a deep knowledge of the complexity 
of the technology in its social environment.  
We sum up our analysis of what is difficult in Table II, 
expanding Table I with rows from this more detailed analysis 
of the nature of the difficulties. 
TABLE II.  
WHAT IS DIFFICULT SEEN FROM THE USER 
What is 
difficult 
Kinds of difficulties  
Artifact  
Context 
Activities by 
others 
New tasks 
to learn 
Holding the turn-
off  switch. 
Positioning of the 
charger. 
Online tax 
services. 
Personal economy 
after retiring. Charge 
device after use. 
Check pre-completed 
form 
Check and act if 
something 
unusual 
 
Old 
tasks 
to unlearn 
Handling paper 
forms.  
Putting kettle on 
stove.  
Charge device before 
use.  
Not pushing the 
horse.  
Changed tax rules.  
Need trust to 
stop doing.  
Basic 
knowledge 
for the task 
Understand tax 
and web pages. 
Understand a 
water boiler.  
When does the new 
apply? 
Understanding 
the ecology of 
humans and 
technology 
Challenges:  
Practical 
measures: 
moving a 
charger,   
teaching. 
Matching artifact 
with own life 
situation or 
circumstances. 
Differentiating 
between old and new. 
Disentangling 
interactions and 
complexities. 
 
All the elements in Table II point to existing competence or 
lack of competence presupposed by the artifact that may 
make the artifact difficult to use. But how do we go from 
knowing what is difficult-to-use to designing something that 
is easy-to-use? 
VII. DESIGNING FOR EASE-OF-USE 
The three different kinds of difficulties can be a basis for 
approaching design of easy-to-use technology solutions. In 
this section, we report from some design experiments with 
elderly people by colleagues and students [5][18][29][42] 
[43]  as well as our own design suggestions based on 
analysis of identified user problems [22].  
Designing from the users’ perspective starts with 
investigating their subjective experiences and competencies. 
Elderly users need much practice and repetition to establish 
new habits and unlearning old habits may be the hardest part. 
Unlearning may require trust to let old habits go to be sure 
that they are not necessary, e.g., for security. As unlearning 
old tasks is a challenge in itself, a design that builds on old, 
habitual tasks will be experienced as less challenging for the 
user. Enhancing and extending the old tasks instead of 
making them obsolete in a new design can be experienced as 
a simple design by the user.  
Using everyday technologies like radios, mobile phones, 
water heaters or remote controls is normally easy and often   
automated and habituated. Many of our memories and 
competencies sit in our bodies as automatic movements or 
perception (e.g., music, smells) and can be carried out 
without conscious deliberation. A design that incorporates 
that the user can rely on his/her old habits can make the 
changing of old practices more likely and the design more 
robust. Robustness towards unintended and unexpected use 
is important for the user’s ability to manage and carry on 
with the original task (see e.g., [44]).  
Designing for new habits in old age is possible, as the 
example of the memory aid for the amnestic people above 
showed [41].  
In the large project on evaluation of technologies for 
independent living, designing for ease-of-use has been 
explored in two ways: through design of artifacts that 
resemble familiar technologies [45], and by collaborative 
design with elderly people on designing or testing different 
technological solutions in order to identify what works with 
a minimum of new tasks to learn.  
 
 
 
Figure 3. The prototypes for the knob (above) and the digital radio (below). 
Photo by Johnsen et al. [43]. 
An example of the first design approach is the design of a 
digital radio that was co-designed with in total 25 elderly 
people [43]. Johnsen et al. aimed to design interaction 
mechanisms that built on old and familiar bodily skills when 
designing a new way of operating a digital radio [ibid]. 
Using rotary controls for operating the radio – like in the old 
days – enabled them to make sense of the interface with their 
body even if they intellectually could not understand or 
remember how to turn on the radio. They easily recognized 
the button as a device for rotary movement. Several buttons 
were designed and tested for a good grip for old hands and 

503
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
recognizable positioning with different textures and shapes 
[43], see Fig. 3. 
 
 
Figure 4. Testing several different induction chargers. Photo: Iversen [42]. 
The second design approach involved testing a large 
number of different solutions to the same problem. One 
example is a test of induction chargers carried out to identify 
problems and ease-of-use [29]. As a way to provide easy 
charging of phones, Iversen and Joshi [29] collected seven 
different off-the-shelf induction chargers and asked a group 
of elderly men to evaluate them (see Fig. 4). Trying out 
different technologies and experiencing how they offered 
different degrees and kinds of difficulties turned out to be 
instructive to the elderly users as well as to the designers. 
Furthermore, Joshi [45] built on knowledge about earlier 
habits, e.g., the fact that in “the old days” (i.e., when they 
were young adults) telephones had wires and were usually 
located in a specific place, on a particular table by the 
entrance door. Maybe it would be easier to charge the mobile 
phone if, instead, always putting the phone in “its place” was 
the thing to remember (see e.g., [46]). 
Another example is from a participatory design process 
organized and facilitated by Stark [31]. A group of elderly 
visitors to an elderly activity centre found their online 
banking services to be difficult to use: the web site was seen 
as confusing, with too much irrelevant information and 
choices on the pages. One of them started a “data club” 
aimed at helping other elderly visitors with their Internet 
banking. Stark recruited some of the people frequently 
visiting the data club to join her in designing a new online 
banking solution. The design process consisted of seven 
meetings, and during these meetings the elderly participants 
suggested a design that was based on a very different logic 
from the current Internet banking solution. In the new “Easy 
Bank” banking solution the service mimics the tasks carried 
out by people going (in person) to the bank: they pay their 
bills or they want information about their bank account(s). 
Instead of presenting the bank customer with a virtual place 
where one can access a range of different bank services, the 
new “EasyBank” design presents the two most frequent 
activities: paying bills and getting information about the 
account, see Fig. 5.  
 
 
Figure 5. A suggestion for an “easy online banking” made by a group of 
elderly users [31]. 
Making online banking easy by referring to well-known 
and established banking habits may make it easier to adopt 
the new way of doing banking. It seems that the logic of the 
current banking solution is grounded in how the bank sees 
the world rather than what bank customers may be interested 
in doing in the bank. One can argue that making the Internet 
bank a virtual “bank place” where lots of services can be 
activated is a more open solution that may serve all bank 
customers, however, for most of the less frequent users of 
bank services paying bills and checking your account are 
what they do in the bank. Stark’s new “Easy Bank” solution 
is an example of taking the non-expert user’s point of view 
when designing the services, and then designing the service 
as it is seen from these users. At a more general level 
technology is often used to automate some tasks and hence 
enable more self-service or more available services.  
Fig. 6 illustrates our view of how technology influences 
the tasks done by a human user. Fig. 6a illustrates a loosely 
defined set of tasks for a particular purpose (e.g., doing 
taxes) as seen from the human’s perspective. Fig. 6b 
illustrates how technology takes over some of the tasks: they 
become automated. Fig. 6c shows the automated task area as 
seen from the human user’s point of you: s/he encounters 
some left-over tasks that are not automated and some new 
tasks.  
The tasks left for the human interacting with the 
technology may appear as fragmented and there may be no 
or little coherence between different subtasks. New tasks can 
be of a very different kind than the original set of tasks. Fig. 
4d illustrates that in order to make the tasks left for the 
human user coherent and foreseeable, we should design a 
coherent set of tasks left for the user instead of letting the 
technology decide what is automated [22].  
 

504
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
 
 
 
 
 
Figure 6. Automation removes some tasks from the user and introduce 
others. a) A set of tasks for a user - not clearly defined. b) Some of the 
tasks are made obsolete because of technology. c) Fragmented tasks left 
for the human user. d) A coherent set of tasks for a user. 
Automation and service development usually takes its 
starting point from the needs and material basis of the service 
provider. Automation is based on what can be automated. 
The service provider’s logic structures how services and 
functionality is presented for the users. Users will need to 
learn and understand the provider’s logic to use the services 
in independent and autonomous ways. Looking for the users’ 
logic will make possible design starting with the user’s 
perspective. 
Managing the boundaries between tasks made redundant 
by technology, tasks left for the user to do and emerging new 
tasks is a challenge in itself. Design from the user’s 
perspective aims to present the tasks for the human 
interacting with technology as a coherent whole and with 
connected subtasks. This will enable the user to disentangle 
the problems s/he encounters.  
Understanding when to deviate from old habits and do 
new tasks requires sorting things out, which should be 
supported by the design and by training and practicing (with 
or without helpers). Matching the artifact with the personal 
use situation and context represents a challenge [22][47], in 
particular if the artifact is complex (like tax). Showing ways 
of matching, e.g., by providing several examples, can help 
the user in the matching of her/his situation with the 
technology requirements: s/he may be lucky and find an 
example similar to her situation. FAQs and help texts can 
provide such examples in the artifact itself, while human 
helpers like call advisors and occupational therapists will 
have to assist if the matching is too difficult to be carried out 
by the user alone. Graphical illustrations and simulations can 
also help explain complex systems like the tax system.  
Often very simple re-designs can contribute to explaining 
how the automated system works, and reduce the users’ 
anxiety that something is wrong (and at the same time reduce 
the load on the service provider’s call centre/help desk). In 
the registration service for new students (see Section III A), 
merely sending an email to new students when they open an 
account that more services will become available as soon as 
they pay their fee, will help. The students understand why 
there are no services/menu choices available and that it is not 
an error [28]. A citizen who changes her tax card online can 
receive an email saying that a change is registered, and when 
she can expect a new tax card to be operative. This will 
enable a citizen who does not receive such an email the next 
time she makes an online change to understand that her 
online changes were not registered. Instead of calling the tax 
authorities, she may be able to check into the matter herself.  
A smooth transition between an old and a new system is 
demonstrated by Denman and Nachman [48], who worked 
with designing for one user: Professor Stephen Hawking. 
Hawking uses a specially built interface that enables him to 
write and speak with an artificial voice based on small 
muscular movements as input. His use of the interface was 
developed through many years, and his practices were deeply 
dependent on and rooted in his old system. Denman et al. 
found that making changes in the interface was challenging 
as “Stephen had a rhythm in his use of his system” and he 
knew some aspects of it by hearth in a way that speeded up 
his operations even though the operation was based on, e.g., 
choosing a word from an alphabetic list. Hawkings knew the 
list by hearth, and was faster using the old list than a new 
word-prediction engine that suggested appropriate words. 
Use of the old list involved more typing, which turned out to 
be faster as Hawking could type without having to read the 
words in the list as he knew it by heart. The new system was 
installed as optional and Hawking could switch between the 
old and new systems, leading him to get practice with the 
new word-prediction engine. After some time of switching 
between the old and the new system, Hawking could make 
better use of the new system and increasingly preferred it 
over the old one [49].  
Starting to use technology that is new to oneself requires 
mental attention and a cognitive effort. Technology use often 
involves symbol manipulation and abstract thinking, which 
may be demanding. People act by force of habit in stressful 
situations and when they have reduced capabilities because 
of for example illness or old age [39].  In demanding life 
situations users need to spend their energies on their primary 
tasks, and there may not be spare capacity available for the 
attention needed to learn to use a technology new to them.  
Elderly people use technology in many ways. However, 
our empiric material show that for elderly people, who are 
not interested in technology as a field of study and for its 
own sake may only embrace new technologies when they fit 
into their life. Using technology can contribute to continuity 
and control, health and well-being when the elderly people 
can use it their own way and for their own purposes [50].  
VIII. CONCLUSION AND FUTURE WORK 
Based on examples from our research on design with and 
for elderly people and on citizens doing taxes, we describe 
how artifacts and systems become difficult to use. We have 
reflected on how we can use knowledge about difficulties in 
b) 
a) 
c) 
d) 

505
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
a constructive way to suggest better designs. In the paper, we 
make an analytical distinction between types of difficulties 
according to where they appear: in the artifact / system itself 
or when used in its use situation / context. Our analysis also 
includes a discussion of the differences between learning 
new tasks and/or competences to benefit from the technology 
and un-learning old habits and practices. In addition, 
difficulties stemming from activities and errors made by 
others may occur, and in order to be able to disentangle the 
problem and sort out what can be done, the user needs to 
understand the larger ecology of the service system.  
We suggest that habits and bodily knowledge can be used 
as resources for design to enable users to benefit from 
familiarity and coherence. Building on and extending old 
habits instead of making them obsolete in a new design can 
be experienced as very simple for the user – independent of 
any usability assessment based on criteria that are external to 
and irrelevant for the particular user in the particular 
situation. Our aim has been to present a conceptual 
framework for design for the user’s subjective perspective.  
Our conclusion is that “easy-to-use” is difficult to design, 
and that the notion of “ease-of-use” hides the complexity that 
comes when artifacts are used in real life contexts. Both the 
identification of what makes things difficult and what turns 
out to be easy to use challenge a notion of “usability” that 
looks at the artifact as a de-contextualized object. Easy to use 
is a characteristic of the relation between a user, her/his 
activity and the technology that supports that activity. It is 
thus both situational and personal. This makes it even more 
challenging to go from what is difficult to use to designing 
easy to use artifacts. What is difficult to use is not so easy to 
detect before the artifact is used hence designers can learn a 
lot from studying use practices. We therefore argue that 
usability might be a less useful measure for evaluating a 
design.  
ACKNOWLEDGMENTS 
The study of technologies for assisted living was part of a 
larger research project on “Autonomy and automation in an 
information society for all”, which has involved several 
colleagues, and we especially thank Suhas Joshi, Anita Woll, 
Rune Rosseland and Sisse Finken for providing data that we 
build on in our discussion. Also a large number of student 
projects has been carried out, and we have included several 
of them in the empirical basis for this paper. We thank them 
for their contributions, and have referred to their reports in 
the reference list. Also the participants in the “BRIS” project 
have contributed to our discussions. We also want to thank 
the staff and elderly residents at the municipal apartment 
building and in the BRIS projects as well as the advisors and 
managers at the Tax Information Call Centre for their 
contributions to our research.  
REFERENCES   
[1] T. Bratteteig and G. Verne, “From Difficult Artifacts to Easy 
to Use Designs,” ACHI, IARIA, 2016, pp. 185-191 
[2] J. Nielsen, Usability Engineering, Morgan Kaufmann 
Publishers, 1994, ISBN 0-12-518406-9. 
[3] B. Shneiderman and C. Plaisant, Designing the User 
Interface: 
Strategies 
for 
Effective 
Human-Computer 
Interaction, Addison-Wesley Publ. Co. Reading, MA, 2010. 
[4] P. Langdon, T. Lewis, and J. Clarkson, “The effects of prior 
experience on the use of consumer products,” Univ.Access 
Inf.Soc., vol.  6, 2007, pp. 179-191. 
[5] S. G. Joshi and T. Bratteteig, “Designing for Prolonged 
Mastery. On involving old people in Participatory Design,” 
Scandinavian Journal of Information Systems, 28(1), 2016. 
[6] S. Bly, B. Schilit, D. W. McDonald, B. Rosario, and Y. Saint-
Hilaire, “Broken expectations in the digital home,” CHI 2006, 
Montréal, Quebec, Canada, Apr. 22-27, pp. 568-573 
[7] L. Suchman, Plans and Situated Actions. The Problem of 
human-machine communication. Cambridge University Press, 
1987. 
[8] L. Suchman, Human-Machine Reconfigurations, Cambridge 
University Press,  New York, 2007. 
[9] L. Gasser, “The Integration of Computing and Routine 
Work,” ACM Transactions on Office Automation, vol. 4, no. 
3, 1986, pp. 205-225. 
[10] J. Söderström, Jävla skitsystem (in Swedish: Stupid bloody 
system), 
Karneval 
2011, 
ISBN 
9789187207525, 
http://www.slideshare.net/Jonas_inUse/stupid-bloody-system, 
retrieved 03/2016. 
[11] J. Grudin, “The case against user interface consistency,” 
Communications of the ACM, vol. 32, no. 19. 1989, pp. 
1164-1173. 
[12] S. R. Barley, “Technology as an occasion for structuring: 
Evidence from observations of CT scanners and the social 
order of radiology departments,” Administrative science 
quarterly,  vol. 31, no. 1, 1986, pp. 78-108. 
[13] W. Orlikowski, “Learning from Notes,” CSCW’92, ACM, 
New York, 1992, pp. 362-369. 
[14] S. L. Star and K. Ruhleder, “Steps Toward an Ecology of 
Infrastructure: Design and access for Large Information 
Spaces,” Information systems research, vol. 7, no. 1, 1996, 
pp. 111-134.   
[15] T. Bratteteig, “The Unbearable Lightness of Grouping: 
Problems of introducing computer support for cooperative 
work,” Proceedings of NOKOBIT 1998, Oslo, 99-113. 
[16] G. Verne, “Two faces of autonomy. Learning from non-users 
of an e-service,” Systems, Signs and Actions, vol. 8,  no. 1, 
2014, pp. 6–24 
[17] C. Ø. Madsen, Why do they keep calling? Single parents' 
Domestication of mandatroy e-government self-service 
channels, PhD dissertation, IT University of Copenhagen, 
2015. 
[18] S. G. Joshi and T. Bratteteig, “Assembling fragments into 
continuous design: On participatory design with old people,” 
Nordic Contributions in IS Research, 6th Scandinavian 
Conference on Information Systems, SCIS 2015, Oulu, 
Finland, August 9-12, 2015, Proceedings 
[19] T. Greenhalgh et al., “What matters to older people with 
assisted living needs? A phenomenological analysis of the use 
and non-use of telehealth and telecare.” Social science & 
medicine, 93:86-94, 2013.  
[20] A. Culén and T. Bratteteig,  “Touch-Screens and Elderly 
users: A Perfect Match?” In Leslie Miller (ed.), ACHI 
2013, IARIA, 2013, pp. 460-465. 
[21] M. L. Cummings, “Automation Bias in Intelligent Time 
Critical Decision Support Systems,” AIAA 3rd Intelligent 
Systems Technical Conference 2004, pp. 1-6. 
[22] G. Verne, The winners are those who have used the old paper 
form. On citizens and automated public services, PhD Thesis, 
University of Oslo, 2015, http://urn.nb.no/URN:NBN:no-
50321. 

506
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[23] J. C. Doksrød, Understanding the complexity of error 
detection in smart homes, Master thesis, Department of 
Informatics, University of Oslo, 2016 
[24] L. Bainbridge, “Ironies of automation,” Automatica vol. 19, 
no. 6, 1983, pp. 775-779. doi:10.1016/0005-1098(83)90046-8. 
[25] C. Marshall and G.B. Rossman, Designing Qualitative 
Research, Sage, 2016. 
[26] D. Randall, R. Harper, and M. Rouncefield, Fieldwork for 
Design. Theory and Practice. Springer Verlag, 2007. 
[27] T. Bratteteig, G. Verne, “Conditions for Autonomy in the 
Information Society: Disentangling as a public service,” 
Scandinavian Journal of Information Systems 24(2), 2012. 
[28] M. Ekdal and S. Tomt, «Hæ? Hvorfor har ingen fortalt meg 
dette?» En analyse av IT-løsningene ved UiO i et 
tjenestedesignperspektiv, Master thesis, Department of 
Informatics, University of Oslo, 2016. 
[29] T. R. Iversen and S.G. Joshi, “Exploring Spatial Interaction in 
Assistive 
Technology 
through 
prototyping,” 
AHFE 
conference, Procedia Manufacturing, Elsevier Publishing Co., 
2015. 
[30] http://www.phonak.com/fi/b2c/fi/products/wireless-
accessories/products/roger.html, retrieved 11/2016. 
[31] K. H. Stark, «Du må vite hvor du skal lete» - Eldres bruk av 
nettbaserte 
tjenester, 
Master 
thesis, 
Department 
of 
Informatics, University of Oslo, 2016. 
[32] T. H. Paulsrud, A discussion of Technological Frames applied 
at a Usability Test, Master thesis, Department of Informatics, 
University of Oslo, 2011. 
[33] R. M. Docampo, Technology Generations handling complex 
User Interfaces, PhD dissertation, TU Eindhoven 2001, ISBN 
90-386-0913-2. 
[34] A. Bandura, “Self-efficacy mechanisms in human agency,” 
American Psychologist vol. 37, no. 2, 1982, pp. 122-147. 
[35] K. V. Wild et al., “Computer related self-efficacy and anxiety 
in older adults with and without mild cognitive impairment,” 
Alzheimer’s & dementia: the journal of the Alzheimer’s 
Association, vol. 8, no.  6, 2012, pp. 544-552. 
[36] J. Hurtienne and P. Langdon, “Prior Knowledge in Inclusive 
Design: The Older, the More Intuitive?” ACM Conference 
2009. 
[37] K. Höök, “Transferring Qualities from Horseback Riding to 
Design,” NordiCHI, October 16-20 2010, pp. 226–235, ACM, 
ISBN: 978-1-60558-934-3. 
[38] T. P. Wheatley and D. M. Wegner, “Automaticity in action,” 
In: N. J. Smelser and P. B. Baltes, International encyclopedia 
of the social and behavioral sciences, London: Pergamon, 
2001, pp. 991-993. 
[39] W. Wood and D. Rünger, “Psychology of Habit,” Annu. Rev. 
Psychol. 2016, 67:11.1–11.26 
[40] S. Haugland, hearing aid specialist, personal communication 
2015. 
[41] M. Wu, B. Richards, and R Baecker, “Participatory Design 
with individuals who have Amnesia,” The Participatory 
Design Conference ,Toronto 2004, pp. 214–223, ACM, ISBN: 
1-58113-851-2/04/07. 
[42] T. R. Iversen, Exploring tangible interaction: Alternative 
interfaces for assisting elderly users, Master Thesis, 
Department of Informatics, University of Oslo, 2015. 
[43] E. Johnsen, M. Ofstad and S. Subaschandran, Care+: Can we 
make the interface of the radio easier for elderly users in the 
digital age?, Student report, Department of Informatics, 
University of Oslo, 2015. 
[44] A. Woll, “Aging in Place: Dealing with Breakdown of 
Welfare Technology,” Selected Papers of the Information 
Systems Research Seminar in Scandinavia, vol.  4, 2013, pp. 
77- 90. 
[45] S. G. Joshi, Prolonging interaction - Re-connecting old people 
with purposeful interaction, PhD. dissertation manuscript, 
University of Oslo, forthcoming, 2017. 
[46] L. Palen and S. Aaløkke, ‘Of Pill Boxes and Piano Benches: 
“Home-made” Methods for Managing Medication,’ CSCW 
2006, pp. 79-88. 
[47] G. Bowker and S. L. Star, Sorting Things Out: Classification 
and Its Consequences. Massachussets Institute of Technology, 
Cambridge, Massachussets, 1999. 
[48] P. Denman and L. Nachman, ‘Designing for „a” user: Stephen 
Hawking’s UI,’ PDC‚ 2016, Aug 15 – 19, Aarhus, Denmark. 
[49] P. Tawadrous,  “UX Designer Pete Denman’s Talents Led 
Him to Stephen Hawking. His Success Shattered Myths and 
Broke Down Barriers,” Jobs@Intel Blog, 
http://blogs.intel.com/jobs/2016/07/12/ux-designer-pete-
denman-and-stephen-hawking, 2016, retrieved 11/2016 
[50] M. Loe, “Doing it my way: old women, technology and 
wellbeing.” Sociol Health Illn 32 (2), 2010, pp. 319-334.  
 
 
 
 
 

