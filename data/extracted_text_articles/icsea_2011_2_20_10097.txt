A Test Purpose and Test Case Generation Approach for SOAP Web Services
S´ebastien Salva, Issam Rabhi
LIMOS CNRS UMR 6158
PRES Clermont University, Campus des C´ezeaux
Aubi`ere, FRANCE
sebastien.salva@u-clermont1.fr, rissam@isima.fr
Abstract—SOA Web services are now supported by most
of major software development companies and industry.
To be reliable, these ones require to be developed with
respect to a complete software development life cycle and, in
particular, they need to be tested. Test purpose-based methods
are black box testing techniques which take advantage of
reducing the time required for test derivation in comparison
with exhaustive methods. Nevertheless, test purposes must
be constructed manually. This paper proposes some test
purpose generation methods for SOAP Web services, modelled
by Symbolic Transition Systems (STS). Prior to generate
test purposes, we augment the speciﬁcation with the SOAP
environment, to beneﬁt from the messages generated by SOAP
processors which give new information about the operations
and the faults received. Then, we describe the test case
generation from test purposes by synchronizing them with the
speciﬁcation. Test cases are ﬁnally translated into XML to be
used later by the Soapui tool.
Keywords-Stateful Web services; STS; SOAP; test purpose
generation.
I. INTRODUCTION
Web services represent a remarkable branch in the evo-
lution of software development since they offer substantial
advantages such as the externalization of Business or so-
cial applications available on the Internet, or the reuse of
software accompanied by cost reduction. During the recent
years, industry has embraced Web services as well-accepted
channel for conducting E-Businesses on the Web.
Nevertheless, to ensure that Web services hold their
promises, it is crucial that testing activities play an important
role in the development process. Indeed, to achieve trustwor-
thy Web services in an environment like the Internet, these
ones must also be tested to check various aspects such as
robustness, security and conformance which is the topic of
this paper. Several testing methods concerning Web services
testing have been proposed recently [1], [2], [3]. Some of
them, dealing with conformance testing, are said exhaustive
i.e., the test case selection is performed to ensure that a
faulty implementation is detected by a least one test case.
This exhaustiveness often implies to construct test cases for
covering all the actions of a speciﬁcation at least one time.
So, the test case generation is often costly and eventually
may lead to a state space explosion.
Test purpose-based methods represent an interesting al-
ternative which solve the previous issues and which can
be used to test various properties (not the whole system).
The test selection is then guided and thereby reduced since
test purposes target the test of some implementation parts
only. But, although using this approach greatly reduces
test costs, the main encountered issue is that test purposes
are formulated manually. This task is particularly difﬁcult
when the system is large, has real-time constraints or is
distributed. Few works propose to solve this issue. For
instance, Henniger et al. propose to generate automatically
test purposes for distributed systems [4] by considering the
speciﬁc properties of these latter. None method has been
proposed for service-oriented applications though. This is
why we present, in this paper, some test purpose generation
methods for stateful Web services to test the following
speciﬁc properties: the operation existence, the critical states
and the exception handling. To test them, we augment the
speciﬁcation, modelled with the STS formalism (Symbolic
Transition System [5]), with the SOAP environment. Indeed,
this one gives more information about the operations and
the faults produced by Web services under test. Then, we
describe the test case generation. We deﬁne a synchronous
product which combines the speciﬁcation and test purposes
to produce test cases which can be executed on the im-
plementation and which contain the test purpose properties.
Finally, test cases are translated into XML to be executed
with the Soapui tool [6], which is dedicated to the functional
testing of Web services.
This paper is structured as follows: In Section II, we
deﬁne both Web service and test purpose modelling. Section
II-A provides an overview on some related works about
Web service testing. We describe the advantages granted by
SOAP for testing in Section III and deﬁne the speciﬁcation
completion. Test purpose generation methods are given in
Section IV. Section V describes the testing method: we
detail the test case generation and the testing framework.
Finally, Section VI describes some experimentation results
and Section VII concludes with some perspectives.
II. WEB SERVICE AND TEST PURPOSE MODELLING
We formalize, in this paper, Web services with Symbolic
Transition Systems (STS [5]). This extended automaton
35
ICSEA 2011 : The Sixth International Conference on Software Engineering Advances
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-165-6

model associates a behaviour with a speciﬁcation composed
of transitions labelled by actions and of internal and external
variables sets, which may be used to send or receive concrete
values and to set guards which must be satisﬁed to ﬁre
transitions. Below, we only summarize the STS suspension
deﬁnition where quiescence (the lack of observation) is taken
into account with the δ symbol. The complete deﬁnition can
be found in [5].
Deﬁnition 1 A (suspension) Symbolic Transition System
STS is a tuple < L, l0, V, V0, I, Λ, →>, where:
• L is the ﬁnite set of locations, with l0 the initial one,
• V is the ﬁnite set of internal variables, I is the ﬁnite
set of external or interaction ones. We denote Dv the
domain in which a variable v takes values. The internal
variables are initialized with the assignment V0, which
is assumed to take an unique value in DV ,
• Λ is the ﬁnite set of actions, partitioned by Λ =
ΛIUΛO: inputs, beginning with ?, are provided to the
system, while outputs (beginning with !) are observed
from it. a(p) ∈ Λ is an action where p = (p1, ..., pk) is
a ﬁnite set of external variables. We denote type(p) =
(t1, ..., tk) the type of the variable set p. δ denotes the
quiescence i.e., the lack of observation from a location,
• →
is
the
ﬁnite
transition
set.
A
transition
(li, lj, a(p), ϕ, ϱ), from the location li
∈
L to
lj ∈ L, also denoted li
a(p),ϕ,ϱ
−−−−−→ lj is labelled by
a(p) ∈ Λ × I, ϕ ⊆ DV × Dp is a guard which
restricts the ﬁring of the transition. Internal variables
are updated with the assignment ϱ : DV × Dp → DV
once the transition is ﬁred.
The STS model is not speciﬁcally dedicated to Web
services. These latter may be invoked with methods called
operations. This is why, for modelling, we assume that an
action a in Λ represents either the invocation of an operation
op which is denoted opReq or the return of an operation op
with opResp. For an STS S, we denote OP(S) the operation
set found in Λ. We also assume that service handlers, which
may be used to modify SOAP messages, are actions of the
speciﬁcation. An example is illustrated in Figures 1(a) and
2 (solid transitions only). This one describes a part of the
Amazon Web Service devoted for e-commerce (AWSEC-
ommerceService). For sake of simplicity, we consider only
two operations, ”CartCreate” which creates a virtual cart
composed of items, and ”CartAdd”, which ﬁlls the existing
cart with new items. Initially, a customer has to create a
cart by giving a correct identiﬁer (AWSAccessKeyID), an
item identiﬁer and a quantity. If the cart is instantiated (the
CartCreate operation response is composed of the variable
Isvalid equal to ”true”), this one can be upgraded with the
CartAdd operation. Note that we do not include all the
parameters for readability reasons.
An STS is also associated to an LTS (Labelled Transition
System) to deﬁne its semantics. Intuitively, the LTS seman-
tics corresponds to a valued automaton without symbolic
variables: the states are labelled by internal variable values
while transitions are labelled with actions and parameter val-
ues. The semantics of an STS S =< L, l0, V, V0, I, Λ, →>
is expressed by an LTS ||S|| =< Q, q0, P, →>.
(a) An STS speciﬁcation
(b) A test purpose
Figure 1.
?a
?CartCreate(String AWSAccessKeyID, String ItemASIN, Integer
quantity) id:=AWSAccessKeyID q:=quantity
!b
!CartCreateResponse(String[]
errors,
String
isvalid)
[isvalid==false & id<>”ID”]
!c
!CartCreateResponse( String CID, String isvalid, Cart cart) [is-
valid==true & id==”ID” & q>0] CartId:=CID
!c2
!(soapfault,cause) [q≤0]
?d
?CartAdd(String AWSAccessKeyID, String ItemASIN, Inte-
ger quantity, String CID) [CID==Cartid] id:=AWSAccessKeyID
q:=quantity
!e
!CartAddResponse(String isvalid) [isvalid==true & id==”ID” &
q>0]
?f1
?CartAdd(String AWSAccessKeyID, String ItemASIN, Integer
quantity, String CID)
!f2
!a(p) [a(p)̸=(soapfault,”Client”) & a(p)̸=(soapfault,”the end-
point...”)]
?g1
?CartCreate(String AWSAccessKeyID, String ItemASIN, Integer
quantity)
?sc1
?CartCreate(String AWSAccessKeyID, String ItemASIN, In-
teger
quantity)
[ItemASIN==B0000457L2
&
quantity==5]
id:=AWSAccessKeyID q:=quantity
!sc2
!CartCreateResponse(String
CId,
String
isvalid,
Cart
cart)
g1=[isvalid==true
&
id==”ID”
&
q>0
&
cart.ItemASIN[0].quantity==5] CartId:=CID
!sc3
!CartCreateResponse(String
CId,
String
isvalid)
g2=[isvalid==true & id==”ID” & q>0 & cart.ItemASIN[0].q ̸=
5] CartId:=CID
!sc4
!CartCreateResponse(String CId, String isvalid) [¬g1 & ¬g2]
Figure 2.
Speciﬁcation symbols
Test purposes describe the test intention. We assume
that they are composed of speciﬁcation properties which
36
ICSEA 2011 : The Sixth International Conference on Software Engineering Advances
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-165-6

should be met in the implementation under test. Usually,
test purposes do not represent complete speciﬁcation paths.
Therefore, they are often synchronized with the speci-
ﬁcation to generate executable test cases. Consequently,
for a speciﬁcation S =< L, l0, V, V0, I, Λ, →>, we also
formalize a test purpose with a deterministic and acyclic
STS TP =< LT P , l0T P , VT P , V 0T P , I, Λ, →T P > where
internal variables of the test purpose and the speciﬁcation
are exclusive (V ∩ VT P
= ∅), →T P is composed of
transitions modelling speciﬁcation properties. So, for any
transition lj
a(p),ϕj,ϱj
−−−−−−→ l′
j ∈→T P , it exists a transition
li
a(p),ϕi,ϱi
−−−−−−→ l′
i ∈→ and a value set (x1, ..., xn) ∈ DI such
that ϕj ∧ ϕi(x1, ..., xn) |= true. A test purpose example
for the AWSECommerceService is illustrated in Figure 1(b).
This one aims to create a cart composed of ﬁve items whose
identiﬁcation number (ASIN) is B0000457L2.
A. Related work on Web service testing
Some test purpose-based methods dealing with Web ser-
vices can be found in literature. These ones propose to
transform and adapt an initial speciﬁcation to be used with
existing test purpose-based techniques [2], [3].
These test purpose-based method assume having an exist-
ing test purpose set constructed manually. Few works have
also proposed automatic test purpose generation techniques:
for instance, in [4], some generation techniques are proposed
for distributed systems by identifying signiﬁcant action se-
quences of the distributed components. From each sequence,
a test purpose is generated. To our knowledge, none method
has been given for service-oriented applications. However,
these ones are composed of speciﬁc properties, e.g., SOAP
faults, operations with data or exceptions. Therefore,these
applications require new test purpose generation techniques
which take into consideration these properties. We introduce,
in this paper, some of these techniques for stateful Web
services, which aim at testing the operation existence, the
critical states and the exception handling. Then, we deﬁne
a synchronous product to achieve the test case selection.
III. THE ADVANTAGES OFFERED BY THE SOAP
ENVIRONMENT FOR TESTING
Web services are deployed in speciﬁc environments, e.g.,
SOAP for SOAP Web services, to structure messages in an
interoperable manner and to manage operation invocations.
In particular, the SOAP environment consists in a SOAP
layer which serializes messages with XML and of SOAP
receivers (SOAP processor + Web services) [7] which is
software, in Web servers, that consumes messages. The
SOAP processor is a Web service framework part which
represents an intermediary between client applications and
Web services and which serializes/deserializes data and calls
the corresponding operations.
SOAP processors complete Web service behaviours by
adding new messages, called SOAP faults, which give details
about the faults raised in the server side. They return SOAP
faults composed of the causes ”Client” or ”the endpoint
reference not found” if services or operations do not exit.
SOAP processors also generate SOAP faults when a service
instance triggers exceptions. In this case, the fault cause is
equal to the exception name. However, exceptions correctly
managed in the speciﬁcation and in the service code (with
try...catch blocks) are distinguished from the unhandled
ones since a correct exception handling produces SOAP
faults composed of the cause SOAPFaultException only.
So, SOAP faults can also be used to test whether the
exception handling is correct by identifying the received
causes. Consequently, taking into account these messages
while generating test purposes sounds very interesting to
check the satisfaction of some service properties. So, we
propose to augment the speciﬁcation with SOAP faults. We
denote (soapfault, cause) a SOAP fault where the variable
cause is the reason of the SOAP fault receipt.
Let S
=< L, l0, V, V0, I, Λ, →> be a Web service
speciﬁcation. S is completed by means of the algebraic
operation addsoap in S which completes the speciﬁcation
with SOAP faults as stated previously. The result is a
new STS S↑. The operation addsoap is deﬁned as follow:
addsoap in S =def S↑ =< LS↑, l0, V, V0, I, ΛS↑, →S↑>
where LS↑, ΛS↑ and →S↑ are deﬁned by the following rules:
•
l1
?opReq(p),ϕ,ϱ
−−−−−−−−−→Sl2,l1
?op′Req(p),ϕ′,ϱ′
−−−−−−−−−−→l/∈→S,
l1
?op′Req(p),∅,∅
−−−−−−−−−→S↑l′,l′
!a(p),ϕ,∅
−−−−−→S↑l,ϕ=[a(p)̸=
l′ /∈LS
(soapfault,”CLIENT ”)∧a(p)̸=(soapfault,”the endpoint...”)]
•
l
?opReq(p),ϕ,ϱ
−−−−−−−−−→Sl′,ϕ′=
^
l′
!opRespi(ri),ϕi,ϱi
−−−−−−−−−−−−→Sl′
i
¬ϕi
l′
!(soapfault,cause),ϕ′,∅
−−−−−−−−−−−−−−−→S↑l
The ﬁrst rule completes the initial speciﬁcation on the
input set by assuming that each unspeciﬁed operation request
returns a SOAP fault message. The second rule completes
the output set by adding, after each transition modelling an
operation request, a transition labelled by a SOAP fault. Its
guard corresponds to the negation of the guards of transitions
modelling responses. A completed speciﬁcation is illustrated
in Figure 1(a) (with solid and dashed transitions). Note
that unhandled exceptions are caught by speciﬁc exceptions
called unhandledException in Java or C# and translated later
by SOAP faults composed of the unhandledException cause.
So, unhandled exceptions are supported by our work since
we differentiate them from the SOAPFault exceptions thanks
to the received SOAP faults.
IV. AUTOMATIC TEST PURPOSE GENERATION METHODS
Although test purposes sound interesting to reduce test
costs, these ones also raise an important drawback since
37
ICSEA 2011 : The Sixth International Conference on Software Engineering Advances
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-165-6

they are usually formulated manually. So, we contribute to
solve this issue by introducing some automatic generation
techniques for Web services. We propose three test purpose
generation approaches which aim at testing the operation
existence, the critical locations, and the exception handling.
A. Operation existence testing
This approach generates test purposes for testing whether
operations in OP(S↑), with S↑ an STS speciﬁcation, are
implemented and can be invoked. With the completion of
the speciﬁcation, detailed in the previous section, it becomes
possible to test the existence of any operation, even those
which do not return any response, i.e., any observable reac-
tion. Indeed, if an operation is not implemented as it is de-
scribed in the speciﬁcation, the SOAP processor will return
a SOAP fault composed either of the cause ”Client” or of the
cause ”the end point reference not found”. So, for a speci-
ﬁcation S↑ =< LS↑, l0S↑, VS↑, V 0S↑, IS↑, ΛS↑, →S↑>, the
test purpose set is given by:
TP =
^
op∈OP(S↑)
{tp =< L, l0, V, V 0, IS↑, ΛS↑, →> where
→=
{l0
?opReq(p),∅,∅
−−−−−−−−−→
l1, l1
!a(p),ϕ,∅
−−−−−→
l2, with ϕ
=
[a(p) ̸= (soapfault, ”Client”) ∧ a(p) ̸= (soapfault,
”the end point reference not found”)]}
The speciﬁcation of Figure 1(a) is composed of two
operations, so we obtain two test purposes. These ones
will be synchronized later with the speciﬁcation to test any
operation invocation.
B. Critical location testing
The second technique aims at testing the speciﬁcation
critical locations. This method is especially suitable when
the speciﬁcation locations have a precise meaning. It is not
obvious to set which location is critical since no general
and formal deﬁnition is given in literature. So, in this paper,
we suggest that the critical locations are those the most
potentially encountered in the acyclic speciﬁcation paths.
Algorithm 1, derived from the DFS (Depth First path Search)
one, returns the critical location set CS, from a speciﬁcation.
Then, for each critical location l ∈ CS, we construct test
purposes to test all the outgoing transitions of l.
The test purpose set, expressed below, is composed of
speciﬁcation paths ﬁnished by output actions to observe the
implementation reactions while testing. For a speciﬁcation
S↑
=<
LS↑, l0S↑, VS↑, V 0S↑, IS↑, ΛS↑, →S↑>, the test
purpose set is given by:
TP =
^
l∈CS
{tp =< L, l0, V, V 0, IS↑, ΛS↑, →> where → is
constructed with the following rules:
•
l
!a(p),ϕ,ϱ
−−−−−→S↑l′,a(p)̸=δ
l0
!a(p),ϕ,φ(ϱ)
−−−−−−−→l′
•
l
?a(p),ϕ,ϱ
−−−−−−→S↑l′,p=l′
a1(p),ϱ1,ϕ1
−−−−−−−→S↑l′
1...
l0
?a(p),ϕ,φ(ϱ)
−−−−−−−−→l′,l′
a1(p),ϕ1,φ(ϱ1)
−−−−−−−−−→l′
1...
l′
n−1
an(p),ϕn,ϱn
−−−−−−−−→S↑l′
n,an(p)∈ΛO
S↑/{δ}
l′
n−1
an(p),ϕn,φ(ϱn)
−−−−−−−−−−→l′n
In both rules, we use a renaming function φ : V → V ′,
φ(v) → v′ to obtain exclusive test purpose internal variables.
The ﬁrst rule is used when an outgoing transition, from a
critical location, is labelled by an output. In this case, this
transition is added to the test purpose. The second rule is
used when a transition is labelled by an input. The test
purpose is completed with this transition followed by a
speciﬁcation path ﬁnished by an output.
Algorithm 2, given below, constructs a test purpose set
from one critical location l. For each outgoing transition t
of l, if t is labelled by an output action then t is a test
purpose (rule R1). Otherwise, we extract a path p with the
Cover procedure such that the test purpose t.p is ﬁnished
by a transition labelled by an output action (rule R2).
In the speciﬁcation of Figure 1(a), we have two critical
locations req and cart. For each, one test purpose is
constructed, with the previous rules, whose purpose is to
test all the outgoing transitions with paths ﬁnished by an
output action. For instance, for the req location, we obtain
a straightforward test purpose composed of one transition
labelled by !b and another one labelled by !c.
Algorithm 1: Critical location search
1 Critical(STS,location);
input : An STS S =< L, l0, V, V 0, I, Λ, →>, the
initial location l0
output: A location set CL
2 ∀t ∈→, label(t) :=”UNEXPLORED”;
3 foreach t = (l, li, ai, ϱi, ϕi) ∈ OutgoingTransition(l)
do
4
if Label(t) == ”UNEXPLORED” then
5
Label(t):=”VISITED”;
6
Count(l):=Count(l)+1;
7
Critical(S, li);
8
else
9
Count(li):=Count(li)+1 ;
10 CL := {location l | Count(l) ≤
P
li∈L Count(li)
card(L)
};
C. Exception handling testing
As described in Section III, SOAP processors return
SOAP faults when exceptions are triggered in a Web ser-
38
ICSEA 2011 : The Sixth International Conference on Software Engineering Advances
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-165-6

Algorithm 2: Test purpose generation dedicated to crit-
ical locations
1 TPgen(STS,location);
input : An STS
S↑ =< LS↑, l0S↑, VS↑, V 0S↑, IS↑, ΛS↑, →S↑>,
a critical location l ∈ LS↑
output: A test purpose
tp =< L, l0, V, V 0, IS↑, ΛS↑, →>
2 ∀t ∈→S↑, label(t) :=”UNEXPLORED”;
3 foreach ti = l
a(p),ϕ,ϱ
−−−−−→ li ∈→S↑ do
4
if a(p) ∈ ΛO
S↑ then
5
→:=→ ∪{l0
a(p),ϕ,φ(ϱ)
−−−−−−−→ li};
6
else
7
p′ := ∅; Cover(li, p′);
→:=→ ∪{l0
a(p),ϕ,φ(ϱ)
−−−−−−−→ li.p′};
8 Cover(location l, path p);
9 if ∃l
a(p),ϕ,ϱ
−−−−−→ l′ ∈→S↑ with a(p) ∈ ΛO
S↑ then
10
p := p.l
a,ϕ,ϱ
−−−→ l′; l := null;
11 else
12
foreach ti = l
a(p),ϕ,ϱ
−−−−−→ li ∈→S↑ labelled by
”UNEXPLORED” do
13
label(ti) :=”VISITED”; Cover(li, p.ti);
14
if l == null then
15
break;
16
label(ti) :=”UNEXPLORED”;
vice operation at runtime. SOAP processors also enable
to differentiate the exceptions resulting of unexpected Web
service crashes from those which are thrown in Web service
operations (with try...catch blocks for instance). In the last
case only, we obtain SOAP faults composed of the ”Soap-
FaultException” cause.
With the speciﬁcation completion described in Section
III, we can construct test purposes to test whether the
exception
handling
is
correctly
implemented
and
not
managed
by
SOAP
processors.
However,
to
trigger
exceptions,
test
purposes
must
be
formulated
over
predeﬁned value sets, that we denote U(t). These ones
are composed of unusual values well known for relieving
bugs, for any simple or complex type t. For instance,
U(string) is composed of the values &”, ”$”, null or
” ”, which usually trigger exceptions. For a speciﬁcation
S↑
=<
LS↑, l0S↑, VS↑, V 0S↑, IS↑, ΛS↑, →S↑>, the test
purpose set is given by:
TP
=
^
l
?opReq(p),ϕ,ϱ
−−−−−−−−−→S↑l′
{tp =< L, l0, V, V 0, IS↑, ΛS↑,
→>
where
→=
{l0
?opReq(p),ϕ′,φ(ϱ)
−−−−−−−−−−−→
l1, l1
(!soapfault,”SOAP F aultException”),∅,∅
−−−−−−−−−−−−−−−−−−−−−−−−−−−→ l2 with ϕ′ =
ϕ ∧ p = (p1, ..., pn) ∈ U(type(p1)) × ... × U(type(pn))}
The speciﬁcation of Figure 1(a) contains two operation
requests. If we suppose that card(U(type(p1)) × ... ×
U(type(pn))) = n, we obtain at most 2n test purposes. It is
observed that the larger the unusual values sets, the larger
the test purpose set will be. To limit it, instead of using a
cartesian product, we have chosen to use pairwise testing [8]
which helps to reduce the coverage of the variable domain
by constructing discrete combinations for pair of parameters
only.
V. TESTING METHODOLOGY
Each test purpose is synchronized with the speciﬁcation
to produce products, formalized with STSs, which combine
the speciﬁcation behaviour with the test purpose proper-
ties. We extract from these synchronous products complete
paths (from their initial location until a ﬁnal one) with an
algorithm which performs a reachability analysis to check
whether the guards of each path can be satisﬁed to guarantee
its execution. These paths are also completed to express the
incorrect (unspeciﬁed) behaviour. We obtain test cases ended
by locations labelled by pass, fail, inconclusive which
represent the test case local verdict. These ones are ﬁnally
translated into an XML format to be used with the Soapui
tool. Each of these steps are described in detail below.
A. Synchronous product
A test purpose represents a test requirement which should
be met in the implementation. To test this statement, both
the speciﬁcation and the test purpose are synchronized to
produce paths which model test purpose runs with respect
to the speciﬁcation.
Similarly to the speciﬁcation S↑ =< LS↑, l0S↑, VS↑,
V 0S↑, IS↑, ΛS↑, →S↑>,
a
synchronous
product
SP
=
S↑ × TP, with TP
=<
LT P , l0T P , VT P ,
V 0T P , IS↑, ΛS↑, →T P > a test purpose, is deﬁned as
an STS SP =< LS↑ × LT P , l0S↑ × l0T P , VS↑ ∪ VT P ,
V 0S↑ ∪ V 0T P , ΛS↑, →SP >, where the transition relation
→SP is deﬁned with the following rules. The R2 and R3
rules perform the product of one speciﬁcation transition with
one test purpose one by synchronizing actions, variables
updates and guards. We have written the speciﬁc rule R3
for output actions to add locations labelled by inconclusive.
This rule yields two transitions: the ﬁrst one is composed
of a guard satisfying both the speciﬁcation and the test
purpose ones (ϕi ∧ ϕ′
i). The second transition, ended by an
inconclusive location, is composed of the guard ϕi ∧ ¬ϕ′
i
which satisﬁes the speciﬁcation transition but not the test
purpose one. So, reaching such an inconclusive location
during the tests means that the test purpose transition is not
satisﬁed although the speciﬁcation is not faulty.
39
ICSEA 2011 : The Sixth International Conference on Software Engineering Advances
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-165-6

R1 :
(li,li′)∈LSP ,li
a(p),ϕi,ϱi
−−−−−−→S↑,li′
b(p),ϕi′ ,ϱi′
−−−−−−−→T P lj′
(lili′)
a(p),ϕi,ϱi
−−−−−−→SP (ljli′)
R2 :
(li,li′)∈LSP ,li
?a(p),ϕi,ϱi
−−−−−−−→S↑lj,li′
?a(p),ϕi′ ,ϱi′
−−−−−−−−→T P lj′
(∃x∈D(IS↑ ∪VS↑ ∪VT P )ϕi∧ϕi′(x)|= true)
(lili′)
?a(p),ϕi∧ϕi′ ,ϱi∧ϱi′
−−−−−−−−−−−−−→SP (ljlj′)
R3 :
(li,li′)∈LSP ,li
!a(p),ϕi,ϱi
−−−−−−−→S↑lj,li′
!a(p),ϕi′ ,ϱi′
−−−−−−−−→T P lj′
(lili′)
!a(p),ϕi∧ϕi′ ,ϱi∧ϱi′
−−−−−−−−−−−−→SP (ljlj′)
(∃x∈D(IS↑ ∪VS↑ ∪VT P )ϕi∧ϕi′(x)|= true)
(lili′)
!a(p),ϕi∧¬ϕi′ ,ϱi∧ϱi′
−−−−−−−−−−−−−→SP (ljinconlusive)
The synchronous product of the test purpose given in Fig-
ure 1(b) and the completed speciﬁcation is depicted in Figure
3. The yellow transition, which reaches an inconclusive
location, models a response which does not contradict the
speciﬁcation but does not satisfy the test purpose. Transitions
labelled by ?f1 !f2 still belong to the product. They represent
a CartAdd operation request which may be called before the
CartCreate operation given in the test purpose.
Figure 3.
A synchronous product
B. Test case extraction
Figure 4.
The ﬁnal test cases
Final test cases are constructed with the following steps
from the previous synchronous product SP.
• Synchronous product path extraction with reacha-
bility analysis: acyclic paths are extracted from SP
with Algorithm 3. This one computes a set P of SP
paths p. With the Cover subroutine (lines 4-14), it ex-
plores SP with backtracking and solves the constraints
of p with the solving subroutine to ensure that p may be
completely executed. solving takes a path p and returns
a variable assignment ϱ0 which satisﬁes the complete
execution of p. If the constraint solvers [9], [10] cannot
compute a value set allowing to execute p, then solving
subroutine returns an empty set (lines 19-20). We use
the solvers in [9] and [10] which work as external
servers that can be called by the test case generation
algorithm. The solver [10] manages ”String” types, and
the solver [9] manages most of the other simple types.
In practice, to reduce the time required for solving
guards and to prevent from an explosion of values
possibilities, we assume that the variable domains are
limited by using value sets extracted from database for
instance.
• ”pass” verdict addition: for each path p ∈ P, the ﬁnal
locations not already labelled by ”inconclusive” are
labelled by ”pass” which means that some behaviours
modelled by test purposes has been reached,
• Incorrect behaviour completion: each path p ∈ P is
completed on the incorrect response set: ∀l ∈ L such
that l has the outgoing transitions l
!opResp(r1),ϕ1,ϱ1
−−−−−−−−−−−→
l1, ..., l
!opResp(rk),ϕk,ϱk
−−−−−−−−−−−−→ lk, we add: (1) l
δ,∅,∅
−−−→ fail,
(2) l
!opResp(r),ϕ,∅
−−−−−−−−−→ fail, ϕ = [¬(ϕ1 ∨ ... ∨ ϕk)].
(1) δ models the location quiescence i.e., the lack of
observation. We suppose that if no response is observed
after a deﬁned timeout Tmax, then the Web service
under test is faulty. (2) If the called operation does
not return an expected response, then the implemen-
tation does not satisfy both the test purpose and the
speciﬁcation. Thus, a fail verdict is reached too. Note
that when an operation is called, we cannot observe the
response provided by another operation. So, this case
is not considered in this completion.
Final test cases are given in Figure 4. We obtain two
acyclic paths from the previous synchronous product en-
hanced with the possible verdicts.
C. Test execution and verdict
The implementation under test I is assumed behaving like
an LTS semantics, composed of valued transitions (Section
II). We assume that there is no security constraint or ﬁrewall
between the tester and the implementation, which modiﬁes
the SOAP messages and thus the implementation behaviour.
To produce a verdict on the test purpose satisfaction, the
tester executes each test case by traversing the test case tree:
it successively calls an operation with parameters and waits
for a response from I while following the corresponding
40
ICSEA 2011 : The Sixth International Conference on Software Engineering Advances
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-165-6

Algorithm 3: Testcase(STS): P;
input : An STS SP =<
LSP , l0SP , VSP , V 0SP , ISP , SSP , →SP >
output: A set P of STS paths
1 ∀t ∈→SP , label(t) :=”UNEXPLORED”;
2 p := ∅;
3 Cover(l0SP , p, 0);
4 Cover(location l, path p, int n);
5 if ∃(l, l′, a, ϱ, ϕ) ∈→SP labelled by ”UNEXPLORED”
then
6
foreach ti = (l, li, ai, ϱi, ϕi) ∈→SP labelled by
”UNEXPLORED” do
7
if Solving(p.ti) ̸= ∅ then
8
label(ti) :=”VISITED”;
9
Cover(li, p.(l(n), li(n + 1), ai, ϱi, ϕi), n +
1);
10
label(ti) :=”UNEXPLORED”;
11 else
12
ϱ := Solving(p);
13
V 0p = ϱ //V 0p is the variable initialization of p;
14
P := P ∪ p ;
15 Solving(path p) : ϱ;
16 p = (l0, l1, a0, ϕ0, ϱ0)...(lk, lk+1, ak, ϕk, ϱk);
17 c = ϕ0 ∧ ϕ1(ϱ0) ∧ ... ∧ ϕk(ϱk−1);
18 (x1, ..., xn) = solver(c) //solving of the guard c
composed of the variables (X1, ..., Xn) such that
c(x1, ..., xn) true;
19 if (x1, ..., xn) == ∅ then
20
ϱ := ∅
21 else
22
ϱ := {X1 := x1, ..., Xn := xn}
branch. When a branch is completely executed, a local
verdict is reached. For a test case t, we denote the local
verdict v(t) ∈ {pass, inconclusive, fail}. The ﬁnal verdict
is given by:
Deﬁnition 2 Let I be a Web service under test, P be a test
purpose set and TC be a generated test case set. The verdict
of the test over P, denoted V erdict(I/P) is
• pass, if for all t ∈ TC, v(t) = pass. The pass verdict
means that test purposes in P are satisﬁed,
• inconclusive, if it exists t ∈ TC, v(t) = inconclusive
and for all t ∈ TC, v(t) ̸= fail. This verdict means
that some test purposes in P are not satisﬁed although
the implementation does not sound faulty,
• fail, otherwise. At least on test purpose in P is not
satisﬁed and the implementation is faulty.
VI. EXPERIMENTATION
Existence
Critical locations
Exception handling
test purposes
22
2
22
test cases
44
22
210
fail verdicts
0
0
39
Figure 5.
Test results on the Amazon AWSECommerceService Service
At the moment, we have implemented an incomplete
tool which performs the test purpose generation from a
completed STS and the synchronous products between the
speciﬁcation and test purposes only. So, test cases are
not generated from synchronous products but are extracted
manually. To experiment them on real Web services, test
cases are extracted and written into the Soapui format. So,
these ones can be executed with the Soapui tool [6] which
aims to experiment Web services with unit test cases.
We applied this preliminary tool on several Web ser-
vices to experiment the test purpose generation. Figure 5
describes the results obtained for the Amazon AWSEC-
ommerceService (09/10 version) which is a representative
sample because it is composed of a large operation set
(22 operations) and of many data structures. We limited
the test purpose number to 10 per operation for the ex-
ception handling method. We obtained fail verdicts only
for the exception handling tests. Indeed, we obtained some
SOAP faults composed of the cause Client, meaning that
the requests are incoherent although the test cases satisfy
the speciﬁcation. We also received unspeciﬁed messages
corresponding to errors composed of a wrong cause. For
instance, instead of receiving SOAP faults, we obtained the
response ”Your request should have at least 1 of the fol-
lowing parameters: AWSAccessKeyId, SubscriptionId” when
we called the operation CartAdd with a quantity equal to ”-
1”, or when we searched for a ”Book” type instead of the
”book” one, whereas the two parameters AWSAccessKeyId,
SubscriptionId were right.
In comparison with the other test purpose-based methods
for service-oriented applications [2], [3] or tools, our ap-
proach takes into account the SOAP environment for testing.
This one generates messages which help to conclude if
operations exist as it is stated in the speciﬁcation and which
help to identify the exceptions resulting of unexpected Web
service crashes from those which are thrown in Web service
operations. These features helped to detect the incorrect
SOAP faults, composed of the cause Client in the previous
experimentation. These errors cannot be detected by the
previous methods. But the major beneﬁt of this approach
concerns the automatic generation of test purposes. Most
of the test purpose-based method assume having an existing
test purpose set, constructed manually. As stated earlier, this
manual construction requires time and is difﬁcult when the
system is large.
41
ICSEA 2011 : The Sixth International Conference on Software Engineering Advances
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-165-6

VII. CONCLUSION
We have presented some automatic test purpose gener-
ation methods dedicated to Web services, which aim to
test the operation existence, the critical locations, and the
exception handling. Then, we have deﬁned a synchronous
product of the test purpose with the speciﬁcation to construct
test cases, which are ﬁnally translated into XML and then
executed by means of SOAPUI.
An immediate line of future work is to take into consider-
ation test purposes describing incorrect behaviours. Such test
purposes may be composed of properties which do not be-
long to the speciﬁcation. These ones can be used for testing
behaviours which should be met in the implementation but
also behaviours which should not. With such test purposes,
we could propose new generation methods for robustness or
security testing.
REFERENCES
[1] J. Garc´ıa-Fanjul, J. Tuya, and C. de la Riva, “Generating
test cases speciﬁcations for compositions of web services,”
in in Proceedings of International Workshop on Web Services
Modeling and Testing (WS-MaTe2006), A. Bertolino and
A. Polini, Eds., Palermo, Sicily, ITALY, June 9th 2006, pp.
83–94.
[2] M. Lallali, F. Zaidi, A. Cavalli, and I. Hwang, “Automatic
timed test case generation for web services composition,”
in The 6th IEEE European Conference on Web Services
(ECOWS’08), I. C. S. Press, Ed., Dublin, November 2008,
53–63.
[3] T.-D. Cao, P. Felix, and R. Castanet, “Wsotf: An automatic
testing tool for web services composition,” in Proceedings
of the 2010 Fifth International Conference on Internet and
Web Applications and Services.
Washington, DC, USA:
IEEE Computer Society, 2010, pp. 7–12. [Online]. Available:
http://dx.doi.org/10.1109/ICIW.2010.9
[4] O. Henniger, M. Lu, and H. Ural, “Automatic generation
of test purposes for testing distributed systems,” in FATES,
ser. Lecture Notes in Computer Science, A. Petrenko and
A. Ulrich, Eds., vol. 2931.
Springer, 2003, pp. 178–191.
[5] L. Frantzen, J. Tretmans, and T. Willemse, “Test Generation
Based on Symbolic Speciﬁcations,” in Formal Approaches
to Software Testing – FATES 2004, ser. Lecture Notes
in Computer Science, J. Grabowski and B. Nielsen, Eds.,
no. 3395.
Springer, 2005, pp. 1–15. [Online]. Available:
http://www.cs.ru.nl/∼lf/publications/FTW05.pdf
[6] Eviware, “Soapui,” 2011, http://www.soapui.org/.
[7] W.-I.
organization,
“Web
services
ba-
sic
proﬁle,”
2006,
http://www.ws-
i.org/docs/charters/WSBasic Proﬁle Charter2-1.pdf.
[8] M. B. Cohen, P. B. Gibbons, and W. B. Mugridge, “Construct-
ing test suites for interaction testing,” in Proc. Intl. Conf. on
Software Engineering (ICSE), 2003, pp. 38–48.
[9] N. Een and N. S¨orensson, “Minisat,” 2003, http://minisat.se.
[10] A. Kiezun, V. Ganesh, P. J. Guo, P. Hooimeijer, and M. D.
Ernst, “Hampi: a solver for string constraints,” in ISSTA ’09:
Proceedings of the eighteenth international symposium on
Software testing and analysis.
New York, NY, USA: ACM,
2009, pp. 105–116.
42
ICSEA 2011 : The Sixth International Conference on Software Engineering Advances
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-165-6

