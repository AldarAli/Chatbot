89
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
More on MCS Ontology for Cognition: Revising Selected Concepts, Including 
Cognition and Time, Considering Cognition Links with Philosophy and 
Implementing Automated Cognition in the Real World 
Jean-Daniel Dessimoz and Pierre-François Gauthey  
HEIG-VD, School of Business and Engineering 
HES-SO, Western Switzerland University of Applied Sciences 
CH-1400 Yverdon-les-Bains, Switzerland 
e-mail: {jean-daniel.dessimoz, pierre-francois.gauthey}@heig-vd.ch 
 
 
Abstract—Designing advanced cognitive technologies and 
applications requires a formal ontology, such as the Model for 
Cognitive Sciences (MCS), the theoretical foundations now 
proposed for automated cognition, cognitics. Cognition has the 
ability to create and deliver pertinent information. Discussion 
is made in the current paper of a number of cognitive notions 
including those of reality, time and revisited “speed”, change 
and discontinuity, innate and learned behaviors, as well as the 
human-inspired basics of communication in a group. These 
newly defined notions conveniently complement the existing 
MCS ontology. 
Notions 
are 
delineated 
in 
conceptual 
frameworks and can moreover be made operational, deployed 
in the real world, for validation purpose and for the benefit of 
users. All these elements confirm the rightness of our current 
approaches in solving concrete Artificial Intelligence problems 
and this is illustrated below by some concrete examples taken 
in domestic context, including robots capable of learning. 
Cognition would not make much sense per se, and the paper 
also shows how it can be implemented in the real world, 
notably using our Piaget proprietary environment for 
development and programming of smart robotized systems. 
Experiments prove that the resulting smart systems can indeed 
successfully operate in the real-world, and in particular 
interact with humans, performing with large quantities of 
cognitive components: knowledge, expertise, learning, etc. The 
quantitative approach of MCS and the operationalization of its 
cognitive concepts in real-world systems allow as well for a 
fruitful dialogue about core issues in philosophy as an effective 
design and realization of smart systems for the benefit of 
humans. 
Keywords - cognitive robotics; MCS ontology for cognition; 
cognitics; cognition; time; cognitive speed; discontinuity; reality; 
innate behavior;  communication basics 
I. 
 INTRODUCTION 
The current publication extends some of our past 
published works, and in particular largely revisits the recent 
paper [1], adds a new presentation of the concepts of 
cognition and time, discusses significant links between 
cognition and philosophy, as well as addresses the challenge 
of implementing cognition in the real-world. 
In the past century, a major step in evolution has been 
made when information has been formally defined [2], and 
infrastructure has been provided for communication and 
processing of information in a massive scale. 
In the early days of signal processing, in technical terms, 
information was neatly provided by some transmitters, 
typically originating from some other electronic devices, 
control panels, microphones or sensors. Machine-based 
sources of information were limited to signal generators, 
such as for sine waves or pseudo-random sequences. 
Things have now become much more complex and 
cognition is the new domain to domesticate, where pertinent 
information is autonomously created by expert agents (e.g., 
[3]). It is with this very relevant goal that the MCS theory for 
cognitive sciences has been created (Model for Cognitive 
Sciences [4] [5]. See also the cognitive engine of Figure 1, 
the cognitive concept pyramid of Figure 2, and the metric 
system of Figure 3). The material published so far has 
already 
brought 
interesting 
benefits 
in 
terms 
of 
understanding the core cognitive properties, assessing 
quantitatively their values, and allowing for convincing 
implementation of cognitive robots in selected areas [6].  
 
Figure 1.  Cognition and, effectively, cognitive systems, allow for 
generating relevant information, exactly similar to pre-stored information - 
when the latter is available. Some kind of cognitive engine is necessary 
(e.g. human-based or artificial, implemented on machines). 
Traditionally, people have developed context-dependent 
cognitive indicators (e.g., for expertise, Elo points for chess-
players, Association of Tennis Professionals points for 
tennis-players, grading systems in schools, or IQ scores), but 
unfortunately, beyond the case of information, no other 
work, in our knowledge, has addressed the formal, 
technically-prone definitions of cognitive entities with 
associated units.  
Figure 2 schematically presents the main cognitive 
entities in MCS theory context, and Figure 3 presents the 
equations for their quantitative assessments. Let us briefly 
review their definitions.  

90
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The top group is green, referring to MCS essentials. 
Knowledge is, for an agent (human or possibly machine-
based) the property to deliver the right information; fluency, 
the cognition speed; expertise, the property to deliver 
information right and fast, the product of knowledge and 
fluency; learning, the ability to increase expertise levels; 
intelligence, the capability to learn, and quantitatively, the 
ratio of learning to experience; experience, the amount of 
information witnessed in terms of input and output 
associations (“examples”, “experiments”); complexity, the 
amount of information necessary to exhaustively describe an 
object; abstraction, the property of delivering less 
information than it is incoming; concretization is the inverse 
of abstraction.  
 
 
Figure 2.  Main cognitive entities in MCS theory. Important cognitive 
concepts, defined in MCS theory, are colored in green (left).  They are 
based on a few classic entities, including reality and time, which, though 
classic, also need a discussion from a cognitive perspective 
The lower group is white. Even though in principle the 
corresponding concepts are classical, experience shows that 
their limits are not well understood, and this is especially 
disturbing as the new, green concepts are built on them. Thus 
information is very much time-dependent, the delivery of it 
essentially making its repetition useless; information is 
essentially subjective, which means that the same message 
may convey different quantities to different users; memory is 
considered here as a support for the permanence of 
messages, such as an engraved stone, i.e., without the 
typically associated writing and reading processes; the last 3 
quoted concepts, reality, model and time, are further 
discussed in the sequel of this paper.  
In cognitive systems, scale and time are dimensions that 
are typically much more important than usually perceived. In 
particular, individuals can collectively yield groups, systems 
can often be analyzed as a network of subsystems; and in all 
control loops, occurring in single agents or multi-agent 
systems, strict dynamic constraints allow – or not – for stable 
outcomes. Partial autonomy may have to be granted to 
ancillary subsystems/agents (re. Figure 4). 
In general, commonsense, classical concepts, and 
corresponding MCS concepts are quite synonymous and can 
be described by the same words; nevertheless, there remain 
often subtle differences, and in the sequel of this article, 
when the respective distinctions should be made, the “c-“ 
prefix will be added for the terms defined in MCS Ontology; 
for example c-speed (1/s unit) is not the usual displacement, 
motion speed (m/s unit).  
 
 
Figure 3.  Equations for assessing quantitatively the core properties in 
cognition. Information keeps its classical definition though (re. Shannon 
1948 [2]). 
Today another step is considered, whereby artificial 
cognitive agents should effectively approach human 
cognitive capabilities for three complementary reasons: 
better functional services (including those involving human-
machine cooperation), better understanding of human nature, 
and implementation possibility of theories in order to make 
them operational, and thereby possibly validate them. 
Proceeding should now be done in incremental steps along 
two complementary ways: the understanding of concepts, 
and the operationalized implementation of cognition in 
machines.  
 
 
Figure 4.  Time and scale matter. Cognitive agents may have to be 
organized in a hierarchy, for large scope, and dynamically stable control. 
They can aggregate to form groups or be analyzed at a lower scale as a 
nerwork of sub-systems. 
In this endeavors, a first surprise had been to experience 
that the prerequisites, the basis on which the MCS theory 
was built, were not at all as widely understood as expected 
(re. general surveys [7] [8] and focused discussions below). 
A complement had to be progressively brought in MCS, re-
discussing classical topics, namely those relating to the 
notions of information, models and memory.  
Now, at the moment of addressing in its “generality” the 
cognitive faculty of humans, another necessary pre-condition 
for implementing it in machine-based agents appears. A 

91
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
further analysis, of deeper foundations yet on which the 
MCS theory is grounded, cannot be escaped. What is reality? 
What is time? How to cope with the infinite complexity of 
reality? How much innate or wired can be the cognitive 
capability we are considering?  
The paper addresses these questions in successive 
sections: Section II for reality; Section III for time; Section 
IV for ways to cope with the infinite complexity of reality, in 
particular including the innate versus learning paradigms for 
producing new cognitive agents. The general presentation 
made so far will be illustrated in Section V with detailed 
concrete examples, taken from the field of cooperative 
robotics; they will address cooperation both for human and 
machine-based cases, relating to cognitive aspects and 
operations. The final 4 sections will additionally discuss 
cognition in three different contexts: conventional AI and 
aspects of implementation in the real-world (VI), Piaget as a 
key example of environment allowing to automate and 
implement cognition in the real-world (VII), illustrating 
applications (VIII), and considerations relating cognition and 
philosophy (IX).  
II. 
WHAT IS REALITY? 
In MCS theory, reality is in principle viewed as 
everything, including not only physical objects but also 
immaterial ones, including information repositories, models, 
assumptions, novels and if-worlds. It corresponds to the 
universal definition of Parmenides: What is, is. As illustrated 
in Figure 5, reality is infinitely complex (re. the definition of 
complexity in MCS ontology: an infinite amount of bits or 
megabytes of information would be required for the 
exhaustive description of reality), so much so that even any 
tiny part of it, in practical terms, is infinitely complex as 
well. Reality, including self, is also always the ultimate 
reference. All subjects facing reality are bound to adopt a 
constructivist approach [9], relying on means initially self-
provided, as innate or “wired”, and later on, hopefully 
improving those means, in particular by proceeding with 
exploration and learning by experience (Concretely, a human 
starts in particular with DNA; a typical robot of ours is given 
in particular a computer and an executable program; then 
they explore and learn and ultimately successfully achieve 
many new, unforeseen operations). 
This position is similar to the one of Kant [7], for whom 
innate, pre-existing “categories” are initially required, 
allowing cognitive agents to perceive. And simultaneously, 
by careful axiomatic contributions, complex cognitive 
structures including possible collective, shared models 
(culture) can be elaborated. 
In summary, in a first stage where a single individual is 
considered, we do not need to know what is reality, as we 
benefit from the beginning, of an innate (or “wired” in 
machines) capability to cope with it (models). Moreover, in 
parallel, rational processes can also develop, and, with 
automated cognition, with possible exploration tasks, and on 
the basis of acquired experience, this can usually yield 
significant improvements. 
At the next stage, where the creation of a new capacity to 
cope with reality is considered, ingenuity is the key, as 
defined in MCS ontology [5].  
 
Figure 5.  Experience strongly suggests that reality is infinitely complex. 
Models may be simple and validly serve singular goals, but they should 
always be considered as very specific for those goals and infinitely 
lacunary with respect to reality 
III. 
WHAT IS TIME? 
Strangely, time is far from well defined in classical 
terms. The proposal of Kant is interesting with his 
complementary attitudes, leaning on one hand towards 
intuition, 
whereby 
everyone 
has 
a 
spontaneous 
understanding of the time concept; and leaning on the other 
hand towards rationality (Weltweisheit, philosophy), by 
which a rigorous, “mathematical”, definition could be 
elaborated – with no guarantee but chance however to have 
this latter construct coincide with the former one. Similarly, 
St-Augustine claims to know very well what is time - as long 
as nobody asks for a formal definition of it! Even in the 
contemporary time where philosophy and science have both 
well developed, Rosenberg apologizes for simply defining 
time as follows: “time is duration” and “duration is the 
passage of time” [8].  
 
 
Figure 6.  Time characterizes permanence, and speed as defined in MCS 
ontology, i.e., “c-speed”, does it for change. 

92
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
It is well known that dictionaries tend to have circular 
definitions. This should be accepted for at least two reasons: 
as clearly stated by Kant, reality and cognitive world are 
disconnected; in this sense, a “first” definition, i.e., relating 
directly to reality is impossible (convenient complements to 
circumvent 
this 
definition 
obstacle 
include 
gaining 
experience by direct confrontation to reality, visits to 
museums, science parks, touring and lab experiments). Now, 
with circular definitions, the cognitive world appears as a 
maze with multiple entry points. In a chain of 10 so-related 
concepts, the reader has ten chances to hop with his/her/its 
intuition from reality to the cognitive world (which includes 
libraries, languages, dictionaries and Wikipedia). 
Time has already been addressed in MCS ontology, as 
well as two other closely related concepts fluency and 
agility. Here, however, things improve: a clearer articulation 
is made between time and change; speed is defined in a 
universal way, which then helps, with appropriate, specific 
complements, better handle changes in a variety of domains. 
Fluency, thus, becomes the speed of expert information 
delivery and agility the speed of action. 
We propose here to define time as a distributed axiom, in 
a cloud of 6 interconnected concepts: time, permanence, 
eternity, change, speed, and discontinuity (re. Figure 6): 
- Time is a measure of permanence, and is quantified by 
the “second” as a unit. 
- Permanence is the property of things that do not change. 
- A permanence that is persistent for an infinite amount 
of time is eternity. 
- Speed is a measure of change, and is quantified, in 
MCS ontology (“c-speed”), by the inverse of a second 
(notice that this is more general than the usual motion speed, 
assessed in meter per second; it can also apply to all 
dimensions other than linear in distance, e.g., speed of 
rotation, heating, speech, sedimentation, or general cognitive 
operations). 
- Change is the property of things that do not remain 
same, stable, permanent over a certain time.  
- A change that occurs at an infinite speed is a 
discontinuity. 
If any single one of the six previous statements is 
intuitively understood, this evidence can be rationally 
propagated to all the other 5 associated concepts. 
Changes can be of different orders: the speed of change 
may be permanent, constant over a certain time (1st order 
change); or the speed itself may change at constant speed, 
yielding the notion of permanent acceleration (2nd order 
change), etc. (re. “jerk” for 3rd order change). 
In summary, even though time has somehow been 
defined in various ways in the fields of philosophy and 
physics, in MCS ontology it gains in clarity and 
compatibility with other entities crucial for natural cognition 
and automated cognition. 
IV. 
HOW TO COPE WITH THE INFINITE COMPLEXITY OF 
REALITY? 
Section II has shown that reality should be considered as 
infinitely complex. Yet, it appears that much can often be 
achieved in practice. So, what paradigms allow for such 
positive outcomes? The current section presents 5 of them, 
including the selection of (prioritized) goals, the pragmatic 
exploration of local circumstances, the generation of agents 
with some innate or wired initial capabilities, an iterative 
process improving performance, and the accelerated progress 
resulting from setting multiple, coordinated actions in 
parallel. 
A. Necessity of selecting a goal 
As illustrated in Figure 5, experience shows that 
numerous goals can be reached while ignoring most aspects 
of reality. Numerous simple ad hoc models prove effective. 
To the point where even bacteria not only survive in our 
often-hostile world, but even usually live well and multiply. 
A basic paradigm consists in focusing attention on 
selected contexts, successively considering them with as 
many constraints as possible. A good example of this 
approach is notably the famous “hic et nunc – here and now” 
framework in Jesuits’ case studies. Here, are some other 
typical cases: “under assumption”, “with abstract and holistic 
views”, “with more detailed analytical representations”, etc. 
Critical for success is the proper selection of a goal. A 
goal in practice always has a number of peculiarities that 
open possibilities for effective and simple modeling (re. also 
Figure 5). In AI, it is often said in substance that experts 
know what to ignore in a given situation. 
For example, we have stated above what is the main goal 
of the research we refer to in this paper: to make possible the 
design of artificial cognitive agents effectively approaching 
human cognitive capabilities, with further possible positive 
impacts in three areas (see Introduction section). Toward this 
goal, an effective model implies in particular the proposed 
extensions of MCS ontology. 
Some other, more intuitive arguments for selecting a goal 
include the following two:  
- It may be useful to map in cognitive context the well 
established A* algorithm for navigation in space [10] crucial 
elements are the location of goal-site and the one of current 
position. 
- As reality is infinitely complex, non-oriented efforts 
would get as diluted and ineffective as curry powder thrown 
in a river (re. Thai motto recommending humans to focus on 
selected goals).  
B. Pragmatic approach adapted to circumstances 
Careful attention must be given to “current” status, as the 
latter typically evolves. In a pragmatic way, we propose to 
start with the world as is, modeled as simply as necessary for 
reaching the considered goals. In cognition, backtracking is 
the rule. From the selected goal, specifications are derived, 
which then lead the cognitive process, and in particular an 
active perception (“exploration”) faculty 
capable 
of 
acquiring useful information and the possible experience 
elements eventually allowing for improvements (re. Figure 
7). 
C. Innate goal and capabilities 
A prominent place is initially given to innate and current 
capabilities (re. Figure 8). 

93
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
In practice, it is precious to be aware that even humans 
do not start, individually, from scratch. At birth time, they 
already know for example how to grasp, crawl, find their 
food; these tasks are not necessarily obvious for a robot. 
Some chicken for example have such an elaborate pre-
design that they can be industrially grown without any social 
assistance; they can get out of their egg and develop without 
the help of previous generations. 
 
 
Figure 7.  In cognition, backtracking is the rule. From the selected goal, 
specifications are derived, which then lead the cognitive process, and in 
particular an active perception (“exploration”) faculty  capable of acquiring 
the experience necessary for improvements. 
Therefore, it is legitimate also for machine-based agents 
under study to start from some predefined (let us say 
“wired”, or pre-programmed) initial state. And humans have 
created robots. 
D. Improved goal and capabilities 
In the paragraph about reality, care had been taken to 
keep things as simple as possible. Nevertheless, multiple 
cognitive processes, including some innate capabilities, and 
possibly newly acquired experience elements could already 
been mentioned, opening the way for improvements and 
learning. 
 
Figure 8.  Current goals and processes may result from exploration 
performed and/or experience acquired by an agent running a given 
cognitive process in a certain domain of reality. Initial goals and processes 
are innate (or “wired”). 
The next interesting stage occurs when the design and 
creation of a new capacity to cope with reality is considered 
(Figure 9). For connecting directly to reality, chance (as in 
Darwin’s theory,) or ingenuity (as defined in MCS ontology 
[5]) are the main keys.  
E. Collective approach; elements of communication, 
credibility, reputation, and trust 
Experience shows that the coordinated forces of multiple 
agents – groups- increase the possibilities of successful 
actions in the world. 
This paradigm can be exploited in a multiplicity of ways. 
Of particular interest for our context, we find groups of 
humans, of robots, and of hybrid resources – robots 
cooperating with humans. 
Groups have already been defined in MCS ontology. In 
this context a critical ingredient has been identified as the 
culture of the group, and, in reference to it, the 
communication channel and some kind of formalism, 
protocol or language. 
 
Figure 9.  Current goals and processes may lead to improvements in next 
generation system (in particular for humans or machines). 
Two new elements come now under scrutiny. The first 
one is, for inspiration, the case of baby communication, a 
case reasonably simple for the purpose of progressive 
transfer of approach to machine-based systems. The second 
one is the sharing of error probability of a source, among 
humans, which expands at group-level a feature already 
taken into account for individual cognitive agents. 
In their early months of existence, babies appear to have 
at least 4 types of communication capabilities. In some 
circumstances, babies can express strongly (high arousal) 
their emotions [11], their states of happiness and 
unhappiness (positive or negative valence); they cry, or 
smile, which typically leads to corresponding correcting or 
sustaining actions from their parents. They also test the good 
understanding and adequacy of key behaviors and gestures 
by imitating, and mimicking; they also sometimes just 
synchronize with others in their attitudes and actions (they 
join in or trigger yawning, and laughing). 
The MCS theory has introduced a value, in terms of 
probability of error, for cognitive agents delivering 
information. This affects the quantitative estimation of 
knowledge characterizing these sources. Now we can add a 
similar, interesting property at group level, which allows for 
appropriate propagation of the expected error-rate. In this 
framework, agents would take into consideration the 
credibility of sources and in particular of other group 
members; if shared at group level, this credibility could form 
the basis for, collectively, building up a reputation. Thus 
when receiving a message, such agents could associate to it a 

94
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
trust value, based on reputation. Improvements would result 
in terms of modulation of risk-taking and in the respective 
weighting of multiple conflicting sources being integrated 
(fused). 
V. 
DETAILED EXAMPLES IN COOPERATIVE ROBOTICS 
Let us consider a typical test task of Robocup@Home  
(RaH) competitions, “Fetch and Carry” (F&C). In substance, 
team members can in particular talk to their robots, giving a 
hint about what to fetch (e.g., “a grey box”), and where it 
stands (e.g., “near the front door”); the robot should by then 
know enough about topology and navigation to be able to 
autonomously reach there, locate the object accurately 
enough to get it in the “hand”, grasp it, lift it up, and 
transport it back to the starting location (re. Figure 10). 
The results of Sections II and IV, including §A to E in 
the latter case can be illustrated here, both in human and in 
machined contexts.  
A. Illustration in human context 
In a first stage, a group of international experts have 
elaborated a rulebook where the general goal of designing 
systems useful for humans (re. to Section II, in short SII) is 
focused towards a domestic goal (re. to Section IV.A, in 
short SIV.A), and then backtracked into the specification of 
even more focused subgoals: elementary capabilities to be 
devised. One of them is the task called “Fetch and Carry”, 
addressing a “natural” way for a robot to find, grasp and 
transport an object (SIV.A). This intermediary goal is then 
searched in parallel by multiple teams (SIV.E). This task 
adapts to local infrastructure (SIV.B) and is iteratively 
considered, year after year (SIV.C-D). 
 
Figure 10.  In the F&C task, our proprietary robot RH-Y uses in particular a 
vocal dialogue, a navigation capability typically using a ranger for 
navigation purpose, a time-of-flight camera for recognising and locating 
objects (center) and position and force controlled arm and gripper (left and 
right). 
B. Illustration in robotic context 
The demonstration system is real and thus very complex. 
An overview of the task can be seen on a video available 
online (e.g., [12]) and multiple aspects are presented 
elsewhere. Here we shall discuss a minimum of aspects for 
purpose of example.  
Consider first as an analogy, the problem for a human to 
jump over a wall. This can be easily achieved, or may remain 
totally impossible, depending on how high is the wall; the 
metric height is critical. Similarly, in the cognitive world, 
properties must be precisely defined and metrically 
quantified in order to allow for meaningful descriptions and 
effective requirement estimation. 
For the F&C test task, referees typically retain about 20 
objects, which may be randomly put in 20 possible locations. 
Robots may more or less be wired with initial expertise, e.g., 
in terms of topologies and functions; a common culture is 
also defined (“names” of standard objects and locations are 
published on a wall one day or more before the test). Let us 
practice a quantitative estimation of requirements in terms of 
cognitive entities (re. concepts of Figure 2). Ignoring here 
many processes, such as e.g., word perception and 
recognition, or navigation and handling, let us focus on the 
cognitive task of understanding which object is where. The 
input space would consist in about 10 bits of information for 
each object and rough location specified. On this basis, at the 
most abstract level, one out of 20x20=400 possibilities 
should be resolved (i.e., about 9 bits) to know which object is 
to be fetched, and where it is roughly located. In this very 
minimal form, the necessary knowledge for correctly 
understanding the vocal dialogue amounts to approximately 
K=14 lin. With a dialogue lasting for 5 s, the amount of 
expertise for this cognitive task amounts to E=14/5=2.8 lin/s. 
Learning is demonstrated and can be quantitatively estimated 
on this domain:  without dialogue the task cannot be 
achieved in the 5 min allotted to the task (roughly, K=0 lin, 
and therefore, E=0 lin/s), while with a successful dialogue, 
lasting for, say 5 s, E increases to about 3 lin/s. The MCS 
intelligence index is thereby of i=3/5=0.6 lin/s2.  
In the specified location (e.g., “near the door”) the object 
is manually moved by referees by +/- 20cm just before the 
test, making it impossible for robots to have it fully (pre-) 
wired. Therefore exploration as in SIV.B is performed, using 
Time-of-Flight (TOF, distance) perception. Notice that here, 
as in most usual cases, the perception process features (or 
requires) a lot more knowledge and expertise than the above 
cognitive operation: in particular the input space includes 
here 176x144 samples, each with 1cm accuracy in a 500cm 
range, i.e., about 150’000 bits of information; similarly, the 
output stage is relatively large for successful trajectory 
specification (about 10’000 bits of output information), and 
the processing time is short (say, 0.1s). 
Time is a very important feature for success, in many 
contexts of these applications (motor control, parallel agent 
management, sensor-based exploration process, etc.). In our 
proprietary “Piaget” environment [13], agents run in parallel, 
with very short, individually granted, time slots, lasting for 
about 100 nanoseconds each in average. Therefore, at low 
level, Piaget defines its own fine-grained time basis 
(“TicksPerSecond”); permanence quantities are estimated as 
numbers of scheduler cycles (“Ticks”), which individually 
last for about 1 microsecond in average. At higher level and 
for longer time increments (>10 ms) time is managed on the 
basis of the system clock, and is thereby compatible with the 
general culture, common to multiple robots and humans, that 
makes effective cooperation possible. 

95
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
VI. 
CONVENTIONAL AI,  COGNITION AND 
IMPLEMENTATION OF COGNITION IN THE REAL-WORLD  
(Artificial) Intelligence is but one concept in a broader 
field, which is (Artificial) cognition. 
AI has been addressed for half a century and longer 
(Turing 1950 [14]), yet no formal theory about it has been 
widely accepted today. Worse than that, experience shows 
that most people intuitively feel that, ultimately, intelligence 
is a property to be exclusively found in humans, implicitly 
thereby making AI, i.e., machine-based intelligence an 
empty set. As a stronger line of defense, the limits for this 
latter case are sometimes restricted to the frontiers of the so-
called general intelligence. 
The situation is really hard for conventional AI. Consider 
even some researchers who address explicitly the goal of 
designing intelligent machines (e.g., [15] Konidaris et al., 
2012). They state their aim at bringing together intelligence 
and machines, implicitly stating once more that machines 
have no intelligence. A better concept and wording would be 
to develop the intelligent capabilities of machines. 
In science and engineering, there have always been some 
researchers looking for integrated solutions, systemic 
answers. For this kind of people, in the case of AI in 
particular, beside the core aspects of world representation 
and 
information 
processing 
at 
a 
cognitive 
level, 
complementary aspects of autonomous implementation and 
immersion in the real world have also been part of the target. 
Some have even gone further to consider that cognition 
could only emerge from an autonomous, real-word, structure 
(e.g., discussion in [16]). 
Traditional difficulties in providing a formal theory, or 
even simply in delineating an appropriate ontology for 
cognition may in particular have come from two major facts: 
first attention has traditionally been deviated from “what is 
it?” to “how to let it operate?”; and the second is that 
connection has not been sufficiently made to the well-
defined information theory (consider e.g., [17]). 
Now as developed above, with MCS theory, reality 
appears as infinitely complex and yet for selected goals, 
much simpler models can be effective. 
VII. PIAGET  FOR IMPLEMENTING COGNITION IN THE REAL-
WORLD  
Cognition has some interest per se, nevertheless, its main 
value relates to the ability to change the world. In this 
section, four aspects of this topic will be treated: the 
necessity of implementing automated cognition in the real-
world, the strategy for ensuring the best possible design, the 
requirements for a new environment supporting development 
and control in this regard, and finally an overview of Piaget, 
which provides solutions in this context. 
A. Necessity of implementation of cognition in the real-
world 
As discussed above, implementing cognition in the real 
world is a crucial requirement for smart machines. In our 
view input information for subsequent reasoning must be 
acquired – perception. And cognitive operations are useless 
if they do not yield results, information to be somehow 
converted into world changes – action. 
Again, let us insist and remind the reader that if he/she 
dogmatically defines intelligence to be exclusively human, 
intelligent machines are obviously impossible. By this token, 
to try to merge intelligence and robots is the most that can be 
done, and do not hope for success. On the contrary, by the 
definitions we advocate above, experience shows that AI is 
not only feasible, but also in fact already largely deployed. 
So the merge has already been done, yet of course significant 
improvements are still clearly expected. 
Notice first that cognition does not only imply 
information and knowledge, but also critically requires an 
engine – step 1 into the real world. In practice we have 
cognitive systems, in particular humans, or artificial 
cognitive systems (ACS). 
And adding the perception and action capabilities to 
cognition is a second step into the real world. This already 
defines a robot; to be possibly augmented with some 
locomotion and communication capabilities. 
Moving along this road, we have searched for the best 
possible design. 
B. Strategy for the best possible design 
The goal just stated in previous paragraph calls for a very 
complex system, embedded in the real world, and in 
particular operational in real-time, capable to address the 
most advanced applications in terms of automation and 
cognitive, human-related tasks. 
To be tractable, the proposed system must be organized 
as a hierarchy of coordinated, specialized resources (e. g. 
Figure 11), contexts, and points of view, each being 
individually much simpler 
Another element of strategy is, at all levels of the 
hierarchy, starting from the very top, to rely in as much as 
possible on existing elementary solutions – subsystems. 
Here where lots of integration must be done, the first 
priority in selecting potential components, strangely, is less 
on the top functional capabilities of these elements than on 
their safe availability and operational robustness. 
Possible candidates in terms of possible components may 
be found, from case to case, on the market, in scientific and 
technological publications, or other sources yet, including 
new proprietary developments. 
C. Requirements for a new set: architecture and language 
On day one, back in 1998, like today still, the system we 
aimed at could not be found, ready-made, on the market or 
in other labs. Nevertheless, more and more powerful 
components were being developed. At the hinge between 
these two realities, the first component to appear as 
necessary for our goal has been the design of a novel set, 
architecture and language, which we have called “Piaget” in 
reference to the famous psychologist of same name, 
recognized scientist of human cognition, who had made 
major contributions especially in the context of young 
children development. It is in fact a computer-based 

96
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
environment, favorable for developing and intelligently 
controlling mobile cooperative agents and industrial robots. 
 
 
Figure 11.  Smart systems sense, perceive, think and act. The table names 
some of the underlying physical resources we have been using in Piaget 
context. 
D. Overview of Piaget 
The “Piaget” concept for architecture and language has 
evolved in two or three major stages, and is described in 
detail in Dessimoz, Gauthey and Omori 2012 [13]. For 
convenience, a few elements about this concept are also 
provided in this paragraph. 
Computers have been around for some time, as well as 
standard products in electronics, precision engineering and 
microtechnologies. 
Some of 
such 
major real-world 
components integrated in our intelligent robots with Piaget 
are shown in Figures 11 and 12. 
The cognitive components of the processes involving the 
real-world resources of Figures 11 and 12 typically relate to 
large amounts of information (>> 1 Mb), and operate at high 
speed  (up to  107 [1/s] and more).  
 
 
Figure 12.  Smart cognitive systems sense, perceive, think and act. While 
the previous figure includes general names, the current one illustrates by 
pictures the corresponding elements. Other elements not shown here 
include Kinect sensor, Katana arm, Aldebaran NAO humanoid, and Kuka / 
Stäubli industrial robots for example. 
The cognitive components of the processes involving the 
real-world resources of Figures 11 and 12 typically relate to 
large amounts of information (>> 1 Mb), and operate at high 
speed  (up to  107 [1/s] and more).  
The first crucial component that appeared to be missing 
though, was an application-oriented environment, with 
parallelism and real-time capabilities, and very open 
possibilities for integration of numerous, heterogeneous, 
products and services. 
 
Figure 13.  Example of instructions in Piaget language. 
In Piaget instructions are numbered (re. Figure 13). A 
meta-level program counter is defined for each task and is 
typically realized in the implementation, lower level 
language as a switch paradigm. A possible “AGN” suffix 
explicitly indicates, when present, that, for the next 
allocated time slot, the program proceeds at the next 
numbered Piaget instruction. 
Our applications make typically use, on the supervisory 
computer, of about 20 parallel agents. And experience 
shows that common, current computers can in average visit 
(enter, do the work, and step out) each task in a single 100 
nanosecond long time slot. 
The Piaget language includes in principle very specific, 
application-oriented instructions, such as for example the 
“ChooseTheBridgeVisually” instruction. It has been found 
useful also to integrate in it a kind of subset of the excellent 
VAL language for robotics, derived from AL [18]. This 
decision brings two main advantages: 1. VAL keeps a 
relatively general view at robotic and automation level (e.g., 
“Signal i” instruction to turn on the digital output number i), 
useful for the early phase of a new application. And 2. this 
paves the way to a common standard for novel, mobile 
agents and classical, industrial robots.  Val can be traced 
back to the beginning of industrial robotics, or even further 
to the above-mentioned AL language, and keeps evolving. 
Piaget supports direct and inverse kinematics as well as 
extensive support for transformation and frame ancillary 
computations, 
in 
matrix 
form 
and 
homogeneous 
coordinates. Motion control is typically hierarchized in three 
levels: programming, coordination and joint control, with 
elementary cycle speed respectively situated at about 500, 
15, and 0.5 milliseconds.  

97
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Now Piaget is typically running on a heterogeneous 
system including powerful components in principle 
interconnected with Ethernet and TCP-IP capabilities; due 
to lack of availability in this standard, quite a few resources 
are similarly connected in a complementary, USB mode. At 
supervisory level, a PC in Windows context is the rule, still 
for reasons of compatibility with complementary existing 
resources (e.g., Figure 14 for interactive “cockpit”). Closer 
to physical action, we can see specialized components such 
as servo-controllers, PLC, cameras, rangers; and the latter 
typically 
provide their own information 
processing 
resources, with power and robustness, in their own 
environment (re. Figure 15). 
 
 
Figure 14.  Example of main screen in interactive Piaget context, along 
with more specialized forms (map of environment and polar ranger data). 
 
 
Figure 15.  The high cognitive and action requirements of our complex 
applications in the real world require a great sophistication of structures, 
and a contingent heterogeneity of resources, communication channels, and 
protocols. 
Piaget has a number of interesting, original features, and 
some of them are the following: extensive simulation 
capabilities, easy interactive actions (interpreted language 
elements), progressive levels of programming techniques, 
and various degrees of inter-cooperation performance. 
The various levels of programming makes it very easy for 
less expert users to define new strategies, as is regularly 
required in matter of hours (and sometimes minutes!) in 
world-level competitions (for more demanding development 
work though, such as, typically, implementing Piaget on a 
new platform, OS, language, the effort is similar to usual 
software engineering). The open architecture allows quite 
effortless to reuse specialized subsystems and software 
packages. 
VIII. EXAMPLES AND PROVEN RESULTS – COGNITICS AND 
PIAGET 
This section provides 3 sets of exemplary applications 
developed and driven by Piaget, of examples in automated 
cognition, in cognitics (or AI, in classical terms, deployed in 
the real-world). The first ones reflect two of the main 
successive application areas of Piaget: Robocup@Home 
[19] [20], and industrial robotics; the last one highlights the 
ease of estimation in quantitative cognitics (re. Dessimoz 
2011 [5]) as supported in Piaget. Some prominent concepts 
of MCS are illustrated below, but of course not all of them 
can be illustrated here; they have also been validated 
though. 
A. 
Piaget and cognitics for intelligent robots in 
Robocup@Home competitions 
Piaget had concretely first been created for Eurobot 
competitions. On the other hand, industrial robotics, 
computer vision and classical AI techniques had been 
practiced in R&D initiatives, projects and ad hoc curricula 
(e.g.. Figure 16). Then those fields somehow converged in a 
project adopting the common goal of the Robocup@Home 
league. 
 
Figure 16.  Early skilled competences in Piaget environment included the 
fast visual perception of colors and recognition of objects, as well as 
coordinate transforms from picture onto field, as illustrated here, as well as, 
not shown here, the 300 times per second localization of opponent robot. 
Moving to Robocup@Home called for more complexity, 
in particular as a result of merging into less structured 
environment (home), and because of the necessity of 
cooperation, moreover in a “natural” way, with humans.  
Figure 17 illustrates vocal and dialogue management as 
typically supported in Piaget environment and language, as 
well as vision-based face recognition. At the moment the 
screen is frozen, we are between recognized sentences; a 
recognized vocal sentence could be for example “Go to 
door”. If “echo” is selected, the robot will typically confirm: 

98
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
“I have heard: go to door”, and if this is critical, the 
dialogue manager will ask for a confirmation (“is this 
correct?”). 
 
 
 
Figure 17.  On the left, Piaget panels and text-typed fields illustrate typical 
vocal dialogues: e.g., recognized commands are shown in green (here “ “) 
and synthetized text in yellow; yes/now buttons can at will simulate 
microphone inputs. On the right a face is recognized for “Who is Who” 
test. 
Advanced tests in terms of cognitive capabilities and 
human 
robot 
interaction 
capabilities 
have 
been 
demonstrated in Robocup@Home world competitions, e.g., 
“CopyCat”: programming by showing – the robot learns 
what to do; (Figure 18) and “FastFollow”: leading and 
training a robot in new homes just by walking –the robot 
learns a path, and can for example guide the human back to 
the starting point; “OpenChallenge”: in Singapore our 
robotic group included three coordinated robots, and in 
particular a humanoid for the purpose of mediation between 
human and machines (Figure 19).  
 
 
Figure 18.  On the left, RH-Y robot visually analyzes and immediately 
replicates each of the object displacements manually performed by 
President Asada. On the right, RH-Y moves fast, following its guide, 
crossing another team, and completing first the imposed visit of a home. 
 
 
Figure 19.  “Open Challenge” (Robocup@Home world competition, 
Singapore). Nono, a NAO-typed robot, discusses with “Daniel”, moves on 
OP-Y platform and then calls RH-Y, which brings drinks and snacks. 
Application developed and programmed in Piaget 
Like for Eurobot competitions, in Robocup-at-Home 
contests, results have always been reasonably good, in both 
cases reaching the 4th place in rank for the best year. Many 
videos of past competitions are available, on our server 
and/or on YouTube.  
B. 
Piaget and cognitics for intelligent robots in 
industrial applications 
Industrial applications can also been driven by Piaget. 
Figures 20 and 21 illustrate two cases, the former one 
involving a Staubli robot and the latter one a Kuka. 
 
 
Figure 20.  “Chip count and accuracy test”: Application mostly developed 
and programmed in Piaget, including the industrial robot arm visible on the 
picture and other resources: optical fiber, PLC, camera, motorized rotating 
table, servocontroller, Ethernet switch, PC and other components yet. 
In both cases, the robot arms are driven, at elementary, 
lowest level, by manufacturers’ controllers (incl. KRL for 
Kuka; Val3 for Stäubli) and, at higher levels, by a program 
developed in Piaget environment and expressed in Piaget 
language. 
 
 
Figure 21.  Three windows relating to an industrial application involving a 
Kuka robot (The first two belong to Piaget environment; the third one is a 
remote desktop linked to Kuka controller). 
Piaget supports fast and robust vision, in many modes 
(infrared/BW, color, thermal, 3D-time of flight sensors; 
various processes).  
C. 
Integrated capabilities in Piaget for quantitative 
estimation of cognitive properties 
A particular interest of Piaget environment is to provide a 
tool for convenient, quantitative estimation of core cognitive 
properties: knowledge, expertise, experience, speed/fluency, 
intelligence, as well as low-level ingredients: probability 

99
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
calculus, quantization, sampling rate, input and output 
information signals and quantities, all this along with an 
interactive example (Figure 22). 
 
Figure 22.  Piaget environment includes a form for the quantitative 
estimation of cognitive properties in general, along with a specific 
example: learning how to accurately click in the center of 4 targets. 
IX. COGNITION AND PHILOSOPHY 
Cognition was given ontology above, including notably 
definitions for time, reality and wisdom. This overlaps to a 
large extent with domains of interest in classical philosophy 
though. 
Nevertheless, 
each 
fields 
retains 
important 
distinctive properties. This section suggests that a cross 
feeding of results achieved in the respective fields mutually 
helps and it shows some concrete examples in this regard.  
Philosophy literally means "love of wisdom" and was 
used in Ancient Greek to refer to any pursuit of knowledge 
[21-24]. In that era, the field was very broad, including not 
only core cognitive elements, such as formal logic and 
syllogisms but also domains considered today on their own, 
such as physics, sciences and politics. In fact even today 
philosophy keeps the universal view, and in this sense keeps 
including the latter domains, though in their most abstract 
forms only.  
On the other side advances in tools and techniques have 
progressively led to automation and, more recently, out of 
necessity, to a formal and quantitative theory of cognition. In 
this evolution, the scientific approach has led to epistemic 
observation and a theory including axiomatic definitions of 
core concepts and the proposal of related metrics [5] [25-27]. 
Cognition is essentially the faculty to deliver correct 
information, ensured by specific internal structures and 
operative flows, typically processing information rationally, 
with high performance levels, for example in terms of 
complexity, knowledge, abstraction, learning, or expertise. 
While historically rather exclusively considered in human 
context, cognition is also, today, and increasingly, 
concerning man-made artifacts (re. artificial cognition, 
traditionally commonly described as AI).  
In philosophy, cognition is central, and yet as the 
etymology of the former word can doubly prove it, 
philosophy is much more than that. Interestingly, Thomas 
Aquinas has formally distinguished behavior in two main 
categories. While indeed the cognitive category is one of 
them, there is also a decisive other one, which encompasses 
the affective components, feelings and emotions [28]. 
Precisely with the notions of « love » and « wisdom », 
philosophy strongly refers to non-cognitive components: the 
former case is evident, love is a feeling; the latter case 
requires more explanations. Wisdom is a specific property of 
cognitive agents, referring to their ability to take good 
decisions (to be expert in delivering the messages that make 
agents reach a given goal); here at least two problems remain 
out of cognitive reach: which goal is appropriate? And are 
the required non-cognitive components, necessary to reach 
the goal, also ready for action (e.g., availability of energy, 
affects, physical elements or social partnerships)?  
In consequence, philosophy is necessary for addressing 
problems at both ends of the reasoning chain, typical of 
cognitive processes: 1. the intuitive, experimental process 
extracting initial, axiomatic data and model features from 
reality; 2. the selection of relevant goals (re. ethics and, 
ultimately for humans, the choice of individual roles in 
universe).  
Reciprocally, as is shown below in five points, the formal 
framework initially developed for advances in machine-
based cognition, with means for quantitative assessments, 
suggests that other distinctions can be beneficial and allow 
for a novel clarity of many philosophical issues.  
Rational, cognitive processes, for humans as for 
machines, can only develop in formal, well-defined 
structures that finally remain necessarily extremely simple 
with respect to reality; they develop in the scope of ad hoc 
models. Figure 5 above has qualitatively illustrated the fact 
that the simplicity of models has a huge cost: a similarly 
extreme restriction in terms of respective goals that any 
model can help to reach. The mentioned framework for 
cognitive sciences quantitatively defines complexity (and in 
an analog way, simplicity) as a direct function of the quantity 
of information (for which quantitative assessment is well-
founded). Everyone knows that models are never complete 
with respect to reality, but going quantitative shows that the 
ratio in their complexities with respect to reality tends to zero 
(“zero–plus”?). This has tremendous consequences in 
philosophy: in particular what debate with respect to truth 
can be meaningful? How not to underestimate the 
importance of goal setting? The fact is that faith cannot, 
ultimately, be the defense of any truth, but in priority should 
represent adherence to a certain freely chosen goal.  
Research in cognition has brought other, new results in 
terms of system granularity and group nature. A similar 
scheme can repeatedly be observed at very different scales, 
whereby apparently “individual”, autonomous systems can 
appropriately be merged thereby yielding the emergence of a 
new holonic entity (a “group”), or on the contrary those same 
structures can be observed as coherent, collective entities 
(i.e., as ”groups” as well), and consequently be analyzed in 
finer cooperating substructures. In particular, from a 
cognitive perspective, much of the paradigm is similar 1. as 
neural networks cooperate at brain/body level (re. 
“thinking”), and 2. as individual agents cooperate at a 
collective, higher level, yielding a group behavior (re. 
“society”).  
Experience shows that the effective, integral capability of 
groups is not always guaranteed, at any level, and the 
challenge gets more serious when, as is most of the time the 
case, a same resource may simultaneously be part of multiple 
groups, of different “cultures” and boundaries. Consider for 
example the risk of schizophrenia and possibilities of 

100
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
membership conflicts for a human involved in several allied 
families, an employing company, various friendship circles, 
one 
or 
multiple 
religious 
entities, 
political 
parties 
cooperating in broader, secular frameworks, spaceship Earth, 
etc. 
A particular advantage of automated cognition is that it 
allows theory in cognition to be operationalized. Coherence 
between a theory and the corresponding praxis has probably 
never been so close to guarantee. The very equations and 
structures that describe a cognitive phenomenon can now be 
computed in real-time and used to guide actions accordingly 
in the real world, as embedded computers and cooperating 
robots start routinely to do so.  
Research in automated cognition has brought further, 
crucial results in terms of system dynamics. Careful, 
quantitative estimations and specific structural aspects can 
for example detect instability conditions and may call for 
changes in organization, such as granting autonomy to 
selected subsystems. Consequences can be drawn with 
benefits in the context of social philosophy. Reciprocally, it 
is also true that classical models in philosophy can help 
design novel automated systems featuring machine cognition 
(including AI).  
X. CONCLUSION 
Designing 
advanced 
cognitive 
technologies 
and 
applications requires a formal ontology, such as the MCS 
Model for Cognitive Sciences, the theoretical foundations 
now proposed for automated cognition, cognitics. Cognition 
has the ability to create and deliver pertinent information, 
both for the case when it is embedded in humans, and also 
for the case when it is machine-based, automated (re. 
« cognitics » in this latter case). 
Starting in a pragmatic way from where we stand, in 
particular with humans creating robots, progressing with 
distributed axioms, navigating through small contexts in 
direction of selected goals (the design of high performance 
machines, of robots cooperating with humans, and a better 
understanding of cognition in humans), we adopt a 
constructivist approach in conceptual framework and 
validate them gradually by making them operational in test 
tasks. 
 Past works had taken for granted that reality and time 
were notions evident for everyone. Now, at the moment of 
attempting a practical implementation of those notions in 
robots, the situation is quite different. Early results in the 
context of MCS theory had made it clear that reality is 
infinitely complex, practically out of reach for cognition, 
under condition of exhaustivity. 
Discussion has been made above of a number of 
cognitive notions including those of reality, time and 
revisited “speed”, change and discontinuity, innate and 
learned behaviors, as well as the human-inspired basics of 
communication in a group. These newly defined notions 
conveniently complement the existing MCS ontology. 
Notions are delineated in conceptual frameworks and can 
moreover be made operational, deployed in the real world, 
for validation purpose and for the benefit of users. All these 
elements confirm the rightness of our current approaches in 
solving concrete Artificial Intelligence problems and this is 
illustrated below by some concrete examples taken in 
domestic context, including robots capable of learning. 
Further research has been performed and the current 
paper could sketch ways to cope with the infinite complexity 
of reality. Several other cognitive notions could also be 
newly discussed, including those of time and revisited 
“speed”; change and discontinuity; innate and learned 
behaviors; as well as the human-inspired basics of 
communication in a group. On the basis of the proposed 
MCS ontology, and taking often advantage of innate/wired 
expertise, it can be concluded that robots can be effectively 
deployed in quantitatively bound domains, as illustrated in 
several concrete examples. 
Cognition would not make much sense per se, and the 
paper has also shown how it can be implemented in the real 
world, notably using Piaget, our proprietary environment for 
development and programming of smart robotized systems. 
Experiments prove that the resulting smart systems can 
indeed successfully operate in the real-world, and in 
particular interact with humans, performing with large 
quantities of cognitive components: knowledge, expertise, 
learning, etc.  
The 
quantitative 
approach 
of 
MCS 
and 
the 
operationalization of its cognitive concepts in real-world 
systems allow as well for an effective design and realization 
of smart systems for the benefit of humans as a fruitful 
dialogue about core issues in philosophy. 
ACKNOWLEDGMENTS 
The authors acknowledge the contributions of numerous 
engineers, interns and students, as well as the support of 
various research funds, private companies and technical 
services in our university HEIG-VD, who have more or less 
directly contributed to the reported project. In particular, this 
year, Neenarut "Nann" Ratchatanantakit, and Panuwat “Jarr” 
Janwattanapong can be mentioned. 
REFERENCES 
[1] Jean-Daniel Dessimoz, Pierre-François Gauthey, and Hayato 
Omori, "Some New Concepts in MCS Ontology for 
Cognitics; Permanence, Change, Speed, Discontinuity, Innate 
versus Learned Behavior, and More", Cognitive-12, The 4th 
International 
Conference 
on 
Advanced 
Cognitive 
Technologies and Applic., Nice, France, July 22-27, 2012. 
[2] Shannon, C. E. , A mathematical theory of communication. in: 
Bell System Technical Journal, Vol. 27, 1948, pp.379-423, 
623-656. 
[3] Bernard Claverie, “Cognitique - Science et pratique des 
relations à la machine à penser”, Editions L'Harmattan, 2005, 
pp. 141. 
[4] Jean-Daniel Dessimoz, "Cognition Dynamics; Time and 
Change 
Aspects 
in 
Quantitative 
Cognitics", 
Second 
International Conference on Intelligent Robotics and 
Applications. Singapore, 16 - 18 December, 2009; also in 
Springer Lecture Notes in Computer Science, ISBN 978-3-
642-10816-7, pp. 976-993. 
[5] Jean-Daniel Dessimoz, "Cognitics - Definitions and metrics 
for cognitive sciences and thinking machines", Roboptics 
Editions, Cheseaux-Noréaz, Switzerland, ISBN 978-2-
9700629-1-2, 
pp. 
169, 
January 
2011, 
also, 
http://cognitics.populus.ch. 

101
International Journal on Advances in Intelligent Systems, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[6] Wisspeintner, T., T. van der Zant, L. Iocchi, and S. Schiffer, 
"RoboCup@Home: 
Scientific 
Competition 
and 
Benchmarking for Domestic Service Robots", Interaction 
Studies, vol. 10, issue Special Issue: Robots in the Wild, no. 
3: John Benjamin Publishing, pp. 392--426, 2009. 
[7] Frederick Charles Copleston, “A history of philosophy”, 
Volume 6, Continuum International Publishing Group Ltd.; 
Édition : New edition, June 5, 2003, pp. 528. 
[8] Alexander 
Rosenberg, 
“Philosophy 
of 
science: 
a 
contemporary 
introduction”, 
Routledge 
comtemporary 
introductions to philosophy, 2005 
[9] George E. Hein, “Constructivist Learning Theory”, The 
Museum and the Needs of People CECA (International 
Committee of Museum Educators) Conference, Jerusalem 
Israel, 15-22 October, Lesley College. Massach., USA, 1991. 
[10] Hart, P. E.; Nilsson, N. J.; and Raphael, B., "A Formal Basis 
for the Heuristic Determination of Minimum Cost Paths", 
IEEE Transactions on Systems Science and Cybernetics SSC4 
4 (2), pp. 100–107, 1968. 
[11] Julie A. Jacko (Ed.), “Human-Computer Interaction. Novel 
Interaction Methods and Techniques” 13th Internat. Conf., 
HCI Internat. 2009, Proc. Part II, San Diego, CA, USA, 
Springer. 
[12] http://rahe.populus.ch/rub/4 , last downloaded on June 3rd, 
2012. 
[13] Jean-Daniel Dessimoz, Pierre-François Gauthey, and Hayato 
Omori, "Piaget Environment for the Development and 
Intelligent Control of Mobile, Cooperative Agents and 
Industrial Robots", accepted for publication, ISR 2012, 
International Symposium for Robotics, Internat. Federation of 
Robotics, Taipei, Taiwan, Aug.27-30, 2012. 
[14] Turing,  A. M. “Computing Machinery and Intelligence”, in: 
Mind, New Series, Vol. 59, No. 236, 1950, pp. 433-460. 
[15] Konidaris, George,  Byron Boots, Stephen Hart, Todd Hester, 
Sarah Osentoski, and David Wingate, Org., Designing 
Intelligent 
Robots: 
Reintegrating 
AI, 
AAAI 
Spring 
Symposium 2012, March 26th-28th, Stanford University 
[16] D. Vernon, G. Metta, and G. Sandini. A survey of artificial 
cognitive 
systems: 
Implications 
for 
the 
autonomous 
development of mental cap- abilities in computational agents. 
IEEE Transaction on Evolutionary Computation, 11(2):151–
180, 2007.  
[17] Z. W. Pylyshyn. Computation and Cognition (2nd edition). 
Bradford Books, MIT Press, Cambridge, MA, 1984.  
[18] Goldman, R. “Recent work with the AL system”. 
Proceedings: 
Fifth 
Annual 
Conference 
on 
Artificial 
Intelligence. M.I.T., 1977.  
[19] Kitano, H., M Asada, Y Kuniyoshi, I Noda, and E. Osawa, 
“Robocup: The robot world cup initiative”, AGENTS '97 
Proceedings of the first international conference on 
Autonomous agents, ACM New York, NY, USA ©1997 
[20] van der Zant, T.  and Thomas Wisspeintner,  « 
RoboCup@Home: Creating and Benchmarking », Tomorrows 
Service Robot Applications , Robotic Soccer, Book edited 
by:Pedro Lima, ISBN978-3-902613-21-9, Itech Educationand 
Publishing, Vienna, Austria, pp.598, December 2007 
[21] Philosophy 
- 
Wikipedia, 
the 
free 
encyclopedia, 
http://en.wikipedia.org/wiki/Philosophy,Retrieved2011-08-06. 
[22] "Philosophia, Henry George Liddell, Robert Scott, ''A Greek-
English 
Lexicon'', 
at 
Perseus" 
(http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Ate
xt%3A1999.04.0057%3Aentry%3D%23111487&redirect=tru
e). Retrieved 15.05.2013.  
[23] "Online 
Etymology 
Dictionary". 
Etymonline.com. 
http://www.etymonline.com/index.php?search=philosophy& 
searchmode=none. Retrieved 15.05.2013.  
[24] The deﬁnition of philosophy is: "1.orig., love of, or the search 
for, wisdom or knowledge 2.theory or logical analysis of the 
principles underlying conduct, thought, knowledge, and the 
nature of the universe". Webster's NewWorld Dictionary 
(Second College ed.). Retrieved 15.05.2013. 
[25] John McCarthy, What is Artificial Intelligence?,  rev. 12 Nov. 
2007, 
http://www-
formal.stanford.edu/jmc/whatisai/whatisai.html , Retrieved 15 
May (2013). 
[26] T. Fong, I. Nourbakhsh, and Kerstin Dautenhahn, “A survey 
of socially interactive robots”, Robotics and autonomous 
systems, 2003, Elsevier 
[27] John Child “Organizational structure, environment and 
performance: the role of strategic choice”, Sociology, 1972  
[28] Cognition 
- 
Wikipedia, 
the 
free 
encyclopedia, 
http://en.wikipedia.org/wiki/Cognition, Retrieved 15.05.2013. 
 

