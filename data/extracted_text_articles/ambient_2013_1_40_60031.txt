Ambient Storytelling Experiences and Applications for Interactive Architecture
Jennifer Stein and Scott Fisher
School of Cinematic Arts
University of Southern California 
Los Angeles, Californa 
email: steinjen@usc.edu, sfisher@cinema.usc.edu
Abstract—This paper explores ongoing research into ambient 
storytelling experiences and applications for the built 
environment and presents a design prototype for Place-based, 
Ubiquitous, Connected, and Kinetic (PUCK) interactive 
architecture.  Through the use of ubiquitous technologies, it is 
our goal to enhance environmental awareness, augment 
presence in the physical environment, and enable participation 
through ambient interfaces. 
 This research specifically 
investigates ambient storytelling through responsive 
environments, and explores how buildings can act as animate 
storytelling entities that engage and interact with their 
inhabitants. 
Keywords- Ambient Storytelling; Environmental Media; 
Interactive Architecture; Lifelogging
I.     INTRODUCTION 
  
As ubiquitous computing research had predicted in the 
early 1990’s [1], embedded computing technologies and 
mobile devices have become part of our environment [2], 
making it possible to widely connect people to the world 
around them. 
 However, whereas earlier ubiquitous 
computing research focused on making these systems 
invisible and utilitarian, less has been said about the 
possibilities for weaving evocative and ambient interfaces 
for storytelling and narrative into our everyday experiences. 
This project specifically addressees new types of 
personalized, location- and context-specific interactive 
architectural experiences that emerge through the use of 
real-time environmental sensor and human data in 
conversation with one another over the lifetime of a 
building.  This paper explores a design prototype entitled 
Place-based, Ubiquitous, Connected and Kinetic (PUCK) 
Experiences for Interactive Architecture.
Our current research projects and design prototypes focus 
on interactive architecture within the context of 
environmental media to enhance environmental awareness, 
augment presence in the physical environment, and enable 
participation in new ways of placemaking.  Furthermore, this 
research investigates the idea of ambient storytelling [3], or 
how the built environment can act as a storytelling entity that 
engages and interacts with people in ambient and evocative 
ways. Within the PUCK application, development of 
personalized responsive and interactive environments arise 
as people spend time in and build a relationship with the 
spaces they inhabit habitually through a series of ongoing 
conversations between inhabitants and physical space.
With this in mind, PUCK reconsiders earlier notions of 
genius loci, specifically with regard to distinctions between 
space and place, and how the spirit of place was thought to 
take on a distinct character. As noted by Christian Norberg-
Schulz [4], “...ancient man experienced his environment as 
consisting of definite character.  In particular he recognized 
that it is of great importance to come to terms with the 
genius of the locality where his life takes place. In the past, 
survival depended on having a ‘good’ relationship to the 
place in a physical as well as a psychic sense.”  This focus 
on spaces having character and the importance of having a 
good relationship with places is an important underlying 
concept for exploring ambient storytelling and how building 
inhabitants can have meaningful, ongoing relationships with 
their buildings.  Therefore, by integrating context-aware 
interactions with a building lifelog [5, 6] and access to 
backstory about an environment, ambient stories and 
characters emerge and present themselves through mobile 
and pervasive computing technologies, applications, and 
public displays. 
This paper is organized as follows: in Section II, we 
discuss our overarching research approach to ambient 
storytelling and interactive architecture through the historical 
lens of lifelogging.  In Section III, we describe the design 
prototype we designed for a newly built campus building. 
Section IV introduces the technical developments 
implemented in the PUCK prototype and the paper is 
concluded in Section V.   
II.     APPROACH
Our approach focuses on the social and participatory 
elements of both ambient storytelling and interactive 
architecture.  The research project described below uses a 
campus building as both a character and the setting for 
collaborative, context-specific storytelling in which the 
building inhabitants become an integral part of the story 
world.  By inviting inhabitants to engage with both the 
building and their fellow inhabitants, we have introduced a 
new paradigm for place making within a playful, 
personalized, and interactive environment. 
Research into lifelogging and backstory further provides 
a groundwork for thinking about new forms of storytelling. 
This has guided our research into how these stories could be 
customized and delivered in specific contexts and locations 
throughout the day, which we have termed Ambient 
Storytelling.  This term is used to describe the context-
specific and location-specific stories that emerge over time 
and immerse inhabitants in a story world through daily 
interactions with a building or architectural space. This form 
of storytelling within the built environment is enhanced 
through mutual participation and collaboration between 
inhabitants and the building as they begin to learn from and 
23
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-309-4
AMBIENT 2013 : The Third International Conference on Ambient Computing, Applications, Services and Technologies

interact with one another over time.  The development of a 
personalized responsive environment therefore evolves 
within the context of one’s surroundings, creating a deeper 
connection and sense of presence within a specific location.
The practice of lifelogging, or documenting and 
broadcasting one’s daily activities with wearable computing 
devices, has been a recurrent topic of our research. 
 
However, instead of people documenting their activities, 
we are focusing on designing lifelogs for the built 
environment.  The notion of the lifelog has traditionally 
been tied to the idea of memory prosthesis for a single 
human participant or user.  This coupling of the lifelog 
concept with a human participant has deep historical roots. 
In describing the MyLifeBits project, Jim Gemmell & 
Gordon Bell et al. [6, 7, 10] point consistently to Vannevar 
Bush’s Memex system [8] as inspiration, and in particular 
they draw attention to the Memex as an indexing and 
recording system designed to augment a researcher’s mental 
and physical experience.  The centrality of a human user 
further embedded in Bush’s description of an interconnected 
web of human knowledge (presaging the internet) that 
enables humans to share and navigate vast stores of 
information.  But, while the imagined protagonist of Bush’s 
tale is a human participant, our current media environment 
suggests a significant shift towards the recognition of non-
human participants as authors and readers of sensor data in 
an emerging Internet of Things.  
 
In more recent years, research focus has expanded 
beyond Bush’s original emphasis on knowledge retrieval to 
subsume more experiential memory augmentation through 
video capture.  However, this work largely retains the 
original assumption of an individual human participant. In 
the 1980s, Steve Mann began experimenting with streaming 
video and started recording his life using the Wearable 
Wireless Webcam in 1994 [11, 12]. 
 Similarly, Bell 
integrated the SenseCam video recording system [12] into 
the MyLifeBits software. In both of these projects, the 
perspective of the video camera is aligned with that of a
human participant observing their environment through a 
camera mounted to the chest or eye (a perspective that 
Mann has described as sousveillance [11]).  However, recent 
research points to new perspectival orientations for 
lifelogging by using objects in the environment to capture
video.  For example, Lee et al. designed a lifelog system 
that captures images and other data from the perspective of 
objects (in proximity to humans) [10]. Nevertheless, 
previous research has yet to address interest in the 
possibility that objects and environments might themselves 
be positioned as the subjects of lifelogging.    
Lifelogs for physical spaces therefore combines various 
building, environmental and human sensor data sets, as well 
as collaboratively-authored character development, to create 
an ongoing presence of a story.  Through the integration of 
these various sensors and collaborative character 
development, the building itself offers a daily snapshot of 
both infrastructural behaviors, but also the behavior of the 
inhabitants of a building (movement through space, interests 
in context-specific information, time spent in the building). 
These elements, when combined, create the groundwork for 
ambient and persistent storytelling based on contextually 
relevant information collected and authored throughout the 
day.
For the purpose of our research, ambient storytelling 
takes place through the use of lifelogs, sensor networks and 
mobile devices within the built environment. By thinking 
more deeply about context and location specificity, we have 
experimented with what a lifelog for an architectural space 
might be and what backstories the objects within might 
contain, i.e., what a building would lifelog about, how it 
would communicate this lifelog to its inhabitants or to other 
buildings, what kinds of backstories the objects tell, and the 
stories that might emerge from this buildings’ lifelog and 
backstories. 
Finally, this model for ambient storytelling provides a 
platform for making sensor and environmental data more 
evocative and playful within the actual context of physical 
space and inhabitant activity.  However, this engagement 
happens without explicitly revealing the data through a 
traditionally transparent information visualization model. 
Rather than simply visualizing the data that is produced and 
captured throughout the day, this information becomes a part 
of the story through ongoing conversations between a 
building and its inhabitants in which both learn from one 
another, further engaging an inhabitant in an ambient 
narrative experience. 
 To demonstrate how ambient 
storytelling works within the built environment, we have 
developed a design prototype for PUCK: Place-based, 
Ubiquitous, Connected, and Kinetic Experiences for 
Interactive Architecture.
III.     PUCK DESIGN PROTOTYPE
A.
Overview
PUCK explores the new conditions for interacting with 
architectural spaces and the kinds of evocative experiences 
and interfaces that emerge from these interactions. 
Ubiquitous and embedded technologies introduce scenarios 
in which objects, buildings and people produce an infinite 
amount of data and information, and are in constant 
communication with the Internet and with each other. 
Buildings have become dynamic, conversant entities that 
communicate directly with their inhabitants, objects, and 
other buildings through mobile devices, public displays, and 
ambient interfaces.
 
PUCK has been implemented within the School of 
Cinematic Arts Building (SCA) at USC as a test bed to 
explore the possibilities for new kinds of ambient 
characters, storytelling, and experiences of place to emerge 
within interactive environments. The SCA Building was 
chosen due to its new, state-of-the-art Building Information 
Modeling (BIM) and Building Management Systems 
(BMS), networks, and its unique context within the 
longstanding tradition of innovative storytelling at the 
School of Cinematic Arts. The SCA testbed contains over 
4000 embedded sensors within its Building Management 
System, 60 WiFi access points, networked public displays, 
touch screens, near field communication nodes and 
approximately 2000 regular inhabitants populating it.  For 
this case study, several design prototypes were implemented 
specifically for the SCA building.  The following offers a 
24
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-309-4
AMBIENT 2013 : The Third International Conference on Ambient Computing, Applications, Services and Technologies

description of how PUCK engages its inhabitants through 
mobile and ambient interfaces by describing how 
interactions progressively reveal themselves to building 
inhabitants through a mobile smartphone interface and 
various distributed environmental displays.  
B.
PUCK Mobile Application
 
The PUCK mobile application (see Figure 1) provides a 
platform for building inhabitants to connect to all PUCK-
enabled buildings, and for buildings to connect to individual 
inhabitants.  After downloading the PUCK application to a 
mobile device, the user will be detected by the specific 
building she enters based on location sensors, GPS 
coordinates, or near-field communication technologies. 
Once a PUCK building has sensed a user and her mobile 
device’s presence, the building will invite the inhabitant to 
add that specific building location to her application for 
further engagement and profile development. After an 
inhabitant has joined a building, she will receive 
notifications and prompts for action from a specific 
building, and will begin to develop an ongoing relationship 
with each individual building.
 
PUCK experiences are context- and location-specific, 
therefore, inhabitants can only access information about 
their relationship with a specific building when they are 
physically located in that building.  After an inhabitant adds 
a specific building to her PUCK app, that building will 
recognize her every time she enters. This recognition plays 
an important part in the profile and relationship 
development for each specific inhabitant and building, and 
will impact how each building engages with its inhabitants.
 
When an inhabitant is detected by a specific building, 
that inhabitant is able to access information specific to the 
systems, networks, and experiences for the building she is 
in. Different aspects of each building will slowly reveal 
themselves to inhabitants as they spend more time in a 
building, providing a record of personal experiences with a 
building, as well as character traits for each unique building.
C.
Environmental Interfaces
 
A PUCK building displays dynamic information about 
itself, as well as personalized information about its 
inhabitants based on various data points throughout the day. 
Visualizing the data produced by the systems embedded 
within buildings provides a new kind of narrative platform 
for telling stories about each building.  This is the first point 
at which the character of each building is able to reveal 
itself, using its building system data within the context of 
specific physical space to communicate stories to its 
inhabitants. These stories emerge from fluctuations in data, 
often driven by changes in inhabitant behavior or system 
failures, and begin to make transparent the correlations 
between space, time and human impact throughout the day. 
However, the building data visualizations are not meant to 
be fully transparent to inhabitants, but rather draw them in 
to a rabbit hole of building data and systems through a 
somewhat mysterious public interface.
 
Therefore, to introduce inhabitants to all of their data-
generating systems and sensors embedded within the walls, 
floors, and ceilings, PUCK buildings make themselves 
transparent through evocative data representations, 
revealing their inner complex systems and networks as 
dynamic stories of the life of the building. By drawing 
inhabitants into the data, PUCK buildings begin a 
conversation with their inhabitants about how a building 
responds to its inhabitants, presenting an image of how 
much energy and water is being consumed, fluctuations in 
temperature and carbon dioxide levels, wireless network 
activity throughout the building, and how inhabitants impact 
both the digital and physical landscape of buildings through 
their use of buildings. This point of entry into a deeper 
understanding of how inhabitants use buildings and how 
you as an inhabitant directly contribute to changes in these 
systems begins to reveals itself in a data visualization. 
Furthermore, each building uses Twitter to communicate 
real-time sensor data, network activity and the presence of 
specific inhabitants while providing context to each 
visualization.
 
Data Visualization and Twitter:  Data generated by each 
building is presented to inhabitants in real time through a 
dynamic data visualization (see Figure 2). This data 
visualization provides a glimpse into daily building activity 
and is viewable on various displays within the common 
Figure 1:                    Puck mobile phone interface
25
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-309-4
AMBIENT 2013 : The Third International Conference on Ambient Computing, Applications, Services and Technologies

areas of buildings, as well as through the PUCK mobile 
application. This data visualization acts as the point of entry 
for inhabitants to engage with the building in a more 
meaningful way, revealing the life of the building that exists 
behind the walls, through its networks, and within the 
digital layer of the building.  As inhabitants become aware 
of this secret life, they are invited to engage more deeply 
through personal interactions and conversations with the 
building.
 
To help inhabitants understand the various data points 
being used to generate the real-time data visualization, 
PUCK buildings use Twitter to tweet and display 
information about specific sensor readings, WiFi usage, and 
number of inhabitants in the building. Furthermore, 
inhabitants can follow each of their PUCK buildings on 
Twitter, contribute to a building’s Twitter stream by sending 
messages as specific PUCK buildings, or by re-tweeting 
building information. Twitter also provides a social platform 
for buildings to reach out to their inhabitants and ask them 
to directly contribute information and media by engaging 
inhabitants in missions and other activities.
 
Personal Engagement with Buildings:  After inhabitants 
are introduced to the kinds of stories the building tells 
through its data visualization and Twitter, the building will 
begin to directly engage specific inhabitants through visual 
and sonic interactions within the common spaces of the 
Figure 2.        Public Data Visualizaion of Building  Sensor Data
building (see Figures 3 and 4).  By using the data a building 
is able to capture about an inhabitant through their mobile 
device, such as their presence in the building, the parts of 
the building they use most often, and the time of day they 
inhabit the building, a profile is developed by the building 
for each inhabitant. This is the first step towards the 
building becoming aware of and attentive towards its 
inhabitants.
  
PUCK generates a graphic identifier, or identicon, for 
each inhabitant based on a number of variables it learns 
about its inhabitants.  This personal data identicon is an 
integral part of the relationship development process and is 
PUCK’s way of showing an inhabitant that it knows she is 
present, that it recognizes the personal information shared 
with it, and that it wishes to engage an inhabitant directly. 
The parameters a PUCK building uses to generate a 
personal identicon is based on the context of each building, 
but includes data such as days per week a inhabitant has 
spent in a specific building, hours per day, or a tally of 
direct interactions an inhabitant has engaged in with a 
building, and the locations of the building most frequented.
 
These identicons are revealed to each inhabitant in 
various ways within PUCK buildings, appearing on public 
screens throughout each building, as well as within the 
PUCK mobile application. Inhabitants receive a new 
identicon each week, and are able to review all past 
identicons on their mobile device. This provides an 
overview of how one’s relationship with each building is 
progressing, and also highlights milestones reached within 
an inhabitant’s profile and relationship development with 
each building. Furthermore, these identicons develop 
different behaviors over time, based on how one’s 
relationship develops, current data, and network conditions 
within the building.
D.     Data Sculpture
 
To communicate the significance of the process of 
relationship development, PUCK uses what it has collected 
about itself and its individual inhabitants to create a data 
sculpture to show its appreciation (see Figure 5).  PUCK 
generates this data sculpture as a physical representation of 
digital information to show inhabitants what it has learned 
 
Figure 3.                            The building personally engages 
                              inhabitants through personalized data Identicons
Figure 4.                    Personal Data Identicon 
26
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-309-4
AMBIENT 2013 : The Third International Conference on Ambient Computing, Applications, Services and Technologies

about them, what they have learned about PUCK through 
their interactions, and how the two have worked together to 
establish a sense of place within SCA. This data sculpture is 
printed by PUCK into a tangible 3D object for an inhabitant 
after a number of milestones have been reached between the 
building and the inhabitant. Inhabitants are then lead to their 
personal data sculpture by following their identicon to a 
collection point within the building.
 
The personal data sculpture is generated using specific 
datasets and parameters to design an object that will always 
be unique to a specific inhabitant. These parameters are 
drawn from the data discussed above, including the overall 
building sensor data collected over a specified amount of 
time, each of the inhabitant’s personal data sets, i.e., days of 
week spent in the building, number of hours each day, and 
milestones reached in their relationship development. The 
result is a generative model that is then printed using a 3D 
printer.
IV.
    TECHNICAL IMPLEMENTATION
 
PUCK has been designed with a combination of off-the-
shelf technologies, custom hardware and software, and 
open-source applications. 
 Much of the off-the-shelf 
technology was creatively reappropriated to meet the needs 
of PUCK.  The result is a unique set of technologies and 
interactive systems that has provided a preliminary 
framework for ongoing research into data collection and 
more robust indoor location tracking through wireless 
access point triangulation.
A.  Data Collection and Visualization 
 
The data visualization is driven by real-time sensor data 
collected by the Building Management System (BMS), data 
tunneling OPC software, MySQL Database, Google App 
Engine (GAE), Python web services, and Processing.js.  
 
To access building sensor data, the BMS data, i.e., 
temperature, CO₂, energy use, is tunneled from a facilities 
  
Figure 5.                       Personal Data Sculpture
server and logged in a MySQL database on the virtual 
server.  This allows us to format the data most usable for our 
purposes.  Our virtual server then posts data from MySQL 
to the GAE data store through a web service interface.  A 
Python web service was created to make a call to the data 
store to get a snapshot of the last update was from the 
MySQL database.  This data is then reformatted into a 
Comma Separated Value (CSV) file, which was used to 
dynamically update the data visualization.
 
The Data Visualization is written using Processing.js 
visual programming language to be easily displayed on the 
web.  This program looks for the updated CSV data from the 
Python web service, and updates with new data every 6 
minutes as new data was generated, making the 
visualization dynamic through near real-time data.  The 
CSV data is also archived so that a snapshot of 24 hours 
worth of data is viewable as data is generated and the 
visualization grows.  Furthermore, the building Twitter feed 
was displayed along side the visualization, which would use 
the building sensor data being generated to send Twitter 
messages with sensor locations and current readings.
B.  Indoor Location Tracking and User Engagement
 
A number of options for passively tracking inhabitants 
were explored during the development of PUCK.  Global 
Positioning System (GPS) technology was initially tested 
but was ruled out early due to lack of signal within the 
building, and also could not provide the level of data 
granularity for each inhabitant. 
 Radio Frequency 
Identification (RFID) and other near field communication 
(NFC) technologies were explored but did not provide the 
passive collection of data.  
 
In order to passively collect data that would be linked to 
each specific inhabitant, we looked for a technology that 
could be directly connected to a mobile phone so that data 
could be transmitted to a server and be linked to an 
inhabitant’s device identification.  We, therefore, explored 
the ANT+ protocol [13] for wireless sensor networks.  The 
ANT+ protocol is most widely used in Heart Rate Monitors 
(HRM) and speed sensors for fitness monitoring and 
tracking.  This protocol allowed us to use and modify off-
the-shelf sensors and devices to accomplish the desired level 
of data collection related to a specific inhabitant, but also 
limited our options to using only the mobile phone for 
personal data collection in this iteration.  
 
To determine an inhabitant’s location using the ANT + 
wireless sensor network protocol, we designed location 
nodes that were distributed throughout the building.  These 
nodes consisted of heart rate monitors connected to Arduino 
Mini microcontrollers and potentiometers, and were a 
creative hack that was necessitated by a technical hurdle. 
We discovered through the design process that heart rate 
monitors only transmit a signal after they have detected a 
user’s heartbeat.  Because we were not using the heart rate 
monitors for their intended purpose, which is to detect and 
monitor a human heartbeat, the heart rate monitors needed 
to be modified.  We require the HRM’s to constantly send 
27
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-309-4
AMBIENT 2013 : The Third International Conference on Ambient Computing, Applications, Services and Technologies

out a radio signal that could be detected by the ANT+ sensor 
plugged into the mobile phone.  To do this, the HRM’s are 
connected to the Arduino Mini and a potentiometer to 
regulate the signal at a constant output.  Each location node 
is assigned an ID number that corresponded to a location in 
the building.  When the mobile phone sensor detects a signal 
from a location node, that location ID information is pushed 
to Google App Engine and we can then determine where in 
the building an inhabitant currently is.
 
The mobile application was developed to detect the 
specific building in which it is launched.  The current 
application detects a specific radius around the GPS 
coordinates for the campus building.  When the app is 
launched within those coordinates, it displays an 
inhabitant’s personal statistics of use for that building.  At 
the same time, the code that has been written to scan for the 
nearest three HRM radio frequencies runs in the background 
of the current interface application.  As the phone scans and 
recognizes the nearest HRM’s through the mobile phone 
ANT+ sensor, this information is updated in real time to 
Google App Engine throughout the day and will also 
procedurally generate the development of an inhabitant’s 
Identicon within the application.  Furthermore, because the 
scanning application looks for the nearest three HRM’s, it 
can also determine which direction the inhabitant is moving 
in through triangulation. 
 
A tablet application is also used to display real-time 
information and personal Identicons as each inhabitant 
navigates the building.  The tablet app has been developed 
using the Unity game development tool so that we can 
create dynamic assets in real time to be displayed on the 
tablets.  The location node information that is sent to Google 
App Engine from the mobile phone sensor informs the 
tablet application where an inhabitant is and displays his or 
her personal Identicon on the corresponding tablet, which is 
associated with a specific location node ID.  This allows the 
personal Identicons to follow inhabitants as they move 
through the building with their mobile application launched. 
Furthermore, each Identicon is procedurally generated in 
Unity from the real time Google App Engine data so that the 
Identicon in constantly updated to reflect the data that the 
inhabitant is generating as he or she navigates the building.  
V.     CONCLUSION
 
PUCK highlights important questions about how 
inhabitants come to understand and engage with ambient 
interfaces, ubiquitous computing systems, and context-
specific interactions with the built environment.  PUCK 
uses sensors, displays, and location to engage and teach 
inhabitants about the data being gathered on a daily basis. 
This data becomes a part of an emergent character of the 
building, in which stories emerge through data 
visualizations, personalized responses delivered to each 
inhabitant, and through data sculptures that tell the story of 
each inhabitants engagement with the building.  This 
engagement with the system over time becomes a vital part 
of each inhabitant’s personal profile and the relationship that 
emerges between the building and its inhabitants.
 
PUCK is meant to raise questions about how we think 
about and engage with the spaces that we inhabit, those that 
exist somewhere between being purely physical and 
somewhat digital. Lastly,  PUCK brings to light concerns of 
privacy and surveillance by making the active profiling and 
data collection transparent, while engaging you in an active 
conversation about the future of interacting with 
environments that sense, generate data, and teach their 
inhabitants while simultaneously learning from them.
ACKNOWLEDGMENT
 
PUCK was developed with the support of the Mobile 
and Environmental Media Lab (MEML) in the School of 
Cinematic Arts, University of Southern California.  The 
MEML team for PUCK is Scott Fisher, Josh McVeigh-
Schultz, Jeff Watson, Hyung Gy Oh, Jacob Boyle, Michael 
Annetta and Amanda Tasse.  
REFERENCES
[1]
M. Weiser, “The Computer for the 21st Century,” Scientific 
American 265, 1991, pp. 94-104.
[2]
M. McCullough, “New Media Urbanism: grounding ambient 
information technology,” Environment and Planning B: 
Planning and Design, volume 34,  2007, pp. 383-395.
[3]
J. Stein and S. Fisher, “Ambient Storytelling: The Million 
Story Building,” ACM SIGCHI Conference on Tangible, 
Embedded, and Embodied Interaction, Madeira, Portugal, 
2011, pp. 1-7.
[4]
C. Norberg-Schulz,  Genius Loci: Towards a Phenomenology 
of Architecture. New York, NY: Rizzoli, 1979.
[5]
J. McVeigh-Schultz, J. Stein, J. Watson, and S. Fisher, 
“Extending the Lifelog to Non-Human Subjects: Ambient 
Storytelling for Human-Object Relationships,” ACM 
Multimedia 2012, Nara, Japan, pp. 1205-1208.
[6]
J. Gemmell, “MyLifeBits : Fulfilling the
Memex Vision,” ACM Multimedia 2002, Les Pins, France, 
pp. 235-238.
[7]
G. Bell,  “A New Relevance for Multimedia When We Record 
Everything Personal,” ACM Multimedia October 2004, New 
York, NY,  p. 1.
[8]
V. Bush,  “As we may think,” Atlantic, 1945.
[9]
J. Gemmell, R. Lueder, and G. Bell, “The MyLifeBits lifetime 
store,” Proceedings of the 2003 ACM SIGMM workshop on 
Experiential telepresence ETP 03, Ft Lauderdale, Fl,. 2003, 
pp. 80–83.
[10] S. Lee, “UbiGraphy : A Third-Person Viewpoint Life Log,” 
CHI 2008, Florence, Italy, pp. 3531–3536.
[11]  S. Mann, “Sousveillance: Inverse Surveillance in Multimedia 
Imaging,”  ACM Multimedia, 2004, New York, NY, pp. 620–
627.
[12] S. Mann, “WearCam (the wearable camera),” Proceedings of 
ISWC 1998, Pittsburg, PA), pp. 124–131.
[13]  R. Belchior, D. Junior, and A. Monteiro.  “ANT+ Medical 
Health Kit for Older Adults,”  MobiHealth 2012, Paris, 
France, pp. 20-29.
28
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-309-4
AMBIENT 2013 : The Third International Conference on Ambient Computing, Applications, Services and Technologies

