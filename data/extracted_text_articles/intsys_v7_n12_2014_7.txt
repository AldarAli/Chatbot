74
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Applications of Languages with Self-Interpreters to
Partial Terms and Functional Programming
Lev Naiman
Department of Computer Science
University of Toronto
Toronto, Canada
Email: naiman@cs.toronto.edu
Abstract
—Those programming languages that contain self-
interpreters have the added power of reﬂection, and allow dynam-
ically controlling execution. In a logical language a complete self-
interpreter is necessarily inconsistent. However, we demonstrate
a logical language with a reasonably complete self-interpreter.
We argue for its use as a simple formalism for reasoning
about partial terms, and functional languages that allow both
general recursion and dependent types. Since reﬁnements of
programming speciﬁcations often include partial terms, they need
to be handled using formal rules. Likewise, we show formal rules
for handling general recursion consistently in a simple language.
Moreover, we demonstrate how to use an interpreter to reason
about lazy evaluation. We argue that the interpreter can be
integrated within theorem provers.
Keywords
— logic; partial-terms; theorem prover; two-valued
logic; expression interpreter; functional programming; general
recursion; lazy evaluation
I. INTRODUCTION
In this paper we argue that logics for programming must be
able to cope with general recursion and partial terms, and that
an interpreter [1] is a viable solution.
General recursive and partially recursive functions natu-
rally occur in programs. This is an effect of recursively
deﬁned datatypes such as trees, and the computation paths that
arise in sufﬁciently complex programs. Aside from necessary
complexity while programming, partially recursive functions
are often the result of computation that is non-terminating.
While often this indicates programmer error is is undesirable,
there are many cases where a non-terminating program is
intentional. This includes any application code that waits and
responds to user input, and some semi-decision procedures.
Therefore, general recursion is not a property that should be
excluded, but rather desirable in a functional language for the
ease of use of programmers.
Despite their power and expressiveness, general and par-
tially recursive functions pose challenges for a number of
theories of programming and practical tools. The issues present
themselves both in the difﬁculty of proof of their properties
and with the possible partiality or at worst inconsistency that
they introduce. For example, the language Gallina within the
interactive theorem prover Coq [2] requires that all functions
terminate. Non-terminating programs would introduce logical
inconsistency. Likewise, theories of programming such as
Morgan’s Programming from Speciﬁcations [3] exclude non-
terminating programs from its standard theory and require a
proof of termination for all programs. In the Vienna Devel-
opment Method [4] non-terminating computation corresponds
to partial functions. In a well-typed or dependently typed
language this partiality naturally arises when a function is
required to produce a certain result for a pre-condition stronger
than true.
The occurrence of partial terms are not limited to non-
terminating functions. There are often cases where expressions
within programs do not denote a value. For example the
indexing of a sequence with a negative number results in
an error in most programming languages. Formal reasoning
about partial expressions often occurs when using a formal
programming theory, even one that requires termination. Both
issues of partial terms and general recursion pose a similar type
of problems to a theory: they produce expressions to which
no formal rules apply, and make proofs of intuitively simple
theorems impossible. At worst, the result is inconsistency.
It is crucial for a formal program theory to consistently
and elegantly deal with general recursion and partial terms,
introducing the minimal amount of extra values and extra
theory to do so. The interpreter formalism can be applied for
reasoning about both of these features, and is an extension of
the interpreter presented in [1].
A. General Recursion
For formal typed functional languages recursion is often
restricted. This is because logically reasoning about functions
with both constructive types and general recursion is incon-
sistent. For example, from the following deﬁnition:
f : nat → nat
(1)
f = λx : nat · 1 + f x
(2)
It is immediately clear that f n = f n+1, and since f n : nat
we have the contradiction that 1 = 0. There are a number of
methods to maintain consistency that either restrict recursion,
require functions to be constructive, or require proof that both
argument and result of a function is a value [5]. A constructive
type theory is desirable in order to perform effective error
checking statically. Dependent types are more expressive, and
allow type information to encode invariants.

75
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
B. Partial Terms
In programming speciﬁcations and their reﬁnements we
commonly encounter partial terms. Partial terms are deﬁned as
expressions that fail to denote a value. A term t in a theory T
is partial if there are no laws in T that apply to t. An example
is where a function or an operator is applied to an argument
outside of its domain, such as 1/0. We also say that a formula e
is unclassiﬁed in theory T if it is neither classiﬁed as a theorem
or an anti-theorem. Such expressions are present in proofs
of programs due to the partial functions and operators that
are often used in speciﬁcations. Borrowing an example from
[6], we might implement the difference function as follows
(where the domain of diff is integers, and the assumed theory
is arithmetic and ﬁrst-order two-valued logic).
diff i j = if i = j then 0 else (diff i (j + 1)) + 1 ﬁ
(3)
We would like to prove
∀i, j : int · i ≥ j ⇒ (diff i j) = i − j
(4)
but when trying to simplify this expression instantiated with
1 and 2 respectively for i and j we get
1 ≥ 2
⇒
(diff 1 2) = 1 − 2
(5)
= F
⇒
(diff 1 2) = −1
and we cannot apply any laws at this point to simplify it
further. A law would allow simplifying the expression to true,
but it requires that both operands be boolean. The expression
diff 1 2 is a partial term because no laws apply to it. For this
reason we cannot use any law to conclude that (diff 1 2) = −1
is a boolean, even though it has the form X = Y . Tools
that reason with such expressions must be based on formal
rules in order to have conﬁdence in their proofs. We propose
a character-string interpreter to solve this problem.
The rest of the paper is organized as follows: in Section II
we examine the existing approaches in the literature to cope
with partial terms. In Section III we describe the background
theories we use to deﬁne the interpreter in Section IV.
Section V shows how the interpreter can be used to cope
with partial terms. Section VI describes other beneﬁts of the
interpreter when constructing theories. Section VIII describes
how we can extend the deﬁnition of the interpreter to be more
expressive.
II. CURRENT APPROACHES TO PARTIAL TERMS
One approach to resolve partial terms is to make all terms
denote. Formally this means that for each partial term such
as x/0, a law must exist saying which set of values that
expression is a member of. This set of values is assumed to
already be deﬁned in the logic, as opposed to newly created
values. In this case there could be a law deﬁned saying that
∀x : int · x/0 : int. This is the approach used in the
programming theory of [3]. Such laws do not explicitly say
what value a partial term is equal to, and this can cause certain
TABLE I
THREE-VALUED BOOLEAN OPERATORS
T
F
⊥
¬
F
T
⊥
TT
TF
FT
FF
T⊥
⊥T
⊥F
F⊥
⊥⊥
∨
T
T
T
F
T
T
⊥
⊥
⊥
∧
T
F
F
F
⊥
⊥
F
F
⊥
peculiar and possibly unwanted results such as 0/0 = 0 being
a theorem.
0
(6)
= 0 × (1/0)
= 1 × (0/0)
= 0/0
This approach can be slightly modiﬁed and the value of partial
terms can be ﬁxed. However, this might cause some unwanted
properties. In the case of division by zero a choice of 42 as
used in [7] cannot be allowed due to inconsistency.
In [8], the authors point out that underspeciﬁcation alone
may cause problems. If we allow domains of single elements
then these problems can go as far as inconsistency. The
semantic model of our interpreter uses underspeciﬁcation, but
not exclusively. In some cases, similarly to LPF, the interpreter
would leave some expressions unclassiﬁed. One way of ﬁnding
a model for partial functions in set theory is the standard
approach of mapping any unmapped element from the domain
to a special value, usually called ⊥ [9]. The denotational
semantics for a generic law for equality are extended with
this value, and in this particular model 7/0 = 5/0 would be a
theorem (assuming strict equality). However, a user of a logic
that includes the interpreter would not need to perform any
calculations that concern this extra value.
The Logic of Partial Terms (LPT) [10], [11] is an example
of a logic that does not include the undeﬁned constant. It
does however include a deﬁnedness operator ↓. In this theory
the specialization law (∀x · A(x)) ⇒ A(v) requires that v
be deﬁned. The basic logic of partial terms (BPT) [12] is
a modiﬁcation of LPT, and relaxes the previous requirement
for some laws. It allows for reasoning with non-terminating
functional programs. Some logics such as [13] include multiple
notions of equality to be used in calculations. This may
complicate the laws of quantiﬁers.
Another approach to deal with partial terms is a non-
classical logic such as LPF [7] with more than two values.
In these logics the truth table of boolean operators is usually
extended as in Table I (where ⊥ represents an “undeﬁned”
value, and the column heads are both of the arguments to
the operator). In this logic the expression 0/0 = 1 would not
be classiﬁed to one of the boolean values, but would rather
be classiﬁed as ⊥. Undeﬁnedness is either resolved by the

76
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
boolean operators or is carried up the tree of the expression.
Some three valued logics have a distinct undeﬁned value for
each value domain, such as integers and booleans.
Three and more valued logics have varied useful applica-
tions. However, a drawback of using a logic with multiple
truth values is that certain useful boolean laws no longer hold.
This is particularly true of the law of the excluded middle,
∀x : bool · x ∨ ¬x, which in a three value logic can be
modiﬁed to ∀x : bool · x ∨ ¬x ∨ undefined(x). In the Logic
of Computable Functions (LCF) [14] there is a ⊥t value for
each type t, requiring the modiﬁcation of several laws. Another
issue of multiple valued logics is that not knowing the value
of an expression seems to be pushed one level up; attempting
to formalize these extra values will result in a semantic gap.
There are always expressions that must remain unclassiﬁed for
a theory to remain consistent.
A further method of dealing with partial terms is condi-
tional, or short-circuit operators [15]. This approach is similar
to those logics with three values, since it gives special treat-
ment to partial terms. Boolean operators have an analogous
syntax a cor b, a cand b, a cimp b, etc. In these expressions
if the ﬁrst value is undeﬁned, then the whole expression is
undeﬁned. These conditional operators are not commutative.
For many of these non-classical logics the authors of [16]
demonstrate a relationship, and how to transform undeﬁned
terms in one logic to another in a similar method to data-
reﬁnement.
III. BACKGROUND THEORIES
We introduce two theories from [17] that we will use to
deﬁne the interpreter.
A. Bunch Theory
A bunch is a collection of objects. It is different from a
set, which is a collection of objects in a package. A bunch is
instead just those objects, and a bunch of a single element is
just the element itself. A number, character or boolean is an
element. Every expression is a bunch, but not all bunches are
elementary. Here are some bunch operators.
A , B
A union B
(7)
A ‘B
A intersect B
(8)
A : B
A in B, or A included in B
(9)
¢A
cadinality of A (10)
If x is an element, then ¢x = 1. The empty bunch, whose
cardinality equals zero, is the constant null. The union of two
elements x, y is not an element iff x‘y = null. Both bunch
union and intersection are symmetric, associative, and idem-
potent. The deﬁnition of bunches essentially gives algebraic
properties to a comma as an operator. Operators such as a
comma, colon, and equality apply to whole bunches, but some
operators apply to their elements instead. In other words, they
distribute over bunch union. For example
1 + (4, 7)
(11)
= 1 + 4 , 1 + 7
= 5 , 8
Bunch comprehension is denoted with the section sign §. For
element x, bunches A and B, and predicate f, § is deﬁned as
follows:
(§v : null · f v)
=
null
(12)
(§v : x · f v)
=
if f x then x else null
(13)
(§v : A, B · f v)
=
(§v : A · f v), (§v : B · f v)
(14)
Where nat is the bunch of naturals, we deﬁne the notation
x, ..y, read as “x to y” as
x, ..y = §i : nat · x ≤ i < y
(15)
Bunch distribution is similar to a cross-product in set theory.
Sets do not distribute over bunch union, and set brackets can
be placed around a bunch to form a set (which itself is an
element). For example, {null} is the empty set, and ¢{null} =
1. Set comprehension {x : D|f x} is an abbreviation for {§x :
D · f x}.
B. String Theory
A string is an indexed collection of objects. It is different
from a list or ordered pair, which are indexed collections of
objects in a package. A string of a single item is just that item.
The simplest string is the empty string, called nil. Strings are
joined together, or concatenated with the semicolon operator
to form larger strings. This operator is associative but not
commutative. The string 0; 1 has zero as the ﬁrst item and
one as the second. For a natural number n and a string S,
n*S means n copies of S. Let nat be the bunch of natural
numbers. The copies operator is deﬁned as follows.
0*S = nil
(16)
∀ n : nat · (n + 1)*S = (n*S); S
(17)
Strings can be indexed, and their length can be obtained with
the length operator (↔).
Sn
S at index n (18)
↔ S
length of S (19)
A semicolon distributes over bunch union, and so does an
asterisk in the left operand. Similarly to bunches, a number,
character, or boolean is an item. If x is an item, then ↔ x = 1,
and only the string nil has length zero. The concatenation of
two items is not an item. Note that null is not an item, and
that ↔ null = null. Operators and functions, whose domains
include only items, distribute over concatenation. For example
(0; 2; 4) + 1 = 1; 3; 5
(20)

77
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Since a string S can be thought of as a function that maps
natural numbers from 0, .. ↔ S to the items of S, quantiﬁers
can be lifted to apply to strings.
ΣS = Σn : 0, .. ↔ S · Sn
(21)
∀S = ∀n : 0, .. ↔ S · Sn
(22)
Analogously to the bunch notation x, ..y the notation x; ..y for
items x, y, z is deﬁned as
x; ..x = nil
(23)
x; ..(x + 1) = x
(24)
(x; ..y) ; (y; ..z) = x; ..z
(25)
Similarly to the relationship between sets and bunches, strings
can be pakcaged into lists. Lists are denoted with square
brackets, and operators of lists are
[S]
List containing S (26)
[S] + [T] = [S; T]
List Concatenation (27)
[S]n = [Sn]
List Indexing (28)
Some examples of the operators deﬁned are
↔ (7; 1; 0) = 3
(29)
(7; 1; 0)0 = 7
1; (5, 17); 0 = (1; 5; 0), (1; 17; 0)
3*(0; 1) = 0; 1; 0; 1; 0; 1
(0, 1)*(0; 1) = 0*(0; 1), 1*(0; 1) = nil, 0; 1
The preﬁx “copies” operator *S is deﬁned to mean nat*S, or
informally the bunch of any number of copies of S. Finally,
we introduce characters, which we write with double-quote
marks such as “a”, “b”, etc. To include the open and close
double-quote characters we escape them with a backslash:
“\“”. Strings that contain exclusively character strings are
sometimes abbreviated with a single pair of quotes: “abc”
is short for “a”; “b”; “c”. Let the bunch of all characters is
called char. Then the bunch of all two-character strings is
char; char.
Bunch and string theory are used because they allow for
compact language deﬁnitions. For example, denoting the col-
lection of naturals greater than zero in set theory can be done
by writing {n : nat|n > 0}. In bunch theory it can be written
as nat + 1. We can of course deﬁne an addition operator
that distributes over the contents of a set, but the beneﬁt of
bunch theory (and analogously string theory) is that no such
duplication is necessary. This built-in distributivity comes at
a cost: the cost is that at times it is required to prove that
some bunches are elements. Consider the bunch bool deﬁned
as bool = T, F. Then we prove
¬bool
(30)
= ¬(T, F)
(31)
= F, T
(32)
= bool
(33)
However, this does not mean that bunch theory is inconsistent.
In order to simplify bool = ¬bool to F, we must know that
bool is an element.
IV. DEFINING THE INTERPRETER
An interpreter is very similar to a semantic valuation
function, except that it does not require a universe of val-
ues. In addition, it will be extended to interpret a language
that includes the interpreter symbol itself, which if na¨ıvely
done causes inconsistency. While standard notation does not
explicitly distinguish logic from meta-logic (unless different
operators are used), we put quotes around the interpreted
language. Since the interpreter essentially encodes meta-logic,
we would like to keep it simple in the sense that it should
introduce as few new operators as possible. It should also
preserve the properties of existing operators. In this way we
both avoid a separate meta-language, and do all reasoning
within a single logic. In the literature authors often use one
set of symbols for the meta-logic operators and another for
the object logic. We use character strings instead both for
clarity, and in the case where we wish to use the logic to study
itself. Where as multiple level of meta-logic might require
multiple sets of symbols, reasoning with the interpreter only
requires adding more quotes. We take the idea of the character-
string predicate of Hehner [18], and we extend it to be a
general interpreter for any expression in our language. To
maintain consistency we exclude the interpreter itself from
the interpreted language in this section. The interpreter, which
we call I is an operator which applies to character strings and
produces an expression. The interpreter can be thought of as
unquoting a string. We ﬁrst deﬁne our language as a bunch of
character strings.
Let char be the bunch of all character symbols, let alpha
be the bunch of character symbols in the English alphabet,
and let nat be the bunch of naturals. We have the following
deﬁnitions
digit
=
“0”, “1”, “2”, “3”, “4”,
“5”, “6”, “7”, “8”, “9”
(34)
var
=
alpha; *alpha
(35)
num
=
digit; *digit
(36)
uniops
=
“¬”, “ − ”, “∀”, “∃”, “Σ”
(37)
binops
=
“ = ”, “ ∧ ”, “ ∨ ”, “ ⇒ ”, “ ⇐ ”, (38)
“; ”, “ − ”, “ + ”, “ ”, “ ∈ ”
charstring
=
“\“”; *char; “\””
(39)
We deﬁne our language lang to be the following bunch of
strings.

78
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
var, num, string, “T”, “F” : lang
(40)
“⟨”; var; “ : ”; lang; “ → ”; lang; “⟩” : lang
“(”; lang; “)” : lang
“{”; lang; “}” : lang
“(”; uniops; lang; “)” : lang
“(”; lang; binops; lang; “)” : lang
Here we have deﬁned a language that includes boolean
algebra, numbers, logical quantiﬁers, functions, and strings.
This language is fully bracketed for simpler laws, and non-
bracketed expressions should be read as abbreviations. The
language is deﬁned similarly to how a grammar for a language
would be given. Function syntax is ⟨v : D → B⟩, where
the angle brackets denote the scope of the function, and v
is the introduced variable of type D. We treat quantiﬁers as
operators that apply to functions. The quantiﬁers ∃ and ∀ give
boolean results. When we use more standard notation such
as ∀v : domain · body we mean it as an abbreviation for
∀⟨v : D → B⟩.
The interpreter is intuitively similar to a program interpreter:
it turns passive data into active code. Our interpreter turns a
text (character string) that represents an expression into the
expression itself. The interpreter is deﬁned very closely to
how lang was deﬁned. The laws are as follows.
I “T”
=
T
(41)
I “F”
=
F
∀ s : num · ∀ d : digit · I(s; d)
=
(I s) × 10 + (I d)
∀ s, t : lang · I (“⟨a : ”; s; “ → ”; t; “⟩”) = ⟨a : I s → I t⟩
∀ s : lang · I “(”; s; “)”
=
I s
∧
I “{”; s; “}”
=
{I s}
∧
I (“¬”; s)
=
¬(I s)
∧
I (“ − ”; s)
=
− (I s)
∧
I (“∀”; s)
=
∀(I s)
∧
I (“∃”; s)
=
∃(I s)
∧
I (“Σ”; s)
=
Σ(I s)
∀s, t : lang ·I (s; “ = ”; t)
=
(I s) ∧ (It)
∧
I (s; “ ∧ ”; t)
=
(I s) = (I t)
∧
I (s; “ ∨ ”; t)
=
(I s) = (I t)
∧
I (s; “ ⇒ ”; t)
=
(I s) ⇒ (I t)
∧
I (s; “ ⇐ ”; t)
=
(I s) ⇐ (I t)
∧
I (s; “; ”; t)
=
(I s); (I t)
∧
I (s; “ − ”; t)
=
(I s) − (I t)
∧
I (s; “ + ”; t)
=
(I s) + (I t)
∧
I (s; “ ∈ ”; t)
=
(I s) ∈ (I t)
∧
I (s; “ ”; t)
=
(I s) (I t)
∀ s : *char · I (“\“”; s; “\””)
=
s
To save space we leave out the interpretation of each digit.
For scopes the introduced variable must be an identiﬁer, and
the expression Ia in that position would not satisfy this
requirement. We instead have a law for only the identiﬁer a,
and other identiﬁers can be obtained through an application of
a renaming law.
Note that we deﬁned lang as a bunch of texts, and not
the expressions themselves. When these texts are interpreted,
the results are expressions or values in the language. The text
“2” is in lang, but not the value 2. The interpreter is similar
to a function of strings and distributes over bunch union. It
is possible to have a logical language to parallel the texts in
lang; all the expressions in the language which do not contain
I can then be denoted as I lang. In this paper we leave out
some operators from lang, such as the ones in bunch theory.
Note that unlike a semantic valuation function the interpreter
does not necessarily map every string in the language to a
value. Rather, we later introduce generic laws that reason with
these partial terms directly. Lastly, we will show how the
interpreter can be included in the interpreted language without
inconsistency.
A. Variables
One signiﬁcant change that we allow in our logic is for
variables. We say that a variable with the name a is an
abbreviation for I“a”, and similarly for all other variable
names. Although in our initial deﬁnition we excluded the
interpreter from the interpreted strings, we later show in
Section VIII how we can extend our language to safely include
the interpreter.
There is an important consequence of making variable
syntax more expressive: function application and variable
instantiation is no longer a decidable procedure in general.
This is because deciding whether two variable strings are equal
is now as difﬁcult as all of proving. However, this does not
pose a problem for the implementation of function application
along with the interpreter in a theorem prover. The simple
solution is that whenever we see an interpreter in the body, we
do not apply the function; it is treated as a syntactic variable
that can only be replaced by its interpretation. We argue that
this rarely hinders the use of the interpreter, since in the sub-
language that does not include the interpreter users can do
all calculations exactly as before. In the case where reasoning
with the interpreter is desired, standard proof obligations can
be generated and discharged.
We ﬁnish this section by noting that we could have simpli-
ﬁed the deﬁnition considerably if we had a preﬁx language.
All operator interpretation could be compressed to a single
law, and some bracket characters removed.
V. RESOLVING PARTIAL TERMS WITH THE INTERPRETER
Our solution to reasoning with partial terms is neither at the
term or propositional level. We rather say that some operators,
such as equality or bunch inclusion are generic. For example,
here are two of the generic laws for equality.
∀a, b : lang · I (a; “ = ”; b) : bool
Boolean Equality (42)
∀a : I lang · a = a
Reﬂexivity (43)

79
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The ﬁrst law says that any equality is a boolean expression,
similarly to the Excluded Fourth Law in LPF which implies an
equality is either true, false or undeﬁned [6]. The arguments
can be any expressions in the interpreted language. For a
simple formal example of the use of the law we continue with
the difference example.
(44)
F ⇒ diff 1 2 = −1
Bool Base Law
Type Checking Proof Obligation
(diff 1 2 = −1) : bool
Interpreter laws
= I“diff 1 2 = −1” : bool
String Assoc.
= I(“diff 1 2”; “ = ”; “ − 1”) : bool
Bool Equality
= T
= T
As we can see in the example, since the interpreter unquotes
expressions, using it in proofs is usually just the reverse
process.
A. Implementation
In general, implementing laws that use the interpreter in a
theorem prover is non-trivial. This is because it is difﬁcult to
determine if uniﬁcation alone is sufﬁcient to check if a law
applies. We deliberately wrote two equality laws differently to
illustrate a couple cases where this task can be made easy. If
the only place the interpreter appears in a law is the expression
I lang in the domain of a variable, it can be treated as a
generic type. Type checking can be done by scanning to
see that the interpreter does not appear in any instantiated
expression with a generic type. In the case of the second law,
instantiating the variables and parsing yields a valid expression
without any further computation.
VI. METALOGICAL REASONING WITHIN THE LOGIC
There are several beneﬁts of deﬁning the interpreter and
using it to create laws. One such beneﬁt is the creation
of generic laws, where type-checking for variables is not
necessary. The removal of type-checking is not only beneﬁcial
for simplicity, partiality, and efﬁciency, but some operators
are meant to be truly generic. For example, the left operand
of the set-membership operator (∈) can be any expression
in the language, and set brackets can be placed around any
expression. By including the interpreter in the logic these laws
are expressed with full formality. For sets, an example would
be
∀A, B : I lang · ({A} = {B}) = (A = B)
(45)
Another beneﬁt is compact laws. For example, we wish to
deﬁne a generic symmetry law for natural arithmetic in our
logic. If we had a preﬁx notation then we could have written
the law as
∀f : (+, ×, =) · ∀a, b : nat· = (f a b)(f b a)
(46)
Using the interpreter we can create a law in a similar fashion
for non-preﬁx notation.
∀f : “ + ”, “ × ”, “ = ” · ∀a, b : lang·
(47)
I (a, b) : nat ⇒ I (a; f; b) = I (b; f; a)
This law can be made completely generic and include more
than arithmetic operators. It even becomes simpler to write.
∀f : “ + ”, “ × ”, “ ∧ ”, “ ∨ ”, “ = ” · ∀a, b : lang·
(48)
I (a; f; b) = I (b; f; a)
(49)
These sorts of laws allow us to capture an idea like
associativity or commutativity in a compact way, and can be
easily extended by concatenating to the operator text. Some
further abbreviations can be particularly useful:
∀v · P = ∀v : I lang · P
(50)
∃v · P = ∃v : I lang · P
(51)
Σv · P = Σv : I lang · P
(52)
§v · P = §v : I lang · P
(53)
⟨v → P⟩ = ⟨v : I lang → P⟩
(54)
It appears as if the language has unrestricted quantiﬁcation,
comprehension, and domain-less functions. This is useful for
generic quantiﬁcation and generic functions. Of course, the
expressions in the domains of the quantiﬁers and function
above must not include the interpreter.
One of the most useful features of the interpreter is rea-
soning about the syntactic structure of an expression without
requiring a meta-logic. These laws include function application
and several programming laws. Some laws have caveats, such
as requiring that in some expressions certain variables or
operators do not appear. For example, there is a quantiﬁer
law for ∀ that says if the variable a does not appear free in P
then
(∀a : D · P) = P
(55)
We would like to formalize this caveat. It is straight forward to
write a program that checks variable or operator appearance
in a string (respecting scope). We formalize a speciﬁcation
of the “no free variable” requirement using the interpreter.
For simplicity, assume that variables are single characters, and
strings are not in the interpreted language. For a string P in
our language and a variable named a we specify
∃i : (0, .. ↔ P) · Pi = “a”
∧
(56)
¬∃s, t, D, pre, post : *char·
(pre; “⟨a : ”; D; “ → ”; s; Pi; t; “⟩”; post) = P
∨ (pre; “⟨”; Pi; D; “ → ”; s; “⟩”; post) = P
This speciﬁcation says that a is free in P. The ﬁrst part says
that there is an index i in P at which a appears. The second
part says that a is not local. Let free denote this speciﬁcation
parameterized for an expression and a variable; free “a” P

80
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
says that a is free in P. The caveat for the quantiﬁer law is
formalized as
¬(free “a” P)
⇒
I (“∀a : ”; D; “ · ”; P) = I P
(57)
In a similar manner we can avoid including axiom schemata
in some theories and have just a single axiom. The notation
allows us to refer to all variables in an expression.
VII. FIXED-POINTS
Quines are self-reproducing expressions; their interpretation
is equal to themselves. Fixed-points of the interpreter are then
Quines, formally satisfying
I Q = Q
(58)
A Quine under this deﬁnition need not be a program. The
following expression is a Quine [17]:
“\“\“[0; 2*(0, ..15)]\”[0; 2*(0, ..15)]”
(59)
Of course, if we have Q = “Q” then it is trivially a Quine,
and therefore the deﬁnition of Quines is often restricted to
expressions with no free variables.
VIII. INCLUDING THE INTERPRETER
The deﬁnitions above exclude the interpreter itself from the
interpreted language to maintain consistency. G¨odel’s First
Incompleteness Theorem implies that it is not possible to
deﬁne the interpreter to be both consistent and complete [19],
[20]. A simpler proof of G¨odel’s theorem by [18] shows why
a straight-forward inclusion of the interpreter by the laws
“I”; lang : lang
(60)
∀s : lang · I “I”; s = I s
(61)
is inconsistent. In that paper the interpreter was deﬁned to be
a mapping lang → bool, which is not the case without deﬁ-
nitions. Nonetheless, since both completeness and consistency
cannot be achieved at once, any consistent logic that includes
the interpreter will necessarily include strings that cannot be
consistently interpreted, and hence be incomplete. Speciﬁcally,
let rus be the expression {§x : I lang · ¬(x ∈ x)}. Then rus
cannot have its string representation interpreted consistently.
The proof is as follows, and is similar to Russell’s paradox.
rus ∈ rus
(62)
= rus ∈ {§x : I lang · ¬(x ∈ x)}
= rus : (§x : I lang · ¬(x ∈ x))
= ¬(rus ∈ rus) ∧ rus : I lang
= ¬(rus ∈ rus) ∧ {§x : I lang · ¬(x ∈ x)} : I lang
= ¬(rus ∈ rus)
Since rus ∈ rus is boolean and an element, the proof above
shows a contradiction in the logic. The interpreter is therefore
incomplete for expressions such as rus, but all expressions
for which the interpreter is incomplete include the interpreter.
However, as [18] also suggests, any logic can be completely
described by another. This point is intuitively manifested in the
fact that all expressions that cannot be interpreted include the
interpreter itself. In a sense, we relegate all issues of partiality
in our logic to involve only the interpreter.
However, we can weaken the restriction on the interpreter
being excluded from the language. The motivation for includ-
ing the interpreter is to reason about languages that allow
this sort of self-reference. In practice, theorem provers such
Coq [2] allow reﬂection as a proving technique. Reﬂection
is a proof technique that allows a program (written in the
functional language of Coq) to reason about expressions in
Coq syntactically (at a meta-level). For example, a tactic for
normalizing variable ordering in arithmetic equations would
need to reason about expressions syntactically. It improves the
performance of proof search considerably by eliminating the
need for a number of applications of a commutative law.
A simple interpreter can be deﬁned for arithmetic expres-
sions in Coq in a straight-forward manner: the semantics of
an expression would parallel its syntactic deﬁnition. However,
such an interpreter must be well-typed, while the interpreter in
this paper may fail to denote a value. It is non-trivial to deﬁne
an interpreter in Coq whose interpreted language includes the
interpreter itself.
We would like to use the interpreter as a simple way of
reasoning about termination and consistency of deﬁnitions.
The key insight is that a mathematical function disregards
computation time.
The domain xnat is the naturals extended with ∞. The
domain of both T and TI is nat and their range is xnat. We
deﬁne a parsing function from strings in the language to a tree
data structure as follows:
∀v : var, num, string, “T”, “F” · parse v = graft v nil
∀s, t : lang · ∀v : var · ∀bin : binops · ∀uni : uniops·
parse uni; v
= graft uni (parse s)
parse s; bin; t
= graft bin (parse s); (parse t)
parse “(”; s; “)”
= graft “()” (parse s)
parse “⟨”; v; “:”; s; “→”; t; “⟩” = graft “⟨⟩” (parse s); (parse t)
We can measure interpretation time recursively by deﬁning
the following timing functions.

81
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
T nil = TI nil = 0
T s = T (parse s)
T graft op subtrees
=
if op = “I” then
1 + ΣTI (subtrees)
else
ΣT (subtrees)
TI graft op subtrees
=
if op = “I” then
1 + ΣTI (subtrees)
else if op : var
T (parse (I op))
else
ΣTI(subtrees)
This function is in a way parallel to how an interpretation
works, except that it counts time. The time in question is the
number of law applications needed to simplify an expression
to have no interpreter symbol in it. At each “if”-statement
the function checks for the occurrence of a certain piece of
syntax, and the vertical ellipsis would include a similar check
for the rest of the syntax. The special part of this function
is when we see the interpreter symbol. If the interpreter was
applied to a string representing a variable, and that variable’s
value is a string in the language, we recurse on its value. If
the interpreter is applied to any other expression, we recurse
on that expression’s string representation. For example, if we
have
Q = “¬I Q”
(63)
then we calculate
T Q
(64)
= T “¬ I Q”
= T “I Q”
= TI “Q”
= 1 + T Q
and therefore T Q = ∞ since T Q : xnat. For any string that
does not include the interpreter the time is linear in the size
of the string; this can be proven by structural induction over
lang if we add an induction axiom along with the construction
axioms we deﬁned earlier. We should only interpret an expres-
sion that includes the interpreter if the execution time of the
interpretation is ﬁnite. If it is inﬁnite or cannot be determined,
then there is a potential for inconsistency had we decided
to interpret it regardless. We can add the interpreter to the
interpreted language as follows:
∀s : lang · T s<∞ ⇒ I “I”; s = I s
(65)
As an example of calculating with the interpreter, consider
an expression normalizer N that linearizes an associative
expression. For a sample input of “a+((b+c)+d)” it would
output “a+(b+(c+d))”. For the language lN of expressions
containing variables, brackets and plus, N is a total function.
A partial speciﬁcation of its behaviour is
∀s : lN · I (N s) = I s
(66)
We want to normalize the expression (a + I t) + (b + c).
The sub-part t of the expression that is input to N might
be unknown, such as if it came from a stream communicating
with a different process. However, if we know that t : lN, and
that the variables in string t do not contain a, b, c, then it is
reasonable to prove that (a+I t)+(b+c) = a+(b+(c+I t))
using the deﬁnition of the normalizer. The calculation would
be
(a + I t) + (b + c)
(67)
= I “(a + I t) + (b + c)”
= I (N “(a + I t) + (b + c)”)
= I “a + (b + (c + I t))”
= a + (b + (c + I t))
Although the proof appears simple, a proof obligation
required to justify the steps is that the interpretation time of
I t must be ﬁnite. We argue that this example is representative
of real computations that can be reasoned about using the
interpreter.
The requirement to prove ﬁnite interpretation time in order
to evaluate the interpretation of a string in the language
is similar to the concepts of partial and total correctness
proofs in program theories [3], [15]. One is a proof about
the result of execution, and the other about the execution
time. Many programming theories require ﬁnding either a
bounded-decreasing function of the input to a program, or
ﬁxed-points for loops [21] [3]. Other functional and proof
languages restrict the language itself, often constructively. In
effect, that is excluding those strings from the language that
cannot be built constructively. Instead of interpretation time,
we can deﬁne constructively the interpretable strings which
include the interpreter. Let those strings be called ilang,
whose deﬁnition parallels the deﬁnition of lang, except that
for variables:
∀v : var · I v : ilang ⇒ v : ilang
(68)
And then we add that
“I”; ilang : ilang
(69)
“I”; ilang : lang
(70)
We prove that for all strings in ilang the interpretation time is
ﬁnite by induction. The base case is strings in terminal, for
which T is zero. For strings in unary, binary or bracketing
operators T
is the sum of the interpretation time of the
operands. For strings pre-ﬁxed with the interpreter, T is one
plus TI of the operand, which by the induction hypothesis is
ﬁnite. Finally, only variables whose interpretation is in ilang
may be included, so for v : var we have TI v = T (I v)

82
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
which is ﬁnite by the inductive hypothesis, which concludes
the proof
.
Therefore, no expressive power was gained with a restricted
language as opposed to demanding proof of ﬁnite interpreta-
tion time. We argue that it is preferable not to restrict the
language to ﬁnite interpretation time, because reasoning about
strings with inﬁnite interpretation time can be of the same
use as reasoning about inﬁnite computations. The antecedent
requiring ﬁnite interpretation time is sufﬁcient for consistency.
However, not all strings in the language whose interpretation
time is inﬁnite cause an inconsistency.
In general, proving a ﬁnite execution time is the halting
problem. When reasoning about logics it may be useful to
include the interpreter in the interpreted language. For many
practical purposes it can be left out.
IX. GENERAL RECURSION IN FUNCTIONAL LANGUAGES
AND LAZY EVALUATION
The Trellys project [22][5] aims to create a functional
language with general recursion and dependent types. The
current approach is to separate the logical language from
the computational language, because otherwise the result is
inconsistency. The logical language and computational lan-
guage share some parts, such as some shared data-types, but
it is only the computational language which may have general
unrestricted recursion. However, the interpreter can be applied
to decouple timing from the language deﬁnition and allow the
logic and computational language to be the same.
We claim that the interpreter can be used to simply and
expressively reason about functional programming languages,
and to deﬁne one with general recursion in a simple way. To
do this, the interpretation of a functional program requires a
ﬁnite execution time, and we decouple these two properties
using the interpreter. Consider the following deﬁnition for the
simple language of lambda calculus λlang.
var : λlang
(71)
“(”; λlang; “ ”; λlang; “)” : λlang
(72)
“λ”; var; “ · ”; λlang : λlang
(73)
Although consistent within its own domain, lambda calculus
is not consistent when combined with other theories such
as boolean algebra and arithmetic. However, even without
requiring typed lambda terms, there are programming lan-
guages such as Python that implement consistently lambda
terms within the programming language. This suggests that
by restricting the evaluation of β-reductions to only those with
ﬁnite execution time can resolve the inconsistency. For v : var
and s, t : λlang we deﬁne interpretation for lambda calculus
as follows:
Iλ “λv · ”; s = λv · Iλ s
(74)
Iλ “(”; s; “)” = Iλ s
(75)
Tλ (s; “ ”; t)<∞ ⇒
Iλ s; “ ”; t = (Iλ s) (Iλ t) (76)
In the same way as before, variables are abbreviation of the
interpretation of strings in var, so Iλ “a” is an abbreviation
of a. We assume the existence of a function β that performs
β-reductions on strings in λlang. For v : var and s, t : λlang
the timing function for lambda calculus is:
Tλ v = 0
(77)
Tλ “λ”; v; “ · ”; s = Tλ s
(78)
Tλ “(”; s; “ ”; t; “)” = 1 + Tλ (β s t)
(79)
The proof of inconsistency for untyped lambda calculus
shows that the β-reduction of (λx · ¬(x x)) (λx · ¬(x x))
is equal to its negation. However, the deﬁnition of Iλ requires
ﬁnite interpretation time for β-reduction, which is not the case
for this term:
Tλ “((λx · ¬(x x)) (λx · ¬(x x)))”
(80)
= 1 + Tλ β (“λx · ¬(x x)” “λx · ¬(x x)”)
(81)
= 1 + Tλ “¬((λx · ¬(x x)) (λx · ¬(x x)))”
(82)
= 1 + Tλ “(λx · ¬(x x)) (λx · ¬(x x))”
(83)
And therefore the interpretation time is equal to ∞ as
before. We have decoupled interpretation from execution,
and made the theory consistent. The interpretation time was
mapped to the underlying computation model, albeit slightly
abstracted: β-reduction costs time 1, and all else is free.
In general, for any logic whose inconsistency is due purely
to operators that take inﬁnite time to compute, it can be used
as a consistent computation logic with no change. In essence,
the computation logic of a theory makes operators incomplete
for inﬁnite executions. For this reason lambda calculus can be
used as a computation logic with no change.
Furthermore, interpretation time allows a ﬂexible timing
policy. If instead the computation model is an Oracle Turing
Machine, then the cost of β-reduction becomes ﬁnite even for
inﬁnite computations, and the theory becomes an inconsistent
computation logic. The timing function can be further general-
ized to consider valuation of inputs. This is particularly useful
for reasoning about lazy evaluation of functional programs,
because a lazy language can use the exact same logic as
its non-lazy counter-part with the only difference being their
interpretation time. A lazy language can allow for inﬁnite data-
types such as inﬁnite lists, or inductively deﬁned inﬁnite data-
types. Consider the following deﬁnition of an inﬁnite list of
naturals:
natlist = 0; (1 + natlist)
(84)
which can be equivalently deﬁned without explicit recursion
using a Y-combinator as
natlist = (λf · (f f)) (λs · 0; (1 + (s s)))
(85)
and that we wish to evaluate natlist42. As currently deﬁned,
Tλ is a lazy timing policy, and Tλ (natlist42)
=
42. An
eager timing policy results in inﬁnite execution time, and is
achieved by the simple change to the timing function:
Tλ “(”; s; “ ”; t; “)” = 1 + (β (Tλ s) (Tλ t))
(86)

83
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
X. PROOF OF CONSISTENCY
To prove the interpreter consistent we will ﬁnd a model in
set theory. Characters are implemented as natural numbers,
having
“0” = 0, . . . “9” = 9, “a” = 10, . . . “z” = 25, . . .
(87)
Strings are implemented as ordered pairs in the standard way.
a; b = {{a}, {a, b}}
(88)
The interpreter is a mapping from the set of all strings in our
language lang to the class of all sets. I ⊆ lang × Sets. It
is assumed that all other theories (functions, boolean algebra,
numbers) are implemented in set theory in the standard way.
For this reason partial functions might be implemented using
another special value that all remaining domain elements will
be mapped to. We will not delve into the implementation of
functions and other theories, since once they are implemented
in set theory, they are included in the class Sets.
We must prove that there exists a function I such that the
interpreter axioms are true. The recursion theorem will be used
to prove this [9]. The theorem states that given a set X, an
element a of X, and a function f : X → X there exists a
unique function F such that
F 0 = a
(89)
∀n : nat · F (n + 1) = f(F n)
(90)
Since I ⊆ lang × Sets it is necessary to ﬁrst ﬁnd a function
from lang to the naturals; this is an enumeration of the strings
in lang. Let charNum be the total number of characters in
char. Character string comparison for strings s, t is deﬁned
as
(s > t) = strNum(s) > strNum(t)
(91)
strNum = ⟨S : *char → if S = nil then 0
(92)
else S0 + charNum × S1,..↔S ﬁ⟩
The enumeration function enum of strings in lang is deﬁned
as
enum = (g−1)
(93)
g = ⟨n : nat → if n = 0 then (MIN s : lang · s)
(94)
else (MIN s : (§t : lang · t > g(n − 1)) · s) ﬁ⟩
The function strNum assigns a unique number to each
string. Some character strings are not in lang, and we desire an
enumeration free from gaps. The function g assigns a unique
string in lang to each natural as follows: zero is mapped to
the ﬁrst string in the language, and each subsequent number is
mapped to the next smallest string. Since g is one-to-one, we
deﬁne enum as its inverse. We deﬁne function F for a given
state in the model with ﬁnite single-character variables as
F 0 = {0; 0}
(95)
...
F 9 = {9; 9} ∪ F 8
For all s : char let m = enum(“\“”; s; “\””) in
F m = {m; s} ∪ F (m − 1)
(96)
F (n + 1) = {(n + 1); (H (n + 1) (F n))} ∪ F n
(97)
(H is deﬁned below)
At each argument n function F is a mapping of all previous
numbers to their corresponding expressions, in addition to the
current one. The base elements are the variables, numbers and
strings. Function H constructs expressions using the operators
in our language from previous expressions. It is deﬁned as
follows.
H k I =
(98)
{S : Sets|∃n, m : dom(I) · g k = (g n); “ + ”; (g m)
∧ S = I n + I m} ∪
{S : Sets|∃n, m : dom(I) · g k = (g n); “ ∧ ”; (g m)
∧ S = I n ∧ I m} ∪
{S : Sets|∃n : dom(I) · g k = “¬”; (g n) ∧ S = ¬I n} ∪
...
The vertical ellipsis represents a similar treatment for other
operators and is used to save space. Since g is one-to-one,
only a single set in this union will have an element in it. In
other words, each number is mapped to a single expression
(but not vice-versa). Finally, the interpreter is implemented as
follows.
I = ⟨s : lang → (F (enum s)) (enum s)⟩
(99)
XI. CONCLUSION
We have presented the formalism of an expression in-
terpreter for the purpose of encoding meta-logic within a
logic. This allows effective reasoning with partial terms and
about functional languages. Our technique requires no separate
meta-logic, and we believe that our encoding of expressions
as character strings is simple and transparent. The use of
the interpreter allows proofs with partial terms to proceed
in a fully formal fashion classically; that is, with just the
standard boolean algebra. We show how the interpreter can
be used to create generic and compact laws, which also
allow syntactic reasoning about expressions. We also argue
that the incorporation of the interpreter in theorem provers is
reasonable, since the parsing that is required for its use is an
efﬁcient linear-time algorithm. We show how the interpreter
can be used to implement a logic for functional programming
that allows general recursion while maintaining consistency.

84
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The encoding permits a ﬂexible timing policy of execution,
which also allows reasoning about lazy evaluation.
REFERENCES
[1] L. Naiman, “Using an expression interpreter to reason with partial
terms,” in COMPUTATION TOOLS 2013: the fourth international
conference on Computational Logics, Algebras, Programming, Tools,
and Benchmarking, ser. IARIA ’11, 2011, pp. 37–43.
[2] The Coq development team. (2004) The coq proof assistant reference
manual.
LogiCal
Project.
Version
8.0.
[Online].
Available:
http://coq.inria.fr. Access: 2013-01-20.
[3] C. C. Morgan, Programming from speciﬁcations, 2nd Edition.
Upper
Saddle River, NJ, USA: Prentice Hall, 1994.
[4] C. B. Jones, Systematic Software Development Using VDM (2Nd Ed.).
Upper Saddle River, NJ, USA: Prentice-Hall, Inc., 1990.
[5] G. Kimmell, A. Stump, H. D. Eades, III, P. Fu, T. Sheard, S. Weirich,
C. Casinghino, V. Sj¨oberg, N. Collins, and K. Y. Ahn, “Equational
reasoning about programs with general recursion and call-by-value
semantics,” in Proceedings of the Sixth Workshop on Programming
Languages Meets Program Veriﬁcation, ser. PLPV ’12.
New York,
NY, USA: ACM, 2012, pp. 15–26.
[6] C. B. Jones and C. A. Middelburg, “A typed logic of partial functions
reconstructed classically,” ACTA, vol. 31, no. 5, pp. 399–430, 1994.
[7] C. B. Jones, M. J. Lovert, and L. J. Steggles, “A semantic analysis
of logics that cope with partial terms,” in ABZ, ser. LNCS, J. Derrick,
J. A. Fitzgerald, S. Gnesi, S. Khurshid, M. Leuschel, S. Reeves, and
E. Riccobene, Eds., vol. 7316.
Springer, 2012, pp. 252–265.
[8] C. B. Jones, “Partial functions and logics: A warning,” IPL, vol. 54,
no. 2, pp. 65–67, 1995.
[9] W. Just and M. Weese, Discovering Modern Set Theory. I.
American
Mathematical Society, 1996, vol. 8.
[10] M. Beeson, Foundations of Constructive Mathematics.
New York, NY,
USA: Springer-Verlag, 1985.
[11] ——, “Lambda logic,” in Automated Reasoning: Second International
Joint Conference, IJCAR 2004.
Springer, 2004, pp. 4–8.
[12] R. F. St¨ark, “Why the constant ’undeﬁned’? logics of partial terms
for strict and non-strict functional programming languages,” J. Funct.
Program., vol. 8, no. 2, pp. 97–129, 1998.
[13] R. D. Gumb, “The lazy logic of partial terms,” JSYML, vol. 67, no. 3,
pp. 1065–1077, 2002.
[14] M. J. C. Gordon, R. Milner, and C. P. Wadsworth, Edinburgh LCF, ser.
Lecture Notes in Computer Science.
Springer, 1979, vol. 78.
[15] D. Gries, The Science of Programming.
New York: Springer-Verlang,
1981.
[16] J. Woodcock and V. Bandur, “Unifying theories of undeﬁnedness in utp,”
in UTP, ser. LNCS, B. Wolff, M.-C. Gaudel, and A. Feliachi, Eds., vol.
7681.
Springer, 2012, pp. 1–22.
[17] E.
C.
R.
Hehner,
A
Practical
Theory
of
Program-
ming.
New
York:
Springer,
1993.
[Online].
Available:
http://www.cs.toronto.edu/ hehner/aPToP/. Access: 2014-05-27
[18] ——, “Beautifying g¨odel,” pp. 163–172, 1990.
[19] K. G¨odel, “ ¨Uber formal unentscheidbare S¨atze der Principia Mathemat-
ica und verwandter Systeme,” Monatshefte f¨ur Mathematik und Physik,
vol. 38, no. 1, pp. 173–198, 1931.
[20] R. Zach, “Kurt g¨odel and computability theory,” in Logical Approaches
to Computational Barriers, ser. Lecture Notes in Computer Science,
A. Beckmann, U. Berger, B. L¨owe, and J. Tucker, Eds. Springer Berlin
Heidelberg, 2006, vol. 3988, pp. 575–583.
[21] C. A. R. Hoare and J. He, Unifying Theories of Programming.
New
York: Prentice Hall, 1998.
[22] V. Sj¨oberg, C. Casinghino, K. Y. Ahn, N. Collins, H. D. E. III,
P. Fu, G. Kimmell, T. Sheard, A. Stump, and S. Weirich, “Irrelevance,
heterogeneous equality, and call-by-value dependent type systems,” in
MSFP, 2012, pp. 112–162.

