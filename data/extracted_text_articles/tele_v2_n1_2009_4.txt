Deducing a User’s State of Mind from  
Analysis of the Pictographic Characters and Emoticons used in  
Mobile Phone Emails for Personal Content Delivery Services  
 
Kazumasa TAKAMI†  Ryo YAMASHITA†  Kenji TANI†  
Yoshikazu HONMA† and Shinichiro GOTO‡ 
†Faculty of Engineering, Soka University   
‡NTT Information Sharing Platform Laboratories, NTT Corporation  
†k_takami@soka.ac.jp ‡goto.shinichiro@lab.ntt.co.jp 
 
Abstract - As the ubiquitous environment is taking root, 
there are calls for services that deliver content 
appropriate for the individual user’s personal interests 
and preferences. However, it is difficult to deduce the 
ever-changing preferences of people who live in a 
complicated society. In this paper, we focus on mobile 
phones, whose users are growing in number and which 
offer many sophisticated functions besides the ability 
to talk. We propose a method of deducing the state of 
mind of the user by analyzing the pictographic 
characters and emoticons used in his or her emails. 
Moreover, we have proposed a method of selecting an 
appropriate piece of music based on a music type, 
which is represented by the "number of chords", 
"sound strength", and "melody pattern" in a piece of 
music. We have developed the algorithm to deduce the 
user’s state of mind from an email and applied the 
algorithm to the selection of music, which is 
considered to be close related to people’s feelings.  
 
Keywords; content delivery service; interests and 
preferences; deduction of state of mind; mobile phone 
email; pictographic character; 
 
1. Introduction 
 
As the ubiquitous society develops, the demand for 
personalized services is growing. For example, there is 
a Web mail service that analyzes the text of each email 
received, and delivers advertisements related to the 
words contained in that email [2]. As terrestrial digital 
broadcasting and one-segment TV services become 
widespread and as the memory capacity of mobile 
phones increases, people expect to see personalized 
video or music delivery services. 
To provide personalized services, it is necessary to 
capture the preferences and dynamic state (physical/ 
mental/ emotional) of each user, and to determine the 
type of service to provide in light of the user’s state so 
captured. There have been a variety of studies that 
address these needs [3][4][5]. As regards capturing the 
user’s state, methods of determining the user’s current 
location using GPS [4][5], and of capturing the user’s 
state of mind by text mining have been proposed 
[6][7][8]. However, since text mining requires a vast 
computing time and vast resources, it is unfit for 
capturing the ever-changing state of mind of the user 
in real time. 
By March 2008, the number of mobile phone users 
exceeded one hundred million and is still growing in 
Japan [9]. The mobile phone has evolved into a 
sophisticated mobile information terminal, capable of 
email, Web access, credit card transactions, pre-paid 
card functions, GPS-based navigation, functioning as a 
digital camera and so on, in addition to voice 
communication. This means that a mobile phone is a 
comprehensive treasure trove of the behavior and 
preference information of its user. In particular, more 
than 80% of mobile phone users use pictographic 
characters in order to convey a variety of emotional 
concepts that are difficult to express in text [10][11]. 
Recently, a progress has been made to standardize 
pictographic characters among different mobile phone 
providers. Mobile phone emails have the following 
characteristics: 
y There is a strict restriction on the number of 
characters that can be included in each email, so 
most emails are short, making it relatively easy to 
analyze them. This means that mobile phone emails 
can be analyzed at low cost. 
y The style of writing is relatively close to spoken 
language. A wide assortment of means of 
expression is used, such as symbols, pictographic 
characters, and emoticons. These make it easy for 
the user to write an email that directly reflects how 
he or she feels at the moment. 
We are studying how to deliver content appropriate 
for the user’s current state of mind by analyzing his or 
her interests and preferences in daily life [1]. In 
particular, this paper proposes a method of deducing 
the user’s state of mind by analyzing facial 
37
International Journal On Advances in Telecommunications, vol 2 no 1, year 2009, http://www.iariajournals.org/telecommunications/

<User’s state of mind and interests>
The user is interested in soccer.
He wants to get information about the next game.
<User’s state of mind and interests>
He overslept and is pressed for time because.
He is encouraging a friend who is going to have an interview.
He is interested in noodles.
<User’s state of mind and interests>
He is tired because he has had many things to do.
He will be busy the next day.
Yesterday’s soccer game was exciting. 
We cannot miss the next game.
When will the next game be played?
I woke up late.
Gook luck with your interview
I’m going to eat noodles. 
I am tired because I’ve had many things to do since the 
morning.
I will be busy tomorrow, too. 
ex1
ex2
ex3
<User’s state of mind and interests>
He is sad and very tired.
I want to return home. (´・ω・`)
I feel sleepy because I ate too much fried chicken. (;´Д`)
ex4
The Japanese team don’t seem
to be able to score.
The Japanese team don’t seem to
be able to score.
(a) Anger
(b) Sorrow
pictographic characters and emoticons contained in 
emails exchanged using a mobile phone. We have 
chosen to focus on music because user's feeling is the 
major factor in the selection of music. We have chosen 
to use the "number of chords", "sound strength", and 
"melody pattern" as music elements that characterize a 
piece of music. Based on these elements, we define the 
relationship between a piece of music and a user’s 
feeling. We also propose a method of searching for an 
appropriate piece of music. Section 2 presents the 
information delivery system assumed, and the service 
it provides. This system and service information has 
been used to identify research topics. Section 3 
proposes solutions for these topics. Section 4 describes 
the prototype system developed to evaluate the 
proposed algorithm, the experiments conducted and 
the evaluation results. It also describes the evaluation 
of the algorithm by having a group of students use the 
system, and the evaluation of the music selection 
method. Finally, Section 5 presents the conclusions 
and issues for future study. 
 
2. Content delivery system that involves 
the analysis of mobile phone emails 
 
This section describes examples of email that reveal 
the user’s state of mind and interests, and example of 
use of the information content delivery service. Then, 
the research topics are addressed. 
 
2.1. Emails containing pictographic characters 
and emoticons to express interests and state 
of minds 
 
The words and pictographic characters and 
emoticons in emails reveal the user’s interests and 
preferences, and the user’s expressions (choice of 
words) and types of pictographic characters and 
emoticons reveal the user’s current state of mind and 
the extent of the user’s fatigue. An example of an 
email that reveals the current state of mind and 
interests is shown in Figure 1. The idea, “The Japanese 
team don’t seem to be able to score”, can be expressed 
in different ways, as shown by the two emails in 
Figure 2. Email (a) shows that the user is irritated 
while Email (b) shows that the user is discouraged. So, 
the same sentence can covey a different state of mind 
depending on the pictographic character used. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. Examples of email that reveal the 
user’s state of mind and interests 
 
 
 
 
Figure 2. The same sentence can convey a 
different state of mind. 
2.2. Content delivery system 
 
With this system, we aim to determine the user’s 
interests, preferences, and the extent of his or her 
fatigue by consecutively analyzing emails containing 
pictographic characters that he or she exchanges daily 
with friends and family members, and to deliver 
content that is appropriate for his or her interests and 
current state of mind. An example of potential use of 
the service to be provided by this system is shown in 
Figure 3. The service proceeds as follows: 
1) The user exchanges emails with friends as usual. 
2) An application extracts and analyzes words, 
pictographic characters and emoticons contained in 
these emails. 
3) The application determines the user’s interests and 
current state of mind and saves that data in the 
mobile phone. 
4) When the user wants to receive content 
appropriate for his or her interests and state of mind, 
38
International Journal On Advances in Telecommunications, vol 2 no 1, year 2009, http://www.iariajournals.org/telecommunications/

the analysis result in 3) is sent to his or her TV 
(which relays the result to the delivery server). 
5) The delivery server delivers content appropriate 
for the user. 
 
2.3. Research topics 
 
(1) Classify and characterize pictographic characters 
and emoticons. 
In order to allow the deduction of the users’ interests 
and state of mind from the pictographic characters and 
emoticons used in his or her emails, it is necessary to 
determine the deeper meaning that each pictographic 
character and emoticon conveys [12]. 
(2) Establish an algorithm to determine the user’s 
interests and state of mind. 
It is necessary to establish an algorithm to determine 
the user’s interests and state of mind from the words, 
pictographic characters and emoticons contained in his 
or her email.  
(3) Establish an algorithm to determine the appropriate 
content to be delivered. 
It is necessary to establish an algorithm for selecting 
the content appropriate for the user, based on his or her 
interests, preferences and state of mind, which have 
been deduced from his or her email. 
 
3. Proposed algorithms 
 
This section describes our solutions to topics (1) (2) 
and (3) identified in Section 2.3. 
 
3.1. Algorithm for determining interests and 
preferences 
 
Figure 4 shows the algorithm for determining 
interests and preferences from words, pictographic 
characters and emoticons contained in an email, and 
for deducing the state of mind and extent of fatigue 
from the expressions, pictographic characters and 
emoticons used. 
The interests and preferences are deduced from 
words that indicate interests, such as baseball and 
tennis, and pictographic characters that indicate 
interests, such as   and  , and also from past 
analysis results. Similarly, the state of mind and extent 
of fatigue are deduced from expressions used (choice 
of words), the percentage of pictographic characters 
and emoticons used in email text, and the types of 
pictographic characters and emoticons used. It can be 
assumed that a person in a poor state of mind tends to 
use plain or blunt expressions, that a person in a better 
mood tends to use pictographic character and 
emoticons more often, and that a person uses different 
types 
of 
pictographic 
character 
and 
emoticon 
depending on his or her state of mind. To confirm 
these 
assumed 
tendencies, 
we 
conducted 
a 
questionnaire survey with nine frequent users of email. 
More than half of the respondents said that they use 
more pictographic characters and emoticons when they 
are in a better mood, and almost all of them said that 
the pictographic characters and emoticons they choose 
reflect their state of mind. 
We propose the algorithm for deducing the state of 
mind and extent of fatigue from pictographic 
characters and emoticons shown in Figure 4. 
 
Figure 3. Example of use of the information content delivery service 
Today’s movie was 
interesting.
Let’s see an action 
movie next time.
My PC seems to 
be in trouble.
What happened?

Extracted words
From 1st email:
・movie
・action movie
From 2ndemail:
・PC
Extracted pictographic 
characters and emoticons
From 1st email:
・
From 2ndemail:
・
From 3rd email:
・ (´・ω・`)(;´Д`)
It is determined that the 
user is “interested in 
action movies and slightly 
dejected, sad, tired.”
Save
Send emails
Send info about interest 
and state of mind
Deliver a movie or a music
I want to return 
home. (´・ω・`)
I feel sleepy because 
I ate too much fried 
chicken. (;´Д`)
39
International Journal On Advances in Telecommunications, vol 2 no 1, year 2009, http://www.iariajournals.org/telecommunications/

3.2. Algorithm for deducing the state of mind 
from pictographic characters and emoticons 
 
In this paper, we focus on the pictographic 
characters offered in NTT DoCoMo’s [13] mobile 
phone service and emoticons, including 2-byte 
characters. Today, more than 200 pictographic 
characters and more than 1000 emoticons are used. In 
order to narrow down the list and select only those 
pictographic characters and emoticons useful for 
deducing the state of mind, we classified and 
characterized them in the following sequence of steps. 
 
3.2.1. Selection and classification of pictographic 
characters 
and 
emoticons. 
We 
selected 
43 
pictographic characters that were found to express 
facial 
expressions 
and 
feelings. 
From 
among 
frequently used emoticons pre-installed in mobile 
phones and other emoticons, including 2-byte 
characters, we selected 64 emoticon that were found to 
indicate feelings clearly. 
 
3.2.2. Classification of state-of-mind elements and 
weighting factors. We selected six state-of-mind 
elements: happy, angry, sad, optimistic, tired and  
affectionate. 
The 
newly 
selected 
element, 
“affectionate”, is usually not relevant to the selection 
of an item of content, but is used only when its value is 
extremely high or extremely low. Since one 
pictographic character or emoticon can convey a 
variety of feelings, each is defined as a combination of 
vector values of several state-of-mind elements. The 
vector value of each element ranges from 0 to 5. For 
example, for one pictographic character “”,  a vector 
value 5 may be assigned to “happy”, 0 to “angry”, 
0 to “sad”, 3 to “optimistic”, 0 to “tired”, and 
2 to “affectionate”. 
We conducted a questionnaire survey with 36 
students (29 males and 7 females) in our university to 
validate our selection of the six state-of-mind elements, 
and to determine the vector values of each pictographic 
character. We asked the students to select the states of 
mind that are associated with each pictographic 
character or emoticon. The distribution of state-of-
mind elements for each pictographic character is 
shown in Figure 5. The value of each state-of-mind 
vector was normalized by dividing the total votes in 
the survey by the number of respondents, and 
multiplying the result by 50. The one decimal place of 
this value was rounded off. A small number of 
respondents suggested the inclusion of “surprised” and 
“worried” as possible state-of-mind elements, but most 
claimed that the six states-of-mind elements were 
appropriate and sufficient for mapping the pictographic 
characters and emoticons. Examples of vector values 
for some pictographic characters are shown in Table 1. 
With some pictographic characters, a few students 
associated states of mind that are quite different from, 
or even opposite to, those of other students. The 
differences were particularly pronounced between 
male and female students. However, the majority gave 
consistent 
associations 
between 
pictographic 
characters and emoticons and states of mind. 
Figure 4.  Algorithm for determining interests and preferences 
Words
Words, such 
as baseball 
and tennis, 
used in email 
text
The words 
indicate 
interests or 
the current 
state.
Expressions
Choice of words 
in email text
Choice of words 
reflects the 
current state of 
mind.
Pictographic 
characters
“” means golf.
“” means 
soccer, etc.
Some 
pictographic 
characters 
directly indicate 
interests.
Total of scores of pictographic 
characters and emoticons
A score is assigned in advance to 
each pictographic character and 
emoticon that is likely to indicate 
state of mind, and the scores of the 
pictographic characters  and 
emoticons contained in an email 
are totaled.
The better the state of mind, the 
higher is the total.
Number of pictographic 
characters and emoticons
The number and percentage 
of pictographic characters  
and emoticons in an email
The user tend to use more 
pictographic characters and 
emoticons when he or she is in 
a good state of mind
Determine interests and 
preferences
Determine state of mind and 
extent of fatigue
Weighted total
Weighted total
Results of 
previous 
analyses
40
International Journal On Advances in Telecommunications, vol 2 no 1, year 2009, http://www.iariajournals.org/telecommunications/

Table 1. Example of state-of-mind vectors of 
individual value 
 
 
 
 
 
 
 
 
3.2.3. Use the regular expression for searching. In 
order to find emoticons efficiently, we chose to use 
pattern matching of character strings in an email. A 
new emoticon is often created by adding a character(s) 
to an existing emoticon. For example, the emoticon 
(^o^) (smiling face) is expanded to ＼ (^o^) ／  or 
v(^o^)v. If the regular expression is used, a pattern 
matching operation can find not only (^o^) but also ＼
(^o^) ／  and v(^o^)v. Since the meanings of these 
derivatives are not so different from the original 
emoticon, this search method is effective in finding 
emoticons that have been created by adding parts to an 
existing emoticon. 
 
3.2.4. Algorithm for determining states of mind 
from pictographic characters and emoticons. We 
assume that the state of mind of a person can be 
expressed by a finite number of state-of-mind elements. 
Therefore, we express the state of mind using k-
dimensional vectors.  
Suppose there are m pictographic characters and 
emoticons in an email text, M. Then, the state-of-mind 
vector ε(pi) of an individual pictographic character or 
emoticon pi can be expressed as: 
Where eji indicates the intensity of the specific state-
of-mind element. The state-of-mind vector that can be 
deduced from the pictographic characters used is 
defined as: 
ωp is a weighting factor. It reflects such factors as the 
ratio of the number of pictographic characters to the 
number of emoticons or the ratio of the number of 
males to the number of females. 
The algorithm for calculating the state-of-mind 
vector F(M) is as follows. Note that the state-of-mind 
vector of each pictographic character or emoticon 
(such as the one in Table 1) is pre-registered in the 
database. 
Step 1: Extract a pictographic character or emoticon 
pi by analyzing the mail text. 
Step 2: Find the state-of-mind vector values for each 
of m pictographic characters and emoticons 
pi in the database. 
　
∑
=
=
m
i
i
p
p
m
M
F
1
)
(
1
)
(
ε
ω r
r
)
1,
(
)
(
)
(
1
m
i
M
p
e
p
i
j k
ji
i
≤ ≤
∈
=
≤ ≤
　　
εr
Figure 5. Result of questionnaire survey on the relationship between pictographic 
characters, emoticons and states of mind 
0 %
20%
40 %
60 %
8 0%
100 %
Happy
Angry
Sad
Optim istic
Tired
Affectionate
Σ (￣ □ ￣ ;)
(´・ω ・`)
(T _T )
(>_< )
(`・ ω ・´ )
(￣ ＾￣ )
(*^-^)b
(≧ ∇ ≦ )
(*^-^*)
(^o^)










State of mind
elements
Characters

5
0
0
3
0
2

3
0
0
2
0
5
(^-^)
5
0
0
2
0
3
(>_<)
2
0
5
1
3
2
Happy Angry
Sad
Optimistic Tired Affectionate
41
International Journal On Advances in Telecommunications, vol 2 no 1, year 2009, http://www.iariajournals.org/telecommunications/

Step 3: Obtain F(M) by calculating the average 
vector value of each state-of-mind element 
for m pictographic characters and emoticons. 
 
3.3. Composition of the music database and 
database search method 
 
In order to determine the music type (number of 
chords, sound strength, and melody pattern) that the 
user is likely to want to hear at present, we analyze the 
state-of-mind elements. We have developed an 
algorithm for a music search and delivery system. 
We created 12 MIDI (Musical Instrument Digital 
Interface) files in different music categories with 
different 
chord 
patterns. 
We 
investigated 
the 
relationship between music types and the states of 
mind with 24 students. We asked them to write ○ 
when the music type they heard matched their state of 
Table 2. Related data base of rhythm and state of mind 
Chord
Ratio Volume
Melody
Happy
Angry
Sad
Optimistic
Tired
Affectionate
Music １
Blues
B♭major B♭7
6.0
E♭7
3.0
Cm7
1.5
F7
1.5
Edim
1.0
Music ２
Bop
E♭major B♭m7
1.0
Cm7
1.0
Music ３
Country
Cmajor
F
1.0
G
1.0
Em
1.0
Am7
1.0
Music ４
Pops
Cmajor
F     Bb
1.0
Fmajor
G     C
1.0
Em   Am
1.0
Am7 Dm
1.0
Music ５
Classic
D♭major D#m
7.0
C#
2.0
B
5.0
D#sus4
4.0
G#m
1.0
C#sus4
1.0
Music ６
R＆B
Cmajor7
CM7
1.0
C6
1.0
Dm7
1.0
Dm6
1.0
Music ７
Rock
Cmajor7
FM7
1.0
G
1.0
Em
1.0
G9
1.0
Music ８
Latin
Cmajor7
CM7
2.0
Dm7
1.0
D♭M7
1.0
Music ９
Jazz samba
Emajor
D
1.0
E
1.0
F#m
0.8
G#m(♭5) 0.5
A
2.8
Bm
1.8
A#aug
1.0
Music １０ Ballad
Cmajor
A7sus4
2.5
D9
1.5
Music １１ Techno
Aminor
DM7
1.0
E6
1.0
Music １２ Rock
Ｄmajor
Ｄ
5.0
Ｇ
4.0
Ａ
2.0
Bm
1.0
passing tone
Large
Small
passing tone
Small
passing tone
passing tone
Large
auxiliary tone
Large
passing tone
Large
auxiliary tone
Small
auxiliary tone
Small
auxiliary tone
Small
auxiliary tone
Small
auxiliary tone
Large
-0.6
-0.6
0.4
0.2
-0.4
-0.6
-0.6
-0.4
2.5
0.4
-0.4
0.2
-1.0
0.6
1.7
-1.7
-1.9
3.3
2.5
1.7
2.9
-1.3
-0.4
1.5
0.6
0.8
2.7
-1.7
0.8
-1.3
1.3
1.0
-0.8
2.3
3.1
0.0
1.3
1.7
-0.2
1.0
1.0
1.7
3.0
2.0
1.7
-0.4
-1.7
-0.2
-0.4
1.7
1.9
0.6
1.0
0.8
-1.7
-0.4
Category
Key
Rhythm
4.4
0.2
1.0
auxiliary tone
Large
0.0
2.0
-1.0
2.0
1.0
-3.0
4.0
-2.0
0.0
1.0
State of mind
2.9
-2.3
-1.7
42
International Journal On Advances in Telecommunications, vol 2 no 1, year 2009, http://www.iariajournals.org/telecommunications/

mind, × when they did not match, and nothing (space) 
when neither of them was true. If ○, 1 is added to the 
value. If ×, 1 is subtracted from it. If nothing, no 
operation was made. The state-of-mind value was 
calculated by dividing the total by the number of 
people, and multiplying it by 5. The results for each 
music type are shown in Table 2. 
We created music metadata that consists of music 
title, category, key, chord, and state-of-mind elements. 
Music type data was extracted from each MIDI file. 
The state-of-mind data was obtained by searching the 
basic element database. The process of deriving state-
of-mind element data from a MIDI file (MUi) is as 
follows. 
Step 1: Extract the number of chords, volume, and 
melody pattern from the MIDI (MUi) file. 
Step 2: Compare these with data in the basic element 
database (Table 2), and determine the music 
type that best matches the extracted data. 
Step 3: Obtain the state of mind element values from 
the matched music type, and register them as 
the state of mind values of MUi. 
Step 4: Repeat steps 1 to 3 for MU0 to MUj. Build a 
music database for each of MU0 to MUj. 
Step 5: Compare the user’s actual feeling data with the 
feeling element data in the music database, and 
determine that music that best match each other. 
 
4. Development of a prototype system and 
evaluation 
 
This section describes our prototype system to 
evaluate the proposed methods and the experimental 
results also. 
 
4.1. Prototype evaluation system 
 
We 
implemented 
the 
state-of-mind 
deducing 
algorithm and the state-of-mind element database for 
the proposed pictographic characters and emoticons on 
a PC. In order to collect sample mails and evaluate the 
algorithm, we built a website with an input form 
written in JavaScript. The form enabled the user to 
input his or her personal information, such as name, 
gender, age, and the prefecture in which he or she had 
been brought up, as well as mail sentences and his or 
her subjective feeling values. We used a set of "i-
pictographic characters [14]" for the input of 
pictographic characters, and a piece of free software 
called "Emoticon Helper Mini [15]" for the input of 
emoticons. The prototype software was written in Perl. 
The state-of-mind database was built using MySQL. 
We registered the state-of-mind elements and scores of 
43 pictographic characters and 64 emoticons in the 
database. Figure 6 shows the configuration of the 
prototype system. The system operates as follows.  
Step 1: The user inputs an email that contains 
pictographic characters and emoticons using the 
input form. The user also inputs his or her 
subjectivity values. 
Step 
2: 
Extract 
pictographic 
characters 
and 
emoticons that express user's feelings from the 
email text. 
Step 3: Access the MySQL database to extract the 
score of each state-of-mind element of the 
pictographic characters and emoticons. 
Step 4: Calculate the state-of-mind element score, 
and deduce the state of mind. Identify the three 
strongest emotions in each state of mind. 
Step 5: Save the email text and the deduction result 
in text form. 
Figure 6. Block diagram of the system and programs developed 
Windows
HTML input form
in JavaScript
Input tools of 
pictographic characters 
and emoticons
Main programs
of algorithm
(Perl)
MySQL database of 
pictographic characters
and emoticons
Deduction result
(Perl)
Input data and
state-of-mind
deduction result
:Developed programs
IE display
Input
Text preservation
Inquiry
Read
Return
Display
①
②
③
④
⑤
⑥
43
International Journal On Advances in Telecommunications, vol 2 no 1, year 2009, http://www.iariajournals.org/telecommunications/

Step 6: Display the extracted pictographic characters 
and emoticons, the user's subjectivity feeling 
value, and the state-of-mind deduction result. 
 
4.2. Evaluation 
 
We collected one sample mail from each of 64 
students (43 males and 21 females) by using a 
prototype system. We calculated the state-of-mind 
value of each person and compared it with each 
person's subjective feeling value. Using this result, we 
excluded the item of data with the highest state-of-
mind value and the item of data with the lowest value, 
leaving 62 items of data for evaluation.  
Figure 7. Correlation between the subjective value and the evaluation value 
(Note：◆Male  ■Female) 
Happy
0
1
2
3
4
5
0
1
2
3
4
5
Subjective value
Evaluation value
Angry
0
1
2
3
4
5
0
1
2
3
4
5
Subjective value
Evaluation value
Sad
0
1
2
3
4
5
0
1
2
3
4
5
Subjective value
Evaluation value
Tired
0
1
2
3
4
5
0
1
2
3
4
5
Subjective value
Evaluation value
Affectionate
0
1
2
3
4
5
0
1
2
3
4
5
Subjective value
Evaluation value
Optimistic
0
1
2
3
4
5
0
1
2
3
4
5
Subjective value
Evaluation value
44
International Journal On Advances in Telecommunications, vol 2 no 1, year 2009, http://www.iariajournals.org/telecommunications/

The correlation between the calculated state-of-
mind value and the subjective self-declared feeling 
value for each state-of-mind element is shown in 
Figure 7. The correlation for “angry” was the highest 
(the correlation coefficient = 0.66), and that for 
“affectionate” the lowest (the correlation coefficient = 
0.34). The correlation coefficients for “happy”, “sad”, 
“optimistic” and “tired” were 0.53, 0.65, 0.35 and 0.49, 
respectively. The average was 0.5. These results were 
more or less what we had expected. The definitions of 
"optimistic" and "affectionate" were vague and 
differed between genders and between individuals. The 
definitions of these states of mind made by the students 
may have been different from what we had in mind, 
and this fact would explain the low correlation for 
“anger” and “affectionate”. Overall, the correlation 
coefficients of the female students were lower than 
those of male students. This is probably because there 
were more male students than female students among 
our subjects. 
Figure 8 shows the statistics of the correlation 
between subjective feeling values and calculated 
values of all state-of-mind elements. The average 
correlation coefficient value for males and females 
were 0.63 and 0.57, respectively, and the overall 
average was 0.61, which is sufficiently high. 
We evaluated whether an appropriate item of music 
can be selected from the state-of-mind values by 
referring to the music database. We selected three 
students (two males and one female) who recorded a h  
igh correlation value. Specifically, w  e compared the 
strong state of mind obtained from the deduction result 
with data in the database shown in Table 2, and 
selected three pieces of music. We checked whether 
the pieces of music selected matched their feelings. We 
asked each student to write ◎  if the first piece 
matched their feeling,  ○ if the second piece matched 
their feeling, △ if the third piece matched their feeling, 
and  × if none of the three pieces matched their 
feeling.  The results are shown in Table 3. 
The piece number in Table 3 correspond to the piece 
number in Table 2. The piece encircled by ○ is the 
one that matched the subject’s feeling. The state-of-
mind element to which the woman gave the highest 
value was "affectionate." However, since that value 
Table 3.  Evaluation of music recommendation method 
Items
Individual's
Selected
Gender First element Second element Third element correlation coefficient piece of music
Male 1
Sad
Tired
Angry
0.705
3,12, 10
△
Male 2
Sad
Tired
Happy
0.828
10
◎
Female Affectionate
Happy
Optimistic
0.975
4,1, 9
△
Strong state-of-mind element presumed
Evaluation
Figure 8. Statistical graph of individual correlation value 
-0.3
-0.1
0.1
0.3
0.5
0.7
0.9
1
6
11
16
21
26
31
36
41
[Number
of samples]
[Correlation
coefficient]
Male
Female
45
International Journal On Advances in Telecommunications, vol 2 no 1, year 2009, http://www.iariajournals.org/telecommunications/

was not pronounced, we selected pieces mostly from 
"happy" and "optimistic". We found that at least one of 
the three pieces selected matched the subject’s mood. 
Some answered that the second or the third piece best 
suited his or her mood. We find that the evaluation 
result was relatively good. 
 
5. Conclusion and future work 
 
We have proposed an algorithm for deducing the 
user’s state of mind from the pictographic characters 
and emoticons contained in emails, and evaluated its 
feasibility. We have studied the state-of-mind elements 
associated with pictographic characters and emoticons, 
and their weighting factors, and have introduced 
specific values for the weighting factors. We have 
studied the algorithms for extracting pictographic 
characters and emoticons from an email, and for 
deducing the user’s state of mind from the state-of-
mind elements of the extracted pictographic characters 
and emoticons. We have developed a program that 
implements this algorithm, and a prototype evaluation 
system. Using this system, we have verified the 
effectiveness of the proposed algorithms. 
We have also presented an algorithm for extracting 
the number of chords, volume and melody from a 
piece of music. We have identified the relationship 
between the user's state of mind and the music type he 
or she is likely to want to hear, and evaluated the 
relationship. 
Future issues include the method of sending the 
obtained state-of-mind information to the delivery 
server, and the method of sending the appropriate 
content from the delivery server to the user. It is 
necessary to study how to automate the processes for 
determining and providing content appropriate for the 
user based on the obtained state-of-mind information. 
To sum up, future issues include the following: 
• Algorithm for deducing user’s state of mind from 
multiple emails that the user has sent in the last few 
hours in order to take the immediate trend of the 
user’s state of mind into consideration. 
• Algorithm for searching for and analyzing more 
types of emoticons and detailed parts of emoticons, 
such has eyes, mouth, cheek and hand. 
• How to deduce changes in the user’s state of mind as 
the exchange of emails progresses. 
• How to automate the processes for determining and 
providing content appropriate for the user, based on 
the obtained state-of-mind information. 
• Algorithm for deducing more detailed state-of-mind 
data instead of a simply state-of-mind element value 
calculated by the system, in order to achieve a 
stronger linkage with the service of content delivery. 
 
References 
 
[1] 
Kazumasa 
TAKAMI, 
Yoshikazu 
HONMA 
and 
Shinichiro GOTO: “A method of deducing a user’s state 
of mind from an analysis of the pictographic characters 
used in mobile phone emails”, in proceedings of 
UBICOMM2007, pp.83-88, 4-9 November 2007. 
[2] Gmail, http://mail.google.com/ 
[3] Ono, C., Motomura, Y. and Asoh, H., “Study of Movie 
Recommendation System Considering Both Users' 
Personality and Situation”, IPSJ SIG Technical Report 
2005-DPS-125, pp.79-84, 2005 
[4] Kikuchi, T., Sakai, H., Sueda, Y. and Murakami, K., 
“Context-aware human-activity support based on activity 
affinity-level measuring method”, FIT 2003, pp.361-362, 
2003. 
[5] 
Mase, 
T. 
and 
Nakayama, 
Y., 
“Design 
and 
Implementation of Information Provision System Based 
on Position and User's Preference”, FIT  2004, pp.157-
158, 2004. 
[6] H. Yokono, “Categorizing model expressions of dialogue 
sentences for emotion presumption,” IPSJ SIG Technical 
Report 2005-NL-170, pp.1-6, 2005. 
[7] T. Kumamoto and K. Tanaka, “Extracting Feelings from 
Newspaper Accounts on the Web,” IPSJ SIG Technical 
Report 2005-NL-165, pp.15-20, 2005. 
[8] Nakayama, N., Eguchi, K. and Kando, N., A Proposal for 
Extraction of Emotional Expression, IPSJ SIG Technical 
Report 2004-NL-164, pp.13-18, 2004. 
[9] Telecommunications Carriers Association, Number of 
contracts according to entrepreneur, 
http://www.tca.or.jp/japan/database/daisu/yymm/0803ma
tu.html 
[10] Workshop on the Fortune-telling with Pictograph, “The 
Fortune-telling with Pictograph”, JIMOS(2005, in 
Japanese). 
 [11] Shimizu, Y. and Akama, H., Various Meanings of 
Mobile Icons - Their Understandability Depending on 
Semantic Categories -, Proceedings of the 2005 Spring 
Conference of JSKE, pp.70-73, 2005. 
[12] H. Cho, R. Inaba and T. Ishida, “Semantics in Pictogram 
Communication,” IPSJ SIG Technical Report 2006-ICS-
145, 2006/10/25. 
 [13] NTT DoCoMo,  
http://www.nttdocomo.co.jp/service/imode/make/conten
t/pictograph/index.html 
[14] i_pictographic characters Ver.1.21,  
http://www.nttdocomo.co.jp/service/imode/make/conten
t/pictograph/tool. 
[15] Emoticon helper mini Ver.2.01, 
http://www.vector.co.jp/soft/dl/win95/writing/se102620
.html 
 
46
International Journal On Advances in Telecommunications, vol 2 no 1, year 2009, http://www.iariajournals.org/telecommunications/

