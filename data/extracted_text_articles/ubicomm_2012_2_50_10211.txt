User-Centric Personalization and Autonomous Reconfiguration 
Across Ubiquitous Computing Environments 
 
 
 
 
 
 
 
 
 
Abstract—In the era of Ubiquitous Computing (UbiComp), 
during our typical daily routines we may encounter multiple, 
shared and heterogeneous UbiComp environments across various 
locations. As these environments are meant to be shared between 
multiple users, interaction control methods (gestural, touch, voice 
commands, etc.) and the contexts (light, temperature, sound, 
informational services, etc.) of the environment are not 
personalized for individual users naturally. Typically, users are 
required to manually configure interaction preferences and 
conditions each time they encounter UbiComp systems. This 
however, refers to a tedious and redundant reconfiguration 
procedure, which is against the concept of UbiComp. In this 
paper, we present our work targeting on improving the 
personalization and reconfiguration procedure. Firstly, a user-
centric personalization approach is proposed for facilitating users 
in determining how an UbiComp environment should adapt to 
their own preferred configurations. Then, an autonomous 
reconfiguration procedure is proposed, ensuring that a user’s 
preferences are maintained and accessible across multiple 
ubiquitous computing environments seamlessly.  
 
Keywords-Ubiquitous 
Computing; 
personalization; 
reconfiguration;  human computer interaction. 
I. 
 INTRODUCTION 
Current approaches for personalization in Ubiquitous 
computing (UbiComp) environments are mostly based on 
determining a user’s context in order to provide customized 
content 
or 
services. 
Dominated 
by 
developer-centric 
approaches, users are provided with content and services, 
which are statistically or commonly meant to be suitable for 
their current situation. However, a user’s preferences can often 
conflict with these provided services. Therefore, even though 
applications may enable many proactive services, users still 
expect to personalize applications further to suit their own 
particular preferences [1, 2, 3, 4]. Conventional developer-
centric approaches towards personalization in UbiComp 
environments constrain users in taking an active role in 
determining their own preferences for interaction controls and 
conditions. We believe that in UbiComp environments it is 
necessary that users should be supported in taking a dominant 
role in further personalizing how the environment needs to be 
interacted with and how the conditions of the environment 
should suit their preferences accordingly.   
 
There is another issue that so far, personalization 
approaches have been quite isolated, and demonstrated 
partially without considering maintaining the consistency of  
 
personalized interaction controls and conditions across 
multiple environments. UbiComp envision a world where 
implicit interactions between humans and computers naturally 
take place across multiple interfaces of multiple environments 
[5, 6]. As UbiComp environments proliferate in size and 
diversity across many locations, taking a holistic approach in 
designing personalization approaches turns out to be more and 
more important [7]. Ensuring personalized interaction control 
and condition preferences are consistent and memorable 
across multiple UbiComp environments are also reflecting the 
importance for adhering to existing usability design principles 
as founded from the HCI research domain [8, 9, 10, 11, 12]. 
Meanwhile, the usability standards need to be extended further 
and applied towards personalization approaches for UbiComp, 
as they will be integral for ensuring effective usability and 
user experience in the future. However, conventional 
personalization approaches demonstrated are impractical for 
users within a shared UbiComp environment. For instance, 
once a system is personalized, user’s preferences are mostly 
stored with it, which potentially may be shared and used by 
many other users, to whom the UbiComp system may have to 
be manually reconfigured each time. Many other issues have 
been highlighted revealing how the identification and 
ownership of users’ profiles may become susceptible to 
privacy and security concerns as users’ preferences are left 
stored on UbiComp systems. 
 
In this work, we primarily focus on a user-centric 
personalization approach for personalizing and reconfiguring 
conditions 
and 
interaction 
controls 
across 
UbiComp 
environments. The proposed approach indicates a way where 
personalization is determined by the user, who takes an active 
role in defining how UbiComp environments need to be 
interacted with, and how the environments should be 
configured based on their own preferences. An autonomous 
reconfiguration procedure has also been proposed as to 
seamlessly maintain consistency of users’ personal preferences 
across multiple shared UbiComp environments. Environments 
are automatically reconfigured according to current users’ 
preferences each time they encounter them. This ensures that a 
user does not have to explicitly and manually reset each 
system each time. To demonstrate more practically, we have 
developed a testbed with a personal wearable device, which 
stores a user’s preferences and provides them to the UbiComp 
environments. 
 
Kevin O’ Mahony, Jian Liang, Kieran Delaney 
NIMBUS Centre 
Cork Institute of Technology 
Cork, Ireland 
kevin.omahony, jian.liang, kieran.delaney@cit.ie 
 
48
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

Approaches suitable to resolve privacy and security 
concerns, where UbiComp environments resources and users 
profiles are protected from unauthorized access, have been 
considered as separated research topics in regards to the focus 
of our work. The provisioning of user profiles between the 
UbiComp environments and the user is only available when 
authentication is firstly accomplished. The personal device for 
keeping user’s preferences can be integrated with many 
authentication subsystems, such as biometric checking, to 
prevent unauthorized usage. Therefore, a user is not required 
to repeat authentication through the more typical approaches. 
Another consideration we have made is the management of 
concurrency issues of an UbiComp environment, which can be 
modeled separately and solved systematically on the backend 
so that end users are protected from the complexity of 
potential 
interactivities. 
Finally, 
it 
is 
proposed 
that 
systematically, ownership and privacy of user’s preferences 
are protected; as user’s “profiles” are only shared during the 
session when the user is active in the UbiComp environment.  
  
The rest of the paper is organized as follows: we position 
our work against other related research in Section II. Then, the 
user-centric methodology is presented in Section III. Technical 
implementation details are explained in Section IV. To 
demonstrate, a user case scenario is described in Section V, 
where evaluations from two experiments are presented.  At the 
end of the paper, our findings and future work are discussed in 
Section VI. 
II. 
RELATED WORK 
In this work, we primarily focus on user-centric 
personalization and autonomous reconfiguration of interaction 
control 
and 
condition 
preferences 
across 
UbiComp 
environments. This is distinctive from most personalization 
research in the UbiComp domain, which has concentrated 
primarily on personalization of information (graphical user 
interfaces and informational content) displayed on interface 
screens. 
 
Research has explored how user-centric personalization 
approaches can support users in configuring user preferences 
further due to the versatile characteristics of UbiComp. Such 
work from Atia and Tanaka [13] has demonstrated this where 
context parameters affect gesture-based interaction in 
UbiComp environments. Their experiments show positive 
results of how user interaction performance and experience is 
impacted when context parameters in UbiComp change. They 
also highlighted that people like to customize hand gestures 
accordingly when context parameters change in a situation. 
Kawsar and Nakajima have presented Persona [4], which is a 
portable tool that enables existing proactive systems 
applications to become extended to support multimodal 
personalization. These user centric approaches have illustrated 
the core concept of personalization and its necessity. However, 
once a user specifies one personalized configuration on one 
system, it is typically inaccessible across multiple systems, as 
the personalized settings are only stored on local system 
repositories. The user, therefore, has to manually personalize 
each system they encounter, new or shared interactive 
systems.  Protecting ownership and access to personalized 
settings are in potential risk in this way also.  
 
We focus on related research, which advocate user-centric 
personalization approaches, which address the challenges 
users experience interacting across multiple UbiComp 
environments. A key challenge addressed in the related 
research focuses on how the UbiComp environments should 
also automatically adapt enabling users to access their 
preferences 
across 
multiple 
UbiComp 
environments. 
However, to adhere to the ethos of UbiComp this transition 
should happen seamlessly without interrupting users natural 
activities 
within 
environments. 
Adapting 
UbiComp 
environments is primarily based on the provisioning of user 
preferences (user profiles) to UbiComp systems. As mobility 
support is fundamental to the principles of UbiComp, 
approaches towards provisioning and accessing user profiles 
across multiple UbiComp systems has become an issue for 
contention. Some approaches [4, 13] have stored user profiles 
on individual stationary systems; however, as mentioned 
previously user profiles become inaccessible and more 
vulnerable towards privacy and security concerns in this way. 
Other approaches propose storing user profiles on remote 
centralized repositories where access is dependent on Internet 
connectivity [14]. Microsoft has submitted a patent titled 
“Gesture Personalization and Profile Roaming” [15] which 
details how Microsoft’s Kinect system learns a user’s 
movements and stores this information as personalized 
gestures in a roaming profile. This ensures that when a user is 
using any Kinect System regardless of locations, personalized 
gestures can be accessed remotely over a network (Gesture 
Roaming). Since the user’s personalized gestures are 
recognizable to the system, the system can perform more 
responsively and accurately. However, gesture profiles are 
inaccessible if there is no connection to the remote profile 
repository.  
 
More related approaches to our work focuses on storing 
user preferences as user profiles on users’ personal mobile 
devices. Personal devices such as mobile phones are now 
equipped with supporting technology and carried with the 
user, therefore it seems like a suitable approach for 
provisioning user profiles to UbiComp systems practically.  
Such work by [7, 14, 16] has used personal mobile phones, 
where users profiles are shared between the user’s mobile 
phone and a UbiComp System.  In our work, we have 
considered the impracticalities of this approach from a 
usability and user experience perspective. The mobile phone is 
used as a peripheral device as it is carried and held by the user 
for the provisioning of user profiles to UbiComp systems. The 
natural interaction flow is therefore interrupted as the user is 
required to engage with the mobile phone device in order for 
the UbiComp system to be reconfigured suiting users 
preferences, however this apporach conflicts with the 
principles of UbiComp which seek to maintain seamless and 
49
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

natural interaction. Also, a mobile device itself is a peripheral 
device to a user; it is susceptible to risk like other peripherals, 
like being stolen and unintentional exposure of private 
information 
to 
others. 
Therefore, 
we 
considered 
an 
autonomous reconfiguration approach, which would be more 
seamless, and natural, unhindering implicit interaction 
between the user and the UbiComp environment. 
 
A major aspect of UbiComp is mobility, as users naturally 
interact with a variety of shared systems across many 
locations, user profiles should be seamlessly and safely 
accessable where UbiComp systems they encounter do not 
require explicit manual reconfiguration by the user. In our 
work, we believe that a user’s profiles should be stored, 
maintained and utilized with minimum effort from the user. 
For this work, a specifically designed device is dedicated to 
the role of keeping profiles and exchanging profiles with the 
UbiComp environments when user encounters them. Ideally, 
any carriable devices, such as mobile and PDA can fulfill the 
tasks as long as they are not interrupting user’s natural 
interaction with environments.  
 
III. 
USER-CENTRIC METHODOLOGY 
A 
user-centric 
methodology 
describes 
standardized 
approaches for user-centric personalization and autonomous 
reconfiguration of interaction control and conditions across 
UbiComp environments.  
 
A. User-Centric Personalization 
User-centric personalization is embodied through enabling 
users to determine themselves how conditions such as (light, 
temperature, sound, information services, etc.) in a UbiComp 
environment, should respond concurring with their own 
personal preferences for particular contexts. Also, through 
enabling users to map interaction control techniques (gestural, 
touch, voice commands, etc.) with actions to be performed, 
conditions such as (light, temperature, sound, information 
services, etc.) can be explicitly controlled based on users 
interaction control preferences.  
 
A primary form factor intrinsic to supporting our user-
centric personalization approach will be a wearable NFC 
device, which can be carried by a user. This device will be 
used for bridging the gap between the user and the UbiComp 
environment 
for 
the 
purpose 
of 
personalization 
of 
environmental conditions and control interactions. We apply a 
user-centric personalization procedure where the user is 
provided with a personalization management capability 
through an application deployed on a touchable interface 
(NFC enabled Smartphone).  
 
1) User Personalization Profile (UP Profile) 
 
Through the personalization management application, the 
user can create new or update existing “User Personalization 
Profiles” for UbiComp environments and particular contexts. 
A “UP Profile” consists of two parts, the User Profile and the 
Personalization Profile, which are shown in Figure 1. A User 
Profile consists of a unique ID, user’s name/title, location, 
visual 
profile 
and 
access 
control 
permissions. 
A 
Personalization Profile consists of defined parameters of data 
that pertains to users personal preferences for environmental 
conditions (light, temperature, sound, etc.) and interaction 
controls (interaction/action pairs). Individual “UP Profiles” are 
created to determine how conditions in the UbiComp 
environment should react for particular contexts such as 
working, relaxation or sleeping. For example, an instance of 
“UP Profile”-“working profile”-is created through the 
personalization manager of the application, parameters such as 
light intensity, light colour, which are comfortable for user’s 
working context are configured and documented.  
 
 
 
Figure 1.   A User Personalization Profile 
 
2) Interaction/Action Mapping 
 
Although not practically implemented in this work, our user-
centric personalization procedure incorporates a method of 
mapping interaction techniques with actions to be initiated. To 
support consistency and memorability of interaction control 
across multiple shared UbiComp environments our user-
centric personalization procedure describes a method of 
pairing interaction techniques with actions, which will be 
practically implemented in our future work. Through this 
method users can create logical mappings between interaction 
techniques and actions to be initiated. This method affords 
users to make more cohesive pairings, which are compatible 
with their own personal habitual interpretation of interactions 
for controlling UbiComp environments [8, 9, 10, 12]. Through 
the personalization management application they can select an 
explicit interaction technique from a menu and map it with an 
action, for example (light on/off). Once the user explicitly 
performs the selected interaction technique in the UbiComp 
environment the selected mapped action is initiated. For 
example, a user could select a gesture technique such as a 
hand wave up/down motion from the personalization manager 
application menu and pair it with the light intensity 
increase/decrease action.  
50
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

Once a user has completed configuring their preferences 
for interaction control and conditions these are then saved as a 
“UP Profile” called ‘working profile” by the user. This 
“working profile’ is locally stored on the user’s wearable 
device, where it can be automatically queried in the UbiComp 
environment again and in the future and across other shared 
UbiComp environments, which are capable and compatible to 
load this format of profile.  
 
B. Autonomous Reconfiguration 
Autonomous Reconfiguration describes a procedure 
following which multiple shared UbiComp environments 
automatically reconfigure interaction control methods and 
conditions to suit a user’s preferences. The activity logic of 
our approach for Autonomous Reconfiguration is illustrated in 
Figure 2.  
 
 
Figure 2.  Activity Logic 
 
Through wireless local communications, “UP Profiles” are 
uploaded from the user’s carrier device to the UbiComp 
system. Existing configurations on the UbiComp system are 
substituted with user’s “UP Profile”. Based on the 
configuration saved as the “UP Profile” the UbiComp 
environment responds accordingly adapting to suit the user. 
As the “UP Profile” is stored on the device which is constantly 
with the user, it is roaming together with him/her; then 
connectivity and the provisioning of “UP Profiles” to 
UbiComp systems depends on users physical location and 
movement as they share their “UP Profile” with UbiComp 
systems. We call this “User Profile Roaming”, due to the 
profile being linked with the user. Subsequently, a “UP 
Profile” is readily available as the user encounters multiple 
shared UbiComp environments across other locations. 
Therefore, the user does not have to manually reconfigure 
shared UbiComp systems each time they encounter them to 
suit their preferences for interaction control and conditions. 
Also, to ensure that ownership and privacy concerns are 
maintained, “UP Profiles” are only shared during the session 
when the user is active in the UbiComp environment.  Once 
the user has completed the session within the UbiComp 
environment, “UP Profiles” are automatically cleared from the 
UbiComp System.  
IV. 
IMPLEMENTATION 
There are various ways to practically build up a prototype 
system which can realise the proposed methodology. In this 
section, we present both the structure and the implementation 
components of our testbed system. 
 
A. System Architecture 
The options for building a UbiComp system are only 
limited by people’s imagination nowadays. System developers 
are provided with an abundant of technologies and also 
technical commodities which aim to be integrated into 
something useful requiring minimum effort. Therefore, 
simplicity is the main characteristic of the system structure we 
have decided. As described in Section V, two physical small 
scale models representative of two UbiComp environments are 
transformed as our UbiComp testbed where a few major 
components are embedded as catagorised below and illustrated 
in Figure 3. 
 
- 
Profile interface, through which user’s preferred 
settings, stored as a structural profile file, are 
uploaded to the environment; also when user adjusts 
the settings and decides to keep it for a longer term, 
the updated settings are downloaded to the user 
through this interface. Different communication 
methods can be applied in practical implementation. 
- 
Control GUI is a visual interface that enables the user 
to explicitly manage controlling the settings of the 
encountered environment. 
- 
Manipulatable contexts are typical adjustable utilities, 
which normally function differently according to 
various users, in the environment, such as lights and 
heating. 
- 
Backend computing, which is invisible to users, 
orchestrates all other components, such as loading 
current user’s profile, displaying the information on 
the control GUI and interpreting the user profile into 
manipulation commands to the contexts. Linkages 
can be both wired and wireless. 
- 
Structural profile is the file stored on the user carry-
on device, recording user’s preferences of the context 
setting. 
51
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

  
 
 
              Figure 3. System structure of an UbiComp system 
 
B.  Testbed implementation 
In building our testbed, we choose LAMP (Linux, Apache, 
MySQL and PHP) based web services and python based 
interface program as the backend computing. NFC (Near Field 
Communication) is selected as the communication method 
between profile interfaces; one interface is embedded within 
the UbiComp environment, while the other is on the user’s 
carry-on wearable device. Lighting is set as the demonstrative 
manipulatable context. And wired connection is used to 
deliver control signals to the individual lighting device. 
Control GUI is implemented with a game engine – Unity3D – 
which generates a virtual 3D indoor environment with 
intuitive control functions that enable users to adjust the 
context 
lighting 
and 
save 
their 
preferences. 
“User 
Personalization Profiles” are the structural profile, where 
components of the “User Personalization Profile” are defined 
in an XML schema.  
V. 
CASE STUDY 
In this section, we firstly describe a possible user-case 
scenario, which we use to indicate how our methodology 
could be applied more practically across remote UbiComp 
environments in the future. We then validate our methodology 
with two sets of experiments; firstly the user-centric 
personalization experiment; and secondly, the autonomous 
reconfiguration experiment. The experiment testbed setup is 
described also and illustrated in Figure 4.  
 
A. User Case Scenario 
 “Mr. Jones’s job requires him to travel abroad quite 
frequently. He spends much time staying and working from 
different offices and hotel rooms across many locations. When 
Mr. Jones is working or relaxing he prefers the ambient 
lighting conditions of his accommodation to suit his 
preferences for such contexts. He would prefer the ambient 
lighting conditions in all environments he stays in to 
automatically adapt to suit his preferences for working, 
relaxation and sleeping, rather than having to adjust all the 
lights manually each time.”  
 
 
 
Figure 4. Experimental Testbed Setup 
 
B. Experiment Testbed Setup 
The possible user-case scenario described is demonstrated 
in a way more feasible for our experimentation purposes. The 
experiment testbed setup consists of two small physical scale 
models representative of two UbiComp environments. For 
descriptive purposes, the physical scale model as illustrated in 
Figure 4(B) is used as the first location representative of a 
user’s local office environment, whereas the physical scale 
model illustrated in Figure 4(D) is used as the second location 
representative of a hotel room. In Figure 4(A, C) we show 
screenshots of the control GUIs taken from the personalization 
management application. Control GUIs provide virtual 3D 
environments 
indicating 
the 
users 
current 
physical 
environment, as to comprehend more meaning to the user. In 
both Figure 4(A) and Figure 4(C) the control GUI is deployed 
and accessible from touchscreen platforms, which are already 
part of both UbiComp environments.  
 
C. User-Centric Personalization Experiment 
To demonstrate the user-centric personalization procedure 
as shown in Figure 4(A, B), we firstly share a default UP 
Profile with the UbiComp System (Local Office), when there 
is a pairing between the wearable carrier device and the 
UbiComp system (Local Office), this is achieved through the 
profiling interface as illustrated in Figure 3.  In our testbed 
setup, we consider the profiling interface to be already a part 
of the UbiComp system. In this experiment we firstly consider 
the user, Mr. Jones, to be initially carrying a default UP 
Profile, which has not been previously configured by him 
beforehand. When he encounters the first UbiComp System 
(Local Office), once a pairing between his wearable device 
and the UbiComp System (Local Office) is initiated, the 
default UP Profile is uploaded to the UbiComp System (Local 
Office). Once uploaded, the UbiComp environment’s lighting 
conditions adapt according to the information stored as the 
default UP Profile. This is also comprehended in a meaningful 
way through a virtual 3D environment as displayed to Mr. 
Jones on the Control GUI, see Figure 4(A). The default 
52
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

lighting conditions may not be suitable towards his 
preferences; 
through 
the 
Control 
GUI 
interface 
he 
reconfigures the light intensity by directly selecting each light 
from the 3D virtual environment interface. User interface 
control buttons are mapped according to each light, which are 
used to increase/decrease the light intensity, see Figure 4(A). 
As described in the user-case scenario, Mr Jones is enabled to 
configure the light intensity to suit his contexts such as for 
working, relaxation or sleeping. Therefore, once satisfied with 
the light intensity he is then enabled to save these as UP 
Profiles where they can be updated, saved and uploaded to the 
his carrier device for future usage. 
 
D. Autonomous Reconfiguration Experiment 
To demonstrate autonomous reconfiguration, in our 
experimental testbed setup we use a second small-scale model 
representative of a remote hotel UbiComp environment, see 
Figure 4(D), as it is demonstrates how UP Profiles can be 
reused again to maintain consistency of Mr. Jones’s 
preferences across multiple UbiComp environments.  When 
there is a pairing between the user’s wearable carrier device 
and the second UbiComp system (Hotel Room), Mr. Jones’s 
working UP Profile as created previously is uploaded from the 
wearable device to the UbiComp system (Hotel Room). The 
light intensity in this second UbiComp environment 
automatically dimmers to the exact parameters matching the 
light intensity configured previously for a working context in 
the first environment (Local Office). This ensures that Mr 
Jones does not have to manually adjust the light intensity 
again to suit his working context, as his preferences for 
environmental conditions automatically remain consistent 
across multiple UbiComp environments. When he has 
completed interacting with an UbiComp environment, his 
personal UP Profiles are removed from the UbiComp system 
repository, as UP Profiles are only permanently stored on the 
user’s wearable device.  
VI. 
CONCLUSION 
In this paper, we have presented a new methodology of 
user-centric personalization and autonomous reconfiguration 
across multiple shared ubiquitous computing environments. 
Through this methodology, it is emphasized that users should 
play a dominant role in deciding their own preferences for 
interaction control and the environmental context. Another 
aspect highlighted in this paper is the seamless maintenance of 
consistency of user experience across multiple UbiComp 
environments. Scenario based experiments have shown how 
the methodology is practically implemented and the 
effectiveness it brought into the real-life scenarios. For this 
stage of our work, room models have been used for simplicity 
in demonstrating the concept. In the following work, 
deployment within a real-life environment will be carried out, 
including optimization of GUI designs and reliability of the 
pairing procedure on the profile interface. More modalities of 
interaction controls (gestural, touch and voice) and more 
contexts (temperature, sound and humidity) will be included 
into the real-life deployment.  
ACKNOWLEDGMENT 
This work is sponsored through an Enterprise Ireland Project – 
eGo: easily connect the world (IR-2010-0005). Juan Francisco 
Martinez integrated the hardware. 
REFERENCES  
[1] D.A. Norman, Emotional Design, NY: Basic Books,  2005.  
[2] M.R. Morris, J.O. Wobbrock and A.D. Wilson, “Understanding 
users’ preferences for surface gestures,” Proc. of Graphics 
Interface (GI ’10), Canadian Information Processing Society, 
Toronto, Ont., Canada, pp. 261–268, 2010. 
[3] J.O. Wobbrock, M.R. Morris and A.D. Wilson, “User-defined 
gestures for surface computing”, Proc. of the 27th International 
Conference on Human Factors in Computing Systems, ACM, 
New York, NY, USA, pp. 1083–1092, 2009. 
[4] F. Kawsar and T. Nakajima, “Persona: a portable tool for 
augmenting 
proactive 
applications 
with 
multimodal 
personalization support,” Proc. of the 6th international 
conference on Mobile and ubiquitous multimedia. New York, 
NY, USA: ACM, 2007. 
[5] M. Weiser, The Computer for the 21st Century, Scientific 
American, September 1991. 
[6] D. Salber, A.D. Dey, and G.D. Abowd, “Ubiquitous Computing: 
Defining an HCI Research Agenda for an Emerging Interaction 
Paradigm, GVU Technical Report; GIT-GVU-98-01, Georgia 
Institute of Technology, 1998. 
[7] D. Chalmers, M. Chalmers, J. Crowcroft, M. Kwiatkowska, R. 
Milner, E. O’ Neill, T. Rodden, V. Sassone, and M.Sloman, 
“Ubiquitous Computing: Experience, design and Science”, 2006. 
[8] R.D. Vatavu, “Nomadic Gestures: A technique for reusing 
gesture commands for frequent ambient interactions,” Journal of 
Ambient Intelligence and Smart Environments 4, pp. 79–93. 
2012. 
[9] D.A. Norman, Natural user interfaces are not natural, ACM 
Interactions 17(3), pp. 6–10, 2010. 
[10] D.A. Norman and J. Nielsen, Gestural interfaces: A step 
backward in usability, ACM Interactions 17(5) (2010), 46–49. 
International Standards for HCI and Usability, 2012. 
[11] N. Bevan, “International standards for HCI and usability,” 
International Journal of Human-Computer Studies, v.55 n.4, pp. 
533-552, October 2001.  
[12] D. Saffer, In Interactive Gestures: Designing Gestural Interfaces, 
O Reilly Media, Inc, 1005 Gravenstei Highway North, 
Sebastopol, CA 95472, 2008. 
[13] A. Atia, S. Takahashi, K. Misue, and J. Tanaka, “UbiGesture: 
Customizing and Profiling Hand Gestures in Ubiquitous 
Environments, “ Proc. 13th International Conference on Human-
Computer Interaction. Part II: Novel Interaction Methods and 
Techniques, Springer-Verlag, July. 2009. 
[14] J. Bohn, User-Centric Dependability Concepts for Ubiquitous 
Computing. PhD thesis, No. 16653, ETH Zurich, Zurich, 
Switzerland, May 2006. 
[15] Z. Zhang et al, “Gesture Personalization and Profile Roaming,” 
US Patent 2011/0093820 A1, October 19th, 2009. 
[16] D. Retkowitz, I. Armac, and M. Nagl: “Towards Mobility 
Support in Smart Environments,” Proc. of the 21st International 
Conference 
on 
Software 
Engineering 
and 
Knowledge 
Engineering (SEKE 2009), Boston, Massachusetts, USA, pp.  
603-608. Knowledge Systems Institute Graduate School, 3420 
Main Street, Skokie, Illinois 60076, USA, 2009. 
 
53
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

