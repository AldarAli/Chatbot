Stance Classiﬁcation Using Political Parties
in Tokyo Metropolitan Assembly Minutes
Yasutomo Kimura
Otaru University of Commerce
Department of Information and Management Science
Hokkaido, Japan
Email: kimura@res.otaru-uc.ac.jp
Minoru Sasaki
Ibaraki University
Ibaraki, Japan
Department of Computer and Information Sciences
Email: minoru.sasaki.01@vc.ibaraki.ac.jp
Abstract—Stance classiﬁcation is an important component of
argument mining. We focus on politicians’ utterances in assem-
bly minutes to classify political parties afﬁliation. This paper
describes a novel stance classiﬁcation task that classiﬁes each
politician’s utterance for the politician’s stance. Our task is to
classify politicians into 20 political parties using their utter-
ances in the Metropolitan Assembly minutes. Japanese assembly
members are divided into many political parties in the local
assembly. Our proposal is to apply several baseline methods to our
novel dataset, which includes political parties in the Metropolitan
Assembly minutes. In this paper, we deﬁne a political stance for
a political party in Japan. We assess the difﬁculty of our dataset
to evaluate several baseline methods, such as Support Vector
machines (SVM), decision tree, random forest, and Naive Bayes.
Keywords–Stance classiﬁcation; Political party; Local assembly
minutes.
I.
INTRODUCTION
Automatic classiﬁcation is abundant in social science re-
search, such as political science and economics [1], and stance
classiﬁcation is a core component of argument mining [2][3].
We address the problem of classifying politicians’ stances
in terms of political parties. Previous research has deﬁned a
stance classiﬁcation as a binary classiﬁcation [4][5], and the
datasets are usually generated by tweets or debates.
In this paper, we propose a novel stance classiﬁcation
approach to political parties using both assembly minutes and
political parties. We deﬁne a political stance for a political
party in Japan. The Japanese governmental structure of local
governing bodies is called a dualistic representative structure.
Assembly members interrogate a governor to conﬁrm whether
the governor’s master plans should be carried out. These
questions and answers are recorded in the assembly minutes,
which are transcripts instead of summarized texts in Japan.
Furthermore, our goal is to classify each assembly mem-
ber’s political stance using the Tokyo Metropolitan Assembly
minutes. Politicians’ stances occasionally change over time,
and each politician’s stance depends on the individual political
issue. Thus, there should be a large spectrum of political
stances.
We focus on political parties in the Tokyo Metropolitan
Assembly minutes in Japan. The number of political parties
in the assembly minutes is usually higher than the number
of national parties; there were 20 Tokyo Metropolitan parties
between 2011 and 2015.
The main interest of this research is that political stance is
primarily a question of classiﬁcation using domestic political
parties. In Japan, assembly members occasionally change
political parties through their policies. Previous classiﬁcation
tasks have not used the content of the utterances to classify
political stances that reﬂect political beliefs.
Our contributions can be summarized as follows:
1)
Novel dataset for stance classiﬁcation: We created a
corpus for stance classiﬁcation using political parties
exceptional to Japan.
2)
New approach to stance classiﬁcation: Our task was
to classify each assembly member into multiple po-
litical parties.
3)
Evaluation of task difﬁculty: We applied the previous
methods to the dataset.
The rest of this paper is organized as follows. Section
II brieﬂy reviews related work on the stance classiﬁcation.
Section III describes the classiﬁcation of the political party.
Section IV describes the experiment. Finally, we conclude this
paper in Section V.
II.
RELATED WORK
Stance classiﬁcation is the challenge faced when classify-
ing the attitude taken by an author in a text.
In the International Workshop on Semantic Evaluation,
SemEval-2016 Task-6 focused on detecting political stance in
tweets [3]. The task is a shared task for detecting stance in
tweets; given a tweet and a target entity, such as “Hillary
Clinton” and “Legalization of Abortion”. A system must
determine whether the tweet is in favor of the given target,
against the given target, or neither. For articles that mention
the claim, the data is divided into the following three stances:
“for”, “against” and “observing.” They classiﬁed articles into
three stances.
This paper described public debate functions as forums for
both expressing and forming opinions, which is an important
aspect of public life [4]. It attempted to classify posts in online
debates based on the position or stance that a speaker takes on
an issue, such as favoring or obstructing the issue.
46
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-681-1
DATA ANALYTICS 2018 : The Seventh International Conference on Data Analytics

Information about a political party was used for stance
classiﬁcation [6]; however, the political party was only used
as a feature of classiﬁcation. They annotated six contexts as
features, such as political party, proﬁle, and tweet.
III.
CLASSIFICATION OF POLITICAL PARTY
A. Task Deﬁnition
This task is a classiﬁcation for determining the political
party from an assembly member’s utterances. We focused
on the Tokyo Metropolitan Assembly minutes as a political
dataset. Previous research has created a corpus of the local
assembly minutes of 47 prefectures from April 2011 to March
2015 [7]. We provided the political party information to the
Tokyo Metropolitan Assembly minutes. The dataset comprised
36,046 lines.
B. Dataset
Figure 1 presents an image of the dataset, which includes
a speaker’s name, utterance, and political party in the Tokyo
Metropolitan Assembly. We used a party identiﬁcation num-
ber (ID) as the political party information. Each utterance
included a speciﬁc topic, such as the new Tokyo bank, the
Tokyo Olympics or a care insurance system. We divided the
dataset into portions of the Metropolitan Assembly minutes. In
addition, we divided the utterances into a training dataset and
a test dataset with the percentage ratio 8:2; the ﬁrst portion
was the training data, which constituted 80% (421 utterances)
of the dataset, and the second portion was the test data, which
constituted 20% (106 utterances) of the dataset. There were
527 assembly members in total and 174 distinct members.
The dataset contained the minutes of the Tokyo Metropoli-
tan Assembly from April 2011 to March 2015. Japan is
divided into 47 prefectures, including Tokyo, Kyoto and Osaka.
The corpus contained the local assembly minutes of the 47
prefectures from April 2011 to March 2015 [7], a four-year
period that coincides with the term of ofﬁce for assembly
members in most autonomy. In this study, we focused on the
Tokyo Metropolitan Assembly minutes in Japan, and used a
dataset comprising politicians’ utterances and political parties
in the assembly minutes. This classiﬁcation model was used
to build a classiﬁer for political party by each politician’s
utterance. We attempted to classify political parties afﬁliation
in the Tokyo Metropolitan Assembly. Table I contains 20
political parties that are in the Tokyo Metropolitan Assembly.
IV.
EXPERIMENT
The purpose of this study was to evaluate the difﬁculty of
the dataset. Our task was to classify politicians into 20 polit-
ical parties using their utterances in the Tokyo Metropolitan
Assembly minutes.
A. Method
We assessed the difﬁculty of our dataset to evaluate several
classiﬁcation methods, such as SVM, Naive Bayes, k-nearest
neighbor, random forest and decision trees. We constructed
word vectors from segmented words. Experimental data were
segmented into words using the Japanese morphological anal-
ysis tool MeCab [8] with the Japanese dictionary IPADIC.
TABLE I. NAME OF 20 POLITICAL PARTIES IN THE TOKYO
METROPOLITAN ASSEMBLY. THESE POLITICAL PARTIES ARE THE
POLITICAL STANCES.
ID
Abbreviation
Name of political party
0
DP
Democratic Party
1
TMK
Tokyo Metropolitan Komeito
2
TMLDP
Tokyo Metropolitan Liberal Democratic Party
3
CN
Consumer Network
4
JCPTMA
Japan Communist in
Party Tokyo Metropolitan Assembly
5
AC
Autonomous Citizen
6
JCPTMG
Japan Communist Party
in Tokyo Metropolitan Government
7
I
Independent
8
I(R)
Independent (Restoration)
9
TRP
Tokyo Restoration Party
10
I(FALDP)
Independent ( Fresh Air Liberal Democratic Party)
11
JRP
Japan Restoration Party
12
TMAEP
Tokyo Metropolitan Assembly Everyone’s Party
13
EP
Everyone’s Party
14
EPT
Everyone’s Party Tokyo
15
TMCR
Tokyo Metropolitan Combination and Restoration
16
I(DBT)
Independent (Deep Breathable Tokyo)
17
BT
Bright Tokyo
18
TMRP
Tokyo Metropolitan Restoration Party
19
I(TEI)
Independent (Tokyo Everyone’s Innovation)
B. Results
Table III shows the results of comparative experiment
and the parameters. The correct answer rate is calculated as
follows:
Number
of
correct
political
parties
ID
Number
of
test
data
We conﬁrmed that the highest correct answer rate was
0.5377, given by the Naive Bayes.
C. Discussion
In this comparative experiment, the highest accuracy was
0.5377, determined by Naive Bayes. The difﬁculty and cause
for the low accuracy rate for this corpus are explained. We
consider the dataset to be unbalanced, since the number of
members depends on political party. The number of members
in the test dataset that belonged to party ID2 was 52. Figures 2
and 3 show the confusion matrix for the test dataset and show
that their methods nearly predicted three parties: ID0, ID1,
and ID2. There were 80 members in the top three political
parties. However, SVM and Naive Bayes predicted 105 and
106 members, respectively, in the top three parties, which
included ID0, ID1, and ID2. Thus, we should consider the
number of assembly members in each party.
V.
CONCLUSION
In this paper, we described a new approach to stance
classiﬁcation and created a new data set. The dataset comprised
168 members, 20 political parties and 527 utterances. We
conducted performance evaluation experiments with multiple
machine learning methods to evaluate the difﬁculty of the
datasets. The accuracy rate of Naive Bayes had the highest
performance, 54%. We evaluated the difﬁculty of the dataset
for stance classiﬁcation and determined that future work shuld
consider the number of members in each party.
47
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-681-1
DATA ANALYTICS 2018 : The Seventh International Conference on Data Analytics

Figure 1. Overview of dataset.
TABLE II. EXPERIMENTAL DATASET DIVIDED INTO TWO DATASETS OF 80% AND 20%: TRAINING DATA AND TEST DATA. COLUMNS
INCLUDE NUMBER OF MEMBERS, NUMBER OF WORDS, AVERAGE WORDS, MEDIAN, MAXIMUM AND MINIMUM.
ID
Party
Training data
Test data
(Separation by utterance unit)
(Separation by utterance unit)
Member
Word
Ave
Med
Max
Min
Member
Word
Ave
Med
Max
Min
0
DP
132
156,191
1,183
1,036
6,823
14
13
15,939
1,226
1,022
3,164
414
1
TMK
64
100,016
1,563
1,151
4,723
94
15
21,046
1,403
1,089
4,783
371
2
TMLDP
132
179,856
1,363
1,155
6,391
2
52
54,299
1,044
1,106
6,763
14
3
CN
19
14,330
754
754
1,336
203
4
3,476
869
797
1,301
582
4
JCPTMA
30
51,324
1,711
1,170
4,649
28
11
16,650
1,514
1,242
5,046
27
5
AC
2
2,915
1,458
1,476
1,484
1,431
0
0
0
0
0
0
6
JCPTMG
7
8,059
1,151
943
3,406
331
0
0
0
0
0
0
7
I
3
10,264
3,421
2,512
6,247
1,505
0
0
0
0
0
0
8
I(R)
1
1,272
1,272
1,272
1,272
1,272
0
0
0
0
0
0
9
TRP
6
3,272
545
464
1,062
253
0
0
0
0
0
0
10
I(FALDP)
4
3,002
750
851
1,280
19
1
1,329
1,329
1,329
1,329
1,329
11
JRP
2
1,051
526
526
570
481
0
0
0
0
0
0
12
TMAEP
4
3,199
800
904
998
393
0
0
0
0
0
0
13
EP
4
3,471
868
868
1,262
474
0
0
0
0
0
0
14
EPT
3
2,833
944
712
1,576
545
2
2,075
1,038
1,038
1,229
846
15
TMCR
5
4,370
874
741
1,494
418
2
2,608
1,304
1,304
1,849
759
16
I(DBT)
1
1,353
1,353
1,353
1,353
1,353
1
1,289
1,289
1,289
1,289
1,289
17
BT
2
2,172
1,086
1,086
1,272
900
0
0
0
0
0
0
18
TMRP
0
0
0
0
0
0
4
4,016
1,004
1,069
1,528
350
19
I(TEI)
0
0
0
0
0
0
1
754
754
754
754
754
Total
-
421
-
-
-
-
-
106
-
-
-
-
-
TABLE III. RESULTS OF COMPARATIVE EXPERIMENT. TEST SET
INCLUDES 106 UTTERANCES.
Method
Parameter
Correct answer rate
SVM
kernel=rbf
0.3962
Decision tree
depth=3
0.3113
k-NN
k=3
0.4334
Random Forest
depth=5
0.3490
tree=10
Naive Bayes
0.5377
ACKNOWLEDGMENTS
This work was supported by JSPS KAKENHI Grant Num-
ber JP16H02912 . The research funded for / supported by the
open collaborative research program at the National Institute
of Informatics (NII) Japan is (FY2018).
REFERENCES
[1]
J. Grimmer and B. M. Stewart, “Text as data: The promise and pitfalls of
automatic content analysis methods for political texts,” Political Analysis,
vol. 21, pp. 267–297, 2013, awarded Political Analysis Editor’s Choice
Award for an article providing an especially signiﬁcant contribution to
political methodology.&nbsp;Replication Data:&nbsp;here.
[2]
F. Boltuzic and J. ˇSnajder, “Toward stance classiﬁcation based on claim
microstructures,” in Proceedings of the 8th Workshop on Computational
Approaches to Subjectivity, Sentiment and Social Media Analysis.
Association for Computational Linguistics, 2017, pp. 74–80. [Online].
Available: http://aclweb.org/anthology/W17-5210
48
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-681-1
DATA ANALYTICS 2018 : The Seventh International Conference on Data Analytics

Figure 2. Results of prediction by SVM. This prediction unit is a speech unit.
Figure 3. This ﬁgure shows the result of the prediction by the Naive Bayes.
This prediction unit is a speech unit.
[3]
S. Mohammad, S. Kiritchenko, P. Sobhani, X. Zhu, and C. Cherry,
“Semeval-2016 task 6: Detecting stance in tweets,” in Proceedings of
the 10th International
Workshop
on
Semantic
Evaluation
(SemEval-2016).
San
Diego,
California: Association for Computational Linguistics, June 2016, pp.
31–41. [Online]. Available: http://www.aclweb.org/anthology/S16-1003
[4]
M. A. Walker, P. Anand, R. Abbott, and R. Grant, “Stance classiﬁcation
using dialogic properties of persuasion,” in Proceedings of the 2012
Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, ser. NAACL
HLT ’12.
Stroudsburg, PA, USA: Association for Computational
Linguistics, 2012, pp. 592–596. [Online]. Available: http://dl.acm.org/
citation.cfm?id=2382029.2382124
[5]
D. Sridhar, L. Getoor, and M. Walker, “Collective stance classiﬁcation of
posts in online debate forums,” in Proceedings of the Joint Workshop on
Social Dynamics and Personal Attributes in Social Media.
Baltimore,
Maryland: Association for Computational Linguistics, June 2014,
pp. 109–117. [Online]. Available: http://www.aclweb.org/anthology/
W14-2715
[6]
K. Joseph, L. Friedland, W. Hobbs, D. Lazer, and O. Tsur, “Constance:
Modeling annotation contexts to improve stance classiﬁcation,” in
Proceedings
of
the
2017
Conference
on
Empirical
Methods
in
Natural Language Processing.
Copenhagen, Denmark: Association for
Computational Linguistics, September 2017, pp. 1115–1124. [Online].
Available: https://www.aclweb.org/anthology/D17-1116
[7]
Y. Kimura, K. Takamaru, T. Tanaka, A. Kobayashi, H. Sakaji, Y. Uchida,
H. Ototake, and S. Masuyama, “Creating japanese political corpus
from local assembly minutes of 47 prefectures,” in Proceedings of the
12th Workshop on Asian Language Resources (ALR12).
The COLING
2016 Organizing Committee, 2016, pp. 78–85. [Online]. Available:
http://www.aclweb.org/anthology/W16-5410
[8]
T. Kudo, K. Yamamoto, and Y. Matsumoto, “Applying conditional ran-
dom ﬁelds to japanese morphological analysis,” in In Proc. of EMNLP,
2004, pp. 230–237.
49
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-681-1
DATA ANALYTICS 2018 : The Seventh International Conference on Data Analytics

