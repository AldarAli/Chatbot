TCP Congestion Avoidance using Proportional plus
Derivative Control
Dirceu Cavendish, Hikaru Kuwahara, Kazumi Kumazoe, Masato Tsuru, Yuji Oie
Department of Computer Science and Electronics
Kyushu Institute of Technology
Fukuoka, Japan 810-0004
Email: {cavendish,kuma,tsuru,oie}@ndrc.kyutech.ac.jp, kuwahara@infonet.cse.kyutech.ac.jp
Abstract—We introduce a transmission control protocol with
a delay based congestion avoidance that utilizes a proportional
plus derivative controller. The derivative part of the controller
is shown to be well suited to effectively control TCP sessions,
given the relative shallow buffer space of network elements. We
demonstrate the competitive performance of the protocol via open
source based network experiments over a research network and
the Internet.
Keywords—high speed networks; TCP congestion avoidance;
Packet retransmissions; capacity estimation; path bottleneck;
Proportional plus derivative controller.
I. INTRODUCTION
Recent advances in TCP protocols have departed from
window transmission regulation based on binary information
into multi-bit information [2], [9]. Rich feedback information
indeed holds the promise of better regulating packet transmis-
sion by reducing trafﬁc oscillations typical of binary based
control mechanisms. Moreover, recent advances in TCP ﬂow
probing have made available path estimators that may be
useful for regulating TCP trafﬁc transmission [10].
In our prior work, we have introduced a delay based TCP
window ﬂow control mechanism that uses path capacity and
storage estimation, called Capacity and Congestion Probing
- CCP [5]. The idea is to estimate bottleneck capacity and
path storage space, and regulate the congestion window size
using a proportional controller. We have shown that CCP has
competitive performance as compared with widely known TCP
protocols, such as Reno and Cubic, outperforming them in the
presence of random packet loss scenarios such as in wireless
bottlenecks.
However, quite often path storage space is limited, due
to shallowness of network elements’ buffers. In such cases,
a large proportional gain parameter is needed to increase
throughput performance, which increases the protocol ag-
gressiveness. Motivated by the shallowness of buffers in the
Internet network elements, in this paper we propose to add
a derivative component to the proportional controller used to
regulate TCP congestion window. The idea is to react to the
derivative of the available path storage space, in addition to
the absolute storage space value. When buffers are limited, a
derivative component should help regulate better trafﬁc input
into the TCP session.
In this work, our contributions are as follows. We show the
feasibility of a window ﬂow control mechanism based on a
proportional plus derivative controller, based on non intrusive
path capacity and buffer storage estimators. As previously,
we use a control theoretic framework that ensures stability
regardless of session characteristics (path capacity and round
trip time) and cross trafﬁc activity; we design a congestion
window regulation scheme within the framework of a TCP
protocol, called TCP-Capacity and Congestion Proportional
plus Derivative - CCPD; we demonstrate TCP-CCPD per-
formance via a comprehensive set of open source based
transpaciﬁc network experiments. The material is organized
as follows. Related work discussion is provided on Section
II. Section III introduces the modeling and control theoretic
approach of the window regulation scheme, whereas section
IV reviews the path estimators used to implement the window
regulation. Section V describes the TCP-CCPD protocol, and
section VI addresses its performance evaluation. Section VII
addresses directions we are pursuing as follow up to this work.
II. RELATED WORK
TCP protocols fall into two categories, delay and loss
based. Advanced loss based TCP protocols, such as HS-TCP
and Scalable TCP use packet loss as primary congestion
indication signal, performing window regulation as wk =
f(wk−1), being ack reception paced. Most f functions follow
an Additive Increase Multiplicative Decrease strategy, with
various increase and decrease parameters. TCP NewReno and
Cubic are examples of AIMD strategies.
Delay based TCP
protocols, on the other hand, use queue delay information
as the congestion indication signal, increasing/decreasing the
window if the delay is small/large, respectively. Examples of
these are TCP-Vegas and FAST TCP.
CCP and CCPD fall
into the second category, delay based protocols.
Although TCP-Vegas relies on estimates of round trip prop-
agation delay, its window adjustment function is of the form
wk = f(wk−1), paced by one rtt per adjustment [2]. TCP-
Vegas aims at keeping a small number of packets buffered
in the routers along the path. Fast TCP, on the other hand,
tracks both minimum and average rtt values of a session, in
order to update the window, still via a wk = f(wk−1) function.
Although both of these algorithms can be tuned to convergence
[6], parameter tuning depends on particular characteristics
of each session, such as propagation delays and link speeds
[7]. In contrast, CCP and CCPD both rely on a technique
for dead-time delay systems to ensure stability regardless the
20
INTERNET 2011 : The Third International Conference on Evolving Internet
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-141-0

2
characteristics of a TCP session [12]. This allows us to ﬁne
tune the algorithm’s parameters to trade throughput for packet
loss, without the danger of driving the system to instability. In
addition, CCPD derivative component allows a faster reaction
to transients when buffer space is limited.
Unique to CCP
and CCPD window control is that they do not follow a
wk = f(wk−1) control law, which, together with built in
stability mechanism, allows the protocols to be responsive to
cross trafﬁc disturbances at widely different network scenarios
and trafﬁc conditions.
III. PROPORTIONAL PLUS DERIVATIVE WINDOW
CONGESTION CONTROL
We make use of the control theoretic approach of [3] to
design CCPD protocol. In what follows, we limit ourselves
to summarize the results needed for CCPD protocol design,
augmenting them with a derivative component.
A. Network and Queue Models
The network consists of N = {1, 2, . . ., n} nodes and
L = {1, 2, . . ., l} links. Each link i is characterized by: trans-
mission capacity ci = 1/ti (segments/sec); propagation delay
tdi. The network trafﬁc is generated by source/destination
pairs (S, D), where S, D ∈ N. To each (S, D) session,
there is a number of TCP sessions associated, each of which
having a ﬁxed path p(S, D) over which all segments of
a given session travel. Each source is characterized by its
maximum transmission speed, cs = 1/ts, dictated by its
network interface card.
We further assume that each switch maintains a single queue
for all sessions exiting a given outgoing link. Let xi,j(t) be
the occupancy at time t of the queue associated with link i
and sessionj, and Bi,j a corresponding buffer size.
For the model of the dynamic behavior of each queue, we
assume a deterministic ﬂuid model approximation of segment
ﬂow [11]. Considering the queue associated with the TCP
session T CPj at link i, if the level of queue occupancy at
time t is xi,j(t), its input rate ui,j(t), and cross trafﬁc di,j(t),
a ﬂuid model of the queue system is given by:
dxi,j(t)
dt
=

ui,j(t) + di,j(t)
if xi,j > 0
max(0, ui,j(t) + di,j(t))
if xi,j = 0
(1)
B. Window Control Model
In order to control the queue level x(t) for a speciﬁc session,
we use a proportional plus derivative controller. Letting B be
the size of the bottleneck buffer, we compute the difference
between the buffer size and the current queue level x(t). This
difference, the error e(t), is multiplied by a positive gain Kp,
so that Kpe(t) is the regulated input rate of the T CP source.
In addition, a difference between the current queue level x(t)
and the previously received queue level x(t−tp) is multiplied
by a positive parameter Kd and added to the input rate.
Figure 1 depicts the block diagram of the continuous time
model of a TCP session. Tff denotes the propagation delay
from the ﬂow controlled source to the bottleneck queue, the
most congested intermediate node, whereas Tfb is the propa-
gation delay incurred by trafﬁc carrying feedback information
from the intermediate node to the destination node, plus the de-
lay incurred from the destination node back to the source node.
Therefore, RT T = Tff + Tfb is the round trip propagation
delay incurred by a segment carrying feedback information. In
Figure 1, a generic proportional controller Kp∗(t) is depicted,
rather than a simple proportional controller Kp. In addition,
a derivative component Kd∗(t) is also depicted, acting on
variations of the input signal. The cross trafﬁc rate is d(t),
hence variations in d(t) represent cross trafﬁc variations, or
disturbances, accounting for cross trafﬁc impact on a TCP
session, whereas B is the bottleneck queue size.
x   (t)
i,j
d   (t)
i,j
Tff
Kd  (t)
*
dt
Tfb
+
-
+
u   (t)
i,j
B
+
Kp  (t)
*
+
+
d
dt
Fig. 1: Rate controlled ﬂow model with a K∗(t) controller
We use a Smith Predictor [12] to ensure stability in large
bandwidth delay product paths regardless of the proportional
and derivative gain parameters used. Therefore, we substitute
the controllers Kp∗(t) and Kd∗(t) in Fig. 1 with controllers
such that the resultant system has a delay free feedback loop in
cascade with pure delays [3]. The proportional plus derivative
controller plus the feedback loop predictor gives rise to the
following input rate control equation:
u(t) = Kd[B − x(t) − in flight traffic(t)] +
(2)
Kd d
dt[B − x(t) − in flight traffic(t)]
Eq. 2 implements a proportional plus derivative control ac-
tion with the difference that the actual queue level is increased
by the amount of data transmitted during the last round trip
delay (in flight traffic(t)).
Finally, a discretization of
the above continuous system yields the window adjustment
equation as:
wk = Kp[B − xk − in flight segsk] +
(3)
Kd
tk − tk−1
[xk−1 + in flight segsk−1 +
−xk − in flight segsk]
where
xk
the
buffer
level
at
discrete
time
k,
and
in flight segsk the number of segments transmitted in the
last round trip delay.
Although our main interest is in TCP sender window regu-
lation, Eq. 3 can also be used to account for retransmissions of
lost segments. This is because the window regulation scheme
itself does not distinguish between fresh and retransmitted seg-
ments, as long as they are both accounted for by in ﬂight segs.
Notice that Eq. 3 is not a pure recurrent equation, of the
form wk = f(wk−1). Therefore, a current window size is not
solely dependent on the value of the previous window size,
as in most TCP protocols. 1 In addition, theoretically Eq. 3
would need to be recomputed at a given minimum frequency,
1To be precise, wk depends on the values of all wi within a full round trip
time, due to in ﬂight segs term.
21
INTERNET 2011 : The Third International Conference on Evolving Internet
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-141-0

3
which would require timers associated with transport sockets
that require locks for safe access. Instead, a TCP congestion
avoidance implementation of Eq. 3 does not require timers
because, as soon as a control window worth of packets is
transmitted, no new packets are allowed into the network
until an acknowledgement is received. At that time, we can
recompute Eq. 3 appropriately.
We use Kp parameter for throughput regulation, whereas
Kd is used to quickly respond to variations in path buffer
space. That is, although large values of Kp increase session
throughput, segment loss may be experienced, depending on
cross trafﬁc behavior. Segment losses can be mitigated by
responding quickly to queue build ups via Kd parameter of
the derivative component of the controller.
Summarizing, window regulation through Eq. 3 allows for a
trade off between segment loss and throughput via parameter
Kp. Hence, tuning of Kp can be exercised for trafﬁc engi-
neering purposes. For paths through network elements with
shallow buffers, Kd is tuned so as to provide quick response to
variations in available space. To end this section, we mention
that the control window prescribed by Eq. 3 allows the TCP
sender to send a certain number of segments at line speed,
if wished, without impairing controllability or stability of the
session. This is indeed the typical behavior of a TCP session.
Moreover, each TCP session sees its own buffer size B and a
buffer level caused by its own trafﬁc plus cross trafﬁc on its
path, caused by other TCP sessions and UDP trafﬁc crossing
its path.
IV. PATH ESTIMATORS
Eq. 3 requires estimators for bottleneck buffer size ˆB and
buffer level ˆx. As the estimators used in this paper are a more
accurate version of the estimators used in [5], in this section
we simply summarize the description of the estimators, for
completeness.
A. Capacity estimation
The capacity estimation method of our choice is based on
packet pair dispersion [10] techniques. The idea is to measure
dispersion of the delay of packet pairs sent back to back .
If both probing packets of size MSS of a packet pair sample
do not suffer any queueing delay, and the dispersion between
them is d, the slowest link capacity can be estimated as:
ˆC = MSS
d
(4)
The capacity estimation method is described in detail in [4]. In
this paper, we implemented a version of this method with high
resolution clocks, which allows us more precision, as well as
the bottleneck capacity estimation of a wider range of speeds.
Fig. 2 reports capacity estimation results for short and long rtt
path scenarios, using two Kp parameter values. We can see
that capacity estimation accuracy does not depend on the rtt
nor the set of parameters used.
B. Buffer size estimation
Let rttmax and rttmin be the maximum and minimum rtts
experienced by segments of a given session. A reasonable
estimator for the bottleneck buffer size would then be:
ˆB = ˆC ∗ (rttmax − rttmin)
(5)
a) CCPD(2,100);Rtt=20msec
b)CCPD(2,100); Rtt=190msec
d)CCPD(4,100); Rtt=190msec
c)CCPD(4,100); Rtt=20msec
 0
 50000
 100000
 150000
 200000
 0
 100
 200
 300
 400
 500
 600
X 103(b/s)
(# rtt)
Capest,JGN2plus,RTT=20[ms]
trial1
trial2
trial3
trial4
trial5
 0
 50000
 100000
 150000
 200000
 0
 50  100 150 200 250 300 350 400 450 500
X 103(b/s)
(# rtt)
Capest,JGN2plus,RTT=20[ms]
trial1
trial2
trial3
trial4
trial5
 0
 50000
 100000
 150000
 200000
 0
 100
 200
 300
 400
 500
 600
X 103(b/s)
(# rtt)
Capest,JGN2plus,RTT=190[ms]
trial1
trial2
trial3
trial4
trial5
 0
 50000
 100000
 150000
 200000
 0
 50
 100  150  200  250  300  350  400
X 103(b/s)
(# rtt)
Capest,JGN2plus,RTT=190[ms]
trial1
trial2
trial3
trial4
trial5
Fig. 2: Capacity estimation
However, a precise estimation would be achieved only when
the bottleneck buffer is full, so that rttmax is the rtt of the
segment once stored at the last buffer slot of the buffer,
otherwise the estimator will underestimate the buffer size.
On the other hand, rttmin may represent more than pure
propagation delays, if during the estimation period the bot-
tleneck buffer never empties. In this case, however, one may
argue that the extra buffer space, taken by a persistent trafﬁc,
is never available anyways, so this extra space is perceived
by a TCP session as an additional propagation delay. Fig.
3 report buffer size estimation results for short and long rtt
path scenarios, using two Kp parameter values. Buffer size
estimation accuracy does not depend on the parameter values
used. However, long rtt sessions result in larger buffer size
estimation, as expected.
a) CCPD(2,100);Rtt=20msec
b)CCPD(2,100); Rtt=190msec
d)CCPD(4,100); Rtt=190msec
c)CCPD(4,100); Rtt=20msec
 0
 50
 100
 150
 200
 0
 100
 200
 300
 400
 500
 600
(segs)
(# rtt)
bufsize,JGN2plus,RTT=20[ms]
trial1
trial2
trial3
trial4
trial5
 0
 50
 100
 150
 200
 0
 50  100  150  200  250  300  350  400  450  500
(segs)
(# rtt)
bufsize,JGN2plus,RTT=20[ms]
trial1
trial2
trial3
trial4
trial5
 0
 200
 400
 600
 800
 1000
 0
 100
 200
 300
 400
 500
 600
(segs)
(# rtt)
bufsize,JGN2plus,RTT=190[ms]
trial1
trial2
trial3
trial4
trial5
 0
 100
 200
 300
 400
 500
 600
 0
 50
 100
 150
 200
 250
 300
 350
 400
(segs)
(# rtt)
bufsize,JGN2plus,RTT=190[ms]
trial1
trial2
trial3
trial4
trial5
Fig. 3: Buffer Size Estimation
C. Buffer level estimation
If one tracks each segment rtt, the current buffer level x(t)
can be estimated by ˆx(t) = (rtt(t) − rttmin) × ˆC. Since
sample rtt values typically include high frequency variations,
a smoothed average rtt value rtts(t) is used instead, so:
22
INTERNET 2011 : The Third International Conference on Evolving Internet
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-141-0

4
ˆx(t) = ˆC ∗ (rtts(t) − rttmin)
(6)
Fig. 4 report buffer level estimation results for short and
long rtt path scenarios, using two Kp parameter values. Buffer
level estimation does depend on both the parameter values
used, as well as the session rtt.
a) CCPD(2,100);Rtt=20msec
b)CCPD(2,100); Rtt=190msec
d)CCPD(4,100); Rtt=190msec
c)CCPD(4,100); Rtt=20msec
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 0
 100
 200
 300
 400
 500
 600
(segs)
(# rtt)
buflevel,JGN2plus,RTT=20[ms]
trial1
trial2
trial3
trial4
trial5
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 0
 50  100  150  200  250  300  350  400  450  500
(segs)
(# rtt)
buflevel,JGN2plus,RTT=20[ms]
trial1
trial2
trial3
trial4
trial5
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 0
 100
 200
 300
 400
 500
 600
(segs)
(# rtt)
buflevel,JGN2plus,RTT=190[ms]
trial1
trial2
trial3
trial4
trial5
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 0
 50
 100
 150
 200
 250
 300
 350
 400
(segs)
(# rtt)
buflevel,JGN2plus,RTT=190[ms]
trial1
trial2
trial3
trial4
trial5
Fig. 4: Buffer Level Estimation
V. TCP-CCPD PROTOCOL
Our design follows the TCP framework: slow start, conges-
tion avoidance, fast retransmit, and fast recovery phases, with
adaptations to capacity and congestion probing as follows:
• Slow Start : We use a plain TCP slow start mechanism
so as to focus on characterizing the performance of the
congestion avoidance mechanism proposed in this paper.
The only difference is that the bottleneck capacity and
the buffer size estimation are passively performed during
slow start as well as during congestion avoidance.
• Congestion Avoidance : In congestion avoidance, capac-
ity estimators are updated continuously, so that the CCPD
session can track changes in the path characteristics
due to cross trafﬁc dynamics. In particular, a capacity
segment sample is set at every rtt interval to avoid
interference between samples, provided that the control
window is increased by at least two segments via Eq. 3.
High accuracy clock helps accurate computation of the
derivative component of the controller.
• Fast Retransmit and fast recovery : Duplicate acks
cause segments to be retransmitted. During retransmis-
sion, the congestion window is maintained at the same
size until all segments transmitted during that window
are acknowledged. Moreover, for each duplicate ack
received, the congestion window is increased to allow the
retransmission of the missing segment. During recovery,
rtt measurements become problematic, since segments
may have to be retransmitted several times, artiﬁcially
increasing their rtt. Since CCPD relies on rtt measure-
ments, the protocol does not react to dupacks, avoiding
estimators’ contamination with inﬂated rtt values.
Regarding implementation cost, since no additional packets
are used, there is no bandwidth overhead incurred by CCPD.
Regarding scalability, the protocol requires OS kernel timers
of small enough granularity to detect time differences that
scale with bottleneck capacity speed. We have upgraded
our previous estimators’ implementation with high accurate
clocks, where nanoseconds accuracy allows us to probe path
bottleneck capacity in excess of 100 Gbps.
VI. PERFORMANCE EVALUATION
We now report on a series of open source based experiments
on a high speed research network as well as the Internet
(5. The research network is used to analyze our protocol
properties and performance in detail, as we are able to control
cross trafﬁc and path routes. The Internet scenario is used to
investigate protocol feasibility on paths with realistic cross
trafﬁc. We contrast the CCPD performance with two well
known TCP protocols: NewReno, with a loss based congestion
avoidance; Cubic, the Linux TCP algorithm of choice; and
CCP [5], our previous delay based congestion avoidance
protocol.
a) High Speed Research Network Scenario
 
5
characterized for Kp and Kd parameters. In terms of transfer
speed performance, Table II shows that all protocols perform
similarly for the short rtt and no packet loss scenario. For long
rtts (Table III), we see that Cubic, CCP(4) and CCPD(4,100)
are the fastest protocols, being the most aggressive TCP
congestion avoidance schemes. Hence, the least aggressive
protocols (Reno and CCPD(2,100)) perform poorly in long
rtt scenarios with no cross trafﬁc. For better understanding
of the dynamics of the congestion avoidance, we include a
characterization of the cwnd control window for a single long
rtt trial in Fig. 6. CCP(4) and CCPD(4,100) have similar cwnd
dynamics over large rtts.
Reno
Cubic
CCP(2)
CCP(4)
CCPD(2,100)
CCPD(4,100)
trial 1
1229.7
1227.3
1410.7
1226.2
1459.6
1230.8
trial 2
1221.2
1226.9
1219.3
1222.6
1225.9
1224.1
trial 3
1223.7
1455.8
1220.3
1219.7
1220.6
1224.4
trial 4
1220.0
1453.6
1458.0
1447.2
1222.6
1231.8
trial 5
1218.6
1223.2
1200.3
1222.9
1220.9
1228.3
avg
1222.64
1317.36
1301.72
1267.72
1269.92
1227.8
TABLE II: 100MB delivery time(msec): 0 PER ; rtt=20msec
Reno
Cubic
CCP(4)
CCPD(2,100)
CCPD(4,100)
trial 1
44383.5
23114.0
21548.3
34490.6
19117.5
trial 2
44449.1
23197.8
21868.4
30846.7
22878.3
trial 3
44385.2
23134.4
19116.3
29957.6
21982.2
trial 4
44382.6
23117.9
21788.6
28430.8
22641.4
trial 5
44385.4
25043.9
21485.8
37542.3
23516.9
avg
44397.2
23521.6
21161.5
32253.6
22039.3
TABLE III: 100MB delivery time(msec): 0 PER ; rtt=190msec
a) Reno
b) Cubic
d) CCPD(4,100)
c) CCP(4)
 0
 100000
 200000
 300000
 400000
 500000
 600000
 700000
 0
 50  100  150  200  250  300  350  400  450
(bytes)
(secs)
cwnd,RTT=190[ms],reno,loss=0[%]
trial1
trial2
trial3
trial4
trial5
 0
 500000
 1e+06
 1.5e+06
 2e+06
 2.5e+06
 0
 50
 100
 150
 200
 250
(bytes)
(secs)
cwnd,RTT=190[ms],ccp(4),loss=0[%]
trial1
trial2
trial3
trial4
trial5
 0
 500000
 1e+06
 1.5e+06
 2e+06
 2.5e+06
 0
 50
 100
 150
 200
 250
(bytes)
(secs)
cwnd,RTT=190[ms],cubic,loss=0[%]
trial1
trial2
trial3
trial4
trial5
 0
 500000
 1e+06
 1.5e+06
 2e+06
 2.5e+06
 0
 50
 100
 150
 200
 250
(bytes)
(secs)
cwnd,RTT=190[ms],ccpd(4,100),loss=0[%]
trial1
trial2
trial3
trial4
trial5
Fig. 6: Cwnd(t) without random packet loss : rtt=190msec
C. Transport protocols’ performance with random packet loss
In this experiment set, we characterize the performance
of the TCP protocols when the session experiences random
packet losses. Tables IV and V show the completion time of a
ﬁle of 100MBytes delivered over the research network, when
a 10−4 packet drop (PER) is exercised by a link emulator
placed at the bottleneck link of the session, for 20msec and
180msec rtt scenarios, respectively. CCP is characterized for
Kp = 4, whereas CCPD is characterized for Kp = 2, 4,
and Kd = 100. In terms of transfer speeds, we see that all
protocols completion time get severely affected by the packet
loss, if compared with no loss results, except CCP and CCPD
for long rtt scenario. For short rtt scenario, the protocols with
most impacted ﬁle completion times are the most aggressive
protocols, namely Cubic and CCP. The least affected protocol
is CCPD(2,100), arguably the least aggressive protocol. Figure
7 depicts the cwnd dynamic behavior of one of the long rtt
trial for all protocols. We see that for all protocols except CCP
and CCPD, there is a large drop in cwnd size on every packet
loss experienced. Because CCP and CCPD rely on estimators
that are not related with packet loss, but rather packet delays,
not affected by random losses, their performance do not get
affected by random losses signiﬁcantly.
In summary, two factors signiﬁcantly affect the perfor-
mance of the protocols: packet loss level, and rtt size. For
short rtt scenarios and no packet loss, all protocols deliver
similar completion time performance. For high packet loss,
long rtt scenarios require aggressive protocols for superior
performance, while short rtt scenarios favor less aggressive
protocols in delivering faster completion time.
Reno
Cubic
CCP(2)
CCP(4)
CCPD(2,100)
CCPD(4,100)
trial 1
19781.9
1502.4
1849.3
2364.3
1295.4
1274.0
trial 2
17402.6
2082.8
1981.0
1728.1
1988.2
1711.2
trial 3
20899.0
3634.5
1596.4
1421.4
1623.7
1229.3
trial 4
7699.5
1726.7
2463.0
3603.7
1144.3
1519.9
trial 5
7047.1.2
1304.6
1198.5
1604.0
1508.7
1953.5
avg
14566.0
2050.2
1817.6
2144.3
1512.0
1537.6
TABLE IV: 100MB delivery t(msec): 10−4 PER; rtt=20msec
Reno
Cubic
CCP(4)
CCPD(2,100)
CCPD(4,100)
trial 1
133872.7
38054.4
24262.5
33819.9
23247.3
trial 2
107217.8
39091.7
21772.8
32684.9
22374.0
trial 3
117845.4
65617.6
24245.2
30335.9
21342.4
trial 4
126682.7
45681.4
22435.5
29964.2
21837.4
trial 5
118829.2
38538.0
22616.5
31382.9
23557.9
avg
120889.6
45396.6
23066.5
31637.6
22471.8
TABLE V: 100MB delivery t(msec): 10−4 PER ; rtt=190msec
a) Reno
b) Cubic
d) CCPD(4,100)
c) CCP(4)
 0
 100000
 200000
 300000
 400000
 500000
 600000
 700000
 0
 200
 400
 600
 800  1000  1200  1400
(bytes)
(secs)
cwnd,RTT=190[ms],reno,loss=0.01[%]
trial1
trial2
trial3
trial4
trial5
 0
 200000
 400000
 600000
 800000
 1e+06
 1.2e+06
 1.4e+06
 0
 100
 200
 300
 400
 500
 600
 700
(bytes)
(secs)
cwnd,RTT=190[ms],cubic,loss=0.01[%]
trial1
trial2
trial3
trial4
trial5
 0
 500000
 1e+06
 1.5e+06
 2e+06
 2.5e+06
 0
 50
 100
 150
 200
 250
(bytes)
(secs)
cwnd,RTT=190[ms],ccp(4),loss=0.01[%]
trial1
trial2
trial3
trial4
trial5
 0
 500000
 1e+06
 1.5e+06
 2e+06
 2.5e+06
 0
 50
 100
 150
 200
 250
(bytes)
(secs)
cwnd,RTT=190[ms],ccpd(4,100),loss=0.01[%]
trial1
trial2
trial3
trial4
trial5
Fig. 7: Cwnd(t) with random packet loss
D. Benchmarking CCPD against other TCP protocols
In this subsection, we benchmark CCPD against Reno,
Cubic, and CCP TCP protocols. Two parallel TCP sessions
are initiated for the same ﬁle of 100MByte size, over the
research network and Internet scenarios. We recall that the
Research Network has very little cross trafﬁc. We collect
completion time performance for short and long rtt types of
session. Results are shown in Figs. 8 and 9. Each pair of
bars indicate average completion time over ﬁve trials for two
competing TCP protocols. A range bar on top of the histogram
bar indicates minimum and maximum values across the trials.
24
INTERNET 2011 : The Third International Conference on Evolving Internet
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-141-0

6
As the two sessions come simultaneously into the network,
their completion time performance are comparable.
a) Short rtt scenario: rtt=20 msecs
b) Long rtt scenario: rtt=190 msecs
Fig. 8: Research Network: Completion time performance
a) Short rtt scenario: rtt=20 msecs
b) Long rtt scenario: rtt=300msecs
Fig. 9: Internet: Completion time performance
In the research network scenario, where we have practically
no cross trafﬁc, CCP and CCPD perform better than all other
protocols except CCP(2) and CCPD(2,100), outperformed by
Cubic on long rtt scenario. For short rtt sessions, CCPD out-
performs CCP and other protocols (e.g. CCPD(2,100)/Cubic vs
CCP(2)/Cubic). In the Internet scenario, CCP and CCPD out-
perform the other protocols on average completion time. When
comparing CCPD(x,100)/otherTCP with CCP(x)/otherTCP, we
see that CCPD outperforms CCP for long rtt scenario, whereas
CCP outperforms CCPD for short rtt scenario. CCPD perfor-
mance over the Internet needs further investigation.
VII. FUTURE WORK
In this paper, we have introduced TCP-CCPD, a transmis-
sion control protocol based on control theoretical concepts,
and window regulation based on TCP session estimators.
The protocol regulates trafﬁc injection by tracking capacity
and congestion along the session path during the lifetime of
the session, an implementing a proportional plus derivative
controller. The derivative component of the controller allows
quick reaction to queue build ups. Preliminary experimental
results have demonstrated CCPD competitiveness as compared
to widely used TCPs. We are in the process of generating more
extensive experimental results. In addition, we are currently
studying a hybrid CCP/CCPD congestion avoidance mecha-
nism, which activates the derivative part of the controller only
in appropriate path scenarios. The goal is to guarantee best
performance regardless of the network path characteristics.
ACKNOWLEDGMENT
Work supported in part by JSPS Grant-in-Aid for Scientiﬁc
Research KAKENHI B (21300024).
REFERENCES
[1] K.J.Astrom and B.Wittenmark, “Computer Controlled Systems.” Engle-
wood Cliffs, NJ: Prentice Hall, 1990.
[2] L. S. Brakmo and L. L. Peterson, “TCP Vegas: End to End Congestion
Avoidance on a Global Internet,” IEEE J. Select. Areas Commun., Vol.
13, No. 8, pp. 1465-1480, 1995.
[3] D. Cavendish, M. Gerla, and S. Mascolo, “A Control Theoretical Ap-
proach to Congestion Control in Packet Networks,” IEEE Transactions
on Networking, Vol. 12, No. 5, pp. 893-906, October 2004.
[4] D. Cavendish, K. Kumazoe, M. Tsuru, Y. Oie, and M. Gerla, “Capstart:
An Adaptive TCP Slow Start for High Speed Networks,” IEEE First
International Conference on Evolving Internet, best paper award, pp.
15-20, August 2009.
[5] D. Cavendish, K. Kumazoe, M. Tsuru, Y. Oie, and M. Gerla, “Capacity
and Congestion Probing: TCP Congestion Avoidance via Path Capacity
and Storage Estimation,” IEEE Second International Conference on
Evolving Internet, best paper award, September 2010.
[6] M. Chen, J. Zhang, M. N. Murthy, and K. Premaratne, “TCP Congestion
Avoidance: A Network Calculus Interpretation and Performance Im-
provements,” Proceedings of INFOCOM05, Vol. 2, pp. 914-925, March
2005.
[7] J-Y. Choi, K. Koo, J. S. Lee, and S. H. Low, “Global Stability of FAST
TCP in Single-Link Single-Source Network,” Proceedings of the 44th
IEEE Conference on Decision and Control, pp. 1837-1841, December
2005.
[8] S. Floyd and K. Fall, “Promoting the Use of End-to-End Congestion
Control in the Internet,” IEEE/ACM Transactions on Networking, Vol.
7, No. 4, August 1999.
[9] J. Martin, A. Nilsson, and I. Rhee, “Delay-Based Congestion Avoidance
for TCP,” IEEE/ACM Transactions on Networking, Vol. 11, No. 3, pp.
356-369, 2003.
[10] R. Kapoor, L-J Chen, L. Lao, M. Gerla, and M. Y. Sanadidi, “CapProbe:
A Simple and Accurate Capacity Estimation Technique,” Proceedings of
SIGCOMM 04, Portland, Oregon, pp. 67-78, Sept. 2004.
[11] L. Kleinrock, “Queueing Systems. Volume II: Computer Applications,”
Wiley, 1976.
[12] O.J.Smith, “A controller to overcome dead time,” ISA J., Vol.6, No.2,
pp. 28-33, Feb. 1959.
25
INTERNET 2011 : The Third International Conference on Evolving Internet
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-141-0

