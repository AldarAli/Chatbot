Reliability Evaluation of Erasure Coded Systems
Ilias Iliadis and Vinodh Venkatesan
IBM Research – Zurich
8803 R¨uschlikon, Switzerland
Email: ili@zurich.ibm.com, vinodh.iitm@gmail.com
Abstract—Replication is widely used to enhance the reliability
of storage systems and protect data from device failures. The
effectiveness of the replication scheme has been evaluated based
on the Mean Time to Data Loss (MTTDL) and the Expected
Annual Fraction of Data Loss (EAFDL) metrics. To provide high
data reliability at high storage efﬁciency, modern systems employ
advanced erasure coding redundancy and recovering schemes.
This article presents a general methodology for obtaining the
EAFDL and MTTDL of erasure coded systems analytically for
arbitrary rebuild time distributions and for the symmetric,
clustered, and declustered data placement schemes. Our analysis
establishes that the declustered placement scheme offers superior
reliability in terms of both metrics. The analytical results obtained
enable the derivation of the optimal codeword lengths that
maximize the MTTDL and minimize the EAFDL. It is theoretically
shown that, for large storage systems that use a declustered
placement scheme, both metrics are optimized when the codeword
length is about 60% of the storage system size.
Keywords–Reliability metric; MTTDL; EAFDL; RAID; MDS
codes; Information Dispersal Algorithm; Prioritized rebuild.
I.
INTRODUCTION
The reliability of storage systems is affected by data losses
due to device and component failures, including disk and node
failures. Permanent loss of data is prevented by deploying
redundancy schemes that enable data recovery. However, addi-
tional device failures that may occur during rebuild operations
could lead to permanent data losses. Over the years, several
redundancy and recovery schemes have been developed to
enhance the reliability of storage systems. These schemes
offer different levels of reliability, with varying corresponding
overheads due to the additional operations that need to be
performed, and different levels of storage efﬁciencies that
depend on the additional amount of redundant (parity) data
that needs to be stored in the system [1].
The effectiveness of the redundancy schemes has been
evaluated predominately based on the Mean Time to Data
Loss (MTTDL) metric. Closed-form reliability expressions are
typically obtained using Markov models, with the underlying
assumption that the times to component failures and the rebuild
times are independent and exponentially distributed [2-14].
Recent work has shown that these results also hold in the
practical case of non-exponential failure time distributions.
This was achieved based on a methodology for obtaining
MTTDL that does not involve any Markov analysis [15]. The
MTTDL metric has been used extensively to assess tradeoffs,
to compare schemes, and to estimate the effect of various
parameters on system reliability [16-20].
To cope with data losses encountered in the case of
distributed and cloud storage systems, data is replicated and
recovery mechanisms are used. For instance, Amazon S3 is
designed to provide 99.999999999% (eleven nines) durability
of data over a given year [21]. Similarly, also Facebook [22],
LinkedIn [23] and Yahoo! [24] consider the amount of data
lost in given periods. To address this issue, a recent work
has introduced the Expected Annual Fraction of Data Loss
(EAFDL) metric [25]. It has also presented a methodology
for deriving this metric analytically in the case of replication-
based storage systems, where user data is replicated r times
and the copies are stored in different devices. As an alternative
to replication, storage systems use advanced erasure codes
that provide a high data reliability as well as a high storage
efﬁciency. The use of such erasure codes can be traced back
to as early as the 1980s when they were applied in systems
with redundant arrays of inexpensive disks (RAID) [2][3]. The
RAID-5, RAID-6 and replication-based systems are special
cases of erasure coded systems. State-of-the-art data storage
systems [26][27] employ more general erasure codes, where
the choice of the codes used greatly affects the performance,
reliability, and the storage and reconstruction overhead of the
system. In this article, we focus on the reliability assessment
of erasure coded systems and how the choice of codes affects
the reliability in terms of the MTTDL and EAFDL metrics.
The MTTDL of erasure coded systems has been ob-
tained analytically in [28]. It was theoretically shown that the
MTTDL of erasure coded systems is practically insensitive
to the distribution of the device failure times, but sensitive
to the distribution of the device rebuild times. Simulation
results conﬁrmed the validity of the theoretical model. In
this article, we establish that this also holds for the EAFDL
metric. To reduce the amount of data lost, it is imperative
to assess not only the frequency of data loss events, which
is obtained through the MTTDL metric, but also the amount
of data lost, which is expressed by the EAFDL metric [25].
The EAFDL and MTTDL metrics provide a useful proﬁle
of the size and frequency of data losses. Accordingly, we
present a general framework and methodology for deriving the
EAFDL analytically, along with the MTTDL, for erasure coded
storage systems. The model developed captures the effect of
the various system parameters as well as the effect of various
codeword placement schemes, such as clustered, declustered,
and symmetric data placement schemes. The results obtained
show that the declustered placement scheme offers superior
reliability in terms of both metrics. We also investigate the
effect of the codeword length and identify the optimal values
that offer the best reliability.
The key contributions of this article are the following.
We consider the reliability of erasure coded systems that was
assessed in our earlier work [1] for deterministic rebuild times.
In this study, we extend our previous work by also considering
118
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

arbitrary rebuild times. We show that the codeword lengths
that optimize the MTTDL and EAFDL metrics are similar.
Subsequently, we derive the asymptotic analytic expressions
for the MTTDL and EAFDL reliability metrics when the
number of devices becomes large. We then obtain analytically
the optimal codeword lengths corresponding to large storage
systems. We establish theoretically that, for large storage
systems that use a declustered placement scheme, both metrics
are optimized when the codeword length is about 60% of the
storage system size.
The remainder of the paper is organized as follows. Section
II provides a survey of the relevant literature on erasure coded
systems. Section III describes the storage system model and the
corresponding parameters considered. Section IV presents the
general framework and methodology for deriving the MTTDL
and EAFDL metrics analytically for the case of erasure coded
systems. Closed-form expressions for the symmetric, clus-
tered, and declustered placement schemes are derived. Section
V compares these schemes and establishes that the declus-
tered placement scheme offers superior reliability. Section VI
presents a thorough comparison of the reliability achieved
by the declustered placement scheme under various codeword
conﬁgurations. Finally, we conclude in Section VII.
II.
RELATED WORK
A comparison between erasure coding and replication in
terms of availability in peer-to-peer systems was presented in
[29] and [30]. These works established that erasure codes use
an order of magnitude less storage than replication for systems
with a similar level of reliability. Erasure codes, however, are
more demanding as they may require Galois ﬁeld arithmetic for
encoding and decoding. Therefore, to improve the performance
of erasure coded systems, new codes as well as new encoding
and decoding techniques have been developed (see [31] and
references therein).
The study performed in [30] was conducted by considering
a dynamic environment where nodes join and leave the system
and subsequently trigger data movement. In this context, it was
argued that bandwidth, and not spare storage, is most likely
the limiting factor for the scalability of peer-to-peer storage
systems. Furthermore, not only do erasure codes introduce
a higher complexity in the system owing to the encoding
and decoding process, but also the entire task of maintaining
redundancy in such a dynamic environment becomes more
challenging. In contrast to these works that consider the
codeword lengths being equal to the number of nodes, our
work relaxes this constraint by considering codeword lengths
that may be smaller than the number of nodes. This is desirable
for performance reasons given that in real storage systems the
lengths of the erasure codes used are kept constant and small,
whereas the number of nodes grows with the system capacity.
In addition, having a smaller code length then allows the use
of different placement schemes, some of which enable faster
rebuilds and hence a higher reliability for the same erasure
code.
In [15],[25],[28],[32] and [33], it was shown that the replica
and codeword placements can have a signiﬁcant impact on
reliability. For this reason we also consider and assess the
effect of several codeword placement schemes in this article.
TABLE I.
NOTATION OF SYSTEM PARAMETERS
Parameter
Deﬁnition
n
number of storage devices
c
amount of data stored on each device
l
number of user-data symbols per codeword (l ≥ 1)
m
total number of symbols per codeword (m > l)
s
symbol size
(l, m)
MDS-code structure
k
spread factor of the data placement scheme
b
average reserved rebuild bandwidth per device
X
time required to read (or write) an amount c of data at an average
rate b from (or to) a device
FX(.)
cumulative distribution function of X
Yi
lifetime of the ith device (i = 1, . . . , n)
FY (.)
cumulative distribution function of Yi (i = 1, . . . , n)
seff
storage efﬁciency of redundancy scheme (seff = l/m)
U
amount of user data stored in the system (U = seff n c)
˜r
minimum number of codeword symbols lost that lead to an irrecov-
erable data loss (˜r = m − l + 1 and 2 ≤ ˜r ≤ m)
fX(.)
probability density function of X (fX(.) = F ′
X(.))
1/µ
mean time to read (or write) an amount c of data at a rate b from
(or to) a device (1/µ = E(X) = c/b)
1/λ
mean time to failure of a storage device (1/λ = E(Yi))
III.
STORAGE SYSTEM MODEL
The storage system considered comprises n storage devices
(nodes or disks), with each device storing an amount c of data,
such that the total storage capacity of the system is n c. Modern
data storage systems use various forms of data redundancy
to protect data from device failures. When devices fail, the
redundancy of the data affected is reduced and eventually lost.
To avoid irrecoverable data loss, the system performs rebuild
operations that use the data stored in the surviving devices
to reconstruct the temporarily lost data, thus maintaining the
initial data redundancy.
A. Redundancy
According to the erasure coded schemes considered, the
user data is divided into blocks (or symbols) of a ﬁxed size
(e.g., sector size of 512 bytes) and complemented with parity
symbols to form codewords. In this article, we consider (l, m)
maximum distance separable (MDS) erasure codes, which are a
mapping from l user data symbols to a set of m (> l) symbols,
called a codeword, in such a way that any subset containing
l of the m symbols of the codeword can be used to decode
(reconstruct, recover) the codeword. The corresponding storage
efﬁciency, seff, is given by
seff = l
m .
(1)
Consequently, the amount of user data, U, stored in the system
is given by
U = seff n c = l n c
m
.
(2)
The notation used is summarized in Table I. The parameters are
divided according to whether they are independent or derived,
and are listed in the upper and the lower part of the table,
respectively.
The m symbols of each codeword are stored on m distinct
devices, such that the system can tolerate any ˜r − 1 device
failures, but ˜r device failures may lead to data loss, with
˜r = m − l + 1 .
(3)
From the preceding, it follows that
1 ≤ l < m
and
2 ≤ ˜r ≤ m .
(4)
119
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Examples of MDS erasure codes are the following:
Replication: A replication-based system with a replication
factor r can tolerate any loss of up to r − 1 copies of some
data, such that l = 1, m = r and ˜r = r. Also, its storage
efﬁciency is equal to s(replication)
eff
= 1/r.
RAID-5: A RAID-5 array comprised of N devices uses an
(N − 1, N)-MDS code, such that l = N − 1, m = N and
˜r = 2. It can therefore tolerate the loss of up to one device,
and its storage efﬁciency is equal to s(RAID-5)
eff
= (N − 1)/N.
RAID-6: A RAID-6 array comprised of N devices uses an
(N − 2, N)-MDS code, such that l = N − 2, m = N and
˜r = 3. It can therefore tolerate a loss of up to two devices,
and its storage efﬁciency is equal to s(RAID-6)
eff
= (N − 2)/N.
Reed–Solomon: It is based on (l, m)-MDS erasure codes.
B. Symmetric Codeword Placement
We consider a placement where each codeword is stored
on m distinct devices with one symbol per device. In a
large storage system, the number of devices, n, is typically
much larger than the codeword length, m. Therefore, there
exist many ways in which a codeword of m symbols can
be stored across a subset of the n devices. For each device
in the system, let its redundancy spread factor k denote the
number of devices over which the codewords stored on that
device are spread [28]. The system effectively comprises n/k
disjoint groups of k devices. Each group contains an amount
U/k of user data, with the corresponding codewords placed
on the corresponding k devices in a distributed manner. Each
codeword is placed entirely in one of the n/k groups. Within
each group, all

(a) Spare space reserved in each device.
(b) Distributed rebuild.
(c) Restoration of data on a spare device.
Figure 2.
Rebuild under declustered placement.
symbols, with 0 ≤ j ≤ ˜r. The system is at exposure level u
(0 ≤ u ≤ ˜r), where
u =
max
Dj(t)>0 j.
(5)
In other words, the system is at exposure level u if there are
codewords with m−u symbols left, but there are no codewords
with fewer than m − u symbols left in the system, that is,
Du(t) > 0, and Dj(t) = 0, for all j > u. These codewords are
referred to as the most-exposed codewords. At t = 0, Dj(0) =
0, for all j > 0, and D0(0) is the total number of codewords
stored in the system. Device failures and rebuild processes
cause the values of D1(t), · · · , D˜r(t) to change over time,
and when a data loss occurs, D˜r(t) > 0. Device failures cause
transitions to higher exposure levels, whereas rebuilds cause
transitions to lower ones. Let tu denote the time of the ﬁrst
transition from exposure level u − 1 to exposure level u, and
Figure 3.
Rebuild under clustered placement.
TABLE II.
NOTATION OF SYSTEM PARAMETERS AT EXPOSURE LEVELS
Parameter
Deﬁnition
u
exposure level
Cu
number of most-exposed codewords when entering exposure level
u
Ru
rebuild time at exposure level u
Pu→u+1
transition probability from exposure level u to u + 1
˜nu
number of devices at exposure level u whose failure causes an
exposure level transition to level u + 1
αu
fraction of the rebuild time Ru still left when another device fails
causing the exposure level transition u → u + 1
Vu
fraction of the most-exposed codewords that have symbols stored
on another of the ˜nu devices
Au
amount of data corresponding to the Cu symbols (Au = Cu s)
bu
average rate at which recovered data is written at exposure level u
t+
u the instant immediately after tu. Then, the number of most
exposed codewords when entering exposure level u, denoted
by Cu, u = 1, . . . , ˜r, is given by Cu = Du(t+
u ).
In Section IV-A1, we will derive the reliability metrics
of interest using the direct path approximation, which con-
siders only transitions from lower to higher exposure levels
[15][28][32]. This implies that each exposure level is entered
only once.
2) Prioritized or Intelligent Rebuild: At each exposure
level u, the prioritized or intelligent rebuild process attempts
to bring the system back to exposure level u−1 by recovering
one of the u symbols that each of the most-exposed codewords
has lost, that is, by recovering a total number of Cu symbols.
Let Au denote the amount of data corresponding to the Cu
symbols and let s denote the symbol size. Then, it holds that
Au = Cu s .
(6)
The notation used is summarized in Table II. For an exposure
level u (< ˜r), Au represents the amount of data that needs to
be rebuilt at that exposure level. In particular, upon the ﬁrst-
device failure, it holds that
A1 = c ,
(7)
which, combined with (6), implies that
C1 = A1/s = c/s .
(8)
D. Rebuild Process
During the rebuild process, a certain proportion of the
device bandwidth is reserved for data recovery, with b denoting
the actual average reserved rebuild bandwidth per device. The
121
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

average rebuild bandwidth is usually only a fraction of the total
bandwidth available at each device; the remainder is used to
serve user requests. Let us denote by bu (≤ b) the average
rate at which the amount Au of data that needs to be rebuilt at
exposure level u is written to selected device(s). Also, denote
the cumulative distribution function of the time X required to
read (or write) an amount c of data from (or to) a device by
FX(.) and its corresponding probability density function by
fX(.). The kth moment of X, E(Xk), is then given by
E(Xk) =
Z ∞
0
tkfX(t)dt ,
for k = 1, 2, . . . .
(9)
In particular, let us denote by 1/µ the average time required
to read (or write) an amount c of data from (or to) a device,
given by
1
µ ≜ E(X) = c
b .
(10)
E. Failure and Rebuild Time Distributions
In this work, we assume that the lifetimes Y1, · · · , Yn of
the n devices are independent and identically distributed, with
a cumulative distribution function FY (.) and a mean of 1/λ.
In practice, this assumption is valid when the symbols of a
codeword are placed on independently failing devices, for ex-
ample, on devices located on different nodes/racks/datacenters.
An extension of the analysis to also address correlated failures
is part of future work. We further consider storage devices
with failure time distributions that belong to the large class
deﬁned in [15], which includes real-world distributions, such
as Weibull and gamma, as well as exponential distributions.
The storage devices are highly reliable when the ratio of the
mean time 1/µ to read all contents of a device (which typically
is on the order of tens of hours) to the mean time to failure
of a device 1/λ (which is typically at least on the order of
thousands of hours) is small, that is, when
λ
µ = λ c
b
≪ 1 .
(11)
According to [15][28], when the cumulative distribution
functions FY and FX satisfy the condition
µ
Z ∞
0
FY (t)[1 − FX(t)]dt ≪ 1,
with λ
µ ≪ 1 ,
(12)
the MTTDL reliability metric of replication-based or erasure
coded storage systems tends to be insensitive to the device
failure distribution, that is, the MTTDL depends only on its
mean 1/λ, but not on its density FY (.). In [25], it was shown
that this also holds for the EAFDL metric in the case of
replication-based storage systems and when the rebuild times
are deterministic. In this article, we will show that this also
holds for the EAFDL metric in the case of erasure coded
systems under variable rebuild times.
IV.
DERIVATION OF MTTDL AND EAFDL
We brieﬂy review the general methodology for deriving the
MTTDL and EAFDL metrics presented in [25]. This method-
ology does not involve any Markov analysis and holds for
general failure time distributions, which can be exponential or
non-exponential, such as the Weibull and gamma distributions
that satisfy condition (12).
At any point in time, the system can be thought to be in
one of two modes: normal mode and rebuild mode. During
normal mode, all data in the system has the original amount
of redundancy and there is no active rebuild process. During
rebuild mode, some data in the system has less than the original
amount of redundancy and there is an active rebuild process
that is trying to restore the lost redundancy. A transition from
normal mode to rebuild mode occurs when a device fails;
we refer to the device failure that causes this transition as a
ﬁrst-device failure. Following a ﬁrst-device failure, a complex
sequence of rebuild operations and subsequent device failures
may occur, which eventually leads the system either to an
irrecoverable data loss (DL) with probability PDL or back to the
original normal mode by restoring initial redundancy, which
occurs with probability 1 − PDL.
Let T be a typical interval of a fully operational period, that
is, the time interval from the time t that the system is brought to
its original state until a subsequent ﬁrst-device failure occurs.
For a system comprising n devices with a mean time to failure
of a device equal to 1/λ, the expected duration of T is given
by [25]
E(T) = 1/(n λ) ,
(13)
and the MTTDL by
MTTDL ≈ E(T)
PDL
=
1
n λ PDL
.
(14)
Let H denote the corresponding amount of data lost condi-
tioned on the fact that a data loss has occurred. The metric
of interest, that is, the Expected Annual Fraction of Data Loss
(EAFDL), is subsequently obtained as the ratio of the expected
amount of data lost to the expected time to data loss normalized
to the amount of user data [25]:
EAFDL =
E(H)
MTTDL · U ,
(15)
with the MTTDL expressed in years. Let us also denote by
Q the unconditional amount of data lost upon a ﬁrst-device
failure. Note that Q is unconditional on the event of a data
loss occurring in that it is equal either to H if the system
suffers a data loss prior to returning to normal operation or to
zero otherwise, that is,
Q =
H ,
if DL
0 ,
if no DL .
(16)
Therefore, the expected amount of data lost, E(Q), upon a
ﬁrst-device failure is given by
E(Q) = PDL E(H) .
(17)
From (14), (15) and (17), we obtain the EAFDL as follows:
EAFDL ≈
E(Q)
E(T) · U = n λ E(Q)
U
,
(18)
with E(T) and 1/λ expressed in years.
A. Reliability Analysis
From (14) and (18), it follows that the derivation of the
MTTDL and EAFDL metrics requires the evaluation of PDL
and E(Q), respectively. These quantities are derived by consid-
ering the direct path approximation [15][28][32], which, under
122
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

conditions (11) and (12), accurately assesses the reliability
metrics of interest [13][14][15][25].
Next, we present the general outline of the methodology
in more detail.
1) Direct Path to Data Loss: Consider the direct path
of successive transitions from exposure level 1 to ˜r. In
[15][28][32], it was shown that PDL can be approximated by
the probability of the direct path to data loss, PDL,direct, that is,
PDL ≈ PDL,direct =
r−1
Y
u=1
Pu→u+1,
(19)
where Pu→u+1 denotes the transition probability from ex-
posure level u to u + 1. The above approximation holds
when storage devices are highly reliable, that is, it holds
for arbitrary device failure and rebuild time distributions that
satisfy conditions (11) and (12). In this case, the relative error
tends to zero as λ/µ tends to zero [15].
As the direct path to data loss dominates the effect of all
other possible paths to data loss considered together, it follows
that the amount of data lost H can be approximated by that
corresponding to the direct path:
H ≈ Hdirect .
(20)
Also, from (16) and (20) it follows that
Q ≈
Hdirect ,
if DL follows the direct path
0 ,
otherwise .
(21)
Consequently, to derive the amount of data lost, it sufﬁces to
proceed by considering the H and Q metrics corresponding to
the direct path to data loss.
Note that the amount of data lost, H, is the amount
of user data stored in the most-exposed codewords when
entering exposure level ˜r, which can no longer be recovered
and therefore is irrecoverably lost. As the number of these
codewords is equal to C˜r and each of these codewords contains
l symbols of user data, it holds that
H = C˜r l s ,
(22)
and using (6),
H = l A˜r .
(23)
2) Amount of Data to Rebuild and Rebuild Times at Each
Exposure Level: We now proceed to derive the conditional
values of the random variables of interest given that the system
goes through the direct path to data loss. Let Ru denote the
rebuild times of the most-exposed codewords at each exposure
level in this path, and let αu be the fraction of the rebuild time
Ru still left when another device fails causing the exposure
level transition u → u + 1. In [35, Lemma 2], it was shown
that, for highly reliable devices satisfying conditions (11) and
(12), αu is approximately uniformly distributed between zero
and one, that is,
αu ∼ U(0, 1),
u = 1, . . . , ˜r − 1 .
(24)
Let ⃗α denote the vector (α1, . . . , α˜r−1), ⃗αu the vector
(α1, . . . , αu), ⃗Cu the vector (C1, · · · , Cu) and ⃗Au the vector
(A1, · · · , Au). Clearly, for the rebuild schemes considered, the
fraction αu of the rebuild time Ru still left also represents
the expected fraction of the most-exposed codewords not
yet recovered upon the next device failure. Therefore, the
expected number of most-exposed codewords that are not yet
recovered is equal to αu Cu. Clearly, the fraction Vu of these
codewords that have symbols stored on the newly failed device
depends on the codeword placement scheme. Consequently,
the expected number of the most-exposed codewords when
entering exposure level u + 1 is given by
E(Cu+1 | ⃗α, ⃗Cu) = Vu αu Cu, ,
u = 1, . . . , ˜r − 1 ,
(25)
with Vu depending only on the placement scheme. Similarly,
from (6), it follows that the corresponding expected amount of
data that is not yet rebuilt is equal to αu Au. From (25), we
deduce that
E(Au+1 | ⃗α, ⃗Au) = Vu αu Au, ,
u = 1, . . . , ˜r − 1 ,
(26)
An expression for the expected amount of data to be rebuilt
at each exposure level is given by the following proposition.
Proposition 1: For u = 2, . . . , ˜r − 1, it holds that
E(Au | ⃗αu−1) = c
u−1
Y
j=1
Vj αj .
(27)
Proof: We will prove (27) by induction. For u = 2, (27)
holds owing to (7) and (26). Suppose that (27) holds for u = k,
that is,
E(Ak | ⃗αk−1) = c
k−1
Y
j=1
Vj αj .
(28)
We will show that (27) also holds for u = k + 1, that is,
E(Ak+1 | ⃗αk) = c
k
Y
j=1
Vj αj .
(29)
From (26) it holds that
E(Ak+1 | ⃗α, ⃗Ak) = E(Ak+1 | ⃗αk, Ak) = Vk αk Ak .
(30)
It also holds that
E(Ak+1 | ⃗αk) = EAk | ⃗αk[E(Ak+1 | ⃗αk, ⃗Ak)] .
(31)
Substituting (30) into (31) yields
E(Ak+1 | ⃗αk) = EAk | ⃗αk(Vk αk Ak) = Vk αk E(Ak | ⃗αk) .
(32)
Clearly, the number Ck of most-exposed codewords when
entering exposure level k and the corresponding amount of
data Ak does not depend on the fraction αk of the rebuild
time Rk still left when another device fails causing the
exposure level transition k → k + 1. It therefore holds that
E(Ak | ⃗αk) = E(Ak | ⃗αk−1), and (32) yields
E(Ak+1 | ⃗αk) = Vk αk E(Ak | ⃗αk−1)
(28)
= c
k
Y
j=1
Vj αj . (33)
Remark 1: From (27), it follows that the expected amount
of data to be rebuilt at each exposure level do not depend on
the duration of the rebuild times.
123
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

At exposure level 1, according to (7), the amount A1 of data
to be recovered is equal to c. Given that this data is recovered
at an average rate of b1 and that the time required to write an
amount c of data at an an average rate of b is equal to X, it
follows that the rebuild time R1 is given by
R1 = b
b1
X .
(34)
As the rebuild times are proportional to the amount of data
to be rebuilt and are inversely proportional to the rebuild rates,
it holds that
E
Ru+1
Ru
| ⃗α, ⃗Au

= E
Au+1
Au
| ⃗α, ⃗Au

bu
bu+1
, u ≥ 1 .
(35)
Using (26), (35) yields
E
Ru+1
Ru
| ⃗α, ⃗Au

= Vu αu
bu
bu+1
,
u = 1, . . . , ˜r − 2 ,
(36)
and conditioning on Ru,
E(Ru+1 | ⃗α, ⃗Au, Ru) = Vu αu
bu
bu+1
Ru , u = 1, . . . , ˜r − 2 .
(37)
The above implies that of all the random variables involved in
vectors ⃗α and ⃗Au, only au and Ru are essential for determining
E(Ru+1). We proceed by considering the mean 1/µu of the
rebuild time Ru conditioned on αu−1 and Ru−1:
1/µu ≜ E(Ru | Ru−1, αu−1),
u = 2, . . . , ˜r − 1 .
(38)
From (37) and (38), it follows that
1/µu = Gu−1 αu−1 Ru−1 ,
for u = 2, . . . , ˜r − 1 ,
(39)
where
Gu ≜
bu
bu+1
Vu ,
u = 1, . . . , ˜r − 2 .
(40)
The distribution of Ru, given Ru−1 and αu−1, could be
modeled in several ways. We proceed as in [28] by considering
the model B presented in [15], according to which the rebuild
time Ru is determined completely by Ru−1 and αu−1 and no
new randomness is introduced in the rebuild time at exposure
level u, that is,
Ru | Ru−1, αu−1 = 1/µu w.p. 1, for u = 2, . . . , ˜r−1 , (41)
which by virtue of (39) yields
Ru = Gu−1 αu−1 Ru−1 ,
for u = 2, . . . , ˜r − 1 .
(42)
Repeatedly applying (42) and using (40) yields
Ru = b1
bu
R1
u−1
Y
j=1
Vj αj ,
u = 1, . . . , ˜r − 1 .
(43)
Let ˜nu be the number of devices at exposure level u whose
failure before the rebuild of the most-exposed codewords
causes an exposure level transition to level u+1. Subsequently,
the transition probability Pu→u+1 from exposure level u to
u+1 depends on the duration of the corresponding rebuild time
Ru and the aggregate failure rate of these ˜nu highly reliable
devices, and is given by [15]
Pu→u+1 ≈ ˜nu λ Ru ,
for u = 1, . . . , ˜r − 1 .
(44)
Conditioning on R1 and ⃗αu−1, and substituting (43) into (44),
yields
Pu→u+1(R1, ⃗αu−1) ≈ ˜nu λ b1
bu
R1
u−1
Y
j=1
Vj αj .
(45)
Approximate expressions for the probability of data loss,
PDL, and the expected amount of data lost, E(Q), are subse-
quently obtained by the following propositions.
Proposition 2: It holds that
PDL ≈ (λ c)˜r−1
1
(˜r − 1)!
E(X ˜r−1)
[E(X)]˜r−1
˜r−1
Y
u=1
˜nu
bu
V ˜r−1−u
u
,
(46)
where E(X ˜r−1) is obtained by (9).
Proof: See Appendix A.
Proposition 3: It holds that
E(Q) ≈ l c (λ c)˜r−1 1
˜r !
E(X ˜r−1)
[E(X)]˜r−1
˜r−1
Y
u=1
˜nu
bu
V ˜r−u
u
,
(47)
where E(X ˜r−1) is obtained by (9).
Proof: See Appendix B.
3) Evaluation of E(H): The expected amount E(H) of
data lost conditioned on the fact that a data loss has occurred is
obtained from (17) as the ratio of E(Q) to PDL. Consequently,
using (46) and (47), it follows that
E(H) = E(Q)
PDL
≈
 
l
˜r
˜r−1
Y
u=1
Vu
!
c .
(48)
Remark 2: From (48), it follows that the expected amount
of data lost conditioned on the fact that a data loss has occurred
does not depend on the duration of the rebuild times.
4) Evaluation of MTTDL and EAFDL: Substituting (46)
into (14) yields
MTTDL ≈
1
n λ
(˜r − 1)!
(λ c)˜r−1
[E(X)]˜r−1
E(X ˜r−1)
˜r−1
Y
u=1
bu
˜nu
1
V ˜r−1−u
u
.
(49)
Substituting (2) and (47) into (18) yields
EAFDL ≈ m λ (λ c)˜r−1 1
˜r !
E(X ˜r−1)
[E(X)]˜r−1
˜r−1
Y
u=1
˜nu
bu
V ˜r−u
u
.
(50)
B. Symmetric Placement
Here, we consider the case where the redundancy spread
factor k is in the interval m < k ≤ n. As discussed in
Section III-C2, at each exposure level u, the prioritized rebuild
process recovers one of the u symbols that each of the Cu
most-exposed codewords has lost by reading m − ˜r + 1 of
the remaining symbols. Thus, there are Cu symbols to be
recovered in total, which corresponds to an amount Au of
data. For the symmetric placement discussed in Section III-B,
these symbols are recovered by reading (m − ˜r + 1) Cu
symbols, which corresponds to an amount (m − ˜r + 1) Au
124
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

of data, from the k − u surviving devices in the affected
group. Note that these are precisely the devices at exposure
level u whose failure before the rebuild of the most-exposed
codewords causes an exposure level transition to level u + 1.
Consequently, it holds that
˜nsym
u
= k − u .
(51)
Furthermore, it is desirable to write the recovered symbols
to the spare space of these devices in such a way that no
symbol is written to a device in which another symbol corre-
sponding to the same codeword is already present. This will
ensure that whenever a device fails, no more than one symbol
from any codeword is lost. Owing to the symmetry of the
symmetric placement, the same amount of data is being read
from each of the ˜nu devices. Similarly, the same amount of
data is being written to each of the ˜nu devices. Consequently,
the total average read/write rebuild bandwidth b of each device
is split between the reads and the writes, such that the average
read rate is equal to (m− ˜r+1) b/(m− ˜r+2) and the average
write rate is equal to b/(m−˜r+2). Therefore, the total average
write bandwidth, which is also the average rebuild rate bu, is
given by
bsym
u
=
˜nu
m − ˜r + 2 b ,
u = 1, . . . , ˜r − 1 .
(52)
Once all lost codeword symbols have been recovered, they are
transferred to a new replacement device.
When the system enters exposure level u, the number of
most-exposed codewords that need to be recovered is equal to
Cu, u = 1, . . . , ˜r. Upon the next device failure, the expected
number of most-exposed codewords that are not yet recovered
is equal to αu Cu. Owing to the nature of the symmetric
codeword placement, the newly failed device stores codeword
symbols corresponding to only a fraction
V sym
u
= m − u
k − u ,
u = 1, . . . , ˜r − 1 .
(53)
of these most-exposed, not yet recovered codewords.
Substituting (51), (52), and (53) into (49), (50), and (48),
and using (3), yields
MTTDLsym
k
≈
1
n λ

b
(l + 1) λ c
m−l
(m − l)!
[E(X)]m−l
E(Xm−l)
m−l
Y
u=1
 k − u
m − u
m−l−u
,
(54)
EAFDLsym
k
≈ λ
(l + 1) λ c
b
m−l
m
(m − l + 1)!
E(Xm−l)
[E(X)]m−l
m−l
Y
u=1
m − u
k − u
m−l+1−u
,
(55)
and
E(H)sym
k
≈
 
l
m − l + 1
m−l
Y
u=1
m − u
k − u
!
c
(56)
= l (m − 1)! (k − m + l − 1)!
(m − l + 1) (k − 1)! (l − 1)! c .
(57)
Note that for a deterministic rebuild time distribution,
for which it holds that E(Xm−l) = [E(X)]m−l, and for a
replication-based system, for which m = r and l = 1, (54)
and (55) are in agreement with Equations (42.b) and (43.b) of
[25], respectively.
Remark 3: From (54), (55), and (56), it follows that
MTTDLsym
k
depends on n, but EAFDLsym
k
and E(H)sym
k
do
not.
Remark 4: From (54), (55), and (56), it follows that, for
m − l = 1, MTTDLsym
k
does not depend on k, whereas for
m−l > 1, MTTDLsym
k
is increasing in k. Also, for m−l ≥ 1,
EAFDLsym
k
and E(H)sym
k
are decreasing in k. Consequently,
within the class of symmetric placement schemes considered,
that is, for m < k ≤ n, the MTTDLsym
k
is maximized and
the EAFDLsym
k
and the E(H)sym
k
are minimized when k = n.
Also, given that E(X) = c/b, the MTTDLsym
k
and EAFDLsym
k
depend on the (m − l)th moment of the rebuild time distribu-
tion, whereas E(H)sym
k
does not depend on the rebuild times.
Furthermore, given that E(Xm−l) ≥ [E(X)]m−l, random
rebuild times result in lower MTTDL and higher EAFDL
values than deterministic rebuild times do.
Approximate expressions for the reliability metrics of in-
terest are given by the following propositions.
Proposition 4: For large values of k, m, l, and m − l, the
E(H)sym normalized to c can be approximated as follows:
log

and h and x are given by (60) and (61), respectively.
Proof: See Appendix D.
Proposition 6: For large values of k, m, l, and m − l, the
EAFDLsym normalized to λ can be approximated as follows:
log

and h is given by (60).
Proof: From (68) and (69) it follows that
MTTDLclus ≈ 1
nλ
 b
λ c
m−l (m − 1)(m − l)! l!
l m!
[E(X)]m−l
E(Xm−l) ,
(74)
and
EAFDLclus ≈ λ
λ c
b
m−l
l m!
(m − l + 1)(m − l)! l!
E(Xm−l)
[E(X)]m−l .
(75)
Using Stirling’s approximation for large values of n,
n! ≈
√
2πn
n
e
n
,
(76)
(74) and (75) yield
MTTDLclus ≈
1
n λ
 b
λ c
m−l m − 1
l
r
2π(m − l) l
m
(m − l)m−l ll
mm
[E(X)]m−l
E(Xm−l) ,
(77)
and
EAFDLclus ≈ λ
λ c
b
m−l
l
m − l + 1
r
m
2π(m − l) l
mm
(m − l)m−l ll
E(Xm−l)
[E(X)]m−l .
(78)
From (1), (60), and (73), it follows that
l = seff m = (1 − h) m = (1 − h) x n
(79)
and
m − l = (1 − seff) m = h m = h x n .
(80)
Substituting (79) and (80) into (77) and (78) yields (71)
and (72), respectively.
D. Declustered Placement
As discussed in Section III-B, the declustered placement
scheme is a special case of a symmetric placement scheme in
which k is equal to n. Consequently, for k = n, (54), (55),
and (56) yield
MTTDLdeclus ≈
1
n λ

b
(l + 1) λ c
m−l
(m − l)!
[E(X)]m−l
E(Xm−l)
m−l
Y
u=1
 n − u
m − u
m−l−u
,
(81)
EAFDLdeclus ≈ λ
(l + 1) λ c
b
m−l
m
(m − l + 1)!
E(Xm−l)
[E(X)]m−l
m−l
Y
u=1
m − u
n − u
m−l+1−u
,
(82)
and
E(H)declus ≈
 
l
m − l + 1
m−l
Y
u=1
m − u
n − u
!
c
(83)
= l (m − 1)! (n − m + l − 1)!
(m − l + 1) (n − 1)! (l − 1)! c .
(84)
Note that the MTTDL derived in (81) is in agree-
ment with Equation (16) of [28], with c/b = 1/µ and
[E(X)]m−l/E(Xm−l) = M m−l
1

G n−1
l+1 µ

/Mm−l

G n−1
l+1 µ

.
Also, for a deterministic rebuild time distribution, for which
it holds that E(Xm−l) = [E(X)]m−l, and for a replication-
based system, for which m = r and l = 1, (81), (82) and (83)
are in agreement with Equations (36.b), (37.b), and (39.b) of
[25], respectively.
Remark 7: From (81), (82), and (83), and given that
E(X) = c/b, it follows that MTTDLdeclus and EAFDLdeclus
depend on the (m − l)th moment of the rebuild time distribu-
tion, whereas E(H)clus does not depend on the rebuild times.
Furthermore, given that E(Xm−l) ≥ [E(X)]m−l, random
rebuild times result in lower MTTDL and higher EAFDL
values than deterministic rebuild times do.
Approximate expressions for the reliability metrics of in-
terest are given by the following propositions.
Proposition 8: For large values of n, m, l, and m − l,
the MTTDLdeclus normalized to 1/λ can be approximated as
follows:
log

Proof: Immediate from Proposition 6 by replacing k with
n and using (73).
Proposition 10: For large values of n, m, l, and m−l, the
E(H)declus normalized to c can be approximated as follows:
log

0
10
20
30
40
50
60
0.85
0.9
0.95
1
m
MTTDLapprox / MTTDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(a) MTTDLclus
approx/MTTDLclus
0
10
20
30
40
50
60
1
1.05
1.1
1.15
m
EAFDLapprox / EAFDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(b) EAFDLclus
approx/EAFDLclus
Figure 4.
Accuracy of approximations for clustered placement vs. codeword length for seff = 1/5, 1/4, 1/3, 1/2, 2/3, and 7/8.
0
5
10
15
20
0.85
0.9
0.95
1
m
MTTDLapprox / MTTDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(a) k = 20
0
10
20
30
40
0.85
0.9
0.95
1
m
MTTDLapprox / MTTDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(b) k = 40
0
10
20
30
40
50
60
0.85
0.9
0.95
1
m
MTTDLapprox / MTTDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(c) k = 60
0
50
100
150
200
0.85
0.9
0.95
1
m
MTTDLapprox / MTTDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(d) k = 200
Figure 5.
MTTDLsym
approx/MTTDLsym ratio vs. codeword length for seff = 1/5, 1/4, 1/3, 1/2, 2/3, and 7/8.
0
5
10
15
20
1
1.05
1.1
1.15
1.2
m
EAFDLapprox / EAFDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(a) k = 20
0
10
20
30
40
1
1.05
1.1
1.15
1.2
m
EAFDLapprox / EAFDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(b) k = 40
0
10
20
30
40
50
60
1
1.05
1.1
1.15
1.2
m
EAFDLapprox / EAFDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(c) k = 60
0
50
100
150
200
1
1.05
1.1
1.15
1.2
m
EAFDLapprox / EAFDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(d) k = 200
Figure 6.
EAFDLsym
approx/EAFDLsym ratio vs. codeword length for seff = 1/5, 1/4, 1/3, 1/2, 2/3, and 7/8.
0
5
10
15
20
1
1.01
1.02
1.03
1.04
1.05
1.06
1.07
m
E(H)approx / E(H)
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(a) k = 20
0
10
20
30
40
1
1.01
1.02
1.03
1.04
1.05
1.06
1.07
m
E(H)approx / E(H)
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(b) k = 40
0
10
20
30
40
50
60
1
1.01
1.02
1.03
1.04
1.05
1.06
1.07
m
E(H)approx / E(H)
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(c) k = 60
0
50
100
150
200
1
1.01
1.02
1.03
1.04
1.05
1.06
1.07
m
E(H)approx / E(H)
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 7/8
(d) k = 200
Figure 7.
E(H)sym
approx/E(H)sym ratio vs. codeword length for seff = 1/5, 1/4, 1/3, 1/2, 2/3, and 7/8.
3) m − l ≥ 3: For m − l ≥ 3, (89) can be written as
follows:
MTTDLdeclus
MTTDLclus ≈ m − 1
l + 1
· · · l + 1
l + 1
l
l + 1
n − m + l + 1
l + 1
n − m + l + 2
l + 2
2 m−l−3
Y
u=1
 n − u
m − u
m−l−u
.
(92)
Using (88), (92) yields
MTTDLdeclus
MTTDLclus >
l
l + 1
n − m + l + 1
l + 1
n − m + l + 2
l + 2
2
≥
l
l + 1
l + 2
l + 1
l + 3
l + 2
2
=
l (l + 3)2
(l + 1)2 (l + 2)
= 2[l2 + 2(l − 1) + 1]
(l + 1)2 (l + 2)
+ 1 > 1 .
(93)
Remark 9: From the preceding, it follows that the MTTDL
is maximized by the declustered placement scheme, except in
129
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

the case of m − l = 1, where it is maximized by the clustered
placement scheme.
B. Minimizing EAFDL
From (69) and (82), it follows that
EAFDLdeclus
EAFDLclus ≈ (l+1)m−l (l − 1)!
(m − 1)!
m−l
Y
u=1
m − u
n − u
m−l+1−u
.
(94)
Remark 10: From (94), it follows that the placement that
minimizes EAFDL does not depend on λ, b and c, nor on the
rebuild time distribution.
Depending on the value of ˜r, we consider the following
two cases:
1) m − l = 1: For m − l = 1, (94) yields
EAFDLdeclus
EAFDLclus ≈
m
n − 1 < 1 , for n ≥ m + 2 .
(95)
Note that from (88), it holds that 2 ≤ m ≤ n/2, which in turn
implies that n ≥ m + 2, and therefore (95) holds.
2) m − l ≥ 2: For m − l ≥ 2, (94) can be written as
follows:
EAFDLdeclus
EAFDLclus ≈ l + 1
m − 1
l + 1
m − 2 · · · l + 1
l
l
n − m + l
m−l−1
Y
u=1
m − u
n − u
m−l+1−u
.
(96)
Using (88), (96) yields
EAFDLdeclus
EAFDLclus
<
l + 1
n − m + l ≤
l + 1
(m + 1) − m + l = 1 .
(97)
Remark 11: From the preceding, it follows that the declus-
tered placement scheme minimizes EAFDL for any n, m, l,
λ, b, c, and rebuild time distribution.
C. Minimizing E(H)
From (70) and (83), and using (88), it follows that
E(H)declus
E(H)clus ≈
m−l
Y
u=1
m − u
n − u
< 1 .
(98)
Remark 12: From (98), it follows that for any n, m, l, λ,
b, c, and rebuild time distribution, E(H) is minimized by the
declustered placement scheme.
D. Synopsis
When the codeword length is smaller than the system size
(m < n), the declustered placement scheme minimizes the
expected amount of data lost when a loss occurs, independently
of the device capacity c and its reliability characteristics and
the mean time to failure expressed by λ, the average reserved
rebuild bandwidth b and the resulting rebuild time distribution
of X. Also, for m − l = 1, the clustered placement scheme
maximizes the MTTDL, but the declustered placement scheme
minimizes the EAFDL. However, for m−l ≥ 2, the declustered
placement scheme maximizes the MTTDL and at the same
time minimizes the EAFDL.
Note that the preceding conclusions hold under the as-
sumption that failures are detected instantaneously, which
immediately triggers the rebuild process, and the assumption
that sufﬁcient network bandwidth is available to support the
parallelism of the rebuild process.
VI.
RELIABILITY COMPARISON
Here, we assess the relative reliability of the declustered
placement, which according to Remarks 9, 11 and 12 is the
optimal one, under various codeword lengths m. We perform a
fair comparison by considering systems with the same amount
of user data, U, stored under the same storage efﬁciency, seff.
From (2), it follows that the number of devices n is ﬁxed.
Also, from (80), it follows that the parameter h is ﬁxed. Using
(79) to express l in terms of h and m in (81), (82), and (83),
we obtain
MTTDLdeclus ≈
1
n λ

b
[(1 − h)m + 1] λ c
hm
(hm)!
[E(X)]hm
E(Xhm)
hm
Y
u=1
 n − u
m − u
hm−u
,
(99)
EAFDLdeclus ≈ λ
[(1 − h)m + 1] λ c
b
hm
m
(hm + 1)!
E(Xhm)
[E(X)]hm
hm
Y
u=1
m − u
n − u
hm+1−u
, (100)
and
E(H)declus ≈
 
(1 − h)m
hm + 1
hm
Y
u=1
m − u
n − u
!
c
(101)
=
(1 − h) m ! (n − 1 − hm)!
(n − 1)! (hm + 1) ((1 − h)m − 1))! c . (102)
As
discussed
in
Section
IV-A,
the
direct-path-
approximation method yields accurate results when the
storage devices are highly reliable, that is, when the ratio
λ/µ of the mean rebuild time 1/µ to the mean time to failure
of a device 1/λ is very small. We proceed by considering
systems for which it holds that λ/µ = λ c/b = 0.001 and
the rebuild time distribution is deterministic, for which it
holds that E(Xhm) = [E(X)]hm. The combined effect of
the number of devices and the system efﬁciency on the
normalized λ MTTDLdeclus measure is obtained by (99) and
shown in Figure 8 as a function of the codeword length. The
values for the storage efﬁciency are chosen to be fractions
of the form z/(z + 1), z = 1, . . . , 7, such that the ﬁrst point
of each of the corresponding curves is associated with the
single-parity (z, z + 1)-erasure code, and the second point
of each of the corresponding curves is associated with the
double-parity (2z, 2z + 2)-erasure code. We observe that the
MTTDL increases as the storage efﬁciency seff decreases. This
is because, for a given m, decreasing seff implies decreasing
l, which in turn implies increasing the parity symbols m − l
and consequently improving the MTTDL.
130
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

0
5
10
15
20
10
0
10
5
10
10
10
15
10
20
10
25
m
λ MTTDL
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) n = 20
0
10
20
30
40
10
0
10
10
10
20
10
30
10
40
10
50
m
λ MTTDL
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(b) n = 40
0
10
20
30
40
50
60
10
0
10
20
10
40
10
60
10
80
m
λ MTTDL
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(c) n = 60
Figure 8.
Normalized MTTDLdeclus vs. codeword length for seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8; λ/µ = 0.001 and deterministic rebuild times.
0
5
10
15
20
10
−25
10
−20
10
−15
10
−10
10
−5
m
EAFDL / λ
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) n = 20
0
10
20
30
40
10
−50
10
−40
10
−30
10
−20
10
−10
m
EAFDL / λ
 
 
se, = 1/2
se, = 2/3
se, = 3/4
se, = 4/5
se, = 5/6
se, = 6/7
se, = 7/8
(b) n = 40
0
10
20
30
40
50
60
10
−80
10
−60
10
−40
10
−20
m
EAFDL / λ
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(c) n = 60
Figure 9.
Normalized EAFDLdeclus vs. codeword length for seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8; λ/µ = 0.001 and deterministic rebuild times.
0
5
10
15
20
10
−3
10
−2
10
−1
10
0
10
1
m
E(H) / c
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) n = 20
0
10
20
30
40
10
−5
10
−4
10
−3
10
−2
10
−1
10
0
10
1
m
E(H) / c
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(b) n = 40
0
10
20
30
40
50
60
10
−6
10
−4
10
−2
10
0
m
E(H) / c
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(c) n = 60
Figure 10.
Normalized E(H)declus vs. codeword length for seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8; λ/µ = 0.001.
Let us now consider the single-parity codewords, which
correspond to the ﬁrst points of the curves. Note that, according
to Remark 9 and (90), the clustered placement scheme yields
larger, but of the same order, MTTDL values as the declustered
placement does. Consequently, the MTTDL points for the
single-parity codewords under a clustered placement scheme
are slightly higher than those shown in Figure 8. As seff
increases, so do m and l, which results in a decreasing
MTTDL for these codewords. This is due to the fact that as m
increases, there are l data symbols, that is, more data symbols
associated with each parity. This is in accordance with the
results presented in Figure 2 of [28]. We observe that the same
applies for the double-parity codewords, which correspond to
the second points of the curves.
The combined effect of the number of devices and the
system efﬁciency on the normalized EAFDLdeclus/λ measure
is obtained by (100) and shown in Figure 9 as a function of
the codeword length. We observe that the EAFDL increases
as the storage efﬁciency seff increases. Also, as seff increases,
the EAFDL for the single-parity codewords, which correspond
to the ﬁrst points of the curves, also increases. We observe
that the same applies for the double-parity codewords, which
correspond to the second points of the curves.
The combined effect of the number of devices and the
system efﬁciency on the normalized E(H)declus/c measure is
obtained by (101) and shown in Figure 10 as a function of
the codeword length. We observe that E(H) increases as the
storage efﬁciency seff increases. Also, as seff increases, the
E(H) for the single-parity codewords, which correspond to
the ﬁrst points of the curves, increases as well. We observe
that the same applies for the double-parity codewords, which
correspond to the second points of the curves.
131
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

20
40
60
80
100
120
0
2
4
6
8
10
Number of Devices (n)
m*
MTTDL − m*
EAFDL 
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8
20
40
60
80
100
120
0
2
4
6
8
10
Number of Devices (n)
m*
MTTDL − m*
EAFDL 
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
(b) seff = 1/5, 1/4, 1/3, and 1/2
Figure 11.
The difference between m∗
MTTDL and m∗
EAFDL vs. the number of devices; λ/µ = 0.001 and deterministic rebuild times.
We now proceed to identify the optimal codeword length,
m∗, that maximizes the MTTDL or minimizes the EAFDL
and E(H) for a given storage efﬁciency. Note that we only
consider declustered placements with m < n, but not the
clustered placement with m = n. The optimal codeword length
is dictated by two opposing effects on reliability. On the one
hand, larger values of m imply that codewords can tolerate
more device failures, but on the other hand result in a higher
exposure degree to failure as each of the codewords is spread
across a larger number of devices. In Figures 8, 9, and 10,
the optimal values, m∗, are indicated by the circles, and the
corresponding codeword lengths are indicated by the vertical
dotted lines. Regarding MTTDL and EAFDL, we observe that
for small values of n, it holds that m∗ ≅ n, whereas for
large values of n it holds that m∗ < n. It turns out that
for n ≥ 60, the clustered placement scheme with m = n
does not result in improved reliability. However, for smaller
values of n, that is, for n < 60, the clustered placement
scheme can improve reliability. For instance, for n = 20 and
seff = 4/5, the MTTDL is maximized and the EAFDL is
minimized by the clustered placement scheme with m = n.
By comparing Figures 8 and 9, we deduce that in general the
optimal codeword lengths m∗
MTTDL (for MTTDL) and m∗
EAFDL
(for EAFDL) are similar and for some values of n even
identical. They are, however, signiﬁcantly larger than those
that minimize the E(H), which are shown in Figure 10.
Figure 11 shows the difference between the optimal code-
word lengths for MTTDL and EAFDL. It demonstrates that
the optimal codeword length for MTTDL is always greater
than or equal to that for EAFDL, with the difference being
equal either to z +1, the denominator of the storage efﬁciency
fraction, or to zero. This implies that the optimal codeword
lengths m∗
EAFDL for EAFDL are either equal to or slightly lower
than and adjacent to the optimal codeword lengths m∗
MTTDL for
MTTDL. For example, in the case of n = 40 and seff = 1/2,
Figure 8(b) shows that the maximum value of MTTDL is
achieved when the codeword length m is equal to 34, which
implies that m∗
MTTDL = 34. Also, Figure 9(b) shows that the
minimum value of EAFDL is achieved when the codeword
length m is equal to 32, which implies that m∗
EAFDL = 32.
The value of 32 is adjacent to 34 because when seff = 1/2,
m cannot be equal to 33. Consequently, the difference of the
optimal codeword lengths for EAFDL and MTTDL is given
by 34 – 32 = 2, indicated by a circle in Figure 11. Similarly,
for n = 40 and seff = 2/3, Figures 8(b) and 9(b) show
that both the optimal MTTDL and the optimal EAFDL are
obtained when the codeword length is equal to 36, that is,
m∗
MTTDL = m∗
EAFDL = 36. In this case, the difference of the
optimal codeword lengths for EAFDL and MTTDL is equal
to zero, indicated by a circle in Figure 11.
To investigate the behavior of the optimal codeword length,
m∗, as the storage system size, n, increases, we proceed
by considering the normalized optimal codeword length r∗,
namely, the ratio of m∗ to n:
r∗ ≜ m∗
n
.
(103)
The r∗ values for various storage efﬁciencies and for the
MTTDL and EAFDL metrics are shown in Figure 12. From the
preceding, it follows that the difference r∗
MTTDL−r∗
EAFDL of the
r∗ values for the two metrics is bounded above by (z + 1)/n,
which approaches zero as n increases. Thus, as n increases,
the difference r∗
MTTDL − r∗
EAFDL also approaches zero.
The r∗ values for the MTTDL and EAFDL metrics for
various values of the storage efﬁciency seff and for large
values of n are shown in Figures 13 and 14. It turns out
that it always holds that r∗
EAFDL ≤ r∗
MTTDL or, equivalently,
m∗
EAFDL ≤ m∗
MTTDL. We observe that, as n increases, the
r∗ values tend to decrease. In particular, for a given storage
efﬁciency and as n increases, the r∗ values for MTTDL
and EAFDL approach a common value, denoted by r∗
∞ and
indicated by a small bullet. The r∗
∞ value depends only on seff
and is given by the following proposition.
Proposition 11: As n increases, the r∗ values for MTTDL
and EAFDL approach r∗
∞ that satisﬁes the following equation:
Q(h, r∗
∞) = 0 ,
(104)
where
Q(h, x) ≜ hx + log

[(1 − h)(1−h)2xh2]x(1 − hx)h(1−hx)
.
(105)
132
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

20
40
60
80
100
120
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Number of Devices (n)
r*
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) MTTDL
20
40
60
80
100
120
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Number of Devices (n)
r*
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(b) EAFDL
Figure 12.
r∗ vs. number of devices for seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8; λ/µ = 0.001 and deterministic rebuild times.
20
200
400
600
800
1000
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
Number of Devices (n)
r*
 
 
∞
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) MTTDL
20
200
400
600
800
1000
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
Number of Devices (n)
r*
 
 
∞
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(b) EAFDL
Figure 13.
r∗ vs. number of devices n → ∞, seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8; λ/µ = 0.001 and deterministic rebuild times.
20
200
400
600
800
1000
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
Number of Devices (n)
r*
 
 
∞
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
(a) MTTDL
20
200
400
600
800
1000
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
Number of Devices (n)
r*
 
 
∞
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
(b) EAFDL
Figure 14.
r∗ vs. number of devices n → ∞, seff = 1/5, 1/4, 1/3, and 1/2; λ/µ = 0.001 and deterministic rebuild times.
133
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

20
40
60
80
100
120
1
1.5
2
2.5
3
3.5
4
Number of Devices (n)
rEAFDL
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8
200
400
600
800
1000
10
0
10
1
10
2
Number of Devices (n)
rEAFDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
(b) seff = 1/5, 1/4, 1/3, and 1/2
Figure 16.
The EAFDL efﬁciency ratio rEAFDL vs. number of devices; λ/µ = 0.001 and deterministic rebuild times.
TABLE III.
r∗
∞ VALUES FOR VARIOUS seff
seff
r∗
∞
MTTDL and EAFDL
E(H)
0
=
0
0.648419
0.5
10−4
=
0.0001
0.648404
0.499795
10−3
=
0.001
0.648265
0.498520
10−2
=
0.01
0.646985
0.490770
10−1
=
0.1
0.637940
0.456298
1/8
=
0.125
0.636043
0.450268
1/7
=
0.142857
0.634788
0.446383
1/6
=
0.166667
0.633224
0.441637
1/5
=
0.2
0.631212
0.435664
1/4
=
0.25
0.628500
0.427826
1/3
=
0.333333
0.624638
0.416889
1/2
=
0.5
0.618499
0.4
2/3
=
0.666667
0.613720
0.387097
3/4
=
0.75
0.611679
0.381625
4/5
=
0.8
0.610543
0.378586
5/6
=
0.833333
0.609818
0.376650
6/7
=
0.857143
0.609316
0.375307
7/8
=
0.875
0.608946
0.374322
1 − 10−1
=
0.9
0.608440
0.372971
1 − 10−2
=
0.99
0.606713
0.368368
1 − 10−3
=
0.999
0.606549
0.367928
1 − 10−4
=
0.9999
0.606532
0.367884
1
=
1
0.606531 = 1/√e
0.367879 = 1/e
Proof: See Appendix F.
The r∗
∞ values corresponding to the MTTDL and EAFDL
metrics and to various storage efﬁciencies are listed in Ta-
ble III. Note that the r∗
∞ values are in the interval [e−1/2 =
0.606, 0.648] and decrease as the storage efﬁciency seff in-
creases. In contrast, for small values of n, the r∗ values
increase as the storage efﬁciency increases, as shown in Figure
13. For example, for small n, the r∗ values corresponding to
seff = 1/2 are smaller than those corresponding to seff = 2/3.
However, for large values of n this is reversed, and for the
MTTDL, the ﬁrst instance that this occurs is for n = 619, as
shown in Figure 15, with the r∗ values being equal to 0.637
and 0.635 (indicated by the circle), respectively. Therefore, in
this case, the optimal codeword lengths m∗ are equal to 394
and 393, respectively.
Next we examine the increase of the EAFDL metric if
580
600
620
640
660
0.632
0.634
0.636
0.638
0.64
0.642
Number of Devices (n)
r*
 
 
 619
seﬀ = 1/2
seﬀ = 2/3
Figure 15.
r∗ for MTTDL vs. number of devices for seff = 1/2, 2/3;
λ/µ = 0.001 and deterministic rebuild times.
instead of the optimal codeword lengths m∗
EAFDL, we use the
codeword lengths m∗
MTTDL that optimize the MTTDL metric.
From the preceding, it follows that m∗
MTTDL is either equal to
m∗
EAFDL or adjacent to it, that is, m∗
MTTDL = m∗
EAFDL + z + 1.
We deﬁne the EAFDL efﬁciency ratio, rEAFDL, as the ratio of
EAFDL(m∗
MTTDL) to EAFDL(m∗
EAFDL), that is,
rEAFDL ≜ EAFDL(m∗
MTTDL)
EAFDL(m∗
EAFDL) ,
(106)
where EAFDL(m) denotes the EAFDL corresponding to a
codeword length m. In the case of n = 40 and seff = 1/2,
from the preceding and according to Figure 9(b), it holds
that EAFDL(m∗
EAFDL) = EAFDL(32) = 3.08×10−58 and
EAFDL(m∗
MTTDL) = EAFDL(34) = 5.66×10−58, which
yields an EAFDL efﬁciency ratio rEAFDL of 5.66/3.08 = 1.84.
This is indicated by a circle in Figure 16(a), which shows
the EAFDL efﬁciency ratio as a function of n. Similarly, in
the case of n = 40 and seff = 2/3, from the preceding,
it holds that m∗
MTTDL = m∗
EAFDL = 36, which implies that
rEAFDL = 1, indicated by a circle in Figure 16(a). We observe
that for the storage efﬁciencies considered and as n increases,
134
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

20
200
400
600
800
1000
0.15
0.2
0.25
0.3
0.35
0.4
0.45
Number of Devices (n)
r*
 
 
∞
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8
20
200
400
600
800
1000
0.3
0.35
0.4
0.45
0.5
Number of Devices (n)
r*
 
 
∞
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
(b) seff = 1/5, 1/4, 1/3, and 1/2
Figure 18.
r∗ for E(H) vs. number of devices n → ∞; λ/µ = 0.001.
20
40
60
80
100
120
0.15
0.2
0.25
0.3
0.35
0.4
0.45
Number of Devices (n)
r*
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
Figure 17. r∗ for E(H) vs. number of devices for seff = 1/2, 2/3, 3/4, 4/5,
5/6, 6/7, and 7/8; λ/µ = 0.001.
the EAFDL efﬁciency ratios follow a periodic pattern and
are always less than a factor of four. This implies that using
codewords of length m∗
MTTDL yields the maximum possible
(optimal) MTTDL and also an EAFDL that is either the
optimal one or of the same order as the optimal one. Also, as
the storage efﬁciency decreases, the EAFDL efﬁciency ratio
rEAFDL increases, as shown in Figure 16(b). For any given
storage efﬁciency, rEAFDL follows a periodic pattern and for
seff ≥ 1/4 = 0.25, rEAFDL is always less than a factor of
10. Consequently, using codewords of length m∗
MTTDL yields
an EAFDL that is either the optimal or at most one order of
magnitude higher than the optimal one.
Next, we compare the r∗ values for the MTTDL and
EAFDL metrics shown in Figure 12 with those for the E(H)
metric shown in Figure 17. Clearly, the optimal codeword
lengths for MTTDL and EAFDL are signiﬁcantly larger than
those that minimize E(H). The r∗ values for the E(H) metric
for various values of the storage efﬁciency seff and for large
values of n are shown in Figure 18. The ﬁgure indicates that,
as n increases, the r∗ values oscillate and approach a value
denoted by r∗
∞. The r∗
∞ values (indicated by the small bullets)
are given by the following proposition,
Proposition 12: As n increases, the r∗ values for E(H)
approach r∗
∞ given by
r∗
∞ =
1
h + (1 − h)− 1−h
h
,
(107)
where h is given by (60).
Proof: See Appendix G.
The r∗
∞ values corresponding to the E(H) metric and to
various storage efﬁciencies are listed in Table III. Note that the
r∗
∞ values are in the interval [e−1 = 0.368, 0.5] and decrease
as the storage efﬁciency seff increases. By inspecting Figures
13, 14, and 18, it is evident that also in this case the optimal
codeword lengths for MTTDL and EAFDL are signiﬁcantly
larger than those that minimize E(H).
Next, we consider a system where the distribution of
the rebuild time X is exponential, for which it holds that
E(Xhm) = (hm)! [E(X)]hm. According to Remark 2, this
only affects the MTTDL and EAFDL metrics, but not the
E(H) metric. The combined effect of the number of devices
and the system efﬁciency on the normalized λ MTTDLdeclus
measure is obtained by (99) and shown in Figure 19 as
a function of the codeword length. Similarly to the case
of deterministic rebuild times, we observe that the MTTDL
increases as the storage efﬁciency seff decreases. Also, as seff
increases, the MTTDL for the single-parity codewords, which
correspond to the ﬁrst points of the curves, decreases. We
observe that the same applies for the double-parity codewords,
which correspond to the second points of the curves.
The combined effect of the number of devices and the
system efﬁciency on the normalized EAFDLdeclus/λ measure is
obtained by (100) and shown in Figure 20 as a function of the
codeword length. Similarly to the case of deterministic rebuild
times, we observe that the EAFDL increases as the storage
efﬁciency seff increases. Also, as seff increases, the EAFDL
for the single-parity codewords, which correspond to the ﬁrst
points of the curves, also increases. We observe that the same
applies for the double-parity codewords, which correspond to
the second points of the curves.
135
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

0
5
10
15
20
10
0
10
5
10
10
10
15
m
λ MTTDL
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) n = 20
0
10
20
30
40
10
0
10
10
10
20
10
30
10
40
m
λ MTTDL
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(b) n = 40
0
10
20
30
40
50
60
10
0
10
20
10
40
10
60
m
λ MTTDL
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(c) n = 60
Figure 19.
Normalized MTTDLdeclus vs. codeword length for seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8; λ/µ = 0.001 and exponential rebuild times.
0
5
10
15
20
10
−20
10
−15
10
−10
10
−5
m
EAFDL / λ
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) n = 20
0
10
20
30
40
10
−40
10
−30
10
−20
10
−10
m
EAFDL / λ
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(b) n = 40
0
10
20
30
40
50
60
10
−60
10
−40
10
−20
m
EAFDL / λ
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(c) n = 60
Figure 20.
Normalized EAFDLdeclus vs. codeword length for seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8; λ/µ = 0.001 and exponential rebuild times.
The optimal codeword lengths, m∗, that maximize the
MTTDL or minimize the EAFDL are indicated by the circles
and the corresponding vertical dotted lines. The observations
regarding the optimal codeword lengths made in the case
of deterministic rebuild times also apply here. Note also
that, according to Remark 7, E(H) does not depend on the
rebuild times, and therefore the optimal codeword lengths that
minimize E(H) are those shown in Figure 17 for the case of
deterministic rebuild times.
Similarly to the case of deterministic rebuild times, the
optimal codeword lengths m∗
EAFDL for EAFDL are either equal
to or slightly lower than and adjacent to the optimal codeword
lengths m∗
MTTDL for MTTDL, as demonstrated in Figure 21.
The r∗ values for the MTTDL and EAFDL metrics for various
storage efﬁciencies are shown in Figure 22. In Appendix F, it
is proved that as n increases, and for any storage efﬁciency,
the r∗ values for MTTDL and EAFDL approach a common
value that is the same as the r∗
∞ value obtained in the case of
deterministic rebuild times, which depends on seff and is listed
in Table III.
The EAFDL efﬁciency ratios rEAFDL as a function of n for
various storage efﬁciencies are shown in Figure 23. We observe
that for the storage efﬁciencies considered and as n increases,
the EAFDL efﬁciency ratios follow a periodic pattern, and for
seff ≥ 1/4 = 0.25, they are always less than a factor of 10.
By inspecting Figures 16 and 23, we observe that the rEAFDL
ratios in the case of exponential rebuild times are smaller than
those in the case of deterministic rebuild times.
Figures 24 and 25 show the ratio of the optimal codeword
length, m∗
exp, for the exponential distribution to the optimal
codeword length, m∗
det, for the deterministic distribution for
various storage efﬁciencies. We observe that this ratio never
exceeds one and approaches one as n increases. This implies
that the optimal codeword length for the exponential distribu-
tion is in general smaller than the optimal codeword length for
the deterministic distribution. This can be intuitively explained
as follows. As previously mentioned, larger values of m result
in a higher exposure degree to failure as each of the codewords
is spread across a larger number of devices. The variation of
exponentially distributed rebuild times results in increased vul-
nerability windows and therefore worse reliability. To reduce
the exposure degree to failures, codewords should be spread
across a smaller number of devices, which implies a smaller
optimal codeword length.
VII.
CONCLUSIONS
We considered the Mean Time to Data Loss (MTTDL)
and the Expected Annual Fraction of Data Loss (EAFDL)
reliability metrics of storage systems using advanced erasure
codes. A methodology was presented for deriving the two
metrics analytically. Closed-form expressions capturing the
effect of various system parameters were obtained for arbitrary
rebuild time distributions and for the symmetric, clustered,
and declustered data placement schemes. We established that
the declustered placement scheme offers superior reliability in
terms of both metrics. Subsequently, a thorough comparison of
the reliability achieved by the declustered placement scheme
under various codeword conﬁgurations was conducted. The
results obtained show that the optimal codeword lengths for
MTTDL and EAFDL are similar and, as the system size grows,
they are about 60% of the storage system size.
136
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

20
40
60
80
100
120
0
2
4
6
8
10
Number of Devices (n)
m*
MTTDL − m*
EAFDL 
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8
20
40
60
80
100
120
0
2
4
6
8
10
Number of Devices (n)
m*
MTTDL − m*
EAFDL 
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
(b) seff = 1/5, 1/4, 1/3, and 1/2
Figure 21.
The difference between m∗
MTTDL and m∗
EAFDL vs. number of devices; λ/µ = 0.001 and exponential rebuild times.
20
40
60
80
100
120
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Number of Devices (n)
r*
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) MTTDL
20
40
60
80
100
120
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Number of Devices (n)
r*
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(b) EAFDL
Figure 22.
r∗ vs. number of devices for seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8; λ/µ = 0.001 and exponential rebuild times.
200
400
600
800
1000
1
1.5
2
2.5
3
Number of Devices (n)
rEAFDL
 
 
seﬀ = 1/2
seﬀ = 7/8
(a) seff = 1/2 and 7/8
200
400
600
800
1000
10
0
10
1
10
2
Number of Devices (n)
rEAFDL
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
(b) seff = 1/5, 1/4, 1/3, and 1/2
Figure 23.
The EAFDL efﬁciency ratio rEAFDL vs. number of devices; λ/µ = 0.001 and exponential rebuild times.
137
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

200
400
600
800
1000
0.75
0.8
0.85
0.9
0.95
1
Number of Devices (n)
m*
exp / m*
det 
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(a) MTTDL
200
400
600
800
1000
0.75
0.8
0.85
0.9
0.95
1
Number of Devices (n)
m*
exp / m*
det 
 
 
seﬀ = 1/2
seﬀ = 2/3
seﬀ = 3/4
seﬀ = 4/5
seﬀ = 5/6
seﬀ = 6/7
seﬀ = 7/8
(b) EAFDL
Figure 24.
Ratio m∗
exp to m∗
det vs. number of devices for seff = 1/2, 2/3, 3/4, 4/5, 5/6, 6/7, and 7/8; λ/µ = 0.001.
200
400
600
800
1000
0.75
0.8
0.85
0.9
0.95
1
Number of Devices (n)
m*
exp / m*
det 
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
(a) MTTDL
200
400
600
800
1000
0.75
0.8
0.85
0.9
0.95
1
Number of Devices (n)
m*
exp / m*
det 
 
 
seﬀ = 1/5
seﬀ = 1/4
seﬀ = 1/3
seﬀ = 1/2
(b) EAFDL
Figure 25.
Ratio m∗
exp to m∗
det vs. number of devices for seff = 1/5, 1/4, 1/3, and 1/2; λ/µ = 0.001.
Extending the methodology developed to derive the relia-
bility of erasure coded systems under network rebuild band-
width limitations and in the presence of unrecoverable latent
errors are subjects of further investigation. Also, owing to the
parallelism of the rebuild process, the model considered yields
very small rebuild times for large system sizes. To take into
account the fact that the rebuild times cannot be smaller than
the actual failure detection times requires a more sophisticated
modeling effort, which is also part of future work.
APPENDIX A
ESTIMATION OF PDL
Proof of Proposition 2.
Consider the direct path 1 → 2 → · · · → ˜r of successive
transitions from exposure level 1 to ˜r. For ease of reading, we
denote the successive transitions from exposure level u to ˜r by
u → ˜r. We ﬁrst evaluate PDL(R1), the probability of data loss
conditioned on the rebuild time R1. From (19), and using the
fact that αu does not depend on R1, α1, · · · , αu−1, it follows
that
PDL(R1) ≈ P1→˜r(R1)
= P1→2(R1)P2→˜r(R1)
= P1→2(R1)Eα1|R1[P2→˜r(R1, α1)]
= P1→2(R1)Eα1[P2→3(R1, α1)P3→˜r(R1, α1)]
= P1→2(R1)Eα1[P2→3(R1, α1)Eα2|R1,α1[P3→˜r(R1, α1, α2)]]
= · · ·
= P1→2(R1)Eα1[P2→3(R1, ⃗α1)Eα2[P3→4(R1, ⃗α2) · · ·
· · · Eα˜r−2[P˜r−1→˜r(R1, ⃗α˜r−2)] · · · ]
= E⃗α˜r−2[P1→2(R1)P2→3(R1, ⃗α1) · · · P˜r−1→˜r(R1, ⃗α˜r−2)]
= E⃗α˜r−2
"˜r−1
Y
u=1
Pu→u+1(R1, ⃗αu−1)
#
= E⃗α˜r−2[PDL(R1, ⃗α˜r−2)] ,
(108)
where
PDL(R1, ⃗α˜r−2) ≜
˜r−1
Y
u=1
Pu→u+1(R1, ⃗αu−1) ,
(109)
138
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

with
P1→2(R1, ⃗α0) ≜ P1→2(R1) .
(110)
Substituting (45) into (109), and using (44) and (110), yields
PDL(R1, ⃗α˜r−2) ≈ (λ b1 R1)˜r−1
˜r−1
Y
u=1
˜nu
bu
(Vu αu)˜r−1−u .
(111)
Unconditioning (111) on ⃗α˜r−2, and given that the elements
of ⃗α˜r−2 are independent random variables approximately
distributed according to (24) such that E(αk
u) ≈ 1/(k + 1),
(108) yields
PDL(R1) ≈ (λ b1 R1)˜r−1
1
(˜r − 1)!
˜r−1
Y
u=1
˜nu
bu
V ˜r−1−u
u
.
(112)
The probability of data loss PDL is obtained by unconditioning
PDL(R1) on R1, that is,
PDL = E[PDL(R1)] .
(113)
Unconditioning (112) on R1 using (10) and (34), (113) yields
(46).
APPENDIX B
ESTIMATION OF E(Q)
Proof of Proposition 3.
We ﬁrst evaluate E(Q|R1), the expected amount of data
lost conditioned on the rebuild time R1. From (21), and
considering the direct path 1 → 2 → · · · → ˜r of successive
transitions from exposure level 1 to ˜r, and using the fact that
αu does not depend on R1, α1, · · · , αu−1, it follows that
E(Q|R1) ≈ P1→2(R1)E(Q|R1, 1 → 2)
= P1→2(R1)Eα1|R1[E(Q|R1, α1)]
= P1→2(R1)Eα1[P2→3(R1, α1)E(Q|R1, α1, 2 → 3)]
= P1→2(R1)Eα1[P2→3(R1, α1)Eα2|R1,α1[E(Q|R1, α1, α2)]]
= · · ·
= P1→2(R1)Eα1[P2→3(R1, ⃗α1)Eα2[P3→4(R1, ⃗α2) · · ·
· · · P˜r−1→˜r(R1, ⃗α˜r−2)Eα˜r−1(Q|R1, ⃗α˜r−1)] · · · ]
= E⃗α˜r−1[P1→2(R1)P2→3(R1, ⃗α1) · · · P˜r−1→˜r(R1, ⃗α˜r−2)
E(Q|R1, ⃗α˜r−1)]
(20)(21)
=
E⃗α˜r−1
" ˜r−1
Y
u=1
Pu→u+1(R1, ⃗αu−1)
!
E(H|R1, ⃗α˜r−1)
#
(109)
= E⃗α˜r−1[PDL(R1, ⃗α˜r−2) E(H|R1, ⃗α˜r−1)]
(23)
= E⃗α˜r−1[PDL(R1, ⃗α˜r−2) E(l A˜r|R1, ⃗α˜r−1)]
Remark 1
=
E⃗α˜r−1[PDL(R1, ⃗α˜r−2) l E(A˜r|⃗α˜r−1)]
= E⃗α˜r−1[G(R1, ⃗α˜r−1)] ,
(114)
where
G(R1, ⃗α˜r−1) ≜ l PDL(R1, ⃗α˜r−2) E(A˜r|⃗α˜r−1) .
(115)
Using (27) and (111), (115) yields
G(R1, ⃗α˜r−1) ≈ l c (λ b1 R1)˜r−1
˜r−1
Y
u=1
˜nu
bu
(Vu αu)˜r−u .
(116)
Unconditioning (116) on ⃗α˜r−1, and given that the elements
of ⃗α˜r−1 are independent random variables approximately
distributed according to (24) such that E(αk
u) ≈ 1/(k + 1),
(114) yields
E(Q|R1) ≈ l c (λ b1 R1)˜r−1 1
˜r !
˜r−1
Y
u=1
˜nu
bu
V ˜r−u
u
.
(117)
The expected amount of data lost, E(Q), upon a ﬁrst-device
failure is obtained by unconditioning E(Q|R1) on R1, that is,
E(Q) = E[E(Q|R1)] .
(118)
Unconditioning (117) on R1 using (10) and (34), (118) yields
(47).
APPENDIX C
APPROXIMATE DERIVATION OF E(H)sym
Proof of Proposition 4.
First, we derive an approximation of the product
A ≜
m−l
Y
j=1
m − j
k − j ,
(119)
which appears in Equation (83). From (60), it follows that
m−l = hm, as stated by (80). Substituting the preceding into
(119), and using (61), yields
A =
hxk
Y
j=1
x − j
k
1 − j
k
,
(120)
or equivalently,
log(A) =
hxk
X
j=1
log
 
x − j
k
1 − j
k
!
,
(121)
To evaluate the preceding summation, we ﬁrst establish the
following lemmas.
LEMMA 1: For small values of ǫ, that is, when ǫ ap-
proaches zero, and for any function f(y), it holds that
ǫ
α/ǫ
X
j=1
f(jǫ) ≈
Z
α+ ǫ
2
ǫ
2
f(y) dy ,
∀ α ∈ R .
(122)
Proof: The left-hand side of (122) is written as follows:
ǫ
α/ǫ
X
j=1
f(jǫ) =
α/ǫ
X
j=1
f(jǫ) ǫ .
(123)
For small small values of ǫ, the summation in the right-
hand side of (123) represents the middle Riemann sum that
approximates the deﬁnite integral of the f(y) function in the
interval [ǫ/2, α + ǫ/2], that is,
α/ǫ
X
j=1
f(jǫ) ǫ ≈
Z
α+ ǫ
2
ǫ
2
f(y) dy .
(124)
□
139
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

LEMMA 2: For any functions f(y) and F(y), such that
F(y) =
R
f(y) dy, or F ′(y) = f(y), and for α ∈ R deﬁne
F (1)(α, z) ≜
Z
α+ z
2
z
2
f(y) dy = F

α + z
2

− F
z
2

.
(125)
Then it holds that
F (1)
z
(α, z) = 1
2
h
f

α + z
2

− f
z
2
i
,
(126)
and
F (1)
zz (α, z) = 1
4
h
f ′ 
α + z
2

− f ′ z
2
i
.
(127)
Proof: Immediate from the fact that for any α ∈ R and
function f(y), it holds that df(α+z/2)/dz = f ′(α+z/2)/2. □
Corollary 1: For f(y) = log(x − y) and for all α ∈ R, it
holds that
F (1)(x, α, z) =
Z
α+ z
2
z
2
log(x − y) dy = G(x, α, z) ,
(128)
where
G(x, α, z) ≜ log

(x − z
2)x− z
2
(x − α − z
2)x−α− z
2

− α .
(129)
Also,
F (1)
z
(x, α, z) = Gz(x, α, z) = 1
2 log
x − α − z
2
x − z
2

, (130)
and
F (1)
zz (x, α, z) = Gzz(x, α, z) = −
α
4 (x − α − z
2)(x − z
2) .
(131)
Proof: Equations (128) and (129) are derived from (125) by
taking f(y) = log(x−y) and using the fact that
R
log(y) dy =
y [log(y) − 1], which in turn implies that F(y) =
R
log(x −
y) dy = −(x − y) [log(x − y) − 1]. Equation (130) is directly
obtained from (126), and (131) is obtained from (127) by using
the fact that f ′(y) = −1/(x − y).
□
Note that an approximation of G(x, α, z) for z ≅ 0 can be
obtained through its Maclaurin series as follows:
G(x, α, z) ≈ G(x, α, 0) + Gz(x, α, 0) z + Gzz(x, α, 0)
2
z2 ,
(132)
which by virtue of (129), (130), and (131) yields
G(x, α, z) ≈ log

xx
(x − α)x−α

− α
+ 1
2 log
x − α
x

z −
α
8(x − α)x z2 . (133)
We now proceed with the evaluation of log(A). From (122)
and (128), it follows that
ǫ
α/ǫ
X
j=1
log
x − jǫ
1 − jǫ

= G(x, α, ǫ) − G(1, α, ǫ) .
(134)
From (121) and (129), and using (134) with ǫ = 1/k and
α = hx, we get
log(A) ≈ k F

x, 1
2k

,
(135)
where
F(x, y) ≜ log
 (x − y)x−y (1 − hx − y)1−hx−y
(1 − y)1−y [(1 − h)x − y](1−h)x−y

.
(136)
An expression for log(A) for large values of k, m, l,
and m − l can be obtained from (121) and (134) by using
approximation (133) with ǫ = 1/k and α = hx as follows:
log(A) ≈ k log
xx (1 − hx)1−hx
[(1 − h)x](1−h)x

+ log
 r
1 − h
1 − hx
!
− 1
k
h(1 − x)[1 + (1 − h)x]
8(1 − h)(1 − hx)x
.
(137)
Equation (58) is a direct consequence of (83) and also
of (79), (80), (119), and (137), where the third term of the
summation in (137) is ignored for large k.
APPENDIX D
APPROXIMATE DERIVATION OF MTTDLsym
Proof of Proposition 5.
Using (79) and (80), (81) can be written as follows:
n λ MTTDLsym
k
≈ 1
k

b
[(1 − h)xk + 1] λ c
hxk
(hxk)!
[E(X)]hxk
E(Xhxk)
m−l
Y
j=1
 k − j
m − j
m−l−j
.
(138)
From (138), and using Stirling’s approximation (139) for large
values of k, with k replaced by hxk, that is
(hxk)! ≈
√
2πhxk
hxk
e
hxk
,
(139)
it follows that
log
n λ MTTDLsym
approx
k

≈
log
 r
2πhx
k
!
+ hxk log

hxk b
e [(1 − h)xk + 1] λ c

+ log
[E(X)]hxk
E(Xhxk)

+ log(B) ,
(140)
where B is the product
B ≜
m−l
Y
j=1
 k − j
m − j
m−l−j
.
(141)
We now proceed to derive an approximation of the product
B. By virtue of (61), (80), and (119), the product B can be
140
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

written as follows:
B =
Qm−l
j=1

m−j
k−j
j
Qm−l
j=1

m−j
k−j
m−l =
C
Am−l =
C
Ahxk ,
(142)
where
C ≜
m−l
Y
j=1
m − j
k − j
j
=
hxk
Y
j=1
 
x − j
k
1 − j
k
!j
.
(143)
From (142) and (143), it follows that
log(B) = log(C) − hxk log(A)
(144)
and
log(C) =
hxk
X
j=1
j log
 
x − j
k
1 − j
k
!
.
(145)
To evaluate the preceding summation, we ﬁrst establish the
following corollary from Lemma 2.
Corollary 2: For f(y) = y log(x − y) and for all α ∈ R,
it holds that
F (1)(x, α, z) =
Z
α+ z
2
z
2
y log(x − y) dy = R(x, α, z) , (146)
where
R(x, α, z) ≜ 1
2 log
 
(x − z
2)x2−( z
2 )2
(x − α − z
2)x2−(α+ z
2 )2
!
−α(2x+α+z)
4
.
(147)
Also,
F (1)
z
(x, α, z) = Rz(x, α, z) = 1
2 log
(x − α − z
2)α+ z
2
(x − z
2)
z
2

(148)
and
F (1)
zz (x, α, z) = Rzz(x, α, z) =
1
4

log
x − α − z
2
x − z
2

−
αx
(x − α − z
2)(x − z
2)

. (149)
Proof: Equations (146) and (147) are derived from (125)
by taking f(y) = y log(x − y) and using the fact that
R
y log(y) dy = y2 (2 log(y) − 1)/4, which in turn implies
that F(y) =
R
y log(x − y) dy = (x − y) [3x + y − 2(x +
y) log(x − y)]/4. Equation (148) is directly obtained from
(126), and (149) is obtained from (127) by using the fact that
f ′(y) = log(x − y) − y/(x − y).
□
Note that an approximation of R(x, α, z) for z ≅ 0 can be
obtained through its Maclaurin series as follows:
R(x, α, z) ≈ R(x, α, 0) + Rz(x, α, 0) z + Rzz(x, α, 0)
2
z2 ,
(150)
which by virtue of (147), (148), and (149) yields
R(x, α, z) ≈ 1
2 log
 
xx2
(x − α)x2−α2
!
− α(2x + α)
4
+ α
2 log(x − α) z + 1
8

log
x − α
x

−
α
(x − α)x

z2 .
(151)
We now proceed with the evaluation of log(C). From (122)
and (146), it follows that
ǫ
α/ǫ
X
j=1
j log
x − jǫ
1 − jǫ

= R(x, α, ǫ) − R(1, α, ǫ) .
(152)
From (121) and (147), and using (152) with ǫ = 1/k and
α = hx, we get
log(C) ≈ k2 1
2

hx(1 − x) + S

x, 1
2k

,
(153)
where
S(x, y) ≜ log
 
(x − y)x2−y2(1 − hx − y)1−(hx+y)2
(1 − y)1−y2 [(1 − h)x − y]x2−(hx+y)2
!
.
(154)
An expression for log(C) for large values of k, m, l,
and m − l can be obtained from (145) and (152) by using
approximation (151) with ǫ = 1/k and α = hx as follows:
log(C) ≈ k2
2
"
hx(1 − x) + log
 
xx2 (1 − hx)1−(hx)2
[(1 − h)x](1−h2)x2
!#
+ k
2 hx log
(1 − h)x
1 − hx

+ 1
8 log
 1 − h
1 − hx

−
h(1 − x)
8(1 − h)(1 − hx) . (155)
Substituting (137) and (155) into (144) yields
log(B) ≈ k2
2

hx(1 − x) − log



h
xh2 (1 − h)(1−h)2ix2
(1 − hx)(1−hx)2





+ k hx log(√x)
− 1
8

h(1 − x) − log
 1 − h
1 − hx

.
(156)
Equation (62) is a direct consequence of (140) and (156).
APPENDIX E
APPROXIMATE DERIVATION OF EAFDLsym
Proof of Proposition 6.
From (15), it follows that
EAFDL/λ =
E(H)/c
λ MTTDL · U · c .
(157)
Substituting (2) into (157), and using (60), yields
EAFDL/λ =
E(H)/c
λ MTTDL · (1 − h) n
(158)
or
log(EAFDL/λ) =
log(E(H)/c) − log(λ MTTDL) − log((1 − h) n) .
(159)
Substituting (58) and (62) into (159), after some manipulations
yields (64).
141
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

APPENDIX F
OPTIMAL CODEWORD LENGTHS FOR MAXIMIZING
MTTDLdeclus AND MINIMIZING EAFDLdeclus FOR A LARGE
NUMBER OF STORAGE DEVICES, n
Proof of Proposition 11.
We ﬁrst consider the optimal codeword lengths for maxi-
mizing MTTDLdeclus. From (103), it holds that
r∗
MTTDL(n) = m∗
MTTDL(n)
n
=
arg max
1≤m≤n MTTDLdeclus
n
.
(160)
Using (73), the preceding can be written as follows:
r∗
MTTDL(n) = arg max
1
n ≤x≤1 MTTDLdeclus
(161)
or
r∗
MTTDL(n) = arg max
1
n ≤x≤1 log(λ MTTDLdeclus)
(162)
or, equivalently,
r∗
MTTDL(n) = arg max
1
n ≤x≤1
2 log(λ MTTDLdeclus)
n2

.
(163)
By letting n approach the inﬁnity, we get
r∗
∞ = lim
n→∞ r∗
MTTDL(n)
= lim
n→∞ arg max
1
n ≤x≤1
2 log(λ MTTDLdeclus)
n2

= arg max
0<x≤1 lim
n→∞
2 log(λ MTTDLdeclus)
n2

.
(164)
Using the approximation obtained in (85), (164) yields
r∗
∞ = arg max
0<x≤1 W(h, x) ,
(165)
provided that for the last term of the summation in (85) it
holds that
lim
n→∞
log
[E(X)]hxn
E(Xhxn)

n2
= 0 .
(166)
Remark 13: It turns out that (166) holds for the cases of
deterministic and exponential rebuild time distributions owing
to the following lemmas.
LEMMA 3: In the case of deterministic rebuild times, it
holds that
log
[E(X)]hxn
E(Xhxn)

= 0 .
(167)
Proof:
Equation
(167)
follows
from
the
fact
that
in the case of deterministic rebuild times it holds that
E(Xhxn) = [E(X)]hxn.
□
LEMMA 4: In the case of exponential rebuild times, it
holds that
log
[E(X)]hxn
E(Xhxn)

n2
≈ hx
log
hxn
e

n
+ log(2πhxn)
2 n2
.
(168)
0
0.2
0.4
0.6
0.8
1
0
0.5
1
0
0.1
0.2
0.3
0.4
 x
 h
W(h,x) / h2
Figure 26.
W(h, x)/h2 for h and x ∈ [0, 1].
Proof: In the case of exponential rebuild times, it holds
that E(Xhxn) = (hxn)! [E(X)]hxn, which for large n and by
virtue of (139), yields
log
[E(X)]hxn
E(Xhxn)

≈ log
 
√
2πhxn
hxn
e
hxn!
. (169)
Equation (168) follows directly from (169).
□
From (63), it follows that W(h, x) or, equivalently,
W(h, x)/h2 are non-negative in x ∈ [0, 1], with W(h, 0) =
W(h, 1) = 0, as shown in Figure 26. Consequently, (165)
implies that r∗
∞ satisﬁes the following equation:
Wx(h, r∗
∞) = dW(h, x)
dx

x=r∗∞
= 0 .
(170)
The derivative of W(h, x) with respect to x can be obtained
using the following lemma.
LEMMA 5: For w(y) deﬁned as follows:
w(y) = log

f(y)g(y)
= log (f g) ,
(171)
it holds that
w′(y) = w′ = g′ log(f) + gf ′/f .
(172)
Corollary 3: For v(y) deﬁned as follows:
v(y) = log

f(y)f(y)
= log

 h
 r∞*
0
0.2
0.4
0.6
0.8
1
0.6
0.61
0.62
0.63
0.64
0.65
Figure 27.
r∗
∞ vs. h for MTTDL and EAFDL.
Remark 14: For h = 0, it holds that Q(0, x) = 0. To ﬁnd
the root when h → 0, we consider ﬁnding the root of the
equivalent equation Q(h, x)/h2 = 0. Using L’Hˆopital’s rule,
after some manipulations, we obtain
lim
h→0
Q(h, x)
h2
= x

log(x) + 1
2

= x log(√e x) .
(177)
Combining (176) and (177) yields
r∗
∞ log(√e r∗
∞) = 0 , with r∗
∞ ∈ (0, 1]
or r∗
∞ = 1
√e = 0.606 .
(178)
For h = 1, r∗
∞ is obtained as the unique root in (0, 1] of the
equation
Q(1, x) = x + log

From (188) and (189), we deduce that r∗
∞ satisﬁes the follow-
ing equation:
log
r∗
∞ (1 − h r∗
∞)−h
[(1 − h)r∗∞]1−h

= 0 .
(190)
Solving (190) for r∗
∞ yields (107), which is shown in
Figure 29.
REFERENCES
[1]
I. Iliadis and V. Venkatesan, “Reliability assessment of erasure coded
systems,” in Proceedings of the 10th International Conference on
Communication Theory, Reliability, and Quality of Service (CTRQ),
Apr. 2017, pp. 41–50.
[2]
D. A. Patterson, G. Gibson, and R. H. Katz, “A case for redundant arrays
of inexpensive disks (RAID),” in Proceedings of the ACM SIGMOD
International Conference on Management of Data, Jun. 1988, pp. 109–
116.
[3]
P. M. Chen, E. K. Lee, G. A. Gibson, R. H. Katz, and D. A. Patterson,
“RAID: High-performance, reliable secondary storage,” ACM Comput.
Surv., vol. 26, no. 2, Jun. 1994, pp. 145–185.
[4]
M. Malhotra and K. S. Trivedi, “Reliability analysis of redundant arrays
of inexpensive disks,” J. Parallel Distrib. Comput., vol. 17, Jan. 1993,
pp. 146–151.
[5]
W. A. Burkhard and J. Menon, “Disk array storage system reliability,”
in Proceedings of the 23rd International Symposium on Fault-Tolerant
Computing, Jun. 1993, pp. 432–441.
[6]
K. S. Trivedi, Probabilistic and Statistics with Reliability, Queueing and
Computer Science Applications, 2nd ed.
New York: Wiley, 2002.
[7]
Q. Xin, E. L. Miller, T. J. E. Schwarz, D. D. E. Long, S. A. Brandt, and
W. Litwin, “Reliability mechanisms for very large storage systems,” in
Proceedings of the 20th IEEE/11th NASA Goddard Conference on Mass
Storage Systems and Technologies (MSST), Apr. 2003, pp. 146–156.
[8]
T. J. E. Schwarz, Q. Xin, E. L. Miller, D. D. E. Long, A. Hospodor,
and S. Ng, “Disk scrubbing in large archival storage systems,” in
Proceedings of the 12th Annual IEEE/ACM International Symposium
on Modeling, Analysis, and Simulation of Computer and Telecommu-
nication Systems (MASCOTS), Oct. 2004, pp. 409–418.
[9]
S. Ramabhadran and J. Pasquale, “Analysis of long-running replicated
systems,” in Proc. 25th IEEE International Conference on Computer
Communications (INFOCOM), Apr. 2006, pp. 1–9.
[10]
B. Eckart, X. Chen, X. He, and S. L. Scott, “Failure prediction models
for proactive fault tolerance within storage systems,” in Proceedings
of the 16th Annual IEEE International Symposium on Modeling,
Analysis, and Simulation of Computer and Telecommunication Systems
(MASCOTS), Sep. 2008, pp. 1–8.
[11]
K. Rao, J. L. Hafner, and R. A. Golding, “Reliability for networked
storage nodes,” IEEE Trans. Dependable Secure Comput., vol. 8, no. 3,
May 2011, pp. 404–418.
[12]
J.-F. Pˆaris, T. J. E. Schwarz, A. Amer, and D. D. E. Long, “Highly
reliable two-dimensional RAID arrays for archival storage,” in Pro-
ceedings of the 31st IEEE International Performance Computing and
Communications Conference (IPCCC), Dec. 2012, pp. 324–331.
[13]
I. Iliadis and V. Venkatesan, “An efﬁcient method for reliability evalu-
ation of data storage systems,” in Proceedings of the 8th International
Conference on Communication Theory, Reliability, and Quality of
Service (CTRQ), Apr. 2015, pp. 6–12.
[14]
——, “Most probable paths to data loss: An efﬁcient method for
reliability evaluation of data storage systems,” Int’l J. Adv. Syst.
Measur., vol. 8, no. 3&4, Dec. 2015, pp. 178–200.
[15]
V. Venkatesan and I. Iliadis, “A general reliability model for data
storage systems,” in Proceedings of the 9th International Conference
on Quantitative Evaluation of Systems (QEST), Sep. 2012, pp. 209–
219.
[16]
A. Dholakia, E. Eleftheriou, X.-Y. Hu, I. Iliadis, J. Menon, and K. Rao,
“A new intra-disk redundancy scheme for high-reliability RAID storage
systems in the presence of unrecoverable errors,” ACM Trans. Storage,
vol. 4, no. 1, May 2008, pp. 1–42.
[17]
A. Thomasian and M. Blaum, “Higher reliability redundant disk arrays:
Organization, operation, and coding,” ACM Trans. Storage, vol. 5, no. 3,
Nov. 2009, pp. 1–59.
[18]
K. M. Greenan, J. S. Plank, and J. J. Wylie, “Mean time to mean-
ingless: MTTDL, Markov models, and storage system reliability,” in
Proceedings of the USENIX Workshop on Hot Topics in Storage and
File Systems (HotStorage), Jun. 2010, pp. 1–5.
[19]
I. Iliadis, R. Haas, X.-Y. Hu, and E. Eleftheriou, “Disk scrubbing versus
intradisk redundancy for RAID storage systems,” ACM Trans. Storage,
vol. 7, no. 2, Jul. 2011, pp. 1–42.
[20]
I. Iliadis and V. Venkatesan, “Rebuttal to ‘Beyond MTTDL: A closed-
form RAID-6 reliability equation’,” ACM Trans. Storage, vol. 11, no. 2,
Mar. 2015, pp. 1–10.
[21]
“Amazon
Simple
Storage
Service.”
[Online].
Available:
http://aws.amazon.com/s3/ [retrieved: November 2017]
[22]
D. Borthakur et al., “Apache Hadoop goes realtime at Facebook,”
in Proceedings of the ACM SIGMOD International Conference on
Management of Data, Jun. 2011, pp. 1071–1080.
[23]
R. J. Chansler, “Data availability and durability with the Hadoop
Distributed File System,” ;login: The USENIX Association Newsletter,
vol. 37, no. 1, 2013, pp. 16–22.
[24]
K. Shvachko, H. Kuang, S. Radia, and R. Chansler, “The Hadoop
Distributed File System,” in Proceedings of the 26th IEEE Symposium
on Mass Storage Systems and Technologies (MSST), May 2010, pp.
1–10.
[25]
I. Iliadis and V. Venkatesan, “Expected annual fraction of data loss as a
metric for data storage reliability,” in Proceedings of the 22nd Annual
IEEE International Symposium on Modeling, Analysis, and Simulation
of Computer and Telecommunication Systems (MASCOTS), Sep. 2014,
pp. 375–384.
[26]
C. Huang et al., “Erasure coding in Windows Azure Storage,” in
Proceedings of the USENIX Annual Technical Conference (ATC), Jun.
2012, pp. 15–26.
[27]
“IBM Cloud Object Storage.” [Online]. Available: www.ibm.com/
cloud-computing/products/storage/object-storage/how-it-works/
[re-
trieved: November 2017]
[28]
V. Venkatesan and I. Iliadis, “Effect of codeword placement on the
reliability of erasure coded data storage systems,” in Proceedings of the
10th International Conference on Quantitative Evaluation of Systems
(QEST), Sep. 2013, pp. 241–257.
[29]
H. Weatherspoon and J. Kubiatowicz, “Erasure coding vs. replication:
A quantitative comparison,” in Proceedings of the 1st International
Workshop on Peer-to-Peer Systems (IPTPS), Mar. 2002, pp. 328–338.
[30]
R. Rodrigues and B. Liskov, “High availability in DHTs: Erasure coding
vs. replication,” in Proceedings of the 4th International Workshop on
Peer-to-Peer Systems (IPTPS), Feb. 2005, pp. 226–239.
[31]
J. S. Plank and C. Huang, “Tutorial: Erasure coding for storage
applications,” Slides presented at 11th Usenix Conference on File and
Storage Technologies (FAST’13), San Jose, CA, Feb. 2013.
[32]
V. Venkatesan, I. Iliadis, C. Fragouli, and R. Urbanke, “Reliability of
clustered vs. declustered replica placement in data storage systems,” in
Proceedings of the 19th Annual IEEE/ACM International Symposium
on Modeling, Analysis, and Simulation of Computer and Telecommu-
nication Systems (MASCOTS), Jul. 2011, pp. 307–317.
[33]
V. Venkatesan, I. Iliadis, and R. Haas, “Reliability of data storage
systems under network rebuild bandwidth constraints,” in Proceedings
of the 20th Annual IEEE International Symposium on Modeling,
Analysis, and Simulation of Computer and Telecommunication Systems
(MASCOTS), Aug. 2012, pp. 189–197.
[34]
A. G. Dimakis, K. Ramchandran, Y. Wu, and C. Suh, “A survey on
network coding for distributed storage,” Proc. IEEE, vol. 99, no. 3,
Mar. 2011, pp. 476–489.
[35]
V. Venkatesan and I. Iliadis, “Effect of codeword placement on the
reliability of erasure coded data storage systems,” IBM Research Report,
RZ 3827, Aug. 2012.
144
International Journal on Advances in Telecommunications, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/telecommunications/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

