Wearable Augmented Cognition for Improving Medic Performance 
An Adaptive Transcranial Cognitive Augmentation Device with Wearable Augmented Reality 
 
Jayfus Tucker Doswell  
Juxtopia® Advanced Mixed Reality (JAMR) Lab 
The Juxtopia Group, Inc.  
Baltimore, USA 
e-mail: jayfus@juxtopia.com  
Ken Wilson 
Trauma and Acute Care Surgery 
University of Chicago Medicine 
Chicago, USA 
e-mail: kwilson9@surgery.bsd.uchicago.edu  
 
 
Abstract—Wearable 
Augmented 
Reality 
(AR) 
combines 
research in AR, mobile/ubiquitous computing, and artificial 
intelligence in which an optical see-through Head Mounted 
Display 
(HMD) 
facilitates 
multi-modal 
projection 
of, 
contextually relevant and computer generated visual and 
auditory 
data 
over 
physical 
real-world 
environments.  
Through advancements in Brain Computer Interfaces (BCI), 
wearable AR has capabilities to amplify human cognition by 
delivering on-demand assistance/training, especially in austere 
and extreme situations ranging from emergency medical first 
response and Tactical Combat Casualty Care (TCCC) to 
public health relief efforts in response to mass casualty events. 
This Intelligence Amplification (IA) intervention has potential 
to augment human cognition while wearers naturally interact 
with their environment. However, research gaps must be 
addressed to achieve an adaptive and wearable AR BCI that 
augments human cognition and consequently, improves human 
performance. This paper presents an innovative wearable AR 
HMD with an objective for improving human working/long 
term memory, reduce cognitive load; and contextually adapt to 
an individual’s environment/cognitive/physiological state.  
Keywords-augmented cognition, augmented reality, BCI, 
context-awareness, cognitive display, intelligence amplification, 
wearable. 
I. 
INTRODUCTION 
A. BCI Enabled Wearable Augmented Reality  
    Wearable Augmented Reality (AR) combines research in 
AR technologies, mobile/ubiquitous computing, Artificial 
Intelligence (AI), and human ergonomics in which an 
optical see-through Head Mounted Display (HMD) 
facilitates multi-modal delivery of contextually relevant and 
computer generated visual, auditory, and transcranial data 
over a physical, real-world environment. Through decades 
of empirical research, wearable AR has demonstrated 
capabilities and promise of delivering on-demand assistance 
and training to humans who operate in austere and extreme 
environments ranging from emergency medical first 
response and surgery to Tactical Combat Casualty Care 
(TCCC) and public health relief efforts. This head worn 
Brain Computer Interface (BCI) has potential of providing a 
non-invasive method to augment human cognition and 
intellectual capabilities while wearers complete complex 
tasks. More specifically, wearable AR has capabilities to 
deliver, to humans, contextually aware assistance as multi-
modal perceptual cues combining animation, graphics, text, 
video, and voice, as well as transcranial stimulation and 
tactile feedback. However, despite many advancements 
recently demonstrated by wearable AR systems, there are 
several research gaps that must be addressed in order for 
wearable AR to achieve an adaptive and wearable BCI that 
augments human cognition and consequently, improves 
human performance.   
Figure 1. Milgram’s Mixed Reality Continuum. 
 
    AR falls within Milgram’s mixed reality continuum as 
illustrated in Figure 1. In AR, digital objects are added to 
the real environment. In augmented virtuality, real objects 
are added to virtual ones. In virtual environments (or virtual 
reality), the surrounding environment is completely digital 
[25]. Wearable AR combines research in AR and mobile 
computing in which a wearable see-through head mounted 
display 
(HMD) 
and 
increasingly 
smaller 
computer 
subsystem facilitate wireless communications and context-
aware digital display [1][10][11]. A Wearable AR-BCI 
comprises non-invasive sensors with capabilities to digitally 
collect and interpret neuronal activity to facilitate activities 
ranging from non-verbal AR interface navigation to brain 
region assessment of human attention and learning.  
B. Cognitive Overload  
    A primary challenge presented by such advanced BCI-
HCI technologies is the development of scientifically-
grounded methods for identifying appropriate BCI-HCI 
presentation, brain input, and multi-modal feedback in order 
to optimize performance and mitigate cognitive overload.  
Such multi-modalities must be dynamic, providing the 
human capabilities to adapt interaction configurations to 
accommodate various operational and environmental 
71
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

conditions, as well as user cognitive states, which change 
over time in response to task demands and factors, such as 
sleep, nutrition, stress, and even time of day. Ideally, 
interactive technologies should be capable of adapting 
modalities, in real-time, and in response to task, 
environmental, and user psychophysiological states.   
   Cognitive overload may be best described by the 
Cognitive Load Theory (CLT), which is an information 
processing theory used to explain the human limits of 
working memory based on current knowledge of human 
cognitive architecture [20]. Cognitive architecture refers to 
the concept that human minds have structures, such as 
working memory, long term memory, and schemas [24].  In 
summary, CLT may be described as follows: 
1) Working Memory can only 
handle 
seven (7) 
disconnected items at once [24]. 
2) Overload occurs when Working Memory is forced to 
process a significant amount of information too rapidly. 
3) Long Term Memory is virtually unlimited and assists 
Working Memory. 
4) Schemas are memory templates coded into Long Term 
Memory by Working Memory. 
5) Working Memory is overloaded when its ability to 
build a schema is compromised. 
6) If Working Memory has capacity left over, it can access 
information from long term memory in powerful ways. 
7) Automation (i.e., doing something without conscious 
thought) results from well-developed schemas due to 
Working Memory's interaction with Long Term 
Memory. Well developed schemas come with repeated 
effort and effective practice. [20] 
    Furthermore, information that is retrieval from long term 
memory can be impacted based on external (fast moving or 
disruptive objects) or internal (physiological) stimuli, which 
may significantly impact human performance on tasks.  
    To augment human performance and apply empirically 
researched understanding of CLT constraints of information 
storage and retrieval to/from long term memory, an effective 
contextually intelligent information display is a potentially 
useful intervention; with the use of AI enabled pictorial 
mnemonic systems and non-invasive BCI.   
    Previous research demonstrates that memorization 
techniques (i.e., mnemonic strategies) has resulted in 
improvements in humans’ ability to recall learned 
information [7][9][18] from long term memory. Mnemonic 
strategies are proven systematic procedures for enhancing 
memory recall [22] and facilitate the acquisition of factual 
information because they assist in the memory encoding 
process; either by providing familiar connections or by 
creating new connections between to-be-remembered 
information and the learner’s information acquisition [21].  
    According to Bellezza [3], memory experts learn to create 
mental pictures that endure in the mental space. A medical 
pictorial mnemonic system has the capability to assist the 
recall of procedural steps in a single pictorial form, 
especially if depicted as intuitively formed symbols that are 
easily and immediately recognizable to the individual user.  
    A study by Estrada et al. [12], using a pictorial mnemonic 
system for recalling aviation emergency procedures, 
discovered that this system facilitated the recall of 
uncommon, unfamiliar terms and phrases in a population to 
a level comparable to that of highly-experienced pilots in 
just one week. The findings highlighted the potential for 
such a mnemonic strategy to aid in the encoding of 
information into long-term memory. This encoding and 
catalytic recall method “chunking” seven (7) pieces of 
information into a picture format results in decreased human 
cognitive overload, accelerates human decision making, and 
measurably augments human task completion performance.  
C. Amplifying Cognition  
    The Defense Advanced Research Projects Agency 
(DARPA) Augmented Cognition (AugCog) and Random 
Access Memory (RAM) Replay programs were design to 
extend information processing and management capacity of 
human-computer symbiotic team by an order-of-magnitude 
more by developing and demonstrating enhancements to 
human cognitive ability and memory retrieval in diverse and 
stressful operational environments. Specifically, these 
programs sought to develop BCI required to measure and 
track a user’s cognitive state and replay memories, in real-
time, utilizing these measurements to augment the user's 
environment, and then tailor that environment to a particular 
user's state. The ultimate is to enhance a soldier’s 
operational capability, support reduction in the numbers of 
soldier’s required to perform current functions, and improve 
soldier 
performance 
in 
cognitively 
challenging 
environments.  The resulting augmented technology (AR) 
systems include non-invasive sensors to assess human 
operators’ neurophysiological responses to ongoing events. 
These measures were then combined with cognitive and 
contextual models of user intention and task objectives to 
invoke validated mitigation strategies to enable optimal 
performance from users, returning users to optimally 
functional states as needed.    
    The field of Augmented Cognition (AugCog) has 
demonstrated 
the 
technical 
feasibility 
of 
utilizing 
psychophysiological measures to support real-time cognitive 
state assessment and BCI reconfiguration to mitigate 
cognitive bottlenecks within a wide variety of operational 
environments.  Therefore, Research and Development 
(R&D) in this domain has spanned a wide range of human-
technology platforms and use case paradigms.  However, 
little research has been dedicated to AugCog-based 
assessments of BCI within the context of AR.  Furthermore,    
Intelligence Amplification (IA) is an AugCog that builds on 
human intelligence (i.e., that has evolved over millions of 
years) to adapt neuro-technology to the individual’s 
neuronal state with a programmed goal to measurably 
amplify the individual’s intellectual/cognitive capabilities to 
perform better than human expected optimal intelligence.  
72
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

    AR provides a complement to human cognitive processes 
via integrated information access, error potential reduction, 
enhanced motivation, and the provision of concurrent 
training and performance. Likewise, Nagao [26] proposed 
that 
psychophysiological 
signals, 
such 
as 
Electroencephalogram (EEG), Electrocardiogram (ECG), 
and Galvanic Skin Response (GSR) could be used to 
support personalization of AR interaction. However, 
subsequent R&D has not fully explored this approach. Other 
researchers 
[27] 
outlined 
a 
framework 
in 
which 
physiological measures, such as EEG, heart rate, and body 
temperature could be used to add intelligence to a wearable 
BCI, 
predicting 
individualized, 
programmable 
user 
behaviors, both offline and online. This functionality was 
predicted to support faster user response rates, and to 
support increased freedom and flexibility. This framework 
also included the option to selectively vary the weights from 
the various physiological inputs according to contextual 
factors. Finally, Navarro proposed that the incorporation of 
technologies, such as AR and multimodal personalized BCI 
techniques could be used to increase accuracy in dynamic 
environments, and that this functionality, combined with the 
adoption 
of 
wireless 
technologies, 
would 
support 
instantiation of this paradigm within increasingly mobile 
and dynamic contexts.  Bonanni, Lee, and Selker [6] 
provided evidence that multimodal AR based interactions 
can enhance procedural task performance; and suggested 
that providing visual cues decreases cognitive load because 
memory is a more complex process than visual search based 
on cueing and search principles from attention theory.  
However, metrics of cognitive load were not directly 
assessed. Likewise, Kim and Dey [19] demonstrated the 
effective use of context-sensitive information and a 
simulated AR representation, combined to minimize the 
cognitive load in translating between virtual information 
spaces and the real world.  Other researchers proposed the 
use of VR and AR in combination with hierarchical BCIs 
and learning models in order to increase BCI usability and 
interaction with physical and virtual worlds.  Specifically, 
the proposed approach leverages the benefits of two 
paradigms of Event Related Potential (ERP) stimuli: 
environmental stimuli and stimuli generated by mental 
imagery.  The goal of this approach was to combine 
environmental 
and 
user-generated 
inputs 
within 
a 
hierarchical BCI system capable of adapting to individual 
users. 
    This paper will discuss cognition BCI gaps (i.e., in 
Section II); augmenting medical personnel with IA (i.e., in 
Section III); and researchers conclusion and next steps (i.e, 
in Section IV).  
II. 
AUGMENTED COGNITION BCI GAPS  
    A primary BCI gap that must be addressed in order for 
wearable AR to improve human working/long term memory 
involves real-time assessment of cognitive workload, real-
time adaptive information presentation to mitigate cognitive 
overload, and non-invasive neuronal interpretation to 
ascertain attention and learning to activating neurons in the 
pre-frontal cortex and hippocampus regions. IA and 
AugCog R&D is grounded in a multi-disciplinary scientific 
approach to address issues of human-technology interaction 
through a blending of cognitive science, human factors, and 
operational neuroscience, and artificial intelligence.  While 
much of the research in this field has focused on the use of 
physiological assessment metrics to drive real-time adaptive 
HCI, Tang, Owen, and Biocca [4][5] demonstrated 
improved task performance using AR and suggested that 
AR systems can reduce mental workload on assembly tasks.  
This study also addressed the issue of attention tunneling, 
indicating that AR cueing has the potential to overwhelm 
the user’s attention, reducing performance by causing 
distraction from important relevant cues of the physical 
environment. This phenomenon has yet to be explored using 
objective measures of user attention and associated 
cognitive workload. Multiple AR studies have employed the 
National Aeronautics and Space Administration (NASA) 
Task Load Index (NASA-TLX) to assess mental workload 
[4][5][23].  However, the TLX provides only subjective 
ratings of mental workload and is not assessing in real time 
during task performance, relying on the user’s memory of 
perceived task demands. Authors proposed a framework and 
research methodology to support instantiation of an adaptive 
AR to reduce cognitive load, as well as contextually adapt to 
an individual’s environment or cognitive/physiological state 
(e.g., stress) using AugCog principles.  Specifically, authors 
propose 
real-time 
monitoring 
and 
assessment 
of 
neurophysiological measures capable of indicating user 
cognitive workload, and specifically differentiating between 
verbal working memory and spatial working memory.  
Within this framework, indices of cognitive workload would 
drive a closed-loop HCI adaptive AR interface, reducing 
information presentation to the user during periods of high 
workload and increasing information as appropriate during 
periods of low workload. The proposed system would 
further differentiate between verbal working memory 
overload and spatial working memory overload, adapting 
information presentation as necessary to avoid overtaxing 
one working memory system. The goal of such a 
methodology is to extend human cognitive capabilities 
while remotely interoperating with a network of federated 
computing services.   
III. 
AUGMNENTING MEDICAL PERSONNEL WITH IA 
   This section provides a use case scenario, selected from 
the medical domain involving cognitive, psychomotor, and 
perceptual skills within a dynamic operational environment. 
Recent wearable AR medical research from Azimi, Doswell, 
Kazanzides J., [2], demonstrated the use of context-aware 
wearable AR for use in surgical and trauma medical 
assistance with future implications of augmenting human 
perceptual cues  with multi-modal cognitive cues.  
73
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

   For example, surgical resection is one of the most 
common treatments for brain tumors.  The treatment goal is 
to remove as much of the tumor as possible, while sparing 
the healthy tissue. Image guidance (e.g., with preoperative 
Computed Tomography (CT) or Magnetic Resonance 
Imaging (MRI) is frequently used because it can more 
clearly differentiate diseased tissue from healthy tissue.  
Most image guidance devices contain special markers that 
can be easily detected by a computer tracking system.  
Registering 
the 
tracker 
coordinate 
system 
to 
the 
preoperative image coordinate system gives the surgeon “x-
ray vision.”  However, this modality can be challenging for 
the surgeon to effectively use a navigation system because 
the presented information is not physically co-located with 
the operative visual display field, requiring the surgeon to 
look at a computer monitor rather than at the patient.  This is 
especially awkward when the surgeon wishes to move an 
instrument within the patient while observing the display.  
Such ergonomic issues may increase operating times, 
fatigue, and the risk of errors.  Furthermore, most navigation 
systems employ optical tracking, due to its high accuracy, 
but this requires line-of-sight between the cameras and the 
markers in the operative field, which can be difficult to 
maintain during the surgery. 
    After researchers observed several neurosurgeries, and 
spoke with neurosurgeons and neurosurgical residents, they 
identified a need to overlay a tumor margin (boundary) on 
the neurosurgeon’s view of patient’s anatomy, which served 
as a pictorial mnemonic triggering memory recall and visual 
landmark to cognitively assist surgeons accurately complete 
a psychomotor procedure. It was also desired to correctly 
track and align the distal end of the surgical instruments 
with the preoperative medical images. The aim of the 
research was to investigate the feasibility of implementing a 
head-mounted tracking system with an AR environment to 
provide the surgeon with visualization of both the tumor 
margin and the surgical instrument in order to create a more 
accurate and natural overlay of the affected tissue versus 
healthy tissue and, hence, provide a more intuitive HCI [2].   
    The resulting wearable AR allows the surgeon to see the 
precise boundaries of the tumor for neurosurgical 
procedures, while simultaneously, providing contextual 
overlay of the surgical tools intraoperatively which are 
displayed on Juxtopia® optical see-through goggles worn 
by the surgeon. This AR overlay capability provides the 
most pertinent information without unduly cluttering the 
visual field. It provides the benefits of navigation and  
visualization while being ergonomically more comfortable 
and intuitive for the surgeon. 
    The majority of related research has focused on AR 
visualization with HMDs, usually adopting video see-
through designs.  Many of these systems have integrated 
one or more on-board camera subsystems to help determine 
head pose [13][16][31] and some have added inertial 
sensing to improve this estimate via sensor fusion [8].  None 
of these systems, however, attempt to provide a complete 
tracking system and continue to rely on external trackers.      
    Combining the aforementioned wearable AR intervention 
with multi-modal sensors and BCI that track both 
dynamically changing internal and external stimuli, 
surgeons may visually monitor the AR display feedback 
based on their cognitive fatigue and stress level, as well as 
performance based multi-model cues including, but not 
limited to, multimedia mnemonics that augment’s the 
surgeon capability to better perform the surgery.  
IV. 
CONCLUSION AND FUTURE WORK 
 
 
 
Figure 2. U.S. Army Combat Medic Wearing HoloLens AR  
Performing Cricothyrotomy. 
 
    To prepare young 18-20 year old brains for accelerated 
learning of combat medic skills (as illustrated in Figure 2) in 
preparation for delivering accurate clinical proficiency in 
austere battlefield environments, Dr. Jayfus Tucker Doswell 
and his research team are applying their preliminary 
AugCog and IA research to investigate non-invasive BCIs 
sensors (e.g., EEG, fMRI, etc.) integrated into wearable AR 
HMDs, 
and 
with 
capabilities 
to 
contextually 
and 
autonomously extract neuronal data from target brain 
regions ranging from pre-frontal cortex (attention), inferior 
frontal junction (visual processing), and hippocampus 
(memory) to substantia nigra (eye movement and motor 
planning), and cerebellum (fine motor movement). A 
primary opportunity presented by such advanced BCI 
technologies is the development of methods to quantifiably 
improve human’s intellectual/cognitive state to optimally 
perform better than historically trained persons. Such 
modality selection methodologies must be dynamic, 
providing the capability to adapt interaction configurations 
to accommodate various operational and environmental 
conditions, as well as user cognitive states, which change 
over time in response to task demands and factors, such as 
sleep, nutrition, stress, and even time of day.  Ideally, 
interactive technologies must be capable of adapting 
interaction modalities, in real-time, in response to task, 
environmental, and user psychophysiological states.  The 
fields of Intelligence Amplification (IA) and Augmented 
74
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

Cognition (AugCog) have demonstrated technical feasibility 
of utilizing psychophysiological measures to support real-
time cognitive state assessment and BCI reconfiguration to 
mitigate cognitive bottlenecks within a wide variety of 
operational environments.   
    Researchers will continue to explore how to integrate a 
dynamically 
changing 
BCI 
sensor 
device/software 
framework into a context-aware AR platform [1][2][10][11] 
to augment human perceptual capabilities and for improving 
human performance®.  
ACKNOWLEDGMENT 
    This research was supported by the Juxtopia® Advanced 
Mixed Reality (JAMR) program of The Juxtopia Group, Inc.  
REFERENCES 
[1] A. Sofolahan, F. Ologhobo, E. Ochieng, D. Gillis, J. Doswell, 
C. Dickens, “Context-Aware Augmented Reality System: A 
Medical First Responder Situational Awareness Interface.”. 
Poster Session. Medicine Meets Virtual Reality (MMVR) 
Conference.  Newport Beach, California, 2010. 
[2] E. Azimi, J, Doswell, P. Kazanzides, “Augmented reality 
goggles with an integrated tracking system for navigation in 
neurosurgery,” Conference: Virtual Reality, IEEE Annual 
International Symposium - VR , pp. 123-124, 2012. 
[3] F.S. Bellezza. “The Minds Eye in Expert Memorizers 
Descriptions of Remembering. Metaphor and Symbolic 
Activity,” 7(3, 4), pp. 119-133, 1992. 
[4] F. Biocca, C. Owen, A. Tang, C. Bohil. “Attention issues in 
spatial information systems: directing mobile users' visual 
attention using augmented reality. Journal of Management 
Information Systems, 23(4), pp. 163-184. 2007. 
[5] F. Biocca, A. Tang, C. Owen, F. Xiao, “Attention funnel: 
omnidirectional 3D cursor for mobile augmented reality 
platforms,” In Proceedings of the SIGCHI conference on 
Human Factors in computing systems (pp. 1115-1122). 
ACM., April 2006.  
[6] L. Bonanni, C.H. Lee, T. Selker. “Attention-based design of 
augmented reality interfaces,” In CHI'05 extended abstracts 
on Human factors in computing systems. pp. 1228-1231, 
ACM. April 2005.  
[7] R.N. Carney, J.R. Levin, “Promoting Higher-Order Learning 
Benefits by Building Lower-Order Mnemonic Connections.” 
Applied Cognitive Psychology, vol. 17, pp. 563-575, 2003. 
[8] L. Chai, W.A. Hoff, T. Vincent. “Three-Dimensional Motion 
and Structure Estimation Using Inertial Sensors and 
Computer Vision for Augmented Reality,” Presence. 
11(5):474-492, Oct 2002. 
[9] B.D. Cox. “Children’s Use of Mnemonic Strategies: 
Variability in Response to Metamemory Training,” The 
Journal of Genetic Psychology, 155(4), 423-442, 2001. 
[10] J. Doswell, O. Sampson, M. Jeffrey. “WASA MIST Wearable 
Assistant for Real-Time Emergency Care Providers,”  The 
15th Annual International Meeting of the American 
Telemedicine Association, 2010. 
[11] J. Doswell, M. Anderson, K. Wilson, P. Kazanzides, 
“Wearable Augmented Reality for Medical First Response 
and Situational Awareness,”  Medicine Meets Virtual Reality 
(MMVR19) 
NextGen 
Conference. 
Newport 
Beach, 
California. 2012. 
[12] A. Estrada, J.A. Keeley, P.A. Leduc, J.M. Bass, T.N. Rouse, 
J.G. Ramiccio, T.L. Rowe, “A novel approach in facilitating 
aviation emergency procedure learning and recall through an 
intuitive pictorial system,” U.S. Army Aeromedical Research 
Laboratory Technical Report, No. 2007-07. 
[13] H. Fuchs, M.A. Livingston, R. Raskar, D. Colucci, K. Keller, 
A. State, J.R. Crawford, P. Rademacher, S. Drake, A.A. 
Meyer, “Augmented reality visualization for laparoscopic 
surgery,” MICCAI, pp. 934-943, 1998. 
[14] T. Höllerer, Feiner, T., “"Mobile Augmented Reality," In H. 
Karimi and A. Hammad, editors, Telegeoinformatics: 
Location-Based Computing and Services. Taylor and Francis 
Books Ltd., London, UK, 2004. 
[15] T. Höllerer, K. Feiner, D. Hallaway, B. Bell, M. Lanzagorta, 
D.G. Brown, S.J. Julier, Y. Baillot, LJ. Rosenblum, "User 
Interface Management Techniques for Collaborative Mobile 
Augmented Reality". Computers and Graphics;25(5): pp799-
810.October, 2001.  
[16] W. Hoff, T. Vincent. “Analysis of head pose accuracy in 
augmented reality,” IEEE Trans. Visualization and Comp. 
Graphics, Vol. 6, 2000. 
[17] C.E. Hughes, C.B. Stapleton, D.E. Hughes, E.M. Smith, 
“Mixed Reality in Education Entertainment, and Training,”. 
IEEE Computer Graphics and Applications. pp. 24-30. 
November/December 2005. 
[18] K.A. Kleinheksel, S.E. Summy, S.E. “Enhancing Student 
Learning 
and 
Social 
Behavior 
Through 
Mnemonic 
Strategies,” TEACHING Exceptional Children, 36(2), 30-35. 
2003. 
[19] S. Kim, A.K. Dey. “Simulated augmented reality windshield 
display as a cognitive mapping aid for elder driver 
navigation,” In Proceedings of the SIGCHI Conference on 
Human Factors in Computing Systems, pp. 133-142, ACM. 
April, 2009.  
[20] Learning and ID. “Cognitive Load Theory” [online] 
http://im404504.wikidot.com/cognitive-learning-theory. 2019 
[21] M.E. Levin, J.R. Levin. “Scientific mnemonomies: Methods 
for maximizing more than memory”. American Educational 
Research Journal, 27, 1990, 301-321.  
[22] M.A. Mastropieri, T.E. Scruggs, “Enhancing School Success 
with Mnemonic Strategies. Intervention in School and Clinic, 
33(4). 1998. 
[23] Z. Medenica, A. L. Kun, T. Paek, O. Palinko, “Augmented 
reality vs. street views: a driving simulator study comparing 
two emerging navigation aids,” In Proceedings of the 13th 
International Conference on Human Computer Interaction 
with Mobile Devices and Services, pp. 265-274,. ACM. 
August 2011. 
[24] G.A. Miller, “The magical number seven, plus or minus two: 
Some limits on our capacity for processing information,” 
Psychological Review. 63, 81-97, 1956. 
[25] P. 
Milgram, 
A.F., 
Kishino, 
“Taxonomy 
of 
Mixed 
RealityVisual Displays,” IEICE Trans. Information and 
Systems, vol. E77-D. no. 12. pp. 1321-1329. 1994. 
[26] K. Nagao, “Agent augmented reality: Agents integrate the real 
world 
with 
cyberspace,” 
Community 
Computing: 
Collaboration over Global Information Networks, ed. T. 
Ishida, John Wiley & Sons. 1998. 
[27] K.F. Navarro, “Wearable, wireless brain computer interfaces 
in 
augmented 
reality 
environments,” 
In 
Information 
Technology: Coding and Computing. Proceedings. ITCC 
2004. International Conference on (Vol. 2, pp. 643-647). 
IEEE. April, 2004.  
 
75
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

