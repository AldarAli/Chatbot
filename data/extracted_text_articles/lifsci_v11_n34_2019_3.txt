Human Pose Estimation, Anthropomorphism and Gamiﬁcation
in the Promotion of Physical Activity Among Breast Cancer Survivors
Jo˜ao P. Monteiro
Carolina T. Lopes
Nuno C. Duarte
INESC TEC / Faculdade de Engenharia
Universidade do Porto
Rua Dr. Roberto Frias s/n
4200-465 Porto, Portugal
jpsm@ieee.org
ee11101@fe.up.pt
up201502854@fe.up.pt
Andr´e T. Magalh˜aes
Servic¸o de Cirurgia Geral
Centro Hospitalar de S˜ao Jo˜ao
Alameda Prof. Hernˆani Monteiro
4200-319 Porto, Portugal
amag1976@gmail.com
H´elder P. Oliveira
INESC TEC / Faculdade de Ciˆencias
Universidade do Porto
Rua Campo Alegre 1021/1055
4169-007 Porto, Portugal
helder.f.oliveira@inesctec.pt
Abstract—As breast cancer survivors are living longer, the ad-
verse effects impacting quality of life resulting from the cancer
treatment are more frequent. Concurrently, an emergence of new
technologies has led to major changes in society with hypothesized
potential to automate and assist in otherwise time-consuming
tasks while promoting engagement. In this context, technology
from the video games industry has been used with emphasis in
the recovery and follow-up stages to evaluate and motivate the
patient after treatment. The present work aims to evaluate a
set of graphical user interfaces that make use of data acquired
with a colour and depth sensor to monitor and provide real-time
feedback to a given user. Design guidelines from serious games
are explored within the context of developing a system aid for
physical follow-up care in the form of a set of exercises selected by
the medical community. The proposed interfaces were evaluated
in a clinical setting with a group of breast cancer survivors and
the expressed preferences collected. Results are discussed under
the light of future developments of anthropomorphization and
gamiﬁcation as means to promote engagement.
Keywords–Computer vision; Computerized monitoring; Com-
puter aided instruction; User interfaces; Medical services.
I.
INTRODUCTION
As previously observed [1], while contributing for im-
proved overall survivorship, contemporary breast cancer treat-
ment techniques may result in several impairments in women’s
upper-body function and, consequently, contribute to a de-
creased quality of life [2] that could potentially be monitored
through the application of readily available low cost computer
vision based sensing approaches.
On the subject of the adverse effects resulting from the
cancer treatment, upper body morbidity (e.g., decreased range
of motion, muscle strength, pain and lymphedema) can be
recognized to be among the most prevalent side effects.
Regarding lymphedema alone, a swelling condition resulting
from lymphatic ablation commonly associated with breast
cancer treatment, it has been estimated that over 1 million
Breast Cancer Survivors (BCS) in the United States of Amer-
ica (USA) and 10 million women worldwide may meet the
criteria for breast cancer-related variant of the condition [2].
Persistent postsurgical pain is also an increasingly documented
problem, negatively impacting quality of life and affecting
approximately 20% of new chronic pain patients. The reported
incidence of persistent post mastectomy pain (PPMP) ranges
from 25-60%, in an estimated total of around 2.5 million
survivors in the United States. Among breast cancer patients,
PPMP is rated as the most troubling symptom, leading to
disability and psychological distress, and is notably resistant to
management. While surgical factors, including more extensive
surgery (total or partial mastectomy), axillary lymph node
dissection and reconstruction have been suggested to serve
as important risk factors for chronic pain, several studies
do not support this association [3]. Adjuvant treatment, such
as radiation, chemotherapy, and hormone therapy, has also
been associated with persistent pain. Among demographic
factors, younger age correlates with increased persistent pain
incidence in some studies but not others. Pre-existing pain is
also more frequent in those who go on to develop PPMP [4].
The most commonly cited theory for post mastectomy pain
syndrome is the removal of the intercostobrachial nerves that
run through the axillary region into the arm which provokes
chronic post-operative pain in breast cancer patients, followed
by chemotherapy and radiation therapy. The treatment involves
physical therapy, topical agents, anticonvulsants, antidepres-
sants, antiarrhythmic, nerve block and scar desensitization
injections with dilute local anaesthesia and steroids [5].
While the assessment of the oncological outcome of
the cancer treatment can be easily objectively quantiﬁed by
disease-free and overall survival rates, the same does not hold
for functional aspects closely related to quality of life within
the target population. Assessment of BCS symptoms and
health-related quality of life outcomes are usually made using
Patient Reported Outcome (PRO) questionnaires that quantify
signiﬁcant outcome variables from the patient’s perspective [2].
A prospective surveillance model for BCS has been proposed,
highlighting the importance of monitoring for functional and
physical impairment commonly associated with treatment [6].
Despite available methods for monitoring and assessing, an in-
tegrated approach able to achieve early detection, promote risk-
reduction and self-management, while engaging the user in an
adequate follow-up strategy, is still considered missing [7].
118
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

In Section II, an outline of topics related to the application
of typical elements of game playing is presented in order to
contextualize the proposed methodology, that is presented in
Section III. The paper continues with a discussion of results in
Section IV regarding key questions relating to the application
of strategies of anthropomorphization and gamiﬁcation as
means to promote engagement to particular physical activities
within the context of patient empowerment systems. Lastly, a
discussion on future developments is presented in Section V.
II.
RELATED WORK
Engaging patients in their healthcare can be recognized as
a paramount topic that has evolved through time also as a
reﬂection of speciﬁc technological and societal contexts [8].
In this sense, growing trends of the quantiﬁed-self movement,
personal health records tools dissemination and interactive
video games that combine physical exercise with game-play
and have a primary purpose other than entertainment present
themselves as currently active research lines.
A. Gamiﬁcation
Physical activity promotion programmes tested in patients
with disabilities and impairment problems demonstrate that
patients’ functionality can improve with an intensive training
split that is contextualised and oriented as a pursuit in the
achievement of a well deﬁned goal. However, this task division
is prone to present a major set-back, which is the lack of
interest of the patient in performing repetitive tasks [11].
On the other hand, it is possible to note that a game,
overall, aims to offer the player a challenge of a physical or/and
mental nature that can be completed using a set of rules, being
able to install feelings of amusement or entertainment in the
participant while returning feedback in a form of grades or
scores, while possibly unlocking new challenges based on the
feedback received. Video games have the same goals, only a
computer is used as an intermediary [12].
The concept of serious games is one that is hard to deﬁne,
but it usually refers to games used for training, advertising,
simulation or education. A particular example of such a
gamiﬁed approach, commonly referred to as exergaming or
exergames, can be described as a type of video game, or
multimedia interaction that requires the player to physically
move in order to play [13]. With the evolution of video game
acceptance by the general public, serious games have begun
to surge, spreading into healthcare where they can eventually
provide a more personalized experience to users, improv-
ing not just physical, but also mental aspects of care. This
surge, and the evolution of visual computing, seems to enable
the development of personalized home systems, which could
objectively evaluate the patient’s state, while motivating for
continued physical activity [14]. Speciﬁcally for rehabilitation,
game prototypes have been tested for speciﬁc circumstances,
in particular scenarios, such as upper limb rehabilitation [15].
The usage of games as a rehabilitation tool is a rather
young topic especially taking into consideration that these
usually tend to depend on virtual/augmented reality and low-
cost effective equipment that has only begun being available
relatively recently, with early examples including applications
of devices such as the Playstation EyeToy dating back to 2003.
A selection of reference works related to rehabilitation games
is brieﬂy reviewed and presented in the following list:
-
Esfahlani et al. [16], evaluated a system aiming to
monitor kinematic activity of upper and lower limbs
by using a group of capture devices (Xbox Kinect,
Mya armband and Rudder Pedal), to create a game in
which levels are proposed taking into account current
and expected abilities of the user.
-
Caurin et al. [17], tested a dynamic difﬁculty adapta-
tion game, using an adapted version of the Pong game
playable with a wrist rehabilitation system as an input
mechanic for patients with motor deﬁciencies.
-
Barzilay, et al. [18], proposed the usage of neural
networks paired with a virtual reality platform, com-
posed of a ViconTM motion capture system and a
wireless AurionTM surface EMG ZeroWire, to create
a neuromotor training system for upper-limb rehabil-
itation that proposes exercises based on the feedback
from patient’s initial usage as well as therapist input.
-
Darzi et al. [19], studied a system that regulates the
difﬁculty of a game by analysing the physiological
responses of the users by measuring respiration and
electromyography signals from the posterior deltoid.
-
Ma et al. [20], assessed the use of a Microsoft Kinect
in terms of quantiﬁcation of maximum range for hand
movement, peak velocity and mean velocity, through
its integration in a rehabilitation game, validating it
by comparing it to a ViconTM motion capture system.
From these latter mentioned studies we can observe that
multiple capture devices can be used, although some of them
represent not just custom made solutions but also high-priced
solutions, with the Microsoft Kinect being identiﬁed as a
relative accurate device at a relative low-cost price.
On the other hand, it is also possible to ﬁnd multiple
examples of studies more focused on the usability of such
games and how the patients reacted to them and elements
that should be taken into consideration when developing such
games. Some examples are listed bellow:
-
Alankus et al. [21], created multiple games that used
two Nintendo Wii remotes attached to the user’s arm
in order to detect elbow and arm movement. The
study mainly contributed by studying a set of game
design elements proposed to be considered when
attempting to create rehabiliation games.
-
Seo et al. [22], measured stroke rehabilitation pa-
tients’ expectations for virtual rehabilitation games
before these engaging in three different games. Af-
ter the gaming experience the patients are again
asked to answer a survey in which they evaluate
the games. The games were developed using the
Microsoft Kinect and P5 Glove MIDI as capture
devices.
-
Burke et al. [23], conducted a study in which multiple
games were tested, using different capture devices,
such as the P5 Glove MIDI, Nintendo Wii remote
or off-the-shelf webcams. The study focused on the
usability of these games on able-bodied users before
conducting it on stroke rehabilitation patients. This
secondary study [24] eventually occurred in which
the webcam games were tested at home by the
stroke rehabilitation patients, proving to be successful
both in usability and playability, with potential to be
deployed for home usage.
119
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 1. Example assessment of the strength of the IVBO in relation to the degree of anthropomorphism of a user controlled avatar, and the hypothesized
uncanny valley effect [9], adapted from [10].
Previous studies seem to suggest that the evaluated systems
are not just viable, but appreciated by its users. It is, however,
important to note that although those games are graded as
serious games, many of the principles being put to use were
described for the creation of purely entertainment pastimes. On
that perspective, it is possible to highlight that the ability to
keep a patient engaged in a time-consuming repetitive activity
is usually the biggest hurdle to overcome. Notwithstanding,
in the case of [25], it has been noted that games that are
created for the speciﬁc purpose of rehabilitation make the game
effective, but end up lacking qualities traditional games pos-
sess, especially entertainment, thus leading to a less motivating
experience, and thus resulting in the activity to be less likely to
be repeated. The opposite can also happen when games that are
designed purely for entertainment purposes are adapted to re-
habilitation, in which the user with limited mobility expresses
to have great fun with experience, but is unable to complete
the level without help from a therapist [26]. These games
also tend to focus on the individual recovery, thus lacking
social qualities to it. As an additional variable to be taken
into consideration, previous studies reinforce the need to create
a social rehabilitation game for added motivation, suggesting
the participation of a relative, or even multiple patients. An
additional note to take from [21] is the consideration for the
possibly older audience and the eventual need to hold their
focus by the usage of colourful scenes and sound effects.
Overall, the ability of games to easily create fun challenges,
be it for an individual or a group, seems to make them a good
candidate for a rehabilitation aid tool. This, together with the
existence of various input controllers, accessible systems and
the possibility of such systems to be taken into the user’s home,
make it a very appealing candidate to help ease the problem
of physical activity promotion. But still, does not yet seem to
be settled how to exactly materialize such ideas.
B. Anthropomorphism
Different elements are being included in serious games
as strategies to promote improved adherence [27]. Of those,
it is possible to highlight virtual representations of the self,
through which players are presented to the possibility of
assuming the role of a character in the game [28]. On the topic
of player controlled game characters, the Illusion of Virtual
Body Ownership (IVBO) considers the effect of game players
experiencing a sense of artiﬁcial body parts to be their own,
within the context of an Virtual Reality (VR) setting [10].
Previous research [10] tends to suggest that the IVBO may
result from an interaction of both synchronous visual, motor
and tactile sensory inputs, as well as pre-existing visual and
proprioceptive body representation factors. Another factor is
the virtual body realism in terms of visual human resemblance,
or anthropomorphism [29]. On a related note, the Uncanny
Valley appertains to a theorized relationship between humans
and robots [9] (e.g., Figure 1), that hypothesis that it should
exist a positive relationship between how human a robot looks,
and how comfortable people are with its appearance, up to
the moment a robot would get too close to being human in
appearance, without being fully human, at which point human
reaction would became negative [9].
C. Human Pose Estimation
In vivo measurements of body mechanics have been typi-
cally acquired with optical motion capture or inertial sensor-
based methods in a laboratorial setting [30]. Most commonly
applied techniques employ optical systems that use high-
speed cameras to capture the 3D motion of reﬂective markers
that have been placed on anatomically relevant landmarks of
the subject’s limbs, trunk, and pelvis, being the supportive
assumption that these markers’ motion represent the movement
of the rigid bony segments observed during the movement
(Kernozek et al., 2013). It is possible to verify that an in-
creasing number of studies have been focused on monocular
mark-less approaches based on visual data. Accordingly, it is
possible to recognize that the visual data streams, acquired
by cameras, present the beneﬁt of allowing a person to
be monitored without the need of additional markers to be
employed. From the several types of data that can be captured,
RGB and depth, are, as already recognized, two of the most
commonly used modalities being used. This approach tends to
be much less expensive compared with those specialised opto-
electronic apparatuses for acquiring motion data [31], and can
also be considered to be used in most natural, everyday life
settings. Commercial products include Microsoft’s Kinect or
Intel’s Realsense that also provide an application programming
interface (APIs) to acquire said depth data.
Range of motion is an important element to be taken
into account when evaluating body mobility [32] that can be
challenging for a patient to self report. Despite associated
performance compromises, the Microsoft Kinect has been pre-
viously evaluated as a tool that could easily be used to monitor
such measures without assistance from a trained examiner [33].
120
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 2. Overall architecture of the proposed system, comprising the use of colour and depth data to monitor, and provide real-time feedback to, a user in the
context of a physical activity promotion for breast cancer survivors.
III.
PROPOSED RESEARCH APPROACH
While there are several games that include serious topics,
the inclusion of serious game elements is not yet enough
to induce learning or real-world action [35]. Overall, despite
engagement being considered a valuable resource, research on
patient engagement technologies regarding impact on health
outcomes has been limited [36]. Given this, this work’s main
goal is to develop and assess a game to promote an adequate
exercise routine for BCS, to be used independently, as a
self-management system to support breast cancer survivorship
while monitoring one’s physical status. The overall architecture
of the proposed system is outlined in Figure 2.
We consider the Microsoft Kinect as an easily accessi-
ble, Color and Depth (RGB-D) sensor-device that enables to
monitor a user’s movement and provide feedback through the
usage of an avatar, so that the user is aware of the performed
movement, aiming at promoting adherence to exercise [37].
Both versions of the Kinect range sensor, i.e., the KinectSL,
which is based on the Structured Light principle, and the Time-
of-Flight variant KinectToF, were considered [38]. To create the
game environment, Unity was selected as the game engine,
given its accessibility and widespread use.
In this paper, we pursue the following main topics:
1)
anthropomorphism as a strategy to engage, and
2)
gamiﬁcation as a mean to promote physical activity,
3)
evaluation of RGB-D based human pose estimation
systems for shoulder and elbow angle measurements
about which we present a body of exploratory work, with
particular interest on the investigation of expressed preferences
of the target user population to evaluate the developed demon-
strators in a clinical setting.
A. Exercise programme selection
A standardized exercise programme consisting of shoulder
ﬂexion, abduction, and horizontal adduction was selected in
accordance to the National Institute for Health and Clinical
Excellence (NICE) guidelines [34]. The individual exercises
comprised in the programme are illustrated in Figure 3.
The exercise routine is composed of three sets, each com-
prising ten repetitions of one of the three exercises included
in the programme, and small breaks between sets.
(a)
(b)
(c)
Figure 3. Illustration of the elements of the exercise programme considered for BCS physical activity promotion intervention, consisting of shoulder
ﬂexion (a), abduction (b) and horizontal abduction (c). Adapted from [34].
121
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 4. Illustration of the user controlled character: avatar based characters animated with the user’s tracked movement with different levels of
anthropomorphism a1) and a2).
B. Expressed acceptance assessment
Analysis of engagement can be considered valuable in
providing insights into game mechanisms that can then be
applied to games for learning, or physical activity promo-
tion [39], although not trivial to measure. In order to assess the
acceptance of particular contexts of a given physical activity
promotion intervention, a criteria set, based on [40], was used
as basis for user expressed acceptance assessment. The criteria
comprised the following aspects of testing:
c1)
suitability for the task,
c2)
information accessibility,
c3)
continuity correction,
c4)
visual pleasingness,
c5)
self-descriptiveness,
c6)
adequacy of user workload.
Based on that criteria, a questionnaire composed of six
questions was formulated in Portuguese, and a ﬁve point scale,
ranging from strong disagreement (1) to strong agreement (5),
considered for range of response options.
C. Study on anthropomorphism
1) Participants and design: Following the approval by the
clinical service direction, seventy-two adults (mean age of the
cohort was 57.79 ± 11.16 years, all female) participated in
the study. Participants were recruited via personal invitation
from surgeon-led follow-up consultations of BCS. Participants
were informed that the study was voluntary and part of the
development of an aid designed to promote physical activity
recommend for BCS within the context of an academic disser-
tation work. Written informed consent granting permission to
the use of the anonymously collected data was obtained from
all participants. All participants were ﬂuent in Portuguese and
did not get paid for their participation.
2) Procedure and materials: Participants were invited to
participate in this study via personal invitation at the end of
a follow up consultation at the Breast Center of S˜ao Jo˜ao
Hospital during the period from the end of October until
the beginning of December, 2016. The recruited participants
were prompted to use the system in an adjacent room to the
consultation room.
The architecture illustrated in Figure 2 was adapted so that
it would entail a Non-Player Character (NPC) in the form
of a virtual assistant that exempliﬁed the movements to be
performed according to the established exercise programme
while the user was exercising. The same programme would
be repeated four times, considering additional breaks between
routines, one for each of the considered levels of the user
controlled avatar anthropomorphism (illustrated in Figure 4).
After using the system, each patient was inquired of its
satisfaction level of the usage of the system through a question-
naire that required the user to rate each of the tested interfaces
according to a ﬁve point scale ranging from least preferred (1)
to most preferred (5). Each session took approximately 30
minutes, comprising the usage of the system for the proposed
exercise programme and the ﬁlling of the questionnaire.
3) Results: Each of the four interfaces were evaluated using
the aforementioned score in a ﬁve point scale after the user
completed the exercise programme using all of the proposed
interfaces. Table I presents the mean expressed preferences for
the user controlled character variations.
Although it seems to not exist an abrupt drop on the col-
lected expressed preference between evaluated interfaces with
different levels of user controlled avatar anthropomorphism,
both skeleton and humanoid examples seem to be preferred
over the alternatives with either no visual feedback, or mirror-
based feedback.
TABLE I. AVERAGE AND STANDARD DEVIATION (SD) OF EXPRESSED PREFERENCES OVER THE DIFFERENT USER CONTROLLED
CHARACTER TESTED BY SEVENTY-TWO BCS IN A CLINICAL SETTING.
avatar
no visual feedback
skeleton
humanoid
mirror
Average
4.10
4.22
4.22
4.19
SD
0.77
0.88
0.77
0.82
122
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

(a) Experimental set-up
(b) Printed pamphlet
Figure 5. a) Acquisition environment for the study on gamiﬁcation for the tested system comprising a KinectToF, laptop and additional screen; b) Printed
pamphlet produced at the Breast Center of S˜ao Jo˜ao Hospital and distributed to BCS.
D. Study on gamiﬁcation
1) Participants and design: Sixty-eight adults (mean age
of the cohort was 59.09 ± 10.92 years, all female) partici-
pated. The same recruitment method mentioned in Subsection
III-C (Study on anthropomorphism) was used. A sub group of
22% of participants (15 out of 68) were randomly assigned to
receive printed information resources, in form of a pamphlet
produced at the Breast Center of S˜ao Jo˜ao Hospital.
2) Procedure and materials: As in the study on anthro-
pomorphism, participants were invited to participate after a
surgeon-led follow-up consultation at the Breast Center of S˜ao
Jo˜ao Hospital. The recruitment took place from the beginning
of November until the end of December, 2017. Participants
were informed about the study being part of the development
of an aid to promote physical activity recommend for BCS, and
prompted to use the system, in an adjacent to the consultation
room (as illustrated in Figure 5).
The architecture used for the study on anthropomorphism,
was considered, including the NPC virtual assistant exempli-
fying the exercise programme to be performed. To provide
real-time feedback of the user’s own movement only a human
avatar was used. Differently from the previous study, the user
controlled avatar was animated with the human pose provided
by a KinectToF. A novelty introduced by the second Kinect
version (through its corresponding SDK and respective tools)
is the gesture builder tool.
The gesture builder tool was used to create a database
containing the set of considered movements, and to assess
the completion of a given movement being performed. After
building a library of the selected exercises, this was used to
score the performance of the user. The normal scoring of the
game attributed 1 point for every 1% of progress in each
repetition, and a ﬁnal score was presented as a percentage
of the routine completed (the complete routine corresponds to
3000 points).
After the usage of the system, each patient was inquired to
express level of acceptance that required the user to rate each of
the previously identiﬁed criteria according to a ﬁve point scale
ranging from strong disagreement (1) to strong agreement (5).
Each session took approximately 10 minutes, which comprised
the usage of the interface for the proposed exercise programme
by the user and the ﬁlling of the questionnaire.
3) Results: Table II presents the mean expressed accep-
tance for the proposed Gamiﬁed Aid for Monitoring Exer-
cise (GAME) with a humanoid player controlled character
and an NPC virtual assistant, against an informative printed
pamphlet. Of the total cohort of sixty-eight BCS, ﬁfty-three
were randomly assigned to use the GAME and ﬁfteen assigned
for being shown the printed pamphlet.
In the context of the evaluation, it seems to exist a
stronger agreement, across considered criterion, for the pro-
posed GAME being a preferred medium over printed materials.
TABLE II. AVERAGE AND STANDARD DEVIATION (SD) OF EXPRESSED ACCEPTANCE FOR THE PROPOSED GAME AND A PRINTED
PAMPHLET CONTAINING INFORMATION ABOUT THE SELECTED EXERCISE PROGRAMME.
GAME
pamphlet
Criteria
Average
SD
Average
SD
c1)
4.60
0.74
4.00
1.11
c2)
4.72
0.50
4.08
1.27
c3)
4.92
0.32
5.00
0.00
c4)
4.88
0.29
4.60
0.84
c5)
4.96
0.19
4.60
0.84
c6)
4.88
0.39
4.00
1.11
123
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

(a) Interface for KinectSL virtual goniometer
(b) Interface for KinectToF virtual goniometer
(c) Reference measurments of shoulder and elbow range of motion angles
Figure 6. Snapshots of the developed interfaces for the virtual goniometer for both KinectSL, (a), and KinectToF, (b), and illustration of the measured postural
angles, adapted from [41], (c).
E. Study on postural angles from RGB-D
1) Participants and design: Due to time constraints from
the clinical setting this study of validation of the Kinect sensors
for the task of measuring joint angles was performed in an
academic setting, having participated seven adults (mean age
of the cohort was 27.6 ± 5.44 years, 5 male, 2 female)
recruited via personal invitation from a group of post graduate
students from the Faculty of Engineering of Porto with no
known shoulder impairments. All participants were ﬂuent in
Portuguese and did not get paid for their participation.
2) Procedure and materials: Participants were invited to
participate in this study via personal invitation at two mo-
ments: December, 2016 and December 2017. Participants were
informed that the study was part of the development of an aid
designed to promote physical activity recommend for BCS.
The recruited participants were prompted to use the system, in
an indoor room of the Faculty of Engineering of Porto.
An application for measuring range of shoulder and elbow
motion using input data from both Microsoft Kinect RGB-D
sensors was developed using the cross-platform game engine
Unity. Furthermore, the results are compared against the data
acquired with a clinical gold standard goniometer. The go-
niometer used to register the values of postural angles of the
shoulder and elbow has a range between 0 and 270 degrees,
with a minimum scale value of 2 degrees.
Each subject was recorded performing a shoulder ﬂexion
with the instruction of obtaining a 90 degree angle. For the
shoulder abduction and elbow rotation exercises, the same
procedure as the shoulder ﬂexion has considered. In the case of
shoulder rotation the vectors can be seen as the vector deﬁned
by the points consisting of the chest and the hip, against the
vector deﬁned by the points consisting of the shoulder and
elbow. In the case of elbow rotation, the angle is obtained
by the vector deﬁned from the shoulder to the elbow and
the vector from the elbow to the wrist. These vectors can be
visualized in different planes in Figure 6.
3) Results: Table III presents the mean absolute difference
(disagreement) between the readings of a trained annotator
using a goniometer, and the computed angles from the three-
dimensional location of the anatomical landmarks detected by
both versions of Kinect. The results suggest that despite an
improved design regarding depth estimation of the KinectToF
over the KinectSL, the difference to the goniometer measures
is smaller for the older version of the RGB-D camera, that
seemed to deal better with the partial occlusion of body parts
in the range of view of the acquisition device in the context of
this study. Despite constituting a limitation to the present study,
it does not seem evident to the authors whether a different
result could have been observed would have been possible to
have access to BCS to perform this technical validation.
TABLE III. AVERAGE AND STANDARD DEVIATION (SD) OF SHOULDER AND ELBOW RANGE OF MOTION ABSOLUTE ANGLE DIFFERENCE
IN DEGREES BETWEEN GONIOMETER MEASURES BY A TRAINED ANNOTATOR AND ESTIMATIONS BASED ON THE HUMAN POSE
RECOVERY METHODS PROVIDED WITH BOTH STRUCTURED LIGHT (SL) AND TIME-OF-FLIGHT (TOF) VARIANTS OF KINECT
(
θKINECTV − θGONIOMET ER
 , V = SL, TOF).
Absolute Disagreement [◦]
Shoulder abduction
Shoulder ﬂexion
Elbow ﬂexion
KinectSL
KinectToF
KinectSL
KinectToF
KinectSL
KinectToF
Average
0.936
3.190
0.532
5.170
1.034
7.080
SD
0.630
2.205
0.421
2.200
0.603
7.305
124
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

IV.
CONCLUSION
The present work investigates the impact of providing real-
time feedback to BCS within the context of a physical activity
promotion intervention. A system comprised of a RGB-D
sensor with a processing pipeline to monitor the user, and in
that way animate a user controlled avatar, was considered.
In the ﬁrst exploratory study the effect of different levels
of anthropomorphism of the user controlled avatar was investi-
gated. Seventy-two BCS participated in the cohort. The results
seem to agree with the hypothesised Uncanny Valley effect,
in the sense that a more anthropomorphised representation of
the self (a mirror), seems not to be the preferred interface.
Although not possible to assess from the presented results,
but also supported considering previous research, i.e., [10],
subjectively constructed proprioceptive body representations of
the self, seems to be an apparently worth considering factor
in the context of BCS, with potential impact to adherence to
systems using anthropomorphised avatars.
In the second study a gamiﬁed approach considering an
humanoid avatar and an NPC assistant was evaluated against
a printed pamphlet. From a total of sixty-eight participants,
a subgroup of 15 was randomly assigned to be shown the
pamphlet containing information about appropriate care fol-
lowing breast cancer treatment, including the recommendation
to perform simple exercises to be repeated throughout sur-
vivorship. The remaining participants played a game where
an NPC assistant would exemplify the recommend exercise
programme, while a humanoid avatar would replicate the user’s
movements, and in real-time provide feedback of the exercise
being executed. Overall, the collected expressed acceptance
suggests that the proposed gamiﬁed aid for monitoring exercise
seems suitable for the task, informative, visual pleasing, self-
descriptive, and providing an adequate workload to the user.
For the third study the accuracy of both versions of the
Microsoft Kinect RGB-D capture device in calculating angles
of the shoulder and elbow in speciﬁc poses and the possibility
of using it instead of a tradition instrument the goniometer was
evaluated. A control group of 7 healthy adults was considered
and two separated sessions were performed for the distinct
Structured Light and the Time-of-Flight based depth sensors.
The results compared to the goniometer seem to suggest that
the Microsoft Kinect can be considered as an auxiliary virtual
goniometer in order to facilitate frequent measurement taking,
specially if in coordination with individualized monitoring
context. It seems also possible to recognize a higher disagree-
ment with the gold standard measures for the KinectToF that
can be related with a more frequent interference from detection
errors associated with occluded body parts.
Overall it seems possible to recognize that in the context
of physical activity promotion interventions target at particular
populations monitoring particular measures of physical status
trough automatic methods based on human pose estimation is
feasible. Moreover, the application of gamiﬁed strategies to
promote engagement seem to be well perceived by users, even
though the mid to long term adhesion is yet to be properly
characterized. Furthermore, for the particular context of breast
cancer survivors, the hypnotized relation between humans and
virtual characters in which users would experience higher
levels of comfort when interacting with more anthropomorphic
looking avatars, does not seem to hold.
V.
FUTURE WORK
The considered prospective surveillance model for breast
cancer survivors highlights the importance of monitoring for
functional and physical impairment commonly associated with
breast cancer treatment. Low cost device-based methods have
been studied, and its potential to “enable a continuum of
time scale from a summary of entire interactions to second-
by-second dynamics” continuously highlighted in a myriad
of application scenarios [42]. Notwithstanding, from the pre-
sented work, various topics seem to still present themselves
as pertinent to be explored in future work. Among several,
the problem of recovering the spatial pose of the human
body during dynamic movements, from mark-less set-ups of
acquisition is highlighted bellow.
Computer vision and pattern recognition ﬁelds present
recent insightful research that is constantly innovating. Even
if, at the very front end of development, progress may look
a lot like long-lived methodologies as may be the case of
variations of perceptron inspired learning approaches [43] or
related weights estimation method of back-propagation [44],
rediscovered through a new context of parallel computation
capabilities and extensive data availability [45]. And despite
all that, or even the recent explosion of deep convolutional
neural networks (DCNN), general purpose learning algorithms
that improve themselves in provably optimal ways still seem a
distant future [45]. By the same token, human pose estimation
still remains with several challenges, especially in the 3D
space as reviewed by [46]. One of the challenges arises from
the ill-posed nature of the 3D pose estimation task itself,
especially from a single monocular image. Similar image
projections can be derived from completely different 3D poses.
In such cases, self-occlusions result in ambiguities that limit
the applicability of existing techniques. Furthermore, recent
research primarily focus on frontal views with few occlusions
despite the abundance of occlusion and partial-poses in object
detection in natural environments.
Besides a trend of deep neural networks-based methods, the
existence of prominent publicly made available datasets [47],
[48], [49], recurrently used to stablish benchmarks for the
task of recovering the tri-dimensionality of the human pose
from bi-dimensional visual data, seem to contribute to ad-
vances in the respective ﬁeld. Despite the recent trend of
methods outperforming feature learning strategies in a myriad
of applications [50], the challenging tasks of establishing a
proper learning approach and parameters tuning for a given
task [51], as well as, a compromised interpretability [52] of
the resulting models, still remain relevant open challenges that
gain special importance in clinically related applications. On
that regard, recent regulation in the European Union proposes
that individuals affected by algorithmic decisions have a right
to explanation [53], despite not being completely clear on how
a clinician treating a patient who is aided by a machine learning
algorithm may be expected to explain decisions that use the
patient’s data [54]. The need for less opaque ways to explain
algorithms outcomes, has also motivated the recent DARPA’s
Explainable Artiﬁcial Intelligence (XAI) program [55].
ACKNOWLEDGMENTS
The authors would like to thank the direction, members,
and users of the Breast Center of S˜ao Jo˜ao Hospital, that,
valuably, supported and participated in the research.
125
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

This work is ﬁnanced by the ERDF - European Regional
Development Fund through the Operational Programme for
Competitiveness and Internationalisation - COMPETE 2020
Programme within project POCI-01-0145-FEDER-006961,
and by National Funds through the Portuguese funding agency,
FCT - Fundac¸˜ao para a Ciˆencia e a Tecnologia as part of
project UID/EEA/50014/2013; and also by FCT within the
Ph.D. grant number SFRH/BD/138823/2018.
REFERENCES
[1]
J. P. Monteiro, C. T. Lopes, N. C. Duarte, A. Magalh˜aes, and
H. P. de Oliveira, “Investigations on the impact of anthropomorphism
and gamiﬁcation on breast cancer survivors’ expressed preferences
in a physical activity promotion intervention,” in Proceedings of the
eTELEMED 2019 : The Eleventh International Conference on eHealth,
Telemedicine, and Social Medicine.
IARIA, 2019, pp. 139–143.
[2]
V. M. Boquiren, T. F. Hack, R. L. Thomas, A. Towers, W. B. Kwan,
A. Tilley, E. Quinlan, and B. Miedema, “A longitudinal analysis of
chronic arm morbidity following breast cancer surgery,” Breast Cancer
Research and Treatment, vol. 157, no. 3, 2016, pp. 413–425.
[3]
R. G¨artner, M.-B. Jensen, J. Nielsen, M. Ewertz, N. Kroman, and
H. Kehlet, “Prevalence of and factors associated with persistent pain
following breast cancer surgery,” Jama, vol. 302, no. 18, 2009, pp.
1985–1992.
[4]
K. G. Andersen and H. Kehlet, “Persistent pain after breast cancer
treatment: a critical review of risk factors and strategies for prevention,”
The Journal of Pain, vol. 12, no. 7, 2011, pp. 725–746.
[5]
Y. Briskin and T. Odinets, “Improvement of upper limb’s condition
of women with post mastectomy syndrome with the help of problem–
oriented program of physical rehabilitation,” Pedagogics, psychology,
medical-biological problems of physical training and sports, vol. 19,
no. 11, 2015, pp. 20–25.
[6]
N. L. Stout, J. M. Binkley, K. H. Schmitz, K. Andrews, S. C. Hayes,
K. L. Campbell, M. L. McNeely, P. W. Soballe, A. M. Berger, A. L.
Cheville, C. Fabian, L. H. Gerber, S. R. Harris, K. Johansson, A. L.
Pusic, R. G. Prosnitz, and R. A. Smith, “A prospective surveillance
model for rehabilitation for women with breast cancer,” Cancer, vol.
118, no. S8, 2012, pp. 2191–2200.
[7]
L. Lai, J. Binkley, V. Jones, S. Kirkpatrick, C. Furbish, P. Stratford,
W. Thompson, A. Sidhu, C. Farley, J. Okoli, D. Beech, and S. Gabram,
“Implementing the prospective surveillance model (PSM) of rehabilita-
tion for breast cancer patients with 1–year postoperative follow–up, a
prospective, observational study,” Annals of Surgical Oncology, vol. 23,
no. 10, 2016, pp. 3379–3384.
[8]
W. Tauxe, “A tumour through time,” Nature, vol. 527, no. 7578, 2015,
pp. S102–S103.
[9]
M. Mori, K. MacDorman, and N. Kageki, “The uncanny valley,” IEEE
Robotics & Automation Magazine, vol. 19, no. 2, 2012, pp. 98–100.
[10]
J. Lugrin, J. Latt, and M. E. Latoschik, “Avatar anthropomorphism and
illusion of body ownership in vr,” in Proceedings of the 2015 IEEE
conference on Virtual Reality (VR), 2015, pp. 229–230.
[11]
M. Simon, “Gamiﬁcation and serious games for personalized health,”
Studies in Health Technology and Informatics, vol. 177, 2012, pp. 85–
96.
[12]
F. Laamarti, M. Eid, and A. E. Saddik, “An overview of serious games,”
International Journal of Computer Games Technology, vol. 2014, 2014,
pp. 1–15.
[13]
S. W¨uest, N. A. Borghese, M. Pirovano, R. Mainetti, R. van de
Langenberg, and E. D. de Bruin, “Usability and effects of an exergame–
based balance training program,” Games for Health Journal, vol. 3,
no. 2, 2014, pp. 106–114.
[14]
B. Lange, S. Koenig, E. McConnell, C.-Y. Chang, R. Juang, E. Suma,
M. Bolas, and A. Rizzo, “Interactive game–based rehabilitation using
the microsoft kinect,” in Proceedings of the 2012 IEEE Conference in
Virtual Reality (VR).
IEEE, 2012.
[15]
R. Moreira, A. Magalh˜aes, and H. Oliveira, “A kinect–based system for
upper–body function assessment in breast cancer patients,” Journal of
Imaging, vol. 1, no. 1, 2015, pp. 134–155.
[16]
S. S. Esfahlani, S. Cirstea, A. Sanaei, and G. Wilson, “An adaptive
self–organizing fuzzy logic controller in a serious game for motor
impairment rehabilitation,” in Proceedings of the 2017 IEEE 26th
International Symposium on Industrial Electronics (ISIE), 2017, pp.
1311–1318.
[17]
G. A. Caurin, A. A. Siqueira, K. O. Andrade, R. C. Joaquim, and H. I.
Krebs, “Adaptive strategy for multi–user robotic rehabilitation games,”
in Proceedings of the 2011 Annual International Conference of the IEEE
Engineering in Medicine and Biology Society, 2011, pp. 1395–1398.
[18]
O. Barzilay and A. Wolf, “Adaptive rehabilitation games,” Elsevier
Journal of Electromyography and Kinesiology, vol. 23, no. 1, 2013,
pp. 182–189.
[19]
A. Darzi, M. Gorˇsiˇc, and D. Novak, “Difﬁculty adaptation in a com-
petitive arm rehabilitation game using real-time control of arm elec-
tromyogram and respiration,” in Proceedings of the 2017 International
Conference on Rehabilitation Robotics (ICORR), 2017, pp. 857–862.
[20]
M. Ma, R. Profﬁtt, and M. Skubic, “Quantitative assessment and
validation of a stroke rehabilitation game,” in Proceedings of the 2017
IEEE/ACM International Conference on Connected Health: Applica-
tions, Systems and Engineering Technologies (CHASE), 2017, pp. 255–
257.
[21]
G. Alankus, A. Lazar, M. May, and C. Kelleher, “Towards customizable
games for stroke rehabilitation,” in Proceedings of the Special Interest
Group on Computer-Human Interaction (SIGCHI) Conference on Hu-
man Factors in Computing Systems, 2010, pp. 2113–2122.
[22]
N. J. Seo, J. K. Arun, P. Hur, V. Crocher, B. Motawar, and K. Lak-
shminarayanan, “Usability evaluation of low-cost virtual reality hand
and arm rehabilitation games.” Journal of rehabilitation research and
development, vol. 53, no. 3, 2016, pp. 321–334.
[23]
J. W. Burke, M. McNeill, D. Charles, P. Morrow, J. Crosbie, and
S. McDonough, “Serious games for upper limb rehabilitation following
stroke,” in Proceedings of the 2009 Conference in Games and Virtual
Worlds for Serious Applications, 2009, pp. 103–110.
[24]
J. W. Burke, M. McNeill, D. K. Charles, P. J. Morrow, J. H. Crosbie, and
S. M. McDonough, “Optimising engagement for stroke rehabilitation
using serious games,” The Visual Computer, vol. 25, no. 12, 2009, p.
1085.
[25]
E. Flores, G. Tobon, E. Cavallaro, F. I. Cavallaro, J. C. Perry, and
T. Keller, “Improving patient motivation in game development for
motor deﬁcit rehabilitation,” in Proceedings of the 2008 International
Conference on Advances in Computer Entertainment Technology, ser.
ACE ’08.
ACM, 2008, pp. 381–384.
[26]
D. Rand, R. Kizony, and P. Weiss, “Virtual reality rehabilitation for
all: Vivid gx versus sony playstation ii eyetoy,” in Proceedings of the
5th Intl Conf. Disability, Virtual Reality and Assoc. Tech (ICDVRAT),
2004, vol. 4, pp. 87–94.
[27]
D. Thompson, “Designing serious video games for health behavior
change: Current status and future directions,” Journal of Diabetes
Science and Technology, vol. 6, no. 4, 2012, pp. 807–811.
[28]
M. Rice, R. Koh, Q. Lui, Q. He, M. Wan, V. Yeo, J. Ng, and W. P.
Tan, “Comparing avatar game representation preferences across three
age groups,” in Proceedings of the 2013 ACM SIGCHI Conference on
Human Factors in Computing Systems CHI.
ACM Press, 2013.
[29]
T. Waltemate, D. Gall, D. Roth, M. Botsch, and M. E. Latoschik, “The
impact of avatar personalization and immersion on virtual body owner-
ship, presence, and emotional response,” IEEE Trans. on Visualization
and Computer Graphics, vol. 24, no. 4, 2018, pp. 1643–1652.
[30]
L. Donath, O. Faude, E. Lichtenstein, C. N¨uesch, and A. M¨undermann,
“Validity and reliability of a portable gait analysis system for measur-
ing spatiotemporal gait characteristics: comparison to an instrumented
treadmill,” Journal of neuroengineering and rehabilitation, vol. 13, no. 1,
2016, p. 6.
[31]
A. Patrizi, E. Pennestr`ı, and P. P. Valentini, “Comparison between
low-cost marker–less and high–end marker–based motion capture sys-
tems for the computer–aided assessment of working ergonomics,”
Ergonomics, vol. 59, no. 1, 2016, pp. 155–162.
[32]
S. H. Lee, C. Yoon, S. G. Chung, H. C. Kim, Y. Kwak, H. won Park,
and K. Kim, “Measurement of shoulder range of motion in patients
with adhesive capsulitis using a kinect,” PLOS ONE, vol. 10, no. 6,
2015, p. e0129398.
126
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[33]
M. Huber, A. L. Seitz, M. Leeser, and D. Sternad, “Validity and
reliability of kinect skeleton for measuring shoulder joint angles: a
feasibility study,” Physiotherapy, vol. 101, no. 4, 2015, pp. 389–393.
[34]
J. Yarnold, “Early and locally advanced breast cancer: Diagnosis and
treatment national institute for health and clinical excellence guideline
2009,” Clinical Oncology, vol. 21, no. 3, 2009, pp. 159–160.
[35]
K. Starks, “Cognitive behavioral game design: a uniﬁed model for
designing serious games,” Frontiers in Psychology, vol. 5, 2014, p. 28.
[36]
J. E. Prey, J. Woollen, L. Wilcox, A. D. Sackeim, G. Hripcsak,
S. Bakken, S. Restaino, S. Feiner, and D. K. Vawdrey, “Patient en-
gagement in the inpatient setting: a systematic review,” Journal of the
American Medical Informatics Association, vol. 21, no. 4, 2014, pp.
742–750.
[37]
J. Han, L. Shao, D. Xu, and J. Shotton, “Enhanced computer vision with
microsoft kinect sensor: A review,” IEEE Transactions on Cybernetics,
vol. 43, no. 5, oct 2013, pp. 1318–1334.
[38]
H. Sarbolandi, D. Leﬂoch, and A. Kolb, “Kinect range sensing:
Structured–light versus time–of–ﬂight kinect,” Computer Vision and
Image Understanding, vol. 139, oct 2015, pp. 1–20.
[39]
E. A. Boyle, T. Hainey, T. M. Connolly, G. Gray, J. Earp, M. Ott, T. Lim,
M. Ninaus, C. Ribeiro, and J. Pereira, “An update to the systematic
literature review of empirical evidence of the impacts and outcomes of
computer games and serious games,” Computers & Education, vol. 94,
2016, pp. 178–192.
[40]
K. S. Park and C. H. Lim, “A structured methodology for comparative
evaluation of user interface designs using usability criteria and mea-
sures,” International Journal of Industrial Ergonomics, vol. 23, no. 5-6,
1999, pp. 379–389.
[41]
S. H. Lee, C. Yoon, S. G. Chung, H. C. Kim, Y. Kwak, H.-w. Park, and
K. Kim, “Measurement of shoulder range of motion in patients with
adhesive capsulitis using a kinect,” PloS one, vol. 10, no. 6, 2015, p.
e0129398.
[42]
C. Lecl`ere, M. Avril, S. Viaux-Savelon, N. Bodeau, C. Achard, S. Mis-
sonnier, M. Keren, R. Feldman, M. Chetouani, and D. Cohen, “Inter-
action and behaviour imaging: a novel nethod to neasure mother–infant
interaction using video 3d reconstruction,” Translational psychiatry,
vol. 6, no. 5, 2016, p. e816.
[43]
F. Rosenblatt, “Principles of neurodynamics. perceptrons and the theory
of brain mechanisms,” Cornell Aeronautical Lab Inc Buffalo NY, Tech.
Rep., 1961.
[44]
D. E. Rumelhart, G. E. Hinton, R. J. Williams et al., “Learning
representations by back–propagating errors,” Nature, vol. 323, no. 3,
1986, pp. 533–536.
[45]
J. Schmidhuber, “Deep learning in neural networks: An overview,”
Neural networks, vol. 61, 2015, pp. 85–117.
[46]
N. Saraﬁanos, B. Boteanu, B. Ionescu, and I. A. Kakadiaris, “3d human
pose estimation: A review of the literature and analysis of covariates,”
Computer Vision and Image Understanding, vol. 152, 2016, pp. 1–20.
[47]
L. Sigal, A. O. Balan, and M. J. Black, “Humaneva: Synchronized
video and motion capture dataset and baseline algorithm for evaluation
of articulated human motion,” International journal of computer vision,
vol. 87, no. 1-2, 2010, p. 4.
[48]
M. Andriluka, L. Pishchulin, P. Gehler, and B. Schiele, “2d human pose
estimation: New benchmark and state of the art analysis,” in Proceedings
of the IEEE Conference on computer Vision and Pattern Recognition,
2014, pp. 3686–3693.
[49]
C. Ionescu, D. Papava, V. Olaru, and C. Sminchisescu, “Human3.6m:
Large scale datasets and predictive methods for 3d human sensing
in natural environments,” IEEE transactions on pattern analysis and
machine intelligence, vol. 36, no. 7, 2013, pp. 1325–1339.
[50]
R. Miotto, L. Li, B. A. Kidd, and J. T. Dudley, “Deep patient: An
unsupervised representation to predict the future of patients from the
electronic health records,” Scientiﬁc reports, vol. 6, 2016, p. 26094.
[51]
Y. Guo, Y. Liu, A. Oerlemans, S. Lao, S. Wu, and M. S. Lew, “Deep
learning for visual understanding: A review,” Neurocomputing, vol. 187,
2016, pp. 27–48.
[52]
B. J. Lengerich, S. Konam, E. P. Xing, S. Rosenthal, and M. Veloso,
“Towards visual explanations for convolutional neural networks via
input resampling,” arXiv preprint arXiv:1707.09641, 2017.
[53]
B. Goodman and S. Flaxman, “European union regulations on algo-
rithmic decision–making and a “right to explanation”,” AI Magazine,
vol. 38, no. 3, 2017, pp. 50–57.
[54]
T. Ching, D. S. Himmelstein, B. K. Beaulieu-Jones, A. A. Kalinin, B. T.
Do, G. P. Way, E. Ferrero, P.-M. Agapow, M. Zietz, M. M. Hoffman
et al., “Opportunities and obstacles for deep learning in biology and
medicine,” Journal of The Royal Society Interface, vol. 15, no. 141,
2018, p. 20170387.
[55]
M. T. Ribeiro, S. Singh, and C. Guestrin, ““why should i trust you?”:
Explaining the predictions of any classiﬁer,” in Proceedings of the 22nd
ACM SIGKDD international conference on knowledge discovery and
data mining.
ACM, 2016, pp. 1135–1144.
127
International Journal on Advances in Life Sciences, vol 11 no 3 & 4, year 2019, http://www.iariajournals.org/life_sciences/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

