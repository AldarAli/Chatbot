An Autonomic Framework for Service Configuration 
Patcharee Thongtra 
Department of Telematics 
Norwegian University of Science and Technology 
N-7491 Trondheim, Norway 
patt@item.ntnu.no 
Finn Arve Aagesen 
Department of Telematics 
Norwegian University of Science and Technology 
N-7491 Trondheim, Norway 
finnarve@item.ntnu.no
 
 
Abstract — An autonomic framework for service configuration 
functionality is proposed. The framework has goals and 
policies. Goals express required performance and income 
measures. Policies define actions in states with unwanted 
performance and income measures. All functionality is 
executed by autonomic elements (AEs) that have ability to 
download and execute behavior specifications during run-time.  
An AE has several generic functionality components. Two 
important generic components of an AE are Judge and 
Strategist. A Strategist selects actions in a state with unwanted 
performance and income measures to reach a state defined by 
goal performance and income measures. A Judge gives 
rewards to actions based on the ability to move towards a state 
with goal performance and income measures. The Strategist’s 
selection of actions is based on the rewards given by the Judge. 
AE functionality is realized by the combination of Extended 
Finite State Machines (EFSM), a Reasoning Machine (RM) 
and a Learning Machine (LM). A case study of an adaptable 
streaming system is presented. Using the proposed model, the 
streaming system can select actions for capability allocation 
adaptation 
more 
appropriately 
as 
evaluated 
by 
the 
performance and income measure results. 
Keywords-Autonomic; 
Service 
configuration; 
Policy; 
Autonomic Elements. 
I. 
 INTRODUCTION 
Networked service systems are considered. Services are 
realized by service components, which by their inter-
working provide a service in the role of a service provider to 
service users [1]. Service components are executed as 
software components in nodes, which are physical 
processing units such as servers, routers, switches, PCs and 
mobile phones. A service framework is here defined as the 
overall structural and behavior framework for the 
specification 
and 
execution 
of 
services. 
Service 
configuration comprises capability configuration, capability 
allocation, service deployment and instantiation, system 
performance 
diagnosis, 
fault 
diagnosis 
and 
service 
adaptation. A capability is an inherent property of a node 
required as a basis to implement services [1]. Capabilities 
can be classified into resources, functions and data. 
Examples are CPU, memory, transmission capacity of 
connected transmission links, available special hardware, and 
available programs and data. 
The service configuration is done with respect to 
required capabilities and capability performances as well as 
required service performances. In this paper, we focus on 
service configuration of adaptable service systems, here 
defined as a service system that can adapt by itself related to 
changes by users, nodes, capabilities, system performances 
and service functionalities.  
In this paper, an autonomic approach to adaptable service 
systems is proposed. Autonomic systems have ability to 
manage themselves and to adapt dynamically to changes in 
accordance with given objectives [2, 3]. The autonomic 
system is constituted by distributed components denoted as 
autonomic elements (AEs). An AE is the smallest entity that 
can manage its internal behaviors and relationships with 
other entities in accordance with its defined behavior. A 
service component as already defined is realized by one AE. 
An AE is constituted by several generic functionality 
components. Two important components are Judge and 
Strategist. The Judge and Strategist apply defined goals and 
policies. Goals express required performance and income 
measures. A policy is defined by conditions, constraints and 
actions, and defines accordingly actions to adapt the system 
in states with unwanted performance and income measures. 
The Judge gives rewards to actions based on the ability to 
move towards a state with goal performance and income 
measures. The Strategist selects actions based on the rewards 
given by the Judge.  
The reasons behind the Autonomic Element model and 
the AE functionality components’ specifications (see Section 
III) are service components based on the classical Extended 
Finite State Machine (EFSM) approach can provides the 
software update flexibility [4], and Reasoning Machine 
(RM) using the policies can add the ability to cope with 
various situations more flexible [5, 6]. 
This paper is organized as follows. Section II defines 
autonomic properties. Section III defines the main concepts 
of what is denoted as the Goal-based Policy Ontology. The 
details of the Autonomic Element Model are described in 
Section IV. Section V describes how AEs are used to realize 
service functionalities that are necessary for the service 
configuration. Section VI presents a case study, related 
works are presented in Section VII, and finally, summary 
and conclusions are presented in Section VIII. 
II. 
PROPERTIES OF AUTONOMIC ELEMENTS  
An autonomic system consists of a set of decentralized 
autonomic elements (AEs), as defined in Section I. AE 
functionality is realized by the combination of Extended 
Finite State Machines (EFSM), a Reasoning Machine (RM) 
and a Learning Machine (LM). An AE is a generic software 
116
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

component that can dynamically download and execute 
EFSM, RM and LM specifications. Properties can be 
classified as individual AE properties and shared AE 
properties, i.e., properties of the AEs constituted by the 
cooperation of AEs. AEs have the following individual 
properties: 
 
Automaticity: An AE can manage its EFSM states, 
variables, actions and policies. 
 
Awareness: An AE is able to monitor its own EFSM 
states and performances.  
 
Goal-driven: An AE operates and/or controls its 
functions towards goals.  
 
AEs have the following shared properties: 
 
Automaticity: AEs can manage capabilities and nodes, 
i.e., capabilities and nodes can be added and removed.  
 
Adaptability: The goals, policies and EFSM behavior of 
an AE can be changed. 
 
Awareness: An AE is able to monitor available nodes 
and capabilities. Information about EFSM states and 
performance measures can be made available to other 
AEs.   
 
Mobility: An AE can move to a new node and resume 
its operation. 
III. 
GOAL-BASED POLICY ONTOLOGY 
An ontology is a formal and explicit specification of a 
shared conceptualization [7] containing both objects and 
functions operating on instances of objects. We can define 
independent concepts and relational concepts defined by 
mathematical logics, e.g., if-then-else. In applications with 
reasoning capability, the logic concepts can be represented 
and processed flexibly as rules [1].  
Figure 1 presents a simplified diagram of the concepts in 
the Goal-based Policy Ontology. At the top level we have 
goal, policy and inherent state, which all are related to 
service and capability as defined in Section I. The 
instantiated AEs have inherent states that can comprise 
measures related to functionality and performance of 
services and capabilities as well as income. System 
performance is defined as the sum of capability performance 
and service performance.  
As a basis for the optimal adaptation, service level 
agreements (SLA) are needed between the service users and 
the service provider. An SLA class defines service 
functionalities, capabilities, QoS levels, prices and penalty. 
Service income includes the estimated income paid by the 
users for using services in normal QoS conditions and the 
penalty cost paid back to the users when the service qualities 
and functionalities are lower than defined by SLA. In 
general, goal, policy and inherent state concepts have the 
SLA class as a parameter. 
The goal is defined by a goal expression and a weight. 
The goal expression defines a required system performance 
or service income measure. A goal example is: “Service 
response time of premium service SLA class < 2 secs”. The 
goal weight identifies a goal's importance. A goal can be 
associated with a set of policies. 
A policy is defined by conditions, constraints and 
actions. The condition defines the activation of the policy 
execution. The constraint restricts the usage of the policy, 
and is described by an expression of required and inherent 
functionality and performance of services and capabilities, 
required and inherent service incomes, available nodes and 
their capabilities, as well as system time. An action has an 
estimated operation cost and accumulated reward. 
 
Figure 1.  Goal-based Policy Ontology. 
A policy example related to the goal example given 
above is: “If CPU utilization > 95% and the time is between 
18:00-24:00, ignore new service requests of users of 
ordinary SLA classes that request service time > 2 mins”. It 
is expressed with Conditions: CPU utilization > 95%, 
Constraints: system time between 18:00-24:00 and service 
time request > 2 mins, and Actions: ignore new service 
requests of users of ordinary SLA classes. 
Table I lists notations used for capability, service and 
income concepts. 
TABLE I.  THE  CAPABILITY, SERVICE AND INCOME CONCEPT NOTATION 
ĈR 
Required capability performance set 
ĈI 
Inherent capability performance set 
CR
¯ ¯  
Required capability functionality set 
CI
¯ ¯  
Inherent capability functionality set 
ĈA,n 
Set of available capabilities in node n; n=[1, N] 
ŜR 
Required service performance set 
ŜI 
Inherent service performance set 
SR
¯ ¯  
Required service functionality set 
SI
¯¯ 
Inherent service functionality set 
IR 
Required service income 
II 
Inherent service income 
 
IV. 
AUTONOMIC ELEMENT MODEL 
An AE is composed of four functional modules: i) Main 
Function, ii) Strategist, iii) Judge and iv) Communicator, as 
illustrated by Figure 2. The behaviors of the various modules 
are explained in the following subsections IV.A-IV.D. The 
life-cycle of an AE is described in Section IV.E. 
117
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

 
Figure 2.  Autonomic Element Model. 
A. Main Function 
Main Function coordinates the functionality of an AE. 
An AE has some general behavior which is common for all 
AEs, and some behavior depending on the specific role of 
the AE (see Section V). In general, an AE will have 
requirements with respect to capabilities and capability 
functionalities and performances. The specific need depends 
on the specific functionality of the AE. The Main Function 
behavior is based on an Extended Finite State Machine 
(EFSM) model E defined () as: 
 
E  { SM, SI, SS, V, M, O, Q, FS, FO, FV } 
(1) 
 
where SM is a set of all states, SI is an initial state and SS is a 
set of stable states. V is a set of variables including the 
inherent state variables. M is a set of input messages, O is a 
set of output messages and Q is a message input queue. FS 
is a state transition function (FS: S x M x V -> S), FO is an 
output function (FO: S x M x V -> O) and FV is a set of 
actions performed during a specific state transition.  
An AE can move to a new node. A stable state is a state 
of the Main Function where an AE’s functionality can move 
safely and be re-instantiated in a new node based on the 
restoration of EFSM state, variables, and queued messages. 
Strategist is used by the Main Function to select appropriate 
actions. The Main Function will regularly 
 
Compare the condition part of the policies with inherent 
state variables, and will 
 
Activate the Strategist if a condition is met, which 
returns an action to be used by the Main Function 
B. Strategist 
Strategist selects appropriate actions to be used by the 
Main Function. The Strategist behavior is based on a 
Reasoning Machine (RM) model, extended from [5, 6]. It can 
be triggered by one condition at a time. It will execute all 
policies related to a condition. The RM model R is defined 
as:    
R  { Q, F, P,  }  
 
 
(2) 
where Q is a set of query expressions containing variables, F 
is a generic reasoning procedure, P is a set of policies, and 
 is the strategist data including the inherent states from the 
Main Function and from other AEs, and available nodes and 
their capabilities. 
 
  (SI
¯¯, ŜI, CI
¯ ¯ , ĈI, II, ĈA,n; n=[1, N])  
(3) 
P  { pi }   
 
 
 
(4) 
pi  (Σi, Xi, Ai) 
 
 
 
(5) 
Σi  Expression(SI
¯¯, ŜI, CI
¯ ¯ , ĈI, II) 
 
(6) 
Xi  Expression(SR
¯ ¯ , ŜR, CR
¯ ¯ , ĈR, IR,  
SI
¯¯, ŜI, CI
¯ ¯ , ĈI, II, ĈA,n; n=[1, N], G) 
(7) 
 
A policy pi has conditions Σi, constraints Xi and actions 
Ai. The condition is an expression of the inherent states from 
the Main Function and from other AEs. The constraint is an 
expression of required functionality and performance of 
services and capabilities, required service incomes, the 
inherent states from the Main Function and from other AEs, 
available nodes and their capabilities, as well as system time 
(G). 
The reasoning procedure is applied to select appropriate 
actions with maximum accumulated rewards. It is based on 
Equivalent transformation (ET) [8], which solves a given 
problem by finding values for the variables of the queries. 
The conditions, constraints and actions can have variables. 
The result of the reasoning procedure can, in addition to 
actions, give instantiated variables. 
C. Judge 
Judge gives rewards to actions to be selected by the 
Strategist. The reward is a numeric value based on the ability 
to move towards a state with goal performance and income 
measures. The rewards will be accumulated over a period of 
time. The Judge behavior is based on a Learning Machine 
(LM) model L defined as: 
 
 L  { , , ,  } 
 
 
 
(8) 
 
where  is a set of goals,  is a generic rewarding 
procedure,  is a reward database storing the accumulated 
rewards of actions, and  is the judge data including the 
inherent states from the Main Function and from other AEs.  
We further have: 
 
  (SI
¯¯, ŜI, CI
¯ ¯ , ĈI, II) 
 
 
(9) 
  { gk }   
 
 
 
(10) 
gk  (dk, wk)  
 
 
 
(11) 
 
A goal gk has goal expression dk and weight wk. The sum 
of the goal weights is equal to 1. At time t, the rewarding 
procedure will calculate the reward of an action ai, which 
was applied at time t-1 as: 
 
reward(ai,ik,t-1,dk) =  
((ik,t,ik,t-1)/(dk,ik,t-1)) * wk - cost(ai)  
(12) 
118
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

where ik,t-1 and ik,t are an inherent state measure before and 
after applying the action for an monitoring interval [t-1, t], 
ik   and dk is an associated goal required measures. 
(ik,t,ik,t-1) is the difference between ik,t and ik,t-1. (dk,ik,t-1) is 
the difference between dk and ik,t-1. wk is the goal weight and 
cost(ai) is the operation cost of ai. 
The accumulated reward of an action ai, accumulated- 
_reward(ai,ik,t-1,dk), is then the sum of the rewards of ai, for 
an inherent state measure ik,t-1 and a goal required measure 
dk. 
D. Communicator 
Communicator handles message sending and receiving 
on behalf of the Main Function. The Communicator behavior 
is based on the EFSM model in (1). Other AEs can subscribe 
to the inherent state variables of an AE. The Communicator 
will manage subscription messages and will send inherent 
state variables to other AEs on behalf of the Main Function.  
The Communicator also handles the registration function 
on behalf of the Main Function. Registration message is sent 
to Registry (REG) (see Section V) that is an important AE 
that records the life-cycle state of AEs. The registration 
message contains IP address of the AE.  
The Communicator will regularly broadcast heartbeat 
message, which is used to indicate that an AE is alive. The 
heartbeat messages are monitored by Life Monitor AE 
(LMO) (see Section V). In addition, the Communicator will 
inform REG about changes in the life-cycle state of the AE 
(see Section IV.E). REG will broadcast the changes to other 
AEs that subscribe to such updates. 
E. Autonomic Element Life Cycle 
The combined states of an AE during its life-cycle are 
defined follows:  
 
Initial state: An AE is instantiated in a node where 
there are capabilities and capability functionalities and 
performances as required.  
 
Registering state: An AE registers to REG. 
 
Normal-Active state: An AE provides services with 
normal functionality and QoS level.  
 
Degraded-Active state: If in the Normal-Active-State 
the capabilities are less than required and results in 
degraded functionality and QoS, the life-cycle state will 
change to Degraded-Active state. In this state, some 
actions selected by the Strategist can be taken to 
upgrade the capabilities and performances. From both 
the Normal-Active state and the Degraded-Active state, 
the life-cycle state can change to Moving, Suspended or 
Terminated.  
 
Moving state: An AE’s functionality is being moved 
and re-instantiated in a new node. A move can only 
take place if the EFSM states are stable (see Section 
IV.A). 
 
Suspended state: An AE is suspended, i.e., by an action 
selected by the Strategist, which means that it stops 
executing current behavior specifications. An AE will 
release its allocated capabilities. At this state, an AE 
can start executing new behavior specifications. This 
makes an AE goes back to the Normal-Active state. 
 
Terminated state: Other AEs detect that an AE’s 
heartbeat message is lost or an AE could not be reached 
because of some unintentional reasons, e.g., the 
hardware failure. REG is informed about this by LMO 
or the other AEs, then REG records that an AE is 
terminated. 
V. 
AUTONOMIC ELEMENT-BASED SERVICE 
FUNCTIONALITY ARCHITECTURE 
The 
service 
functionalities 
required 
for 
service 
configuration are constituted by AEs and repositories, as 
illustrated in Figure 3. The AE responsibilities and the 
repositories are described below. 
 
 
Figure 3.  Autonomic Element-Based Service Functionality Architecture. 
Solid arrows indicate the physical connections of AEs and dashed arrows 
represent the message flows between AEs. 
 
Primary Service (PRS) provides ordinary user services. 
 
Registry (REG), as already mentioned in Section IV.D, 
is responsible for AE registration.  
 
Goal and Policy Distribution Manager (GPM) 
distributes goals and policies to corresponding AEs. 
 
Life Monitor (LMO) observes the liveness of AEs by 
listening to heartbeat messages from AEs. LMO 
regularly updates the liveness of AEs to REG. 
 
Capability Administrator (CPA) maintains and provides 
data about capabilities and their functionalities and 
performances in available nodes.  
 
Capability Monitor (CPM) monitors capabilities and 
sends updates to CPA.  
 
Capability Allocation Manager (CAM) generates (re-) 
configuration plans for AEs to be instantiated in nodes. 
CAM fetches the capability requirements and retrieves 
the capabilities from CPA. A configuration plan defines 
in which node an AE should execute. Configuration 
plans are generated based on capability requirements 
and policies. In addition, CAM allocates capabilities to 
AEs. The allocation depends on the capability structure 
119
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

and optimization criteria which can be specified in the 
policies. 
 
Deployment and Instantiation Manager (DIM) executes 
the configuration plan. It creates AEs in the defined 
nodes and assigns the behavior specifications.  
 
Mobility Manager (MOM) supports an AE when it is 
moved and re-instantiated in a new node. The move can 
be related to failures or insufficient capability 
performances. MOM broadcasts messages to inform 
other AEs when an AE’s functionality is suspended or is 
resumed. MOM also handles an AE’s connections by 
getting input messages on behalf of an AE and 
forwarding them to such AE when it is already re-
instantiated.  
 
Ontology Repository (OntRep) stores the goal and 
policy concepts as well as the related capability and 
service concepts.  
 
Service Specification Repository (SpcRep) stores the 
AE 
behavior 
specifications 
and 
the 
capability 
requirements.  
 
Capability Repository (CapRep) stores data about 
available nodes and their capabilities. 
VI. 
CASE STUDY 
A music video streaming system is presented with the 
intention to demonstrate the Strategist and Judge solution in 
the proposed autonomic framework. The system is 
constituted by the AEs as defined in Section V. The Primary 
Service AEs are Streaming Manager (STM) and Streaming 
Client (STC). An STM, executing on a media streaming 
server (MS), streams the music video files to STCs. An STC 
is associated with an SLA class, which defines required 
streaming throughput, price for the service and service 
provider penalties if the agreed QoS cannot be met. Two 
SLA classes are applied: premium (P) and ordinary (O). An 
STC is denoted by its SLA class as STCP or STCO. Each 
SLA class has different required throughput (X); the STCP 
required throughput (XP) can be 1Mbps or 600Kbps for high-
resolution and degraded fair-resolution videos, while the 
STCO required throughput (XO) is 500Kbps for low-
resolution videos. Prices and penalties will be defined later. 
 
 
Figure 4.  Streaming system example. 
Figure 4 illustrates the streaming system. In this case 
study, CAM will accept the streaming requests on behalf of 
STMs. CAM will decide which an STM can serve the 
requests, or CAM may put them in waiting queues. CAM 
can also instantiate a new STM in an available MS that 
there is no executing STM.  
The MS’s required access link capacity (CR,AL) is set to 
100 Mbps. The number of STCs that can use the service at a 
time is limited by the MS access link capacity. When the 
required streaming throughput cannot be provided, a STC 
needs to wait until some connected requests have finished 
using the service. An STCO can be disconnected, while an 
STCP may have to degrade the video resolution. The service 
provider will pay penalties in case of waiting and 
disconnection of the STC. These penalty and price functions 
are given in Table II. A cost unit is the price paid by an 
ordinary client for one second streaming of the rate 500Kpbs. 
The price function for using the service is M(SLA_Class,X) 
(cost units/second). The penalty function for waiting is 
PWAIT(SLA_Class) (cost units/second), and the penalty 
function for disconnection is PDISC(SLA_Class) (cost 
units/connection).  
Note that, the case study and all values, set in Table II, 
are same as our previous work [5, 6] in order to compare 
between the proposed and the previous model. The 
comparison results are in subsection VI.B.1. 
TABLE II.  
THE PRICE AND PENALTY FUNCTIONS 
 
 STCO 
(XO=500Kbps) 
STCP 
 (XP=600Kbps) 
STCP 
  (XP=1Mbps) 
  M(SLA_Class,X)/s 
1 
1.875 
2 
  PWAIT(SLA_Class)/s 
5 
10 
10 
PDISC(SLA_Class)/ 
Connection 
10 
- 
- 
 
The complete set of actions A in this case study is:  
 
A = {aD, aB, aN, aI, aR, aT, aM} 
 
(13)  
 
A subset of A, Á, is defined as: Á = A – {aM}. aD is to 
disconnect the ordinary clients, aB is to decrease the 
throughput of the premium clients, aN is to instantiate a MS, 
aI is to instantiate a new STM, aR is to disconnect a MS, aT 
is to terminate an STM and aM is to move connected client 
sessions from an STM to another STM. These actions are 
selected by the Strategist of CAM. CAM executes aN, aI, 
aR and aT, while CAM suggests aD, aB and aM to STMs.  
In this case study, the considered capability is the MS 
access 
link. 
The 
required 
and 
inherent 
capability 
performance sets are denoted as ĈR  {CR,AL} and ĈI  
{CI,AL}, where CR,AL is the required access link capacity, and 
120
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

CI,AL is the available access link capacity. The inherent 
service performance set ŜI consists of the number of 
connected and waiting premium and ordinary clients (NCon,P, 
NCon,O, NWait,P, NWait,O), the number of disconnected ordinary 
clients (NDisc,O), the number of MS (NNode), the service time 
and waiting time of premium and ordinary clients (TServ,P, 
TServ,O, TWait,P, TWait,O). These values as well as the inherent 
service income (II) are observed per a monitoring interval ∆. 
The service income is defined as: 
 
II = M(STCO,XO)*TServ,O + M(STCP,XP)*TServ,P – 
PWAIT(STCO)*TWait,O – PWAIT(STCP)*TWait,P – 
PDISC(STCO)*NDisc,O – PSer*NNode*∆  
(14) 
 
where PSer is the cost function for adding a new MS which is 
150 units/second per node, while M(SLA_Class,X), 
PWAIT(SLA_Class) and PDISC(SLA_Class) are as already 
defined in Table II. 
A. RM and LM Specification 
In this case study, CAM plays an important role. Its RM 
specification is defined as follows: 
RCAM  { QCAM, F, PCAM, CAM } 
 
(15) 
 
PCAM consists of five policies (p1-p5) as presented in 
Appendix. A policy defines some actions in the set A in 
(13). 
The LM specification of CAM is defined as follows: 
LCAM  { CAM, , CAM, CAM } 
 
(16) 
CAM  { g1, g2}  
 
 
 
(17) 
g1  (d1: IR > 0, w1: 0.8) 
 
 
(18) 
g2  (d2: TWait < ∆, w2: 0.2) 
 
 
(19) 
 
where IR is the required service income, and TWait is the sum 
of the waiting time of premium and ordinary clients. These 
goals are set in order to gain high income and to avoid high 
waiting time. The policy p1-p5 can be used when the 
required service income is not met, while the policy p1-p3 are 
used when the waiting time is higher than expected.  
B. Experiments and Results 
Two set of experiments are presented. In B.1) Á is used 
for the comparison between the proposed and a previous 
model. In B.2) different action sets A and Á are used to 
study the proposed model. The accumulated service income 
and the accumulated waiting time results are illustrated in 
both experiment sets. 
The request arrivals are modeled as a Poisson process 
with an arrival intensity parameter λSLA_Class. The duration of 
streaming connections dSLA_Class is constant and is set to 10 
minutes. The traffic per MS access link ρ is defined as: 
 
ρ = ((λP*dP*XP) + (λO*dO*XO))/ (NNode*CI,AL)  
(20) 
 
The monitoring interval ∆ is 1 minute. The STCs will stop 
waiting and there is no penalty for waiting after 10 minutes. 
The number of available MS = 3. Initially, only one STM is 
instantiated. 
1) Comparison between the proposed and a previous 
model 
Our previous work [5, 6] presented an adaptation 
mechanism executed by a Reasoning Machine, which uses 
policies and goal to manage the adaptable systems. In the 
previous model, a policy consists of constraints and actions, 
and it is not associated with any specific conditions. So all 
defined policies will be executed when the systems are 
entering a reasoning condition. There is only one reasoning 
condition defined, i.e., the number of waiting clients > 0. In 
addition, only one goal based on the service income is used. 
The action is then rewarded by the goodness score (QoX
i) 
that is calculated by the percentage of the increased or 
decreased service income.  
In this section, three different cases of ρ are illustrated:  
a) ρ<1, b) ρ=1 and c) ρ=1.15 (ρ>1). The STCP request 
arrivals intensity (λP) is set to 25%, 50% and 80% of the total 
arrival intensity. 
For case a) ρ<1, both models have the same behaviors. If 
ρ>0.5, they used {aN, aI} to instantiate a MS and to 
instantiate a new STM, otherwise they just disconnected the 
ordinary clients or decreased the throughput of the premium 
clients. The accumulated service income and waiting time of 
both models are almost the same. 
 
 
Figure 5.  The accumulated service income when ρ = 1. 
 
Figure 6.  The accumulated waiting time when ρ = 1. 
121
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

For case b) ρ=1, the proposed model produced higher 
accumulated service income and lower accumulated waiting 
time independent of λP, as depicted in Figure 5 and 6. This is 
because in the previous model {aT, aR}, which terminate an 
STM and disconnect a MS consecutively, was used when 
the number of waiting clients was little more than zero. So 
that, the number of MS was lower than proper required 
amount. It results in decreasing service income and 
increasing waiting time. In the proposed model, {aT, aR} 
might be used only if the inherent service income <= 0; 
however, it does not happen when ρ = 1. 
For case c) ρ=1.15 (ρ>1), the proposed model also 
produced higher accumulated service income and lower 
accumulated waiting time. Figure 7 and 8 illustrates the 
accumulated service income and the accumulated waiting 
time for this case. The proposed model produced better 
results, because it took the actions to adapt the system more 
often than the previous model. When ρ>1, the service 
income could be less than 0 because of the waiting penalty. 
So that, in the proposed model the actions were applied both 
when the service income < 0 and when the waiting time > ∆, 
while the previous model the actions were applied only when 
the number of waiting clients > 0. However, when λP = 80% 
the traffic was too overloaded, and the accumulated service 
income was less than zero in both models. 
 
 
Figure 7.  The accumulated service income when ρ = 1.15. 
 
Figure 8.  The accumulated waiting time when ρ = 1.15. 
 
2) Comparison between different action sets  
In this section, we compare three cases (I-III) of the new 
proposed model. In Case I the complete set of actions A is 
used, while in Case II the subset Á is used. For the last case, 
the complete set of actions A is also used, but there is no 
Judge component in the AEs so the actions are not rewarded. 
The traffics that were simulated for this scenario are relative 
to a function of time. The time with ρ at a fixed level, 
denoted as the ρ period, is set to 30 minutes. ρ varies from 
0.2 to 1.2. λP is set to 50% of the total arrival intensity. 
Figure 9 and 10 shows the accumulated service income 
and the accumulated waiting time of three cases. The brown 
line in these figures shows the variation of ρ. In Case I, the 
system learned that {aM, aT and aR}, which move connected 
STC sessions, terminate an STM and disconnect a MS 
consecutively, is efficient to adapt the system when ρ drops 
and then the required service income is not met. As a result, 
Case I could produce the highest accumulated service 
income and the lowest accumulated waiting time. For the last 
case, the actions were selected randomly and they were not 
appropriate to the states of unwanted service income and the 
waiting time. So, the accumulated service income of Case III 
was the lowest, while the accumulated waiting time was the 
highest. 
 
 
Figure 9.  The accumulated service income for various ρ. 
 
Figure 10.  The accumulated waiting time for various ρ. 
122
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

VII. RELATED WORK 
Existing service system frameworks that support run-
time self-management and adaptation can be classified based 
on the way in which the management and adaptation 
functionalities are specified. The functionalities can be 
statically or dynamically specified. Some works propose to 
use templates [9] or adaptation classes [10] to statically 
specify these functionalities. However, the static approach 
lacks flexibility. All the possible adaptation must be known a 
beginning, and if new adaptations are required, the systems 
must be re-complied. Our work expresses the service 
management functionality for the adaptable service systems 
in the form of the EFSM, RM and LM specification, to be 
dynamically modified, added and removed at run-time. 
When using the EFSM specification, an update of changes is 
done by deployment of the whole specification. When using 
the RM and LM specification, only incremental changes of 
the policies and goals are deployed. However, the complete 
policy and goal based functionality need to be validated off-
line before the deployment of the incremental changes.  
There are several works that use the policies to specify 
the adaptation, such as [11], [5, 6], [12-15]. Accord [11] is a 
framework that can formulate autonomic applications as 
dynamic composition of AEs, with the use of policies to 
describe the adaptation of functional behaviors of AEs and 
interactions between them. However, our approach and the 
rest go beyond the use of policy for the specification by 
adding mechanisms to adapt policies or the way of using 
policies. Such policy adaptation can be grouped into three 
categories: 1) changing the policy parameters, considered in 
[5, 6, 12, 13]; 2) enabling/disabling a policy, found in [5, 6, 
12]; 3) using techniques to select the most suitable policy 
and action; for instance, rewarding policies and their actions, 
presented in [14, 15].  
Our approach is an instance of the first as well as the 
third category as [14, 15]. Tesauro et al. [14] presented a 
hybrid reinforcement technique used for resource allocation 
in multi-application data centers. This technique is to select 
optimal policies that can maximize rewards. Mesnier et al. 
[15] used decision trees to select accurate policies in storage 
systems. These policy adaptation techniques have only been 
applied to a single element, while our approach is potentially 
used in multi-autonomic elements. 
VIII. CONCLUSIONS 
This paper proposed an autonomic framework for 
adaptable service systems. The framework solution consists 
of Goal-based Policy Ontology and Autonomic Element (AE) 
Model. The Ontology defines common concepts of goal, 
policy and inherent state. AEs are generic component that 
can be used to realize any functionality. An AE is constituted 
by Main Function, Strategist, Judge and Communicator 
modules. The functionality of an AE is realized by two 
Extended Finite State Machines (EFSM), one Reasoning 
Machine (RM) and one Learning Machine (LM). EFSM 
behavior, as well as goals and policies can be modified 
flexibly 
during 
run-time. 
For 
attaining 
a 
specific 
functionality, specific EFSM, RM and LM functionality 
must be defined. In this paper, specific AEs handling service 
management functionality is proposed. 
A case study is presented with focus on the Capability 
Allocation Manager (CAM). The experimental results show 
that the proposed model can produce higher service income 
and less waiting time than a previous model. In the proposed 
model, the actions are used appropriately under the 
associated goals and required goal measures. Moreover, it is 
possible to apply several goals, which each are weighed 
differently, depending on its importance. New actions can be 
added, and when there are more actions the system may 
reach the goals quicker. 
REFERENCES 
[1] 
P. Thongtra and F. A. Aagesen. Capability Ontology in Adaptable 
Service System Framework. In Proc. of 5th Int. Multi-Conference on 
Computing in the Global Information Technology, Spain, Sep 2010. 
[2] 
J. O. Kephart and D. M. Chess. The Vision of Autonomic Computing. 
IEEE Computer Society, January 2003, pp. 41-47. 
[3] 
S. White, J. Hanson, I. Whalley, D. Chess, and J. Kephart. An 
architectural approach to autonomic computing. In Proc. of 1st IEEE 
Int. Conf. on autonomic computing, New York, May 2004, pp. 2–9. 
[4] 
P. Thongtra and F. A. Aagesen. An Adaptable Capability Monitoring 
System. In Proc. of 6th Int. Conference on Networking and Services 
(ICNS 2010), Mexico, March, 2010. 
[5] 
P. Supadulchai and F. A. Aagesen. Policy-based Adaptable Service 
Systems Architecture. In Proc. of 21st IEEE Int. Conf. on Advanced 
Information Networking and Applications (AINA’07), Canada, 2007. 
[6] 
P. Supadulchai, F. A. Aagesen and P. Thongtra. Towards Policy-
Supported Adaptable Service Systems. EUNICE 13th EUNICE Open 
European Summer School and IFIP TC6.6 Workshop on Dependable 
and Adaptable Networks and Services. Lecture Notes in Computer 
Science (LCNS) 4606, pp 128-140. 
[7] 
R. Studer, V. R. Benjamins, and D. Fensel. Knowledge Engineering: 
princicples and methods. Data & Knowledge Engineering, vol. 25, 
pp. 161-197, 1998. 
[8] 
K. Akama, T. Shimitsu, and E. Miyamoto. Solving Problems by 
Equivalent Transformation of Declarative Programs. In Journal of the 
Japanese Society of Artificial Intelligence, vol. 13, pp. 944-952, 
1998. 
[9] 
F. Berman, R. Wolski, H. Casanova, et al. Adaptive computing on the 
grid using AppLeS. In IEEE Trans. Parallel Distrib. Syst., vol. 14, no. 
4, pp. 369–382, Apr. 2003. 
[10] P. Boinot, R. Marlet, J. Noy´e, G. Muller, and C. Cosell. A 
declarative approach for designing and developing adaptive 
components. In Proc. of the 15th IEEE Int. Conf. on Automated 
Software Engineering, 2000. 
[11] H. Liu and M. Parashar. Accord: a programming framework for 
autonomic applications. In IEEE Trans. on System, Man, and 
Cybernetics, vol. 36, pp. 341–352, 2006. 
[12] L. Lymberopoulos, E.C. Lupu and M.S. Sloman. An Adaptive Policy-
Based Framework for Network Services Management. In Journal of 
Networks and Systems Management, vol. 11, pp. 277–303, 2003. 
[13] K. Yoshihara, M. Isomura, and H. Horiuchi. Distributed Policy-based 
Management Enabling Policy Adaptation on Monitoring using Active 
Network Technology. In Proc. of 12th IFIP/IEEE Int. Workshop on 
Distributed Systems: Operations and Management, France, Oct 2001. 
123
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

[14] G. Tesauro, R. Das, N.K. Jong, and M.N. Bennani. A Hybrid 
Reinforcement 
Learning 
Approach 
to 
Autonomic 
Resource 
Allocation. In Proc. of 3rd IEEE Int. Conf. on Autonomic Computing 
(ICAC’06), Ireland, Jun 2006, pp. 65–73. 
[15] M. Mesnier, E. Thereska, D. Ellard, G.R. Ganger, G.R., and M. 
Seltzer. File classification in self-* storage systems. In Proc. of Int. 
Conf. on Autonomic Computing (ICAC-04), pp. 44–51. 
[16] W3C, “OWL Web Ontology Language Overview,” 2004 Available 
at: http://www.w3.org/TR/owl-features/ 
[17] V. Wuwonse and M. Yoshikawa. Towards a language for metadata 
schemas for interoperability. In Proc. of 4th Int. Conf. on Dublin Core 
and Metadata Applications, China, 2004. 
APPENDIX 
The appendix includes the policy specifications and a list 
of mathematical expressions found in this paper. 
A: POLICY SPECIFICATIONS 
The policies as well as goals are expressed in OWL (Web 
Ontology Language) [16] and OWL/XDD (XML Declarative 
Description) [17], where the variables can be integrated with 
ordinary OWL elements. The variables are prefixed with the 
$ sign. In this paper, the policy is written in the form: 
     Conditions: Expressions_for_conditions, 
     Constraints: Expression_for_constraints, 
     Actions: {Action_ID},  
     Operation cost: Expression_for_operation_cost 
 
Five policies (p1-p5) used in the case study are listed in Table 
III. The conditions can be the inherent service income $II <= 
0 and the waiting time $TWait >= ∆, where $TWait = $TWait,P + 
$TWait,O. 
TABLE III.  
THE POLICY SET 
 
p1 
Conditions: $II <= 0 or $TWait >= ∆,  
Constraints: PWAIT(STCO) < PWAIT(STCP), 
Actions: {aD},  
Operation Cost: PDISC(STCO) 
This policy can be read as:  aD should be used to disconnect a list of 
STCO when PWAIT(STCO) < PWAIT(STCP), and the number of STCO 
being disconnected is calculated from XP,1Mbps * $NWait,P / XO. aD 
costs PDISC(STCO) units. 
 
p2 
Conditions: $II <= 0 or $TWait >= ∆,  
Constraints: PWAIT(STCO) > M(STCP,XP,1Mbps)-M(STCP,XP,600Kbps), 
Actions: {aB},  
Operation Cost: M(STCP,XP,1Mbps) - M(STCP,XP,600Kbps) 
This policy can be read as: aB should be used to decrease the 
throughput of a list of STCP when PWAIT(STCO) > 
M(STCP,XP,1Mbps) - M(STCP,XP,600Kbps), and the number of STCP to 
decrease the throughput is calculated from XO * $NWait,O  / (XP,1Mbps - 
XP,600Kbps). aB costs M(STCP,XP,1Mbps) - M(STCP,XP,600Kbps). 
 
p3 
Conditions: $II <= 0 or $TWait >= ∆,  
Constraints: (XP, 1Mbps * $NWait,P  + XO * $NWait,O) / CR,AL > 0.1, 
Actions: {aN, aI},   
Operation Cost: PSer * ∆ 
This policy can be read as: aN and aI should be used to instantiate a 
MS and to instantiate a new STM consecutively, when (XP, 1Mbps * 
$NWait,P  + XO * $NWait,O) / CR,AL > 0.1. These actions {aN, aI} cost 
PSer * ∆.  
 
p4
Conditions: $II <= 0,  
Constraints: (XP, 1Mbps * $NWait,P  + XO * $NWait,O) / CR,AL < 0.1, 
Actions: {aT, aR},   
Operation Cost: PDISC(STCO) + PWAIT(STCP) – PSer * ∆   
This policy can be read as: aT and aR should be used to terminate an 
STM and to disconnect a MS consecutively, when (XP, 1Mbps * 
$NWait,P  + XO * $NWait,O) / CR,AL < 0.1. These actions {aT, aR} cost 
PDISC(STCO) + PWAIT(STCP) – PSer * ∆. 
 
p5
Conditions: $II <= 0,  
Constraints: (XP, 1Mbps * $NWait,P  + XO * $NWait,O) / CR,AL < 0.1, 
Actions: {aM, aT, aR},  
Operation Cost: - PSer * ∆ 
This policy can be read as: aM, aT and aR should be used to move 
connected STC sessions, to terminate an STM and to disconnect a 
MS consecutively, when (XP, 1Mbps * $NWait,P  + XO * $NWait,O) / CR,AL 
< 0.1. These actions {aM, aT, aR} make profit = PSer * ∆. 
 
B: MATHEMATICAL EXPRESSIONS 
Table IV lists all mathematical expressions. This table 
also expresses the relations to others expressions (Rel. to 
exp.) as well as the references to table (Ref. to tab.), where 
the notification used in the expression are defined.  
TABLE IV.  
MATHMATICAL EXPRESSIONS. 
No. 
Mathematical expressions 
Rel. to exp. Ref. to tab.
1 
E{ SM, SI, SS, V, M, O, Q, FS, FO, FV } 
- 
- 
2 
R{ Q, F, P,  } 
- 
- 
3 
(SI
¯¯, ŜI, CI
¯ ¯ , ĈI, II, ĈA,n; n=[1, N]) 
2 
I 
4 
P{ pi } 
2 
- 
5 
pi(Σi, Xi, Ai) 
4 
- 
6 
ΣiExpression(SI
¯¯, ŜI, CI
¯ ¯ , ĈI, II) 
5 
I 
7 
XiExpression(SR
¯ ¯ , ŜR, CR
¯ ¯ , ĈR, IR, SI
¯¯, ŜI, 
CI
¯ ¯ , ĈI, II, ĈA,n; n=[1, N], G) 
5 
I 
8 
L  { , , ,  } 
- 
- 
9 
  (SI
¯¯, ŜI, CI
¯ ¯ , ĈI, II) 
8 
I 
10 
  { gk } 
8 
- 
11 
gk  (dk, wk) 
10 
- 
12 
reward(ai,ik,t-1,dk) =  
((ik,t,ik,t-1)/(dk,ik,t-1))*wk -cost(ai) 
8 
 
13 
A = {aD, aB, aN, aI, aR, aT, aM} 
5 
- 
14 
II = M(STCO,XO)*TServ,O + 
M(STCP,XP)*TServ,P – 
PWAIT(STCO)*TWait,O – PWAIT(STCP)*TWait,P 
– PDISC(STCO)*NDisc,O – PSer*NNode*∆ 
3, 6, 7, 
9 
II 
15 
RCAM  { QCAM, F, PCAM, CAM } 
2 
- 
16 
LCAM  { CAM, , CAM, CAM } 
8 
- 
17 
CAM  { g1, g2} 
10, 16 
- 
18 
g1  (d1: IR > 0, w1: 0.8) 
11, 17 
- 
19 
g2  (d2: TWait < ∆, w2: 0.2) 
11, 17 
- 
20 
ρ = ((λP*dP*XP) + (λO*dO*XO))/ (NNode*CI,AL) 
- 
- 
 
 
124
ICCGI 2011 : The Sixth International Multi-Conference on Computing in the Global Information Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-139-7

