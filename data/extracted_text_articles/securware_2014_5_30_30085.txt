Performance Impacts in Database Privacy-Preserving Biometric Authentication
Jana Dittmann, Veit K¨oppen
Christian Kr¨atzer, Martin Leuckert, Gunter Saake
Faculty of Computer Science
Otto-von-Guericke University
Email: [jana.dittmann|vkoeppen|
kraetzer|gunter.saake]@ovgu.de
Claus Vielhauer
Department of Informatics and Media
Brandenburg University of Applied Sciences
Email: vielhauer@fh-brandenburg.de
Abstract—Nowadays, biometric data are more and more used
within authentication processes. These data are often stored
in databases. However, these data underlie inherent privacy
concerns. Therefore, special attention should be paid for handling
of these data. We propose an extension of a similarity veriﬁcation
system with the help of the Paillier cryptosystem. In this paper,
we use this system for signal processing in the encrypted domain
for privacy-preserving biometric authentication. We adapt a
biometric authentication system for enhancing privacy. We focus
on performance issues with respect to database response time
for our authentication process. Although encryption implicates
computational effort, we show that only small computational
overhead is required. Furthermore, we evaluate our implemen-
tation with respect to performance. However, the concept of
veriﬁcation of encrypted biometric data comes at the cost of
increased computational effort in contrast to already available
biometric systems. Nevertheless, currently available systems lack
privacy enhancing technologies. Our ﬁndings emphasize that a
focus on privacy in the context of user authentication is available.
This solution leads to user-centric applications regarding authen-
tication. As an additional beneﬁt, results using data mining are
more difﬁcult to be obtained in the domain of user tracking.
Index Terms—Database Security, Homomorphic Encryption,
Privacy, Multi-Computer Scenarios, Database Performance
I. MOTIVATION
Biometric data are more and more used in daily life. How-
ever, these data underlie privacy concerns by design, because
these data are directly related to individuals. As a result, this
may potentially be misused, e.g., by means of replay attacks,
once accessible by malicious parties. Therefore, biometric data
require protection mechanisms to take advantage of positive
aspects of an authentication scheme. So, privacy-preserving
biometric authentication is a requirement that comes into focus
of databases, which form the core of any biometric system. In
this paper, we present a new approach for user authentication
based on the assumption that encrypted data have to be stored
and at the same time there is no logging information available.
Although data might be deleted from a database, it can be
possible to restore the information partly or even complete.
Grebhahn at al. [1] present an approach for deleting data
in a database whereas at the same time information could
be completely recovered. Although new approaches exist to
cover this information or even to improve the system for
Behavioral or 
Physiological Trait
Raw Data
Raw Feature Data
Discrete Feature 
Vector
Reference 
Storage
Behavioral or 
Physiological Trait
Raw Data
Raw Feature Data
Discrete Feature 
Vector
Data Acquisition
Preprocessing
Feature Extraction
Store Feature Vector
Authentication 
Result
Comparison & 
Classiﬁcation
Enrollment
Authentication
Figure 1. Enrollment and Authentication Pipeline
secure deletion [2], an overall security of traditional database
management systems with respect to such information leakage
cannot be guaranteed.
In a biometric authentication system, two phases are differ-
entiated [3]. Firstly, a user has to create a speciﬁc biometric
template. In practice, these templates are typically stored in a
database. For achieving to store only required information, the
data acquisition (e.g., by using sensors) is followed by a data
preprocessing to ﬁlter out noise and non-related information of
the raw data. Note that required information is often depicted
in a feature space. Secondly, a feature extraction is applied
which is followed by a discretion of the feature values. Finally,
the feature vector is stored. This phase is called enrollment.
We show the basic steps in Figure 1 on the left side.
The second phase is called authentication, where a clas-
111
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-376-6
SECURWARE 2014 : The Eighth International Conference on Emerging Security Information, Systems and Technologies

siﬁcation is required to declare an identity of the biometric
features. We depict this pipeline on the right side of Figure 1.
The ﬁrst steps from data acquisition to the discrete feature
vector should be applied in the same manners as in the
enrollment phase. Otherwise, it cannot be guaranteed that
the same properties are compared. However, the data for
authentication are not stored. In the comparison step, if a one-
to-one matching is performed, we call the authentication ver-
iﬁcation [3]. Another classiﬁcation schema is identiﬁcation,
where a biometric discrete feature vector is compared to a
set of templates from the database. In both schemes, usually a
threshold is used to decide on the success of the authentication.
In case the threshold does not inﬂuence the comparison of
templates, the result set of an identiﬁcation can be the clos-
est match, all, k-nearest, or ϵ-distance-neighbors. With these
result-sets, further analyzes are possible, e.g., data mining or
forensic investigations. Due to complexity, there are several
optimization approaches possible. For instance, it is possible
to use index structures within the database system for an
enhanced data access. However, such index structures need to
be carefully optimized for a multi-dimensional feature space,
see for further details [4]. Another approach is to preserve
privacy in the context of deletion in database index structures
as described in [2].
Data mining enables users to detect patterns that are hidden
in complex data. With the use of computational techniques, it
is also possible to observe and identify relations in the context
of privacy preserving scenarios, see for instance [5], [6], or [7].
The work presented in this paper is based on a master
thesis [8] and summarizes the main results. We present a
methodology based on the Paillier cryptosystem [9] to improve
user preferences with respect to authentication systems. We
present a cross-evaluation of the impact of homomorphic
encryption for biometric authentication using a database within
our evaluation section. The Paillier system is an asymmetric
cryptographic scheme with additive homomorphic properties.
With our new approach, both unique identiﬁers need to be
decrypted for every message. A disclosure of either the key
is more unlikely, user-tracing becomes less likely, and the pad
do not immediately reveal user content data.
The remainder of this paper is structured as follows: In
Section II, we brieﬂy describe the current state of the art
regarding our new approach. In Section III, we present the
architectural requirements. Our extension of the secure sim-
ilarity veriﬁcation is given in Section IV. The evaluation of
our approach regarding performance is part in Section V,
where we show that response times are accompanied with
a small computational effort for privacy preserving aspects.
These ﬁndings are in line with theoretical considerations and
assumptions. Finally, we conclude our results and give a short
outlook in Section VI.
II. BACKGROUND AND RELATED WORK
In this section, we present related work for preserving
privacy in a biometric authentication context. As important
factors, we concentrate on homomorphic encryption as well
as deletion in database systems.
The general security requirements for a biometric authenti-
cation system are summarized in [10]. Here, it is shown that
all security aspects [11] become relevant for all enrollment
and veriﬁcation/identiﬁcation related components as well as
all data transitions between these. Privacy issues are mainly
related to conﬁdentiality, but require integrity, authenticity,
availability, and non-repudiation of privacy related data. For
each security aspect, a security level can also be introduced,
e.g., ranging from non, low, up to high.
Security plays a vital role due to different scenarios, in
which an attack of personal data is imaginable. A differentia-
tion of attacks can be made on a ﬁrst level regarding passive or
active attacks. The data stream between sender and recipient is
not inﬂuenced in passive attacks. Therefore, only the reading
of data is target for such attacks. Besides just reading data, a
specialization is frequency analysis, where for instance for a
substitution cipher an analysis of letter frequency is used to
identify a mapping. Different extensions are applicable, e.g.,
frequency attacks or domain attacks [12].
Protection mechanisms for such Biometric reference sys-
tems exist since more than a decade; prominent examples
are BioHashes [3], Fuzzy Commitment Scheme [13], and
Fuzzy Vault [14]. For an overview on challenges for biometric
template protection and further current protection schemes
see [15]. All these established protection schemes require
data to be compared in an unencrypted form, which leads to
the threat of information leakage as discussed in Section I.
Therefore, these mechanisms are not relevant for the work
presented in this paper.
A. Homomorphic Encryption
Homomorphic encryption is used to perform data operations
on the cipher text which have a corresponding operation on
plain text data. In homomorphic encryption, operations op∗
can be performed on encrypted data that are adequate to
operations op on the plain text. This means that the following
formula holds:
op(x) = decryption (op∗(encryption (x)) .
(1)
In such a case, the mapping is structure preserving. The
operations op and op∗ depend on the cryptosystem. There
exist additive and multiplicative homomorphic cryptosystems.
Gentry [16] proves the existence of a fully homomorphic
encryption scheme. So, it is possible to perform operations
on data without possessing a decryption key. However, such
systems require high computational effort. In this paper, we
make use of homomorphic encryption to perform operations
for authentication in an encrypted domain.
B. Veriﬁcation of Homomorphic Encrypted Signals
Rane et al. [17] [18] developed an authentication scheme
with adjustable fault tolerance. This is especially important
for noisy sensor data. Due to error correction and similarity
112
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-376-6
SECURWARE 2014 : The Eighth International Conference on Emerging Security Information, Systems and Technologies

veriﬁcation, Rane’s method can be applied for a wide range
of biometric traits.
In their application, three participants are involved for a
multi-computer scenario. Whereas the ﬁrst user provides the
biometric signals, the second involved user acts as the central
storage server for all biometric templates. The third user is
responsible for veriﬁcation. However, this user is seen as
vulnerable and therefore, she is not allowed to query the
database system (DBS).
C. Secure Deletion in Databases
Databases can often reveal more information than intended.
If an entry is deleted from the data collection, it is a mandatory
step to avoid the data reconstruction afterward. Stahlberg et
al. [19] and Grebhahn et al. [1] explain how data can be
reconstructed from metadata or system copies. Furthermore,
DBS speciﬁc data, such as index structures, can also be used
for reconstruction of deleted data. This means, even if no
data are left, the system inherent data structure can be used
to gain information from fully deleted data tuples. Therefore,
privacy awareness for database tunings, as described in [2], is
required for biometric DBS to guarantee data privacy, which
is especially challenging for multi-dimensional data [20].
Apart from a possible reconstruction of previously erased
data, saved data can reveal additional information. For in-
stance, the amount of queries for a data tuple can give an idea
about who that tuple belongs to. This kind of vulnerabilities
of the conﬁdentiality needs to be addressed early at the stage
of the database layout. Not all security risks can be solved at
this stage of the design, but a good database layout can indeed
be the foundation of a secure system.
III. ARCHITECTURE FOR PRIVACY-PRESERVING
AUTHENTICATION
In a general authentication setup, there are two instances
that have to share information with each other. There is a
participant using a sensor to authenticate a claimed identity
on the one side. On the other side, there is a reference DBS
containing all enrolled data of all registered users. The DBS
is considered to be semi-trustworthy, which means the data
in this system shall never be available to the database holder
without any kind of restriction or encryption. For that reason,
a system allowing database authentication without revealing
any information to the database holder needs to be applied.
Furthermore, it has to be impossible to decrypt data without
having the secret key. The solution used in this paper to
address this issue is the use of homomorphic encryption.
Here, we use the Paillier crypto system as described in [9].
We slightly extend this scheme with the inclusion of user-
deﬁnable key lengths for the purpose of the performance
evaluations presented in Section V.
In Figure 2, we present a simpliﬁed pipeline of a veriﬁcation
process. Note, in this scenario, a compromised DBS adminis-
trator could keep track of the order of enrolled employees
and therefore, a sequential ID has to be avoided. This is
also conceivable for timestamps and other metadata. So, it
is inevitable to disable any logging of enrollment steps.
User
Name
Security 
Level
Department
ID
...
Feature 
Vector
Authentication 
Data
Veriﬁer
Biometric 
Probe
Authentication
Decision
Encrypted DBS
Figure 2. Authentication Process with Encrypted Database, adapted from [8]
IV. EXTENDING SECURE SIMILARITY VERIFICATION
There exist many biometric authentication systems, which
use quite different biometric modalities. Another aspect in this
domain is the quality of systems with respect to accuracy and
security. To some extent, both properties rely on the trait itself.
So, a system that uses only a small set of features with low
quality is expected to have overlapping features for different
users. Due to the fact that systems often have more than
one server and are using different key pairs, user tracking is
not possible. Additionally, the order of users can be mixed
within different systems. We introduce the padded biometrics
approach, which allows user authentications in a multiple
participant scenario with respect to privacy-preservation. Ad-
ditionally, we present performance impacts and a brief security
impact discussion.
A. The Padded Biometrics Approach
In Figure 3, we depict a scenario for user tracking with
two database systems (DBS). We assume, an attacker has read
access to both databases. The differences between both DBS
are key pairs and user IDs. Assume, with some knowledge, the
attacker identiﬁes in DBS1 User 1. The DBS uses an unsalted
asymmetric encryption which results for a given key and plain
text value always in the same cipher value. Within DBS1, the
attacker ﬁnds the exact same value for another user (User 5).
With the help of this knowledge, both users can be identiﬁed in
DBS2. Due to the fact that the feature vectors are not shufﬂed,
the attacker needs to identify a match between two users in
DBS2 with an overlap of the same two features.
DBS 1
DBS 2
User 1
User 5
z85:jaol7qjfw
z86:965gt4mk0
z88:jutgt4qs0
z31:erh9zuds1
z33:965gt4mk0
z39:ggz763ki8
z85:6rtgkiu99
z86:hdt3loqy0
z88:432jjhzx6
z31:jkas73kl3
z33:hdt3loqy0
z39:gas87gjle
User 7
User 14
. . .
. . .
Figure 3. User Tracking in a Multiple DBS Setup, adapted from [8]
In practice, for a proper biometric trait with an appropriate
resolution this scenario is implausible. As an example, we
113
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-376-6
SECURWARE 2014 : The Eighth International Conference on Emerging Security Information, Systems and Technologies

take the iris codes with 2,048 bit representation for the iris
features; there exist theoretically more than 1074 different
codes. However, the Euclidean vector space is very sparsely
populated due to cluster of iris codes. Such clustering occurs
in many biometric modalities. Therefore, our example, given
in Figure 3, is a result from exact matches for different feature
vectors. Correlations of biometric features are the main reason
for such clusters. Daugman [21] identiﬁes the iris phase code
to be 0 or 1. This results in a Hamming distance with a
very small variance. Daugman uses 249 different features and
obtains µ = 0.499 and σ = 0.0317. There exist several
other analogous examples, e.g., in face recognition for the
distribution of eyes, nose, and mouth that are quite similar
for every person. We conclude that it is very likely that the
data in the feature space are not equally distributed.
With these insights or domain knowledge, it is possible to
link users or even track users as in our example in Figure 3. An
inclusion of the metadata of the database also enables further
possibilities for an information gain, e.g., in the case that an
index structure relates similar values, as the R-tree [22] or the
Pyramid technique [23].
We propose a padding approach. This is comparable to
salting. In Figure 4, we show the idea. Every user receives
a speciﬁc ID (UID). This ID is encrypted together with the
template, e.g., by concatenating ID and biometric feature. This
approach also allows including the feature index (FID) in the
pad which avoids intra-user overlapping.
UID
FID
Biometrics
Pad
Biometric Feature
Figure 4. Lead-Pad for Biometric Features, adapted from [8]
The resulting value of a pad and a biometric feature has
to be encrypted. A leading pad avoids any inter- and intra-
user redundancies. At the same time, the possibility of the
above described attack is close to zero. The padding, seen as a
security layer, can be either maintained by the user or operated
by an additional participant who has paddings and IDs. This
proposal comes at the cost that identiﬁcation is expected to be
more difﬁcult. The pad shifts features semantically away from
others. Therefore, the Euclidean measurements for similarity
cannot be used, but the complete set of pads for each person
has to be processed. We concentrate on performance of our
proposed approach in the following.
B. Performance of the Pad Approach in the DBS
Index methods are widely used in DBMS to increase perfor-
mance [24]. In relational databases, the B-tree [25] [26] and
variants, such as the B+-tree. are used to achieve a logarithmic
lookup performance. A similarity search using B+-trees results
on average in a linear performance overhead additionally.
Including a veriﬁer, as proposed in an encrypted data domain,
inﬂuences the processing time due to transportation effort. We
discuss pros and cons in the following.
TABLE I. PERFORMANCE IN A DATABASE SYSTEM AND COMPARED TO
THE PADDING APPROACH
Query Type
DBS with B+-tree
Padding DBS
Exact Match
O(log(n))
O(n)
Similarity Search
O(n)
O(n)
Sorting and the use of metadata, which can improve query
response times, should be avoided for security reasons. This
requirement is in contrast to typically used index structures
in relational data management systems. Therefore, the identi-
ﬁcation within the authentication process requires linear com-
putational effort. Depending on the size and the application
scenario, different metadata, such as gender, can be utilized
to limit this effort. Note, if small subsets can be created from
this metadata, it is necessary to separate these from biometrics.
Alternatively, the padding approach can be applied to non-
biometrics, too. In Table I, we summarize the computational
efforts for a relational database and also for a database with
encryption using our padding approach. Due to several other
possible performance impacts, such as database size, feature
size, thresholds, or key bit-length, we present in Section V a
short evaluation study.
1) Implementation Issues: We propose to use a distance
result from the veriﬁer instead of a binary decision of ac-
ceptance or decline of an authentication attempt. Besides
a reasonable attack scenario, where learning from accepted
authentications and repeated authentication queries is possible
in the later scenario, this risk can be reduced by disabling
repeated authentication. In our approach, the quality of the
similarity can be computed in an evaluation step. We apply
the following formula:
d (X, Y ) =
Pdim
i=1 |xi − yi|a
τ a · dim
(2)
with threshold τ, a ≥ 1 as degree of freedom, and dim as
dimensionality of the feature vector. These parameters are
important for adjusting quality regarding sensor accuracy, error
rates, and the biometric trait. The better the quality, the lower
can be τ and the larger a.
We use a dictionary to maintain all pads for all enrolled
users. The pads are delivered via a secure channel for each
authentication process. The pads are concatenated before en-
cryption. Due to the non-existence of relations to personal
data, the pads can be generated randomly. The necessary step
before enrollment or authentication is adding the pad. Note, it
is not necessary to add the pad before the signal. Within an
identiﬁcation process, it is necessary to lookup the dictionary
for the pad of a user. If outsourcing the dictionary to an
external server, a processing time increase has to be respected.
In the following, we consider the three participant approach,
for other system architectures from Section III. We measure
the inﬂuence of computation time regarding all three involved
participants. Note, if participants are embedded, as described
in Section III, special security requirements have to be met.
The three participants consist of a user, a veriﬁer, and the
114
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-376-6
SECURWARE 2014 : The Eighth International Conference on Emerging Security Information, Systems and Technologies

DBS, which maintains the encrypted templates. Biometrics are
taken by a sensor at user side. The veriﬁer is responsible for
authentication. Note, communication channels can be realized
in different ways, such as insecure or with encryption. In the
case, that only the user stores all pads to corresponding IDs,
veriﬁer and DBS do not need to be fully trusted. Hill-climbing
should be avoided and therefore, a repeated authentication
from single users has to be disabled. As a result, we can sum
up that applying our approach to this scenario, only the user
and partly the server gain information on the claimed identity.
The ability to learn from the results can only be realized on
user or veriﬁer side. There is no plain information, due to
encryption at user side within the complete process.
C. Security Impacts
In our experiments, we do not focus on crypto-analyzes.
Since data are kept in the DBS, this is a promising entry point
to gain information. A careful design and a proper security
concept are mandatory. Implementation can cause vulnera-
bilities to the protocol that can lead to information leakage.
There are some attacks, which do not immediately address the
protocol. For instance, there are attacks on availability and the
endpoint should be carefully considered.
An attacker can try to take advantage of vulnerability that
originated from poor system design. For example, a system
designer decides to embed the veriﬁer at user side, but does not
meet all steps to guarantee conﬁdentiality. If an unauthorized
user is able to listen to the veriﬁer, an information leakage
occurs.
In the case our padding approach is implemented inappro-
priate, e.g., without secure separation from unauthorized users,
and an attacker gains access to the pads, the conﬁdentiality
is at risk. With access to the pads and the encrypted signal,
known-plain-text attacks [27] are possible.
The asymmetric Paillier cryptosystem is not information-
theoretically secure. Thus, there are threats leading to leakage
of the biometric templates in the DBS. We introduce a padding
approach to avoid opportunity of such attacks. Note, a secure
dictionary is mandatory. The implementation of a system
can enable various security vulnerabilities. These enable an
attacker to gain trusted information. It is mandatory to im-
plement a proper pseudonymization approach in combination
with a secure dictionary.
The conﬁguration of a system is presumably the most
promising path for an attacker. The DBS amount and type of
meta-information can be a threat to security. System designers
have to carefully consider meta-information. Additionally,
backups play an important role. With access to both, DB and
backup, an attacker subtracts users from backup and current
state for user tracking.
Acceptance threshold and quality classes inﬂuence false
acceptance and false rejection rates. The threshold decides
on size of error patterns. There are many additional factors:
level of information conﬁdentiality, quality of the signals,
access frequency, expectations regarding response times, and
combined biometrics.
If the authentication protocol uses web communication, a
denial of service attack (DoS) can disturb the protocol from
functioning and harms availability. Even without using the
web, there are other possible attacks that are not only taking
advantage of communication. For instance, using malware
to prevent participants from following the protocol is an
imaginable attack on availability. Assuming that a biometric
authentication scheme applies the Four Participants scenario,
a DoS attack on the disguise would prevent the system’s
functioning. It is possible to reduce the threat, but impossible
to prevent it completely.
Endpoint security is crucial to provide conﬁdentiality, espe-
cially if users have access to secret keys. Assuming the secret
key is not as easily accessible, an attacker can try to read
parts of communications. This includes plain and encrypted
data such as pads. Assessing these data, follow-up attacks like
known-plain or known cipher text attacks [27] are possible. For
a restriction, basic security steps, including anti-virus software
and ﬁrewalls, should be implemented.
V. EVALUATION
In this section, we present evaluation results on performance
for our approach. We evaluate processing time as performance
metric. For our evaluation, we present experiments regarding
different inﬂuence factors, such as enrolled users, key length,
feature vector dimension, and thresholds. Firstly, we explain
the evaluation setting. Secondly, we show results of our
performance evaluation with respect to enrolled users, key
length, feature dimensions, and threshold by studying with
and without-padding approaches and encrypted versus non-
encrypted scenarios.
A. Experimental Layout
For our evaluation, we use a MySQL database, version
5.5.27. We restrict our evaluation to a two table layout with
index structures as follows:
• Person( Name, Security level, Department, ID)
• Biometrics(Feature, ID, BID).
Every enrolled person in the system has some attributes, i.e.
a name, a security level, and a department. These attributes
can be exchanged or extended by any property. In addition,
every person has an ID to ﬁnd a data tuple unambiguously.
All properties like name, security level and department are
encrypted with the public key. Biometrics are divided by the
count of dimensions of the Euclidean vector. Every feature
is identiﬁed by a biometric ID (BID), while biometrics are
assigned to the corresponding person by an ID.
We make the following assumptions: The DBS is designed
that it can be used for most common discrete biometric
features. The resolution or the quality of the feature has no
inﬂuence on the operative readiness of the biometric system
itself. How accurate the resolution has to be is a question
of acceptable error rates and needs to be adjusted by the
corresponding use case. Features are saved in feature vectors
and have a minimum of at least one dimension and can have
as many dimensions as needed. Everything that depends on
115
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-376-6
SECURWARE 2014 : The Eighth International Conference on Emerging Security Information, Systems and Technologies

the dimension of the feature vector grows corresponding to its
size. For example, the codebooks are depending on the size
of the feature vector.
B. Performance Evaluation
We perform all experiments on an AMD Phenom II X6
1055T Processor, an SSD, and 8GB RAM. In our evaluation,
we focus on response time as crucial performance factor.
We apply 10 replications per evaluation run for validity. We
use artiﬁcial data that we i.i.d. generated from Gaussian
distribution.
TABLE II. PERFORMANCE FOR USERS
Users
Identiﬁcation
Veriﬁcation
in ms
in ms
20
35
87
1,000
63
107
100,000
354
354
First, we test for size of enrolled users. Note, for simplicity,
feature length is 11 dimensions, key size is 64bit, and threshold
is 3. In Table II, we present arithmetic means for identiﬁcation
and veriﬁcation for our padding approach. Our results indicate
that the overall processing increases with a higher amount of
enrolled users. This growth seems linear. Memory manage-
ment and thread scheduling or conﬁguration and running the
DBS cause this increase. Since veriﬁcation only requires data
of one person, the increase is not similar to identiﬁcation. Due
to B+-trees in MySQL, there is an increasing impact according
to the size of enrolled users.
TABLE III. PERFORMANCE FOR KEY LENGTH
Key
Identiﬁcation
Veriﬁcation
Length
in ms
in ms
64
63
107
128
112
87
512
1001
400
1,024
6933
2188
In Table III, we present results regarding key length. Note,
we use 1,000 enrolled users in the DBS and a feature dimen-
sionality of 11. As expected, an exponential growth with an
increase of the key length is obvious. Due to our experimental
setup (using one machine for all tasks), this growth might be
inﬂuenced in our experimental setup. However, using a private
key only increases the processing time in a small amount. A
fast feedback is a user requirement for user acceptance of
biometric authentication.
We test different feature vector sizes (11, 69, 100, 250, and
2,048) and present the results in Table IV. Adding new features
to the feature vectors requires more comparisons, which result
in higher response times. Note, with an increase of the feature
vector the codebooks also increase. Due to this, the growth in
smaller feature vectors can be explained.
As a last evaluation parameter, we vary the threshold from 3
to 1,000 and present our results in Table V. The threshold pa-
rameter is used for quality reasons, see Section IV. Compared
TABLE IV. FEATURE DIMENSIONS PERFORMANCE
Feature
Identiﬁcation
Veriﬁcation
Dimensions
in ms
in ms
11
63
56
69
239
81
100
354
321
250
693
571
2,048
1,065
860
TABLE V. PERFORMANCE FOR THRESHOLD
Threshold
Identiﬁcation
Veriﬁcation
in ms
in ms
3
125
99
5
199
104
10
216
114
100
280
208
1,000
1,572
1,311
to [18], increasing the threshold by 1 means that two additional
comparisons have to be computed. Therefore, the increase
is linear with the number of enrolled users. Signals with a
higher ﬂuctuation, which require a larger range of validity,
require more processing time. This has to be examined for each
application and evaluated regarding hardware, requirements,
and accuracy.
TABLE VI. PERFORMANCE REGARDING THRESHOLD
System Parameters
Padding Approach
Without Pad
in ms
in ms
1,000 users, 2,048 features, 64 bit
25,546
26,014
1,000 users, 11 features, 1,024 bit
28,033
27,197
100,000 users, 11 features, 64 bit
35,009
35,403
As a concluding remark, we present our evaluation results
regarding our approach compared to the approach presented in
[18]. In Table VI, we show three different parameter scenarios
exemplary. This table shows unexpected results. In the ﬁrst and
third experiment, the response times for the padding approach
are slightly lower than without padding. This might be a
result from caching and optimizations that take place in the
experiments. However, our results show, the inﬂuences of our
approach are negligible.
TABLE VII. COMPARISON OF SECURE IDENTIFICATION
Enrolled
Encrypted
Unencrypted
Users
Identiﬁcation
Identiﬁcation
20
35 ms
26 ms
1,000
63 ms
47 ms
100,000
354 ms
310 ms
In the last setting, we show differences between encrypted
and unencrypted identiﬁcation in Table VII. We use again a
key length of 64bit and 11 feature dimensions. The threshold
is set to 3. The results show the cost for encryption. Note, we
only use a very small computation effort regarding encryption
due to a very short key length. With an increase of the key
length the difference for both scenarios increases dramatically.
116
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-376-6
SECURWARE 2014 : The Eighth International Conference on Emerging Security Information, Systems and Technologies

VI. SUMMARY AND OUTLOOK
In this paper, we present an extension to the secure and
similarity veriﬁcation between homomorphically encrypted
signals by Rane [17], [18]. Tracing users is possible in the
original scenario. We present a padding approach, to overcome
this challenge. We extend the original contribution to search
on encrypted values and to use a one-time-pad-concept. Fur-
thermore, we develop a evaluation study of our conceptual
design to evaluate our approach.
With the padding approach, an advanced search in an
encrypted domain is possible. However, if repeated authen-
tication attempts are possible, it is already possible to gain
information regarding the template. One can avoid such tem-
plate reproduction by disabling repeated authentications. Our
approach improves data security. We name some security
requirements for this purpose.
Processing times in our evaluation reveal that our padding
approach comes at very low additional cost compared to [18].
This is an important aspect for user acceptance of such a
system. Whereas the size of enrolled users has logarithmic
impact on computational effort, the key length impacts with an
exponential scheme. The dimensions of the feature vector have
logarithmic inﬂuence as well and the threshold is linear in the
computational effort. All these parameters do not drastically
inﬂuence the system of Rane [18]. Due to simple operations,
such as summation and amount computation, computational
overhead is negligible. However, concept of privacy-preserving
authentication, discussed in this paper, has a strong inﬂuence
on computational effort compared to plain-text biometric au-
thentication systems.
In future work, our approach can be adapted for other
domains. We propose to semantically shift data to complicate
unauthorized decryption attempts, which makes user tracing
via duplicate identiﬁcation unlikely. Particularly, this becomes
important, if the co-domain of the biometric feature is smaller
than the co-domain of the key. The approach presented in [28]
veriﬁes users in the encrypted domain. It is imaginable that
the extensions are of interest, too, for this approach, which
bases on the homomorphic cryptosystem RSA.
ACKNOWLEDGMENT
We thank Martin Sch¨aler for fruitful discussions on the
ﬁrst draft of this paper. The work in this paper has been
funded in part by the German Federal Ministry of Education
and Research (BMBF) through the Research Program ”Digi-
Dak+ Sicherheits-Forschungskolleg Digitale Formspuren” un-
der Contract No. FKZ: 13N10816 and 13N10818.
REFERENCES
[1] A. Grebhahn, M. Sch¨aler, and V. K¨oppen, “Secure deletion: Towards
tailor-made privacy in database systems,” in BTW-Workshops.
K¨ollen-
Verlag, 2013, pp. 99–113.
[2] A. Grebhahn, M. Sch¨aler, V. K¨oppen, and G. Saake, “Privacy-aware
multidimensional indexing,” in BTW.
K¨ollen-Verlag, 2013, pp. 133–
147.
[3] C. Vielhauer, Biometric User Authentication for IT Security, ser. Ad-
vances in Information Security.
Springer, 2006, no. 18.
[4] M. Sch¨aler, A. Grebhahn, R. Schr¨oter, S. Schulze, V. K¨oppen, and
G. Saake, “QuEval: Beyond high-dimensional indexing `a la carte,”
PVLDB, vol. 6, no. 14, 2013, pp. 1654–1665.
[5] F. Emekci, O. Sahin, D. Agrawal, and A. E. Abbadi, “Privacy preserving
decision tree learning over multiple parties,” DKE, vol. 63, no. 2, 2007,
pp. 348 – 361.
[6] A. Inan, Y. Saygyn, E. Savas, A. Hintoglu, and A. Levi, “Privacy pre-
serving clustering on horizontally partitioned data,” in Data Engineering
Workshops, 2006. Proceedings. 22nd International Conference on, 2006,
pp. 95–95.
[7] D. Shah and S. Zhong, “Two methods for privacy preserving data mining
with malicious participants,” Information Sciences, vol. 177, no. 23,
2007, pp. 5468–5483.
[8] M. Leuckert, “Evaluation and extension of secure similarity veriﬁcation
in multi-computer scenarios to sesecure store and communicate biomet-
ric data,” Master’s thesis, Otto-von-Guericke University, 2013.
[9] P. Paillier, “Public-key cryptosystems based on composite degree residu-
osity classes,” in EUROCRYPT, ser. Lecture Notes in Computer Science,
J. Stern, Ed., vol. 1592.
Springer, 1999, pp. 223–238.
[10] C. Vielhauer, J. Dittmann, and S. Katzenbeisser, “Design aspects of
secure biometric systems and biometrics in the encrypted domain,” in
Security and Privacy in Biometrics, P. Campisi, Ed.
Springer, 2013,
pp. 25–43.
[11] S. Kiltz, A. Lang, and J. Dittmann, “Taxonomy for computer security
incidents,” in Cyber Warfare and Cyber Terrorism.
IGI Global, 2008,
pp. 412–417.
[12] S. Hildenbrand, D. Kossmann, T. Sanamrad, C. Binnig, F. Faerber, and
J. Woehler, “Query processing on encrypted data in the cloud,” Systems
Group, Department of Computer Science, ETH Zurich, Tech. Rep., 2011.
[13] A. Juels and M. Wattenberg, “A fuzzy commitment scheme,” in 6th
ACM Conference on Computer and Communications Security.
New
York, NY, USA: ACM, 1999, pp. 28–36.
[14] A. Juels and M. Sudan, “A fuzzy vault scheme,” Designs, Codes and
Cryptography, vol. 38, no. 2, 2006, pp. 237–257.
[15] A. K. Jain, A. Ross, and U. Uludag, “Biometric template security: Chal-
lenges and solutions,” in In Proceedings of European Signal Processing
Conference, 2005.
[16] C. Gentry, “Computing arbitrary functions of encrypted data,” Commun.
ACM, vol. 53, no. 3, 2010, pp. 97–105.
[17] S. Rane, W. Sun, and A. Vetro, “Secure similarity veriﬁcation between
encrypted signals,” US Patent US20 100 246 812 A1, Sep. 30, 2010.
[18] ——, “Secure similarity veriﬁcation between homomorphically en-
crypted signals,” US Patent US8 249 250 B2, Sep. 30, 2012.
[19] P. Stahlberg, G. Miklau, and B. N. Levine, “Threats to privacy in
the forensic analysis of database systems,” in Proceedings of the 2007
ACM SIGMOD International Conference on Management of Data, ser.
SIGMOD ’07.
New York, NY, USA: ACM, 2007, pp. 91–102.
[20] A. Grebhahn, D. Broneske, M. Sch¨aler, R. Schr¨oter, V. K¨oppen, and
G. Saake, “Challenges in ﬁnding an appropriate multi-dimensional
index structure with respect to speciﬁc use cases,” in Proceedings
of the 24th GI-Workshop ”Grundlagen von Datenbanken 2012”,
I.
Schmitt,
S.
Saretz,
and
M.
Zierenberg,
Eds.
CEUR-WS,
2012, pp. 77–82, urn:nbn:de:0074-850-4. [Online]. Available: http:
//ceur-ws.org/Vol-850/paper grebhahn.pdf
[21] J. Daugman, “How iris recognition works,” IEEE Trans. on Circuits and
Systems for Video Technology, vol. 14, no. 1, 2004, pp. 21–30.
[22] A. Guttman, “R-trees: A dynamic index structure for spatial searching,”
SIGMOD Rec., vol. 14, no. 2, 1984, pp. 47–57.
[23] S. Berchtold, C. B¨ohm, and H.-P. Kriegel, “The Pyramid-technique:
Towards breaking the curse of dimensionality,” SIGMOD Rec., vol. 27,
no. 2, 1998, pp. 142–153.
[24] V. K¨oppen, M. Sch¨aler, and R. Schr¨oter, “Toward variability manage-
ment to tailor high dimensional index implementations,” in RCIS. IEEE,
2014, pp. 452–457.
[25] R. Bayer and E. McCreight, “Organization and maintenance of large
ordered indexes,” Acta Informatica, vol. 1, 1972, pp. 173–189.
[26] D. Comer, “The Ubiquitous B-Tree,” ACM Comput. Surv., vol. 11, no. 2,
1979, pp. 121–137.
[27] B. Schneier, Secrets & Lies: Digital Security in a Networked World.
New York, NY, USA: John Wiley & Sons, Inc., 2000.
[28] M. Upmanyu, A. M. Namboodiri, K. Srinathan, and C. V. Jawahar, “Ef-
ﬁcient biometric veriﬁcation in encrypted domain,” in 3rd International
Conference on Advances in Biometrics, 2009, pp. 899–908.
117
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-376-6
SECURWARE 2014 : The Eighth International Conference on Emerging Security Information, Systems and Technologies

