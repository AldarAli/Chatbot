License Plates Recognition of Mexican Private Vehicles 
Carlos Hiram Moreno, NicolÃ¡s Trejo, Martha Soto 
Departmento de IngenierÃ­a en Sistemas Computacionales 
TecnolÃ³gico de Estudios Superiores de Chimalhuacan  
ChimalhuacÃ¡n Estado de MÃ©xico  
Email: {carlosmoreno, nicolastrejo, sistemasteschi} 
@teschi.edu.mx 
Benjamin Moreno-Montiel 
Departamento de IngenierÃ­a ElÃ©ctrica  
Universidad AutÃ³noma Metropolitana 
MÃ©xico City  
Email: bmm@xanum.uam.mx
 
 
Abstractâ€” In most of the investigations about the recognition 
of license plates from different countries it is assumed that they 
have a white background, without texture patterns and with 
black characters. Vehicle registration plates in Mexico are 
different because they have different texture patterns and 
colors in the background depending on the State of the 
Republic; that is why the algorithms of recognition of these 
plates are not always successful. This article proposes an 
algorithm for the recognition of vehicle registration plates of 
Mexico considering three phases: A) Normalization and 
Binarization of the plate, which is achieved by using a 
threshold factor, which separates dark colors that form letters 
from the clearings that are at the bottom. B) Characterization 
C) Modeling of symbols by technics such as Huâ€™s moment, 
Fourier descriptors and correlation cross factors and D) 
Classification, where we have used comparisons between 
different techniques of template matching, Bayesian classifier 
and Artificial Neural Networks to process images of plates 
from different states. The results obtained are discussed at the 
end of the present paper.  
Keywords-license plate recognition; bayesian classifier; artificial 
neural network; correlation factor; principal component 
analysis; Huâ€™s moments. 
I. 
 INTRODUCTION 
Recognition of license plates of vehicles has been 
investigated throughout the world. We can find some 
examples of recognition of license plates in countries like 
Argentina [1], Bangladesh [2], China [3], Egypt [4], India 
[5], Japan [6], Malaysia [7], among others. Normally, these 
works consider four phases: 1) get the image of the vehicle 
2) plates location inside the image, 3) characters extraction 
and 4) classification or recognition of characters.  
In most algorithms found in literature, it is assumed that 
the plate has no textured patterns, the background is usually 
white and the characters black allowing better character 
recognition. However, in the case of Mexican plates it is not 
the case. On one hand, they have patterns of texture in the 
background and on the other hand, each State Government 
can design their own pattern of background texture; this 
generates more than 32 different plates, and this number 
increase with changes in the government administration. 
These structures in the vehicle registration plates of 
Mexico make the traditional algorithms not working 
properly, mainly in the phase of extraction of characters.  
Another important thing to mention is that although each 
State can design the background of its plates, the dimensions 
of the plates and letters, as well as their style, must meet with 
the features that are designated in the official Mexican 
standard NOM-001-SCT-2-2000; these characteristics are 
used to recognize the registration.  
This work proposes an algorithm that segments each 
character and recognizes them depending on their 
characteristics of color and form. To properly segment the 
characters, most of the background texture patterns were 
eliminated by using a threshold factor, which separated the 
dark colors that make up the letters from the light colors that 
make up the background. Once filtered the background 
texture, the image of the plate was binarized and both 
vertical and horizontal histograms were obtained using the 
technique of projection of profiles, just to obtain the 
coordinates of the position used to segment characters. When 
the images of the characters were obtained, we proceeded to 
model them and characterize them using the techniques of 
Huâ€™s moment, Fourier Descriptors, and Cross-correlation 
factor. Data obtained at this stage was used as 
complementary in the classification phase. Finally, in the 
stage of classification, techniques of templates, Bayesian 
classifier and artificial networks neural were used. The 
results obtained are discussed at the end of the present work.  
The article is organized in the following form: in Section 
2 is presented the proposal of recognition of license plates. 
Experiments conducted in the section are presented in 
Section 3. A discussion of the results obtained is made in 
Section 4 and the article ends with conclusions in Section 5. 
II. 
PROPOSAL OF VEHICLE LICENSE PLATE RECOGNITION  
Automatic Number Plate Recognition (ANPR) presented 
in Fig. 1, consists essentially of four stages: 1) To get the 
image of the vehicle using a camera, 2) Extract the image 
plate, 3) Segment and remove the plate characters and 4) 
Recognize the characters extracted.  
In the present work is only discussed the segmentation 
and recognition of characters, stages (3) and (4). Images 
employed contain exclusively the region that conforms to the 
plate, and has the following characteristics: 
â€¢ 
Images of the plates must be obtained between 1 and 
1.5 meters of distance between the camera and the 
registration.  
â€¢ 
They must not have lighting variations.  
â€¢ 
Images are frontal or near frontal, meaning images 
must have very small rotation angles. 
â€¢ 
No occlusions or considerable physical damages. 
13
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

 
 
Figure 1.  Stages of an ANPR system. 
The developed algorithm in this work is presented and 
consists of: 1) Standardization and binarization of the plate, 
2) Segmentation of the characters, 3) Character modeling 
and 4) Recognition of characters. 
A. Normalization and Binarization of the plate 
Normalization of the images is based on the standard 
NOM-001-SCT-2-2000, where it is established that 
dimensions of the plates must be of 2:1, so, all images are 
resized at 700 Ã—350 pixels of being binarized. The same 
standard also establishes the position in which the characters 
must be collocated inside the plate, as well as the size and 
the distance between them, as it is shown in Fig. 2.  
 
 
Figure 2.  Position of the characters inside the registration. 
With this information is eliminated the upper and lower 
sections of the original image, with the objective to get a 
section that contains exclusively characters. The result is 
shown in Fig. 3. 
 
 
Figure 3.  Example of sections elimination upper and lower; (a) original 
image, (b) image obtained after sections elimination. 
Due to the great variety of background colors in plates, 
before being binarized, it was necessary to separate the 
texture of the background from the numbers and letters of 
plates. 
It is important to mention that, in the present work, the 
image colors are represented in the space RGB. In this space, 
the colors are represented as a linear combination of the 
vectors base in red, green and blue; the color of a pixel is 
represented as Ï•=[r, g, b]. Fig. 4 shows the form of the RGB 
space. 
To develop the separation process, we use an 
experimental threshold by graythresh function defined in 
Matlab, which chooses the threshold to minimize the 
interclass variance of the black and white pixels; the 
threshold (Î´) obtained is of 0.73. To separate what is in the 
magnitude of a vector RGB, we start by performing a 
comparison to classify a pixel in a region or another, shown 
in Fig. 4.  
 
Figure 4.  RGB space and threshold of intensity. 
In Fig. 4 it is showed the part of the space where the 
colors from the characters are found. Separation was made 
using the equation (1). 
ğœƒâˆ— = {1âƒ— ,
â€–ğœ™â€– â‰¤ ğ›¿
0âƒ— ,
â€–ğœ™â€– > ğ›¿
                               (1) 
 
where ğœ‚âˆ— = 0.73, 1âƒ— = [1,1,1] and 0âƒ— = [0,0,0]. With the 
proposed method, it is managed to differentiate the 
characters; the background was obtained and therefore the 
possibility of binarizing the images. In Fig. 5 we show two 
examples of binarized images using the Otsu method [8], 
which is normally used for gray scales; therefore, when using 
black and white is also a case for Otsu method. 
 
Figure 5.  Example of two images of plates binarized using the Otsu 
method. 
B. Characters Segmentation 
The horizontal and vertical projection method is used to 
segment characters [9]; this method has been used for similar 
investigations in [6][10][11].  
14
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

Suppose we have an image ğ‘°(ğ’™, ğ’š) with ğ‘¤ğ‘–ğ‘‘ğ‘’ = ğ‘ and 
â„ğ‘’ğ‘–ğ‘”ğ‘¡â„ = ğ‘€ (considering that 1 â‰¤ ğ‘¥ â‰¤ ğ‘ and 1 â‰¤ ğ‘¦ â‰¤ ğ‘€), 
the horizontal and vertical projections are defined as:  
 
ğ‘ƒâ„ğ‘œğ‘Ÿ(ğ‘¦0) = âˆ‘ ğ¼(ğ‘¥, ğ‘¦0)
ğ‘
ğ‘¥=1
, âˆ€ğ‘¦ = 1, â€¦ , ğ‘€                 (2) 
ğ‘ƒğ‘£ğ‘’ğ‘Ÿ(ğ‘¥0) = âˆ‘ ğ¼(ğ‘¥0, ğ‘¦)
ğ‘€
ğ‘¦=1
, âˆ€ğ‘¥ = 1, â€¦ , ğ‘                (3) 
 
The histograms obtained by equations (2) and (3) allow 
determining the coordinates of the area of each letter and 
number in the plates. Fig. 6 shows an example of horizontal 
and vertical projection of a binarized image. 
 
 
Figure 6.  Horizontal and vertical projection of a binarized image. 
Fig. 7 shows some examples of segmented characters 
used to do horizontal and vertical projections. 
 
 
Figure 7.  Examples of characters segmented using horizontal and vertical 
projections. 
C. Modelling of the characters  
The techniques of Hu moments, correlation factor and 
Fourier descriptors are compared because they are 
comparison techniques in which objective values are 
obtained, which identify classifications of letters and 
numbers that will be used in techniques such as Bayesian 
classifier and neural network. 
Segmented characters are modeled using the Correlation 
factor, Huâ€™s moment and Fourier descriptors. 
1) Correlation factor: Correlation is a statistical 
technique that quantifies the strength of the linear 
relationship between two variables.  
The quantification was performed using the coefficient 
of Pearsons correlation linear [12], whose value ranges 
between {-1 and 1}. Suppose we have the variables x and y, 
and on the other hand, O={(x_1,y_1 ),â€¦,(x_m,y_m)} is the 
set of pixels coordinates to have a character extracted, the 
correlation coefficient between both variables is calculated 
as: 
ğ‘Ÿ =
âˆ‘
(ğ‘¥ âˆ’ ğ‘¥Ì…)(ğ‘¦ âˆ’ ğ‘¦Ì…)
(ğ‘¥,ğ‘¦)âˆˆğ‘‚
âˆšâˆ‘
(ğ‘¥,ğ‘¦)âˆˆğ‘‚(ğ‘¥ âˆ’ ğ‘¥Ì…)2
âˆ‘
(ğ‘¦ âˆ’ ğ‘¦Ì…)2
(ğ‘¥,ğ‘¦)âˆˆğ‘‚
            (4) 
2) Huâ€™s moment: Huâ€™s moments have been employed to 
recognize characters in [13] and [14], to measure geometric 
features as ellipticities [15] or circularities [16]. In the Huâ€™s 
moment, the most representative is the centralized and 
standardized moment, ğœ‚ğ‘ğ‘, obtained with:  
 
ğœ‚ğ‘ğ‘ = ğœ‡ğ‘ğ‘
ğœ‡00
ğ‘+1                                                         (5) 
 
 
In equation (5), c and ğœ‡ğ‘ğ‘ is calculated as: 
ğ‘ = ğ‘ + ğ‘
2
,          ğ‘ + ğ‘ = 2,3, â€¦                         (6) 
 
ğœ‡ğ‘ğ‘(ğ‘‚) =
âˆ‘ (ğ‘¥ âˆ’ ğ‘¥Ì…)ğ‘
(ğ‘¥,ğ‘¦)âˆˆğ‘‚
(ğ‘¦ âˆ’ ğ‘¦Ì…)ğ‘                  (7) 
where (ğ‘¥Ì… , ğ‘¦Ì…) is the coordinate of the centroid of the 
objects, calculated as: 
ğ‘¥Ì… = 1
ğ‘š âˆ‘ ğ‘¥                                        (8)
(ğ‘¥,ğ‘¦)âˆˆğ‘‚
 
ğ‘¦Ì… = 1
ğ‘š
âˆ‘ ğ‘¦
(ğ‘¥,ğ‘¦)âˆˆğ‘‚
                                       (9) 
It is important to mention that Huâ€™s moments are 
invariant to the position, rotation, and scaling. 
 
3) Fourier Descriptors: Given {(ğ‘¥1, ğ‘¦1), â€¦ (ğ‘¥ğ‘›, ğ‘¦ğ‘›)} âŠ‚
â„¤2 the set of points that form the outline of a letter, each 
point is represented as a complex number. 
ğ‘§ğ‘› = ğ‘¥ğ‘› + ğ‘—ğ‘¦ğ‘›    ,
ğ‘¤â„ğ‘’ğ‘Ÿğ‘’ ğ‘— = âˆšâˆ’1.            (10) 
 
Discrete Fourier transform of the set of points that make 
up the outline of the characters can be calculated as follows: 
 
ğ¹(ğ‘¢) = 1
ğ‘¢ğœ‹ âˆ‘ ğœ‘ğ‘› [cos (2ğœ‹ğ‘¢ğ‘ ğ‘›
ğ‘ ğ‘š
)
ğ‘š
ğ‘›=1
âˆ’ ğ‘—ğ‘ ğ‘–ğ‘› (2ğœ‹ğ‘¢ğ‘ ğ‘›
ğ‘ ğ‘š
)]                    (11) 
It can be written as: 
ğ¹(ğ‘¢) = 1
ğ‘¢ğœ‹ âˆ‘ ğœ‘ğ‘›ğ‘’ğ‘¥ğ‘ (âˆ’2ğ‘—ğœ‹ğ‘¢ğ‘ ğ‘›
ğ‘ ğ‘š
)
ğ‘š
ğ‘›=1
                    (12) 
 
Finally, the Fourier descriptors are obtained when 
calculating the absolute values of the complex numbers: 
 
ğ‘“(ğ‘¢) = |ğ¹(ğ‘¢)|                                                  (13) 
 
where ğ‘¢ =  1, 2, â€¦ , ğ‘ and N is the total number of 
descriptors to obtain. 
15
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

D. Characters Recognition  
For the characters recognition four techniques are used: 
1) Template matching, 2) Bayesians classifier and 3) 
Artificial Neural Networks (ANN) and Principal Component 
Analysis, which will be explained in more detail below. 
1) The template matching: The comparison of templates 
is a technique that consists of comparing the image of the 
character to be recognized with a series of known templates; 
its similarity can be measured to identify the character that 
contains the image to be classified. This technique has been 
used for the same purpose in [18] and [21]. When an image 
must be classified, it is compared with all the images of the 
templates and the maximum value of similarity is obtained: 
 
Îğœ = ğ‘€ğ‘ğ‘¥(ğ‘Ÿğœ), âˆ€Ïƒ âˆˆ (0, 1, â€¦ , 9, A, B, â€¦ , Z)            (14) 
 
With the value of Îğœ it is defined what symbol is the content 
in the image.  
 
2) Bayesian classifier: The Bayesian classifier [19] is 
based on the Bayes theorem where it is assumed that the 
vector of characteristics is a multivariate Gaussian 
distribution. ğ¶ = {ğ‘˜1, â€¦ , ğ‘˜ğ‘›}   is the set of ğ‘›  class; the 
probability that an object A is a class ğ‘˜ğ‘–  is denoted 
by ğ‘(ğ‘˜ğ‘–|ğ‘¨). The Bayes theorem: 
 
ğ‘(ğ‘˜ğ‘–|ğ€) = ğ‘(ğ€|ğ‘˜ğ‘–)ğ‘(ğ‘˜ğ‘–)
ğ‘(ğ‘¨)
                            (15) 
 
For Bayesian classification, it is chosen the class ğ‘˜ğ‘– 
where ğ‘(ğ´|ğ‘˜ğ‘–)ğ‘ (ğ‘˜ğ‘–) is larger. This way the observed object 
A is assigned to the class ğ‘˜ğ‘–. We assume that the probability 
of the feature vector of object A is of class kj (ğ‘(ğ€|ğ‘˜ğ‘–)), has 
a Gaussian Distribution with mean Î¼ and with covariance 
matrix Î© defined as follows: 
ğ‘ƒ(ğ´|ğ‘˜ğ‘–) = 1
Î” ğ‘’ğ‘¥ğ‘ [âˆ’ 1
2 (ğ´ âˆ’ ğœ‡ğ‘—)
ğ‘‡Î©ğ‘—
âˆ’1(ğ´ âˆ’ ğœ‡ğ‘—)] 
Where Î” = (2ğœ‹)ğ‘š/2(det Î©ğ‘—)
1/2and ğ‘š is the dimension 
of the feature vectors. 
3) Artificial Neural Network: It is a mathematical model 
that is inspired by the way biological neurons work. The 
ANN [20] is applied in the learning of tasks where each 
instance is described by a set of values that represent its 
Special features and where the function objective f (A) can 
take any value from a finite set V. In the present work, there 
are implemented two ANN, one dedicated to the 
classification of numbers and another for letters. The ANN 
deployed is of type Backpropagation, activated by the 
sigmoid function. 
 
4) Principal 
Component 
Analysis: 
The 
Principal 
Components Analysis (PCA) is a technique in which a set of 
correlated variables are transformed to another set of not 
correlated variables that is a linear combination from the 
original variables in which most of these variables can be 
removed with minimal loss of the original information; this 
characteristic allows the PCA to be employed to reduce the 
dimensionality of a large set of data losing the least of 
information. 
III. 
EXPERIMENTS  
To perform the experimentations phase it was employed 
a database of 70 images of plates from the 31 States of the 
Mexican Republic, except Mexico City because these entity 
license plates are different (contain 6 characters instead of 7). 
This database was chosen because it was considered the 
sampling by convenience. The images were captured at a 
distance of 1.5 to 3 meters between the camera and the plate, 
seeking a uniform lighting and subsequently normalized to 
700 Ã— 350 pixels. 
 
Experimentation was made in two phases: 
 
â€¢ 
Training to recognize letters and numbers  
â€¢ 
License plate recognition. 
A. Training torecognizer letters and numbers 
To test the recognizers, 738 characters, 374 letters, and 
364 numbers were used. In Table I we showed the number of 
characters used in each case. That number is not equal for all 
symbols since they do not appear with the same frequency in 
the license plate.  
Three types of characters recognizers were implemented: 
1) coefficient of correlation 2) Bayesian classifier and 3) 
Artificial Neural Network (ANN). These last 2 networks 
were implemented, one for numbers and another for letters. 
TABLE I.  
NUMBER OF EXAMPLES USED DURING THE TRAINING. 
A 
B 
C 
D 
E 
F 
G 
H 
J 
K 
L 
14 
9 
11 
17 
16 
18 
26 
21 
20 
13 
14 
M 
N 
R 
P 
S 
T 
U 
V 
W 
X 
Y 
13 
14 
20 
17 
12 
18 
18 
21 
13 
15 
18 
Z 
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
16 
27 
27 
40 
32 
41 
50 
43 
34 
33 
37 
 
In the case of the Bayesian classifier and ANN, a vector 
of 8-dimension characteristics was used at first, formed by 7 
Huâ€™s moment and correlation Factor; the results to classify 
the numbers and letters are shown in Table II.  In the present 
experiment, the networks are two layers with the following 
structure: {8,10} for numbers and {8,23} for letters. 
TABLE II.  
RESULTS OF CLASSIFICATION WITH 7 HUâ€™S MOMENT AND 
THE CORRELTION FACTOR 
 
 Bayesian classifier 
 
Character 
Hits 
% 
Hits 
% 
Numbers 
246/364  
67.58 
333/364 
91.48 
Letters 
294/374  
78.60  
273/374  
72.99 
 
16
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

Subsequently, vectors were added with characteristics 30 
and 60 Fourier descriptors, forming vectors of dimension 38: 
7 Huâ€™s moment, 30 Fourier descriptors and correlation 
factor, and dimension 68: correlation factor, 7 Huâ€™s moment 
and 60 Fourier descriptors.  Results obtained in the tests with 
the Bayesian classifier can be observed in Table III. 
In this experiment, neural networks were also 
implemented for the 38 and 68 features, establishing several 
elements per layer experimentally. For example, the structure 
for network with 38 features is: letters = {38, 76, 23} and 
numbers = {38, 38, 10}. Both networks correctly classified 
100% of the examples. 
TABLE III.  
BAYESIAN CLASSIFIER RESULTS WITH 38 AND 68 
FEATURES. 
 
          Bayesian classifier 
 
 
Character 
38 hits 
% 
68 hits 
% 
Numbers 
325/364 
89.40 
331/364 
91.50 
Letters 
360/374 
96.4 
369/374 
98.7 
 
Finally, the Principal Components Analysis was 
observed to reduce the dimension of the vector of 
characteristics in the following way: 
 
1) 38 features vector: The number of vectors 
decreased to 9 components, while the letters vectors 
went from 38 to 8 items. Neural networks 
implemented in this case have the following 
composition: numbers: {9, 27, 36, 10}, Letters: {8, 
16, 32, 23}. 
 
2) 68 features vector: The number of vectors 
decreased to 13 components, while the letters 
vectors went to only 11. Neural networks 
implemented in this case have the following 
composition: Numbers: {13, 26, 13, 10}, Letters: 
{11, 22, 46, 23}. 
B. Recognition of Vehicle`s registration. 
Table IV shows the number of images of plates used by 
State.  
TABLE IV.  
EXAMPLES NUMBER OF REGISTRATIONS BY STATE. 
Aguascalientes Baja California 
Norte 
Baja California 
Sur 
Campeche 
Chihuahua 
2 
1 
0 
2 
2 
Colima 
Coahuila 
Chiapas 
Durango 
Estado de 
MÃ©xico 
1 
2 
2 
1 
3 
Guerrero 
Guanajuato 
Hidalgo 
Jalisco 
MichoacÃ¡n 
3 
4 
3 
4 
4 
Morelos 
Nuevo LeÃ³n 
Nayarit 
Oaxaca 
Puebla 
2 
2 
3 
2 
2 
QuerÃ©taro 
Quintana Roo San Luis PotosÃ­ 
Sinaloa 
Sonora 
4 
1 
4 
3 
1 
Tabasco 
Tamaulipas 
Tlaxcala 
Veracruz 
YucatÃ¡n 
2 
2 
1 
2 
2 
Zacatecas 
Total 
 
 
 
3 
70 
 
 
 
 
The results obtained in the test what the recognizers 
developed are shown in Figure 8.  
 
  
Figure 8.  Results of classification plates to different three organizers 
implemented. 
To consider recognition of the registration as a success we 
use the following criteria: A registration is successfully 
recognized if all their characters are classified correctly. 
Otherwise, 
those 
registrations 
are 
not 
recognized 
successfully. 
IV. 
DISCUSSION 
In the development of this proposal, there were 
implemented 3 types of recognizers: 1) correlation factor, 2) 
Bayesian classifier and 3) Artificial neuronal network. Out of 
these techniques, the correlation Factor had the best 
performance as it can be seen in Fig. 8. The main problem 
with this technique is comparing the examples of plates 
presented in Table IV with a properly chosen template. This 
is due, on one hand, to the segmented characters that may 
have an excess of noise, and on the other hand, to the size 
and shape of the character.  
 Using the Bayesian classifier with only 8 features we got 
a percentage of hits of 2.85%. However, when it increased 
the number of features with Fourier descriptors, the 
percentage increased to 45.7% with 38 features and 48.57% 
with 68 characteristics. When the Principal Components was 
incorporated, the percentage decreased by 8%. This shows 
that the cumulative variance cannot be greater than 95%. 
For neural networks, with 38 features we obtained 
47.50% of hits and 17.14% with 68 features. When using 8 
and 9 principal components with 38 features, performance 
decreased only by 5%. On the other hand, when using 13 and 
11 principal components with 68 features, the number of hits 
increased to 43.85%. This shows that increasing the number 
of elements in character modeling is not always the best 
alternative. 
The classification mistakes in the Bayesian classifier 
recognizer is presented in the following form: (a) Number 9 
is classified as 6 and 4, 1 is recognized as 7 and 8 is 
17
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

classified as 0. (b) Letters: J and T are classified as L and H, 
respectively, and letters X and M are recognized as W. 
The classification mistakes in artificial neural networks 
are: (a) Number 9 is recognized as 6 and vice versa, 5 as 3 
and in some cases 4 as 9. (b) Letter R is classified as K; L is 
recognized as J; M is rated as W and vice versa; V is 
recognized as A.  
In the two previous classifiers, an error that occurs in 
both is that they cannot recognize characters that have a very 
similar structure; some examples are 5 and 8 and H and K, or 
characters that look like their rotated version such as M and 
W, 6 and 9, and V and A. 
V. 
CONCLUSIONS 
In this paper, we proposed an algorithm for recognition 
of vehicle registration plates of Mexico, which consider 
different texture patterns and colors in the background of 
plates. This is an improvement with respect to other works, 
since most consider plates formed with black characters on 
white background.  
In the case of the vehicle registration plates of Mexico, 
they have different texture patterns and colors in the 
background; so, when we applied the traditional algorithms, 
their performance was considerably affected. This was 
mainly due to the segmentation of characters; they are 
usually extracted with part of the texture of the background, 
getting incorrect characters. 
The results showed that the proposed algorithm is robust 
because in tests recognition using the Pearson correlation 
coefficient we obtained a 91.42% of recognized characters. 
In this case, we used techniques of template matching, 
which showed that characters segmentation was adequate.  
This proposed algorithm used the Mexican official 
standard NOM-001-SCT-2-2000, which specifies the 
dimensions of the plate, and the size and location of the 
characters; this information provided the phase of 
segmentation of characters.  
By experimentation, it was obtained a threshold of pixel 
intensity for each character that allows us to separate them 
from the background characters with more precision.  
Although the recognition was minimal, it should be 
considered that the misclassification of a single character 
implies that the plate is not acknowledge successfully, 
therefore, a finer threshold to decide when a plaque is or is 
not recognized must be established.  
Using the characterization of the correlation coefficient, 
Huâ€™s moments and Fourier descriptors allowed to recognize 
the characters successfully. So, even though results obtained 
in the phase of license plate recognition were low, good 
results were achieved in an individual way.  
For some alphanumeric characters of the plates, such as 
the M and W, 6 and 9, A and V, based on the characteristic 
that the moments of Hu are invariant, the recognition was 
wrong. This was because, in an invariant process, the 
characters are described through a set of quantifiable features 
(very similar in the previous characters), that are insensitive 
to any type of deformation. For the rotation characters in the 
Hu's moments is necessary to apply mechanisms to reduce 
the number of misrecognized characters, for example, Chain 
Codes. For these, we chose a starting point and travelled the 
border in a clockwise direction indicating the direction the 
border is following, thus having a qualitative and quantitive 
recognition.  
This study is original with respect to Automatic Number 
Plate Recognition (ANPR) literature and addresses harder 
use-case than those commonly evaluated. We believe the 
performances of the proposed algorithm should be compared 
to 
open-source 
ANPR 
engines 
addressing 
textured 
immatriculation plates management. 
The dataset we used in this study is small: 2 plates per 
Mexican state, resulting in 9 to 26 examples for each letter, 
which is rather low to train and evaluate robust systems. This 
is the reason why it is necessary to increase the size of the 
database to improve the results of the proposed algorithm. 
REFERENCES 
 
[1] GazcÃ³n, N. F. (2012). Automatic vehicle identification for 
Argentinean 
license 
plates 
using 
intelligent 
template 
matching. Pattern Recognition Letters , 33 (9), 1066--1074. 
[2] Siddique, N. A. (2012). Development of an automatic vehicle 
license plate detection and recognition system for Bangladesh. 
Electronics & Vision (ICIEV), 2012 International Conference 
on Informatics , 688--693. 
[3] Y. Wang, J. C. (2015). License Plate Recognition Based on 
SIFT Feature. Optik - International Journal for Light and 
Electron Optics. 
[4] M.A. Massoud, M. S. (2013). Automated new license plate 
recognition in Egypt. Alexandria Engineering Journal. 
[5] Nasipuri, S. S. (2014). iLPR: an Indian license plate 
recognition system. Multimedia Tools and Applications. 
[6] Cheng, Y. a. (2004). Car license plate recognition based on 
the combination of principal components analysis and radial 
basis function networks. 7th International Conference on 
Signal Processing , 2, 1455--1458. 
[7] Al Faqheri, W. a. (2009). A real-time Malaysian automatic 
license plate recognition (M-ALPR) using hybrid fuzzy. 
IJCSNS International Journal of Computer Science and 
Network Security , 9 (2), 333--340. 
[8] Otsu, N. (1979). A Threshold Selection Method from Gray-
Level Histograms. IEEE Transactions on Systems, Man and 
Cybernetics , 62-66. 
[9] Erick Cuevas, D. Z. (2010). Procesamiento digital de 
imagenes con MATLAB y Simulink. MÃ©xico: Alfaomega Ra-
Ma. 
[10] Duan, T. D. (2005). Building an automatic vehicle license 
plate recognition system. Proc. Int. Conf. Comput. Sci. RIVF , 
59--63. 
[11] Qin, Z. a. (2006). Method of license plate location based on 
corner feature. 6th World Congress on Intelligent Control and 
Automation , 2, 8645--8649. 
[12] A. Lind Douglas, A. W. (2012). EstadÃ­stica Aplicada a los 
Negocios y la EconomÃ­a. Mexico D. F.: McGraw Hill. 
[13] Wong, W.-H. a.-C.-M. (1995). Generation of moment 
invariants and their uses for character recognition. Pattern 
Recognition Letters , 16, 115--123. 
[14] GÃ³mez GonzÃ¡lez, S. a. (2011). Desarrollo de un sistema 
prototipo de reconocimiento de digitos usando momentos 
invariantes. Universidad TecnolÃ³gica de Pereira. 
18
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

[15] Zunic, D. a. (2014). Shape ellipticity from Hu moment 
invariants. Applied Mathematics and Computation , 226, 406-
-414. 
[16] Zunic, J. a. (2010). A Hu moment invariant as a shape 
circularity measure. Pattern Recognition , 43 (1), 47--57. 
[17] Steven L. Eddins Rafael C. Gonzalez, R. E. (2004.). Digital 
Image Processing Using. Pearson Prentice Hall. 
[18] Du, S. a. (2013). Automatic license plate recognition (ALPR): 
A state-of-the-art review. IEEE Transactions on circuits and 
systems for video technology , 23 (2), 311--325. 
[19] Tom, M. M. (1997). Machine Learning. Ithaca, N. Y.: 
McGraw-Hill. 
[20] T. Hagan MartÃ­n, B. D. (2014). Neural Network Design. 
ISBN-10: 0971732116 
[21] Hu, M.-K. (1962). Visual Pattern Recognition by Moment 
Invariants. IRE Transactions on Information Theory , 179-1z
 
19
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

