An Information Flow Approach for Preventing Race
Conditions: Dynamic Protection of the Linux OS
Jonathan Rouzaud-Cornabas, Patrice Clemente, Christian Toinard
ENSI de Bourges – Laboratoire d’Informatique Fondamentale d’Orléans
88 bd Lahitolle, 18020 Bourges cedex, France
{jonathan.rouzaud-cornabas,patrice.clemente,christian.toinard}
@ensi-bourges.fr
Abstract—In the literature, the notion of Race Condition deals
with the interference between two processes A and B carrying
out three interactions involving a shared object. The second inter-
action of the concurrent process B interleaves with the ﬁrst and
the third interactions of process A. Preventing Race Conditions
attacks between concurrent processes is still an open problem.
Many limitations remain such as preventing only Race Conditions
on a ﬁle system or controlling only direct interactions with the
shared context. That paper covers those various problems. First,
it gives a formal deﬁnition of direct and indirect information
ﬂows at the scale of a complete operating system. Second, it
proposes a general formalization of Race Conditions using those
information ﬂows. In contrast with existing formalizations, our
deﬁnition is very effective and can be implemented on any
operating system. Third, it provides a Mandatory Access Control
that enables to prevent general Race Conditions at the scale
of a whole Linux operating system. The Race Conditions can
be easily expressed as a Security Properties policy. A honeypot
experimentation provides a large scale evaluation of our dynamic
MAC enforcement. It shows the efﬁciency to prevent both direct
and indirect Race Conditions. Performances are encouraging us
to follow our approach of a dynamic MAC for enforcing a larger
range of security properties.
Keywords-Computer security; data security; access control;
operating systems.
I. INTRODUCTION
A Race Condition (RC) happens when there is an unpre-
dictable schedule between accesses of two users or processes
to a conﬂicting resource, having at least one of the two
users/processes modifying the shared resource. Depending on
the scheduling of the accesses, the content of the resource
may be unexpected. Historically, attacks based on RC used
some unpredictable behaviors of OS (e.g., with signals) in
order to modify the behavior of legitimate processes for
example. The time-of-check-to-time-of-use (TOCTTOU) ﬂaw
happens when a process checks the attributes of a ﬁle, and
performs operations on it assuming that the attributes have
not changed when actually they have. In the literature, some
authors have proposed formal description of RCs but provide
only partial or no implementation at all. Other work deals
with RCs within parallel programs. Remaining work focuses
on protecting against RCs attacks but only speciﬁc ones, e.g.,
TOCTTOU. Many limitations remain, and in practice only a
partial cover of this problem is proposed.
This paper is an extended version of [1]. In this paper we
propose a global approach to deal with RCs at the scale of
a complete computer system, at the operating system level.
We provide a formal modeling of OS, and a deﬁnition of
information ﬂows related to any system call available on OS.
That deﬁnition enables to formalize general RCs at the scale of
a whole operating system. It considers a general information
ﬂow including both direct information ﬂows and indirect infor-
mation ﬂows. General information ﬂows are more difﬁcult to
prevent since they can involve several processes and resources
using covert channels. A deﬁnition of RCs is given, based on
three general information ﬂows between concurrent processes.
This deﬁnition is provided using a general framework for
the deﬁnition of any security property related to information
ﬂows. A dynamic Mandatory Access Control is proposed to
enforce the required properties of RCs within the Linux kernel.
An experimentation is presented with several honeypot hosts
exposed to the Internet including well known vulnerabilities.
It shows that our MAC approach correctly prevented the RCs
attacks. Finally, a performance study shows the real efﬁciency
of our implementation.
The paper is organized as follows. Next section details ex-
isting work and motivates the paper. Section III gives a formal
deﬁnition of the operating system and information ﬂows. In
Section Section III-D is presented our general deﬁnition of
RCs, followed in Section III-E with the description of our
linux kernel module PIGA-DYNAMIC-PROTECT. Section IV
presents experiment results. Lastly, Section V gives perfor-
mance evaluations, before concluding the paper, in Section
V-B.
II. RELATED WORK
In this section, we ﬁrst present the state of the art of race
condition. Then, we do a scope of the different protection
mechanisms that have been proposed for operating system.
Finally, we explain our motivation.
A. Race Condition
The authors of [2] have proposed an informal deﬁnition of
a race condition:
Deﬁnition 2.1 (Informal deﬁnition of a race condition):
A race condition happens when there is an unpredictable
34
International Journal on Advances in Software, vol 4 no 1 & 2, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

schedule between accesses of two subjects X and Y to a
shared resources I, having at least one of the two former
subjects performing a write operation to the shared object
between two accesses of the other subject to the shared
object.
Thus, the state of the system depends on the execution order
and thus is unpredictable.
It exists different types of race condition: on data [3], on
signals [4] and on any shared resources. The more common
case of race condition is the one associated with preliminary
checks done by applications on resources. This race condition
is known as time-of-check-to-time-of-use (TOCTTOU) and has
been deﬁned in [5]. Most of the ﬁlesystems are vulnerable to
such attack [6], [7]. Moreover, with the increase of processors’
cores within a single operating system, the detection of (and
protection against) race condition becomes more and more
complex. Indeed, within this scope, the detection becomes a
NP-Complete problem [8].
Four main approaches are used to protect against race
conditions:
• Code analysis: By analyzing the code before compiling
it, it is possible to detect and ﬁnd parts of code that could
lead to race condition ﬂaws [7], [9], [10], [11];
• Dynamic detection: By auditing system calls that could
be used to build a race condition attack, it is possible to
detect them. The most known approach is the one by Ko
and Redmond [12] that detects race conditions but are
not able to protect against them. Other approaches [13],
[14] have used the same idea;
• Dynamic protection: When the concurrency is detected, it
is possible to kill or suspend the corresponding process or
system call. The authors of [15], [16], [17] have proposed
this kind of approach to protect a system.
• Filesystems: It is possible to build ﬁlesystems that take
into account race conditions and concurrency. Two kinds
of such ﬁlesystems have been proposed: one using trans-
actional ﬁlesystems [18], [19] and one with system calls
designed to deal with concurrency [20], [21].
But, except fully transactional systems, no approach pro-
poses a complete protection against race conditions. Trans-
actional approaches misﬁt for operating systems. Moreover,
the previous approaches can not express explicitly which race
condition to control and do not deal with all the kinds of race
condition.
B. Operating System Protection
Two main models of protection are currently used in oper-
ating systems. They are used to control the access of the users
on ﬁles and others objects based on privileges. The Role Based
Access Control [22] (RBAC) does not change anything in term
of security, it eases the writing of security policies.
The Discretionary Access Control (DAC) is the oldest pro-
tection model. But it is always the main access control model
used in modern operating system (Unix, MS Windows, Mac
OSX, ...). With DAC, the privileges are set by the user who
owns the object. For example, the owner of a ﬁle deﬁnes the
read, write, execute privileges on its ﬁles for the other users on
the system (himself, the ones within his group and the others).
Multiple studies [23], [22], [24] have shown the weakness of
DAC models. Indeed, it is based on the fact that users can set
efﬁciently the permissions on their ﬁles. But any errors can
lead to a security ﬂaw. For example, if the users password
ﬁle can be written by any users, anyone with an account on
the operating system can change super-user password and thus
obtain its privileges.
The Mandatory Access Control (MAC) allows to setup a
policy that can not be change by end-users. To monitor the
access between subjects and objects, Anderson [25] has pro-
posed to use a Reference Monitor. This concept is the base of
Mandatory Access Control. It was deﬁned for Bell&LaPadula
approach [26] but is now used to describe any mechanism
that put the management of the security policy outside the
scope of end-users. To ease the writing of security policies for
operating system, it is needed to associate each entity (subject
and object) with a type. This approach of Type Enforcement
has been introduced in [27]. It facilitates the deﬁnition and
aggregation of security model. But the drawback of the MAC
approach is the difﬁculty to deﬁne efﬁcient security policies.
Indeed, you need to have an in-depth knowledge of how work
the operating system (and its applications) and the security
objectives that you want to reach. It is the cause of the low
usage of the MAC approach (GRSecurity, SELinux) in modern
operating systems.
Approaches like [28], [29], [30] try to bring the ease of
DAC with the protection of MAC. They state that: “a good
enough and usable policy is better than a very good security
but hard to manage”. But it is dedicated to the protection of
a desktop operating system from network attacks. Moreover,
they can not express security models and the quality of their
protection is questionable as they does not take into account
indirect ﬂows and based their models on DAC permissions.
Others approaches [31], [32] are oriented toward the control
of information ﬂow. The purpose is to isolate users from
each others. In this kind of approach, the security is enforced
by a reference monitor within the system but the policy are
written by the application developers. Indeed, [31] states that
developers are best to know which security is needed by their
applications. Moreover, the protection is done by the operating
system with a reference monitor in the kernel. Thus, even if the
application contains ﬂaws, it respects the security policy. This
model has been extended to GNU/Linux with the Flume [33]
framework. They also proposes a limited language to describe
the information ﬂow control policy. But all those approaches
can not combine ﬂows. Thus, they are limited to describe
simple security models. Moreover, they request to rewrite part
of the applications’ code. The authors of [34] have modelized
Flume to prove that it does not contain covert channels. It
does not prove the expressiveness of their language but the
dependability of their system.
35
International Journal on Advances in Software, vol 4 no 1 & 2, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

C. Motivation
First, we have explain the need of a mandatory approach
to avoid the weakness of a discretionary control. But, current
mandatory models do not explicitly take into account transitive
ﬂows and are hard to implement on a real operating system.
Second, the existing protections of operating systems do not
propose a language to express security objectives. Thus, they
can not be used to express a complete formal security policy.
The approaches based on the control of the information ﬂows
are difﬁcult to use and do not propose a language to express
security properties.
Our goal is to ease the deﬁnition of any security properties
in order for the operating system to guarantee the requested
properties. In this paper, we focus on race conditions but
others properties have been already deﬁned [35]. The proposed
security property for protecting against race conditions needs
to take into account all kinds of race conditions (ﬁlesystems,
signals, any kind of data, etc). This property is formally
expressed. It explicitly deﬁnes the subjects that are protected.
Moreover, our language takes into account the dynamicity of
a real operating system i.e. its state can change at anytime.
The dynamicity is very important as we want to be able
to implement our language and our protection on existing
operating systems. The ability to implement our proposal is
important as it is a mean to provide a large scale of real world
experimentations.
III. SYSTEM AND SECURITY PROPERTIES MODELING
In order to formalize the security property that protects
against RC attacks, in terms of activities on the operating
system, let us ﬁrst deﬁne the model of the target system. The
ﬁrst requirement is to be able to associate a unique security
label (also called security context) to each system resource. A
security context can be a ﬁle name or the binary name executed
by a process. Our system ﬁts well for DAC OS (GNU Linux,
Microsoft Windows) or MAC ones such as SELinux whereas
security contexts are special entities controlled by the kernel.
A. System dates, entities and operations
In essence, an operating system is deﬁned by a set of entities
performing operations on other entities. Those entities are
referred here as ‘security contexts’. Acting contexts are called
subject contexts while passive ones are called object contexts.
Formally, an operating system consists of the following
elements:
• A set of system dates D.
Any d ∈ D is a number representing a system date.
• A set of subject security contexts SSC.
Each ssc ∈ SSC characterizes an active entity, i.e.
processes, that can perform actions, i.e. system calls.
• A set of object security contexts OSC.
Each osc ∈ OSC characterizes a passive entity (ﬁle,
socket, . . . ) on which system calls can be performed.
• A set of all security contexts SC = SSC ∪ OSC, with
SSC ∩ OSC = ∅.
For example, let us consider the apache webserver read-
ing an HTML ﬁle. The apache process is identiﬁed as a
subject (/usr/bin/apache ∈ SSC in a classical Linux
system or apache_t ∈ SSC in a SELinux environment)
and the ﬁle is considered as an object (/var/www ∈
OSC in a classical Linux system or var_www_t ∈ OSC
in a SELinux environment).
• A set of elementary operations EO.
EO denotes all the elementary operations, i.e. system
calls, that can occur on the system (i.e. read_like and
write_like operations).
• A set of interactions : IT : SSC × EO × SC × D × D.
Each element of IT
is thus a 5-uple that formally
represents an interaction on the system. In essence, an
interaction it ∈ IT represents a subject ssc ∈ SSC
invoking an operation eo ∈ EO on a given context
tsc ∈ SC, starting at a system date s and ending at a
system date e.
• A system trace T.
The execution of an operating system can be seen as
a set of invoked interactions. The executed interactions
modify the OS state [17]. When we consider prevention,
we work with an invocation trace. The invocation trace
contains thus all tried interactions, even those which are
ﬁnally not allowed to be executed. Thus, each time an
interaction iti occurs on a given system (before being
allowed, in case of prevention system), the corresponding
system trace becomes Ti ← Ti−1 ∪ iti.
B. Information Flows
1) Direct Information Flows: In terms of information ﬂows,
when an interaction occurs (i.e. an elementary operation is
performed), there is one potential consequence: that interaction
can produce an information ﬂow from one security context to
another.
An information ﬂow transfers some information from a se-
curity context sc1 to a security context sc2 using a write_like
operation or to sc1 from sc2 using a read_like operation1.
The formal modeling of the system is then extended with
the following sets:
• A subset of EO of read_like operations REO.
• A subset of EO of write_like operations WEO.
Deﬁnition 3.1 (Direct Information Flow): Given a system
trace T, a direct information ﬂow from a subject context
ssc performing a write_like operation to a target context
tsc, starting at a system date s and ending at a system
date e (formally an interaction: (ssc, weo, tsc, s, e), where
ssc ∈ SSC, tsc ∈ SC, weo ∈ WEO, s ∈ D, e ∈ WEO, and
s ≤ e), is denoted by: ssc
T▷[s,e] tsc.
Symmetrically, a direct information ﬂow from a subject
context ssc performing a read_like operation to a target
1To be able to decide if an interaction produces an information ﬂow between
two security contexts, we use a mapping table (not detailed here) that says
for each eo ∈ EO if it can ﬂow information – and in what direction between
the two security contexts – or not.
36
International Journal on Advances in Software, vol 4 no 1 & 2, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

it  (write_like)
  1
it  (read_like)
  2
direct flow 1
direct flow 2
it  ends
 2
it  starts
 2
it  ends
 1
it  starts
 1
sc
1
sc
2
sc
1
sc
2
sc
3
sc
3
indirect flow
time
security contexts
Interactions
Information flows
Fig. 1.
r/w_like interactions and corresponding information ﬂows.
context tsc starting at s and ending at e is denoted by:
tsc
T▷[s,e] ssc.
Notice that we use the following abuses of notation when
respectively s, e or both are not explicitly required:
T▷[_,e],
T▷[s,_],
T▷.
2) Indirect Information Flows: As said previously, an infor-
mation ﬂow can occur directly between two security contexts.
But it can also happen in many indirect ways. For example,
there can exist a ﬁrst ﬂow ssc
T▷ osc and then a second ﬂow
osc
T▷ tsc. We consider this as an indirect information ﬂow
from ssc to tsc. Transitively, there can theoretically be an
inﬁnite number of intermediary contexts between ssc and tsc.
We propose the following deﬁnition of indirect information
ﬂows:
Deﬁnition 3.2 (Indirect Information Flow): Given a system
trace T, an indirect information ﬂow from one context sc1 to
another context sck, starting at a system date s1 and ending at
a system date ek, denoted by sc1
T▷▷[s1,ek] sck (i.e., k is the
number of contexts involved in the indirect ﬂow), is formally
deﬁned by:



∃k ∈ [3.. + ∞], ∀i ∈ [1..k − 2], sci ∈ SC, {si, ei} ∈ D,
(sci
T▷[si,_] sci+1) ∧ (sci+1
T▷[_,ei+1] sci+2)
∧ (si ≤ ei+1)



The Figure 1 shows an example of such an indirect informa-
tion ﬂow where k = 3. The ﬁrst interaction it1 is a write_like
operation from sc1 to sc2. The second interaction it2, is a
read_like operation of sc3 to sc2. Thus, sc3 gets information
from sc2. So, there is an indirect information ﬂow between
sc1 to sc3 via the shared context sc2.
3) General Information Flows: The two previous deﬁni-
tions lead to a more general deﬁnition of information ﬂows. In
essence, there exists an information ﬂow between two security
contexts iff there exists a direct ﬂow or an indirect ﬂow
between those contexts.
Deﬁnition 3.3 (General Information Flow): Given a sys-
tem trace T, an information ﬂow from one context sc1 to
another context sck, starting at the system date s1 and ending
at the system date ek, denoted by sc1
T▷▷▷[s1,ek] sck, is
e
  2
s  
  2
s 
  1
lsc
osc
msc
time
security contexts
...
...
e
  3
General Information 
   Flow 1
   General Information
 Flow 2
   General Information
Flow 3
Fig. 2.
Example of RC between lsc and msc.
formally deﬁned by:
(sc1
T▷[s1,ek] sck) ∨ (sc1
T▷▷[s1,ek] sck)
Again, by abuse of notation,
T▷▷▷[_,e] ,
T▷▷▷[s,_] , and
T▷▷▷
is used when s, e or both are not explicitly required.
C. Race Condition
As presented earlier, [2] gave a general deﬁnition of RC that
we express here under our formalism in order to be able to
deﬁne an enforceable security property to prevent RC attacks.
Deﬁnition 3.4 (General Race Condition): A RC happens
when there is an unpredictable schedule between accesses of
two security contexts sc1 and sc2 to a conﬂicting data context
osc (i.e. a shared security context), having at least one of
the two former contexts (e.g., sc1) performing a write_like
operation to the shared context osc between two accesses of
the other context (e.g., sc2) to the conﬂicting data context osc.
D. Race Condition Security property
Using the General RC deﬁnition above, and in order to
detect or prevent RC based attacks, we propose to deﬁne a
general Security Property for the prevention of RC attacks.
Security Property 3.1: A security context lsc is protected
against a RC from another security context msc iff msc can
not transfer information to a shared context osc between two
accesses of lsc to this shared context osc.
Formally: No_Race_Condition(lsc, msc, T) ⇔
¬








∃osc ∈ SC ∧

user_d
passwd_d
shadow_t
login_d
root_d
tmp_t
<1140,3117>
<1213,3279>
<1677,1856>
<1812 ,  3796>
<1802,1817>
<1752,1762>
<1825,1827>
<1157,3128>
<1846,1895>
<1907,2114>
sshd_d
Subject Context
Object Context
Multiple direct flows
Fig. 3.
IFG for the login RC scenario.
The Figure 2 shows one of those possible schedules. The
ﬁrst information ﬂow represents an access from a legitimate
context lsc to a shared context osc. It corresponds to the line
#1 of the No_Race_Condition security property. The second
information ﬂow corresponds to line #2 of the property. It
represents a ﬂow from a malicious context msc to osc after
or concurrently to the ﬁrst ﬂow. The third ﬂow on the Figure
corresponds to the line #3 of the property. It represents the
second access from lsc to osc (partially) after or during the
modiﬁcation of osc by msc. The line #4 of the property
expresses temporal constraints between the ﬂow, for sequential
or concurrent situations.
E. Enforcing the RC security property
In contrast to [2], this deﬁnition, based on information ﬂows,
allows us to provide an effective and efﬁcient algorithm and
related implementation for the protection against RC attacks.
Our solution computes an Information Flow Graph (IFG).
An example of an IFG is given in Figure 3. The IFG manages
the temporal relationships between the security contexts using
one parameter on each edge connecting two security contexts.
This parameter is a couple of system dates of the ﬁrst and
last occurrences of the represented information ﬂow. Actually,
those are the dates of read_like or write_like interactions.
Thus, an edge on the IFG (e.g., tmp_t ▶<1802,1817>
login_d) can represent multiples ﬂows (e.g., three ﬂows
tmp_t
T▷[1802,1804] login_d,
tmp_t
T▷[1805,1809] login_d
and tmp_t
T▷[1815,1817] login_d) using only two dates (e.g.,
1802 and 1817).
Obviously, using multiple direct ﬂows instead of single
direct ﬂows clearly provides an over-approximation of the
latter ones on the system. But this has the great advantage
of highly reducing the IFG’s size. The number of nodes is
theoretically bounded by n = O(|SC|), whereas the number of
vertexes is theoretically bounded by v = O(|SC|×|SSC|−1).
It thus can ﬁt in memory2.
2E.g., for a Gentoo Linux OS, n < 580 and v < 80000.
Within IFG, the search of an indirect ﬂow between two
security contexts is done by searching for a path between
the two nodes corresponding to the security contexts. We are
using a Breadth First Search (BFS) algorithm that also veriﬁes
causal dependency between each direct ﬂows that compose
the indirect one. The use of a BFS algorithm allows to have
a theoretically bounded complexity of searching indirect ﬂow
due to the nature of IFG.
When we want to compare indirect ﬂows, we need to ﬁnd all
the occurrence of those ﬂows. Our indirect ﬂow algorithm is
able to enumerate all the ﬂows between two security context.
For example, on the Figure 4, the algorithm enumerates two
ﬂows from sc1 to sc5. Those two ﬂows have different ending
date: 1010 for the ﬁrst one f3a (#1 → #2 → #4) and 1150
for the second one f3b (#1 → #3 → #5). This ability is
important for the race condition algorithm as we search for
temporal relation between ﬂows. If we have only one of the
two occurrences of the ﬂow, we can miss a race condition. For
example, if we have only f3a that ends at 1010 and we want
to compare it with a ﬂow f2 that start at 1025, the condition
s2 ≤ e3 will be false. But if we have the two ﬂows f3a and
f3b, the condition will be true as start(f2) ≤ end(f3b).
Fig. 4.
Search all the occurrences of a ﬂow between sc1 and sc5 in the IFG
Using the IFG and the general information ﬂow algorithm,
we are able to compile the property 3.1 into an algorithm.
The algorithm 1 allows to detect any race condition between
a legal entity lsc and a malicious one msc. This algorithm
uses a function that returns every ﬂows corresponding to three
general ﬂows between lsc and msc. Indeed, we need to verify
the temporal relationships between those ﬂows as described in
the property 3.1 ((s1 ≤ e2) ∧ (s2 ≤ e3)). In the algorithm,
it1 is the current interaction i.e. the interaction that is in the
authorization process. The algorithm 1 is a variation of the
property 3.1 with the third ﬂow between the shared object
osc and the legal security context lsc must be a direct ﬂow.
In practice, it is usually the case. Moreover, this algorithm
goes further than previous approaches as it takes into account
indirect ﬂows in two case out of three. This variation of the
property 3.1 allows to reduce the overall complexity of the
algorithm. Indeed, we only use the indirect ﬂow algorithm
two times instead of three.
F. Protecting an Operating System
This section presents PIGA-DYN-PROTECT i.e. our dy-
namic approach to guarantee the security properties expressed
38
International Journal on Advances in Software, vol 4 no 1 & 2, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Fig. 5.
Global architecture of our protection system
Algorithm 1 Algorithm to detect race condition from lcs to
mcs : No_Race_Condition(lsc, msc, it1, IFG)
Require: lsc, msc, it1, IFG
if op(it1) ∈ WEO or op(it1) ∈ REO then
iflow1 = lcs
T▷▷▷ dest(it1)
iflow2 = mcs
T▷▷▷ dest(it1)
list_flow1 = searchAllPath(iflow1, IFG)
list_flow2 = searchAllPath(iflow2, IFG)
if list_flow1 ̸= NULL and list_flow2 ̸= NULL then
for all flow1 ∈ list_flow1 do
for all flow2 ∈ list_flow2 do
if start(flow1) ≤ end(flow2) then
return
FALSE
end if
end for
end for
end if
end if
return
TRUE
with our language. PIGA-DYN-PROTECT enforces a policy
that is a set of security properties. Our architecture reuses
SELinux security contexts. SELinux provides a context for
all processes, users and system resources. In contrast with
approaches like [30], [36], [37], [17], [16], we do not re-
quire a unique context for each entity e.g., /tmp/file1 and
/tmp/file2 are grouped in a common label tmp_t. However,
the SELinux policy is not required. Our solution is a satisfying
approach since deﬁning a consistent SELinux policy is a
complex task. On the other hand, [38], [39] show that a
SELinux protection policy can still present around a million
of attack vectors. So, adding a protection against RC over
SELinux security contexts is very efﬁcient.
Figure 5 describes the global architecture of our protection.
This architecture is composed of several components. We
choose to illustrate each component based on the execution of
a system call. In this example, an application calls a function
fread. The library C (libc) provides this function. Then,
the library calls the read system calls to communicate with
the kernel of the operating system. This system call allows
to execute a read in kernel space. Indeed, it is the only
way to perform an input/output access to transfer information
from or to a physical resources like a hard drive. Before
this input/output operation, the kernel checks the discretionary
permissions such as read, write and execution rights. If the
operation is allowed by DAC then it calls the Linux Security
Module (LSM). LSM is used to plug new security modules that
hook system calls. LSM is used to call the SELinux module.
Then, this module applies Type Enforcement on the system
i.e. it sets a context for each entity of the operating system.
PIGA-DYN-Protect is called by SELinux and collects all the
information needed to build the trace of the system calls.
This trace is sent to PIGA-DYN that uses it to build the IFG.
It computes that graph to verify if the current system call
goes against a security property. The decision is returned to
PIGA-DYN-Protect then to SELinux. Finally, LSM receives
the decision and allows or denies the system call.
In practice, for our RC property, the decision is taken at the
last step of an attack attempt i.e. on the third system call. Thus,
our solution prevents efﬁciently the third ﬂow of a RC attack.
39
International Journal on Advances in Software, vol 4 no 1 & 2, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

user_d
passwd_d
shadow_t
sshd_d
login_d
tmp_t
<1140,3117>
<1213,3279>
<1677,1856>
<1812(s2),3796(e2)>
<1802,1809>
<1752(s1),1762>
<1157,3128>
<1846,1895>
3rd (direct) flow of the RC:  
denied by PIGA-Dyn-Protect    
Subject Context
Object Context
Multiple direct flows
Single direct flow
[1815(s3),1817(e3)]
tmp_t
 T 
login_d
Fig. 6.
IFG for the real protection against the login RC attack.
Moreover, our solution protects against unknown attacks (e.g.,
0-Day attacks) and various covert channels associated with
indirect ﬂows.
G. Example of prevention of a Race Condition
Let
us
give
an
example
of
the
No_Race_Condition
property.
The
property:
No_Race_Condition(login_u:login_r:login_d,
user_u:user_r:user_d,
T)
prevents
a
user
process
(user_u:user_r:user_d) to interfere with the login process
(login_u : login_r : login_d) via a RC attack.
The IFG given in Figure 3 describes the so-called ‘login RC’
attack scenario. Thus, the ﬁrst ﬂow of the considered property
can be seen as the direct ﬂow login_d
T▷[1752,1762] tmp_t.
The second ﬂow is a direct ﬂow user_d
T▷[1812,3796] tmp_t .
The third ﬂow is the direct ﬂow tmp_t
T▷[1802,1817] user_d.
Using this IFG, we are able to block the system call corre-
sponding to the third ﬂow at the kernel level. It thus avoids to
exploit the login’s vulnerability via a RC attack.
IV. REAL WORLD EXPERIMENT
To make real world experimentation of our solution, we
have setup a high-interaction honeypot. It contains services
with exploitable ﬂaws to ease the attacks. A virtual machine
provides the different services. During six month, we exper-
imented many instances of the No_Race_Condition security
property. Let us give the results for two of them. The ﬁrst
one was the protection against the Login RC attack (already
mentioned) and the second was the protection against the
PhpBB RC attack. Others instances, not presented here, cover
attacks on ﬁlesystems, network services and shell scripts.
As any mandatory protection, PIGA-DYN-PROTECT is an
over-approximation of the attacks thus it can generate false
positives. On the other side, the false negatives are due to a
bad deﬁnition of the property or an incorrect conﬁguration
of it. Thus, it can be ﬁxed through a new deﬁnition for the
property or another conﬁguration of it.
A. The Login attack RC to gain root privilege
To welcome attackers for the ﬁrst evaluated attack: the
‘Login Race Condition’, we setup SSH servers on three
machines of our honeypot. Those servers accepted attackers
with the automatic creation of accounts when couples of
login/password were tried.
The attack scenario is the following. An attacker (user_d)
connects to the SSH server (ssh_d). Then, the attacker uses
the authentication service (passwd_d) and gains a user session
(user_d) on the machine. He uses his session to execute
the login command (login_d). Then, he exploits the login’s
vulnerability by changing a value stored in the temporary
ﬁle (tmp_t). When the login process comes back later to
read the (modiﬁed) value, that allows a privilege escalation of
user_d to login_d that has root privileges. The attacker uses
this privilege escalation to modify the shadow passwords ﬁle
shadow_t and especially the root password. The attacker then
uses the login command again to open a root session (root_d)
with the new root password. This attack only involves direct
information ﬂows.
Let us consider a system without our protection solu-
tion in order to detail the ‘Login RC’ attack scenario. The
IFG given in Figure 3 corresponds to the violation of a
No_Race_Condition security property. In this ﬁgure, the
temporal constraints (line #4) of the No_Race_Condition
security property between user_d and login_d are true:
(1752(s1) < 3796(e2)) ∧ (1812(s2) < 1817(e3)).
Our PIGA-DYN-PROTECT module cancels the last interac-
tion of the third ﬂow in order to avoid the RC success. In the
example, PIGA-DYN-PROTECT denies the execution of the
interaction at system date 1817. Thus PIGA-DYN-PROTECT
cancels the interaction corresponding to the (single) direct
ﬂow tmp_t
T▷[1815,1817] login_d: the third ﬂow violating the
No_RC property does not appear in the real IFG, as shown
in Figure 6.
As shown in the ﬁgure 8, we were able to monitor multiple
attacks during the six months experimentation. Moreover,
through SELinux logs analysis [40], we were able to validate
that all the attacks were detected by our solution. With the
protection mode, all the attacks were blocked and no attacker
was able to gain root privilege.
B. PhpBB RC for Remote Shell Execution
We also experimented another kind of RC attacks: the
PhpBB RC attack that can lead to a ‘Remote Shell Execution’.
In order to collect attacks, we build a fake PhpBB forum. We
also advertised about cgi scripts (bash and binary) execution.
For
this
experiment,
the
security
property
against
RC
was
conﬁgured
as
the
following:
No_Race_Condition(apache_u:apache_r:apache_d,
apache_u:apache_r:phpbb_d, T). Compared to the login RC,
40
International Journal on Advances in Software, vol 4 no 1 & 2, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

user_d
apache_d
phpbb_d
cgi_web_t
shell_d
http_socket_t
shell_t
phpbb_php_t
etc_shell_config_t
<6307,   11127>
<6356 , 11186>
<6422,   12158>
<6405 , 12107>
<6501 , 9147>
<6679 , 9252>
<7719(s2) , 8834>
<7750 , 7762>
<7738 , 7746> 
<113, 7822(e2)>
<234(s1), 8843(e1)>
<279(s3), 9001(e3)>
[7719(s2),7822(e2)]
phpbb_d
 T 
cgi_web_t
Subject Context
Object Context
Multiple direct flows
Single indirect flow
Fig. 7.
IFG for the phpBB RC attack scenario.
June
July
Aug
Sept
Oct
Nov
attacks
0
20
40
60
80
NoPIGA
PIGAIDS
PIGAIPS
Fig. 8.
Number of attacks per month per machine for the login race condition
this attack is a more complex one. The Figure 7 describes
the PhpBB attack scenario. First, the attacker (user_d)
has to connect to the apache server (apache_d) through a
socket (http_socket_t) and accesses to the PhpBB forum
(phpbb_d). Then, the attacker uses the remote execution
exploit in the PhpBB forum to execute a shell (shell_d).
He uses the shell to modify the cgi scripts (cgi_web_t).
In summary, this RC based PhpBB attack involves direct
and indirect information ﬂows. The ﬁrst ﬂow of the attack
is apache_d
T▷[234,8843] cgi_web_t. The second one is
indeed an indirect ﬂow: phpbb_d
T▷▷[7719,7822] cgi_web_t
(via
shell_d).
The
third
ﬂow
is
a
direct
one:
cgi_web_t
T▷[279,9001] apache_d.
In the RC PhpBB attack scenario given in Figure 7, the
temporal relations between ﬂows violate the temporal con-
straints (line #4) of the No_Race_Condition security property
between apache_d and phpbb_d: (234(s1) < 7822(e2)) ∧
(7719(s2) < 9001(e3)).
Again, our PIGA-DYN-PROTECT module denies the last
interaction of the third ﬂow. It thus forbids the execution of
the corresponding interaction at the system date 9001.
As shown in the ﬁgure 9, we were able to monitor multiple
attacks during the six months period of our experimentation.
Same as login RC attacks, all the phpBB attacks were detected
and blocked.
V. EFFICIENCY
A. Completeness
To evaluate the correctness of our approach, we conﬁgured
our honeypot hosts with PIGA-DYN-PROTECT in both detec-
tion and prevention mode. That way, we could verify that every
detected attack was prevented or not. During the six months of
experiment, we detected 146 instances of the login RC attack
and 574 instances of the PhpBB RC attack. All attacks were
blocked by our protection mechanism.
B. Performances
In order to evaluate the performances of our solution, several
benchmarks are proposed for three different conﬁgurations:
• a classical Linux system with DAC and SELinux TE.
• a Linux system with DAC and SELinux TE with PIGA-
DYN in analysis mode for detecting the violation of the
required security properties (PIGA-IDS).
• a Linux system with DAC and SELinux TE with PIGA-
DYN in protection mode for enforcing the required secu-
rity properties (PIGA-IPS).
The hardware conﬁguration was the same, a Pentium-4 3Ghz
with 1Gb of memory.
We use lmbench [41] suite running on these three machines
to measure bandwidth and latency. Lmbench attempts to
measure performance bottlenecks in a wide range of system
applications. These bottlenecks have been identiﬁed, isolated
41
International Journal on Advances in Software, vol 4 no 1 & 2, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

June
July
Aug
Sept
Oct
Nov
attacks
0
100
200
300
400
NoPIGA
PIGAIDS
PIGAIPS
Fig. 9.
Number of attacks per month per machine
Operation
Description
memory read
Measuring time to read x byte word from memory
memory write
Measuring time to write x byte word to memory
memory read/write
Measuring time to read an write x byte word to memory
TABLE I
MEMORY OPERATIONS FROM LMBENCH
and reproduced in a set of microbenchmarks that measures
the system latency and bandwidth of data movement. First,
we focus on the memory subsystem and measure bandwidth
with various memory operation listed in the table I.
As shown in the Figure 10, the difference between the
three different conﬁgurations is small. With data blocks larger
than 512Kb, the three conﬁgurations have almost the same
performances. With data blocks smaller than 512Kb, the
overhead due to our security component is unnoticeable. In
the worst case, like memory read/write, the overhead is 5%.
Consequently, we can state that our security component has
little to no inﬂuence on data copy to and from the memory.
In a second time, we used lmbench to measure latency in
ﬁve different parts of the operating system:
• Process: it creates four different types of process and
evaluates the time it takes 1) to invoke a procedure, fork
a process and close it, 2) fork a process and invoke the
execve system call and 3) fork a process and invoke an
interactive shell.
• Context switching: it measures the context switching time
for a number of processes of a given size (in Kb). The
processes are all connected through a ring of Unix Pipe
where each process reads its input pipe, does some work
and writes in its output pipe i.e. the input pipe of the next
process.
• System call: it measures the time to write one byte to
/dev/null. It permits to evaluate the interaction time with
the system.
• Filesystem: it measures the time to create and delete ﬁles
with a size between 0 and 10Kb.
• Network: it measures the time taken to make a HTTP
request (GET/) on a LAN and a WAN HTTP server.
syscall
procedure
latency (nanoseconds)
0
1000
2000
3000
4000
5000
NoPIGA
PIGAIDS
PIGAIPS
Fig. 11.
Syscall and Procedure Latency for the three operating systems
Figure 11 displays, on the ﬁrst set of columns, the latency
(in nanoseconds) to invoke a system call. The operating system
without our solution and with our solution in analysis mode
have the same latency. The overhead due to our solution
in protection mode is minimal (2% on average). Thus, our
solution has little to no inﬂuence on the system call latency.
The second set of columns shows the latency when invoking
a function in a program. The three operating systems have the
same latency. Our solution does not change the procedure call
latency. Indeed, the call of a procedure inside a program does
not require to compute any authorization.
Figure 12 displays the average time (in microseconds) to
create and destroy three types of process: ﬁrst one is just a
creation and a deletion, the second one is a creation then an
execution (execve), the third one is a creation then the invo-
cation of a shell (/bin/sh). The overhead of our two solutions
is high. Indeed, thousands of fork system calls, within few
seconds, create thousands of path searches. The overhead is
about 300% when using our solution in analysis mode and
42
International Journal on Advances in Software, vol 4 no 1 & 2, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

0
1000
2000
3000
4000
5000
6000
7000
8000
9000
512
1024
2048
4096
8192
16K
32K
64K
128K
256K
512K
1M
2M
4M
8M
16M
32M
64M
128M
256M
memory read (nopiga)
memory write (nopiga)
memory read/write (nopiga)
memory read (pigaids)
memory write (pigaids)
memory read/write (pigaids)
memory read (pigaips)
memory write (pigaips)
memory read/write (pigaips)
Fig. 10.
Memory bandwidth performance
fork+exit
fork+execve
fork+shell
latency (microseconds)
0
5000
10000
15000
20000
25000
30000
35000
40000
NoPIGA
PIGAIDS
PIGAIPS
Fig. 12.
Fork Latency for the three operating systems
WAN
LAN
latency (milliseconds)
0
20
40
60
80
100
120
140
160
NoPIGA
PIGAIDS
PIGAIPS
Fig. 13.
Network Latency for the three operating systems
800% in protection mode. This overhead can be reduced by
pre-computing the path on the IFG, such approaches are under
development. However, thousands of forks within a limited
time really is unusual. So, this overhead is not relevant of a
common usage.
As one can see on the Figure 13, the network latency is the
same for the three operating systems. The amount of access
control veriﬁcations for a network system call is small since
our solution does not have to do expensive path searches.
Figure 14 shows the average latency when switching from
a process to another one when 2, 4, 8 and 16 processes
communicate together through a ring of Unix pipe. The
overhead in analysis mode is about 4% on average. A context
latency (microseconds)
0
2
4
6
8
10
12
14
16
18
20
2
4
8
16
nopiga
pigaids
pigaips
Fig. 14.
Context Switch Latency for the three operating systems
create/delete per seconds
0
5000
10000
15000
20000
25000
30000
0Kb
1Kb
4Kb
10Kb
create (nopiga)
delete (nopiga)
create (pigaids)
delete (pigaids)
create (pigaips)
delete (pigaips)
Fig. 15.
Filesystem Latency for the three operating systems
switching generates dozens of access control requests. Our
solution is efﬁcient since it computes the dozens of requests
in a very short delay. With our solution in protection mode,
the overhead is less than 6%.
Figure 15 shows the timing of creating and deleting ﬁles on
a ﬁlesystem (an ext3 ﬁlesystem). It shows how many ﬁles can
be created in one second with a size of 0, 1, 4 or 10Kb and
43
International Journal on Advances in Software, vol 4 no 1 & 2, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

how many ﬁles can be deleted in one second with the same
size. The overhead of our two solutions is less than 1%.
This performance analysis shows that our solution (in anal-
ysis or protection mode) is efﬁcient for common usages. The
fork overhead corresponds to an unusual stress of the system.
To cope with such situations, we are looking at different pre-
computing and optimization methods while keeping a stable
memory usage.
Our paper presents a novel approach to protect a complete
operating system against attacks using Race Conditions. It
provides a large state of art showing that this problem still
is opened. Our solution prevents efﬁciently against both direct
race conditions and indirect ones. A new protection property
is deﬁned to cope with these various race conditions. That
property ﬁts with the enforcement by an operating system
against RCs.
An implementation is proposed for guaranteeing the pro-
posed security property within a Linux system. Our implemen-
tation provides a dedicated MAC approach. For compatibility
reasons, SELinux contexts are reused. However, the SELinux
enforcement is not required and the solution supports ordinary
DAC systems. It requires only security contexts associated to
the different system resources.
Our approach computes the illegal activities dynamically. It
allows to easily deﬁne security properties against RCs attacks.
Real examples show the efﬁciency of our approach for
preventing real attacks using race conditions. A complete
benchmark has been carried out to show the low overhead
of our solution. Improvements are on the way to cope with
unusual stress of the system.
Since our approach allows to formalize a wide range of
security properties, future works will tackle other security
properties dealing with integrity, conﬁdentiality and availabil-
ity.
REFERENCES
[1] J. Rouzaud Cornabas, P. Clemente, and C. Toinard, “An Information
Flow Approach for Preventing Race Conditions: Dynamic Protection of
the Linux OS,” in Fourth International Conference on Emerging Secu-
rity Information, Systems and Technologies SECURWARE’10, (Venise
Italie), pp. 11–16, 07 2010.
[2] R. H. B. Netzer and B. P. Miller, “What are race conditions? some issues
and formalizations,” LOPLAS, vol. 1, no. 1, pp. 74–88, 1992.
[3] Y. Yu, T. Rodeheffer, and W. Chen, “Racetrack: efﬁcient detection of
data race conditions via adaptive tracking,” SIGOPS Oper. Syst. Rev.,
vol. 39, no. 5, pp. 221–234, 2005.
[4] T. Tahara, K. Gondow, and S. Ohsuga, “Dracula: Detector of data
races in signals handlers,” (Beijing, China), pp. 17–24, IEEE Computer
Society, 2008.
[5] W. S. McPhee, “Operating system integrity in os/vs2,” IBM Syst. J.,
vol. 13, no. 3, pp. 230–252, 1974.
[6] M. Bishop, “Race conditions, ﬁles, and security ﬂaws: or, the tortoise
and the hare redux,” Technical Report, vol. 95, sept. 1995.
[7] M. Bishop and M. Dilger, “Checking for race conditions in ﬁle accesses,”
Computing Systems, vol. 9, pp. 131–152, 1996.
[8] R. H. Netzer and B. P. Miller, “On the complexity of event ordering for
shared-memory parallel program executions,” in In Proceedings of the
1990 International Conference on Parallel Processing, pp. 93–97, 1990.
[9] H. Chen and D. Wagner, “Mops: an infrastructure for examining security
properties of software,” in CCS ’02: Proceedings of the 9th ACM
conference on Computer and communications security, (New York, NY,
USA), pp. 235–244, ACM, 2002.
[10] B. Chess, “Improving computer security using extended static checking,”
in Security and Privacy, 2002. Proceedings. 2002 IEEE Symposium on,
pp. 160 – 173, 2002.
[11] B. Schwarz, H. Chen, D. Wagner, J. Lin, W. Tu, G. Morrison, and
J. West, “Model checking an entire linux distribution for security
violations,” in ACSAC ’05: Proceedings of the 21st Annual Computer
Security Applications Conference, (Washington, DC, USA), pp. 13–22,
IEEE Computer Society, 2005.
[12] C. Ko and T. Redmond, “Noninterference and intrusion detection,” in
Security and Privacy, 2002. Proceedings. 2002 IEEE Symposium on,
(Oakland, CA, USA), pp. 177–187, 2002.
[13] K.-s. Lhee and S. J. Chapin, “Detection of ﬁle-based race conditions,”
International Journal of Information Security, vol. 4, pp. 105–119, 2005.
10.1007/s10207-004-0068-2.
[14] A. Joshi, S. T. King, G. W. Dunlap, and P. M. Chen, “Detecting past and
present intrusions through vulnerability-speciﬁc predicates,” in SOSP
’05: Proceedings of the twentieth ACM symposium on Operating systems
principles, (New York, NY, USA), pp. 91–104, ACM, 2005.
[15] C. Cowan, S. Beattie, C. Wright, and G. Kroah-Hartman, “Raceguard:
kernel protection from temporary ﬁle race vulnerabilities,” in SSYM’01:
Proceedings of the 10th conference on USENIX Security Symposium,
(Berkeley, CA, USA), pp. 13–13, USENIX Association, 2001.
[16] E. Tsyrklevich and B. Yee, “Dynamic detection and prevention of
race conditions in ﬁle accesses,” in SSYM’03: Proceedings of the 12th
conference on USENIX Security Symposium, (Berkeley, CA, USA),
pp. 17–17, USENIX Association, 2003.
[17] P. Uppuluri, U. Joshi, and A. Ray, “Preventing race condition attacks on
ﬁle-systems,” in Proceedings of the 2005 ACM symposium on Applied
computing - SAC ’05, (New York, New York, USA), p. 346, ACM Press,
2005.
[18] F. Schmuck and J. Wylie, “Experience with transactions in quicksilver,”
in SOSP ’91: Proceedings of the thirteenth ACM symposium on Oper-
ating systems principles, (New York, NY, USA), pp. 239–253, ACM,
1991.
[19] C. P. Wright, R. Spillane, G. Sivathanu, and E. Zadok, “Extending acid
semantics to the ﬁle system,” Trans. Storage, vol. 3, no. 2, p. 4, 2007.
[20] D. Mazieres and M. Kaashoek, “Secure applications need ﬂexible
operating systems,” in Operating Systems, 1997., The Sixth Workshop
on Hot Topics in, pp. 56 –61, 5-6 1997.
[21] D. Tsafrir, T. Hertz, D. Wagner, and D. Da Silva, “Portably solving
ﬁle tocttou races with hardness ampliﬁcation,” in FAST’08: Proceedings
of the 6th USENIX Conference on File and Storage Technologies,
(Berkeley, CA, USA), pp. 1–18, USENIX Association, 2008.
[22] D. F. Ferraiolo and D. R. Kuhn, “Role-based access controls,” in
15th National Computer Security Conference, (Baltimore, MD, USA),
pp. 554–563, Oct. 1992.
[23] ITSEC, “Information Technology Security Evaluation Criteria (ITSEC)
v1.2,” technical report, June 1991.
[24] P. A. Loscocco, S. D. Smalley, P. A. Muckelbauer, R. C. Taylor, S. J.
Turner, and J. F. Farrell, “The Inevitability of Failure: The Flawed
Assumption of Security in Modern Computing Environments,” in Pro-
ceedings of the 21st National Information Systems Security Conference,
(Arlington, Virginia, USA), pp. 303–314, Oct. 1998.
[25] J. Anderson, “Computer security threat monitoring and surveillance,”
tech. rep., James P. Anderson Company, Fort Washington, Pennsylvania,
April 1980.
[26] D. E. Bell and L. J. La Padula, “Secure computer systems: Mathemat-
ical foundations and model,” Technical Report M74-244, The MITRE
Corporation, Bedford, MA, May 1973.
[27] T. Fraser and L. Badger, “Ensuring continuity during dynamic security
policy reconﬁguration in dte,” pp. 15 –26, may. 1998.
[28] N. Li, Z. Mao, and H. Chen, “Usable mandatory integrity protection for
operating systems,” in SP ’07: Proceedings of the 2007 IEEE Symposium
on Security and Privacy, (Washington, DC, USA), pp. 164–178, IEEE
Computer Society, 2007.
[29] T. Fraser, “LOMAC: Low Water-Mark integrity protection for COTS
environments,” Proceeding 2000 IEEE Symposium on Security and
Privacy. S&P 2000, pp. 230–245, 2000.
[30] Z. Mao, N. Li, H. Chen, and X. Jiang, “Trojan horse resistant discre-
tionary access control,” in SACMAT ’09: Proceedings of the 14th ACM
symposium on Access control models and technologies, (New York, NY,
USA), pp. 237–246, ACM, 2009.
[31] S. Vandebogart, P. Efstathopoulos, E. Kohler, M. Krohn, C. Frey,
D. Ziegler, F. Kaashoek, R. Morris, and D. Mazières, “Labels and event
44
International Journal on Advances in Software, vol 4 no 1 & 2, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

processes in the asbestos operating system,” ACM Trans. Comput. Syst.,
vol. 25, no. 4, p. 11, 2007.
[32] N. Zeldovich, S. Boyd-Wickizer, E. Kohler, and D. Mazières, “Making
information ﬂow explicit in histar,” in OSDI ’06: Proceedings of the 7th
USENIX Symposium on Operating Systems Design and Implementation,
(Berkeley, CA, USA), pp. 19–19, USENIX Association, 2006.
[33] P. Efstathopoulos and E. Kohler, “Manageable ﬁne-grained information
ﬂow,” SIGOPS Oper. Syst. Rev., vol. 42, no. 4, pp. 301–313, 2008.
[34] M. Krohn and E. Tromer, “Noninterference for a practical difc-based
operating system,” in SP ’09: Proceedings of the 2009 30th IEEE
Symposium on Security and Privacy, (Washington, DC, USA), pp. 61–
76, IEEE Computer Society, 2009.
[35] P. Clemente, J. Rouzaud-Cornabas, and C. Toinard, “From a generic
framework for expressing integrity properties to a dynamic enforcement
for operating systems,” in Transactions on Computational Science XI
(M. Gavrilova, C. Tan, and E. Moreno, eds.), vol. 6480 of Lecture Notes
in Computer Science, pp. 131–161, Springer Berlin / Heidelberg, 2010.
[36] H. Liang and Y. Sun, “Enforcing mandatory integrity protection in
operating system,” in ICCNMC ’01: Proceedings of the 2001 Interna-
tional Conference on Computer Networks and Mobile Computing (IC-
CNMC’01), (Washington, DC, USA), p. 435, IEEE Computer Society,
2001.
[37] N. Li, Z. Mao, and H. Chen, “Usable mandatory integrity protection
for operating systems,” in Security and Privacy, 2007. SP ’07. IEEE
Symposium on, (Oakland, CA, USA), pp. 164–178, May 2007.
[38] J. Briffaut, J.-F. Lalande, and C. Toinard, “A proposal for securing a
large-scale high-interaction honeypot,” in Workshop on Security and
High Performance Computing Systems (R. K. Guha and L. Spalazzi,
eds.), (Cyprus), ECMS, 2008.
[39] M. Blanc, J. Briffaut, J.-F. Lalande, and C. Toinard, “Enforcement of
security properties for dynamic mac policies,” in Third International
Conference on Emerging Security Information, Systems and Technolo-
gies (IARIA, ed.), (Athens/Vouliagmeni, Greece), pp. 114–120, IEEE
Computer Society Press, June 2009.
[40] M. Blanc, P. Clemente, J. Rouzaud-Cornabas, and C. Toinard, “Classiﬁ-
cation of malicious distributed selinux activities,” Journal Of Computers,
vol. 4, pp. 423–432, may 2009.
[41] L. McVoy and C. Staelin, “lmbench: portable tools for performance
analysis,” in ATEC ’96: Proceedings of the 1996 annual conference on
USENIX Annual Technical Conference, (Berkeley, CA, USA), pp. 23–
23, USENIX Association, 1996.
45
International Journal on Advances in Software, vol 4 no 1 & 2, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

