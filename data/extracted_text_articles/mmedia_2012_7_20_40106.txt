A Robust and Fast Gesture Recognition Method for Wearable Sensing Garments 
 
 
Ali Boyali 
Department of Computing 
Macquarie University  
Sydney, Australia 
ali.boyali@mq.edu.au 
Manolya Kavakli 
Department of Computing 
Macquarie University 
Sydney, Australia 
manolya.kavakli@mq.edu.au
 
 
Abstract‚Äî‚Äî There is an increasing demand for motion 
capture and full body gesture recognition due to fast paced 
ubiquitous computing developments and their requirements 
for natural input modalities. Analysis and synthesis of human 
body movements are significant issues in bio-medical 
applications for rehabilitation and identification purposes as in 
post-stroke patient rehabilitation and gait recognition studies. 
This paper presents the development of a robust gesture and 
posture recognition algorithm based on an emerging research 
field Compressed Sensing (CS) and Sparse Representation 
(SR), in signal processing for the wearable sensing garment 
which consists of a sensor network having piezo-resistive 
properties.  The gesture recognition algorithm presented in 
this study is highly accurate regardless of the signal acquisition 
method used and gives excellent results even for high 
dimensional signals and large gesture dictionaries. Our 
findings state that gestures can be recognized with over 99% 
accuracy 
rate 
using 
Sparse 
Representation-based 
Classification (SRC) algorithm.  We tested the algorithm using 
3 different gesture dictionaries acquired in 3 different gesture 
domains with user dependent and user independent test 
gesture and dictionaries. The system gives 100% recognition 
accuracy for the gestures performed by sensing t-shirt with 
two different gesture sets.  
 
Keywords-Gesture recognition; wearable sensing garments;  
compressed sensing;  sparse signal classification 
I. 
 INTRODUCTION 
Among the wide variety of motion capture tools in 
Human Computer Interaction (HCI) applications, Motion 
Capture (MoCap) suits are the most complex ones due to 
their high dimensional sensor networks producing complex 
data and the large amount of computations needed to 
interpret a complex data set. 
Motion capture in HCI applications has two aspects. The 
first aspect is the acquisition of motion information, 
extraction of parameters for reconstruction of motion in a 
virtual environment [1], and analysis of motion parameters. 
The second is the synthesis of captured motion information 
to extract meaningful context as in gesture recognition 
studies. Although these two aspects serve for distinct aims 
the latter cannot be implemented without capturing the data. 
The structure of motion capture suits is defined by the 
type of sensor signals, e.g. inertial, acoustic [2], optical, and 
magnetic or hybrid signal types which makes use of several 
signal domains. Every signal domain has pros and cons over 
other domains. Magnetic motion tracking systems suffer 
from distortion in their magnetic field [3], whereas optical 
and accelerometer based systems suffer from occlusion and 
inherent drift respectively [4, 5]. Other motion capture suits 
that employ mechanical connections are obtrusive and are 
not suitable for motion analysis [6, 7] in most cases. In this 
study, our goal is to develop a robust gesture recognition 
system for a wearable sensing garment, namely The Sensor 
T-shirt developed by the research teams at the Electronic 
Engineering Department of University Pisa, Italy [6, 7]. The 
sensor t-shirt consists of piezo-resistive sensor threads 
smeared on an elastic fabric substrate which allows the user 
to perform motions without any constraint. This feature of 
the sensor t-shirt makes it a perfect candidate for analysis 
and synthesis of the motion and many other possible studies. 
The Sensor T-shirt can be used to aid quadriplegic people to 
control a wheelchair using their available muscles [9]; or to 
assist in gesture analysis [10]. 
 The proposed gesture recognition system is based on a 
new research field, Compressed Sensing (CS) which brings a 
new insight into signal acquisition and recovery. CS and 
dimensionality 
reduction 
methods 
such 
as 
random 
projections have been studied intensively in pattern 
recognition studies. One of the most successful applications 
of CS and sparse signal recovery is implemented by Wright 
et al. [11] for face recognition under varying illumination 
and occlusion. The team simply benefit from the 
discriminative nature of sparse signal recovery to classify the 
faces and name their method Sparse Representation-based 
Classification (SRC). 
In this study, we show that gestures can be recognized 
with an accuracy rate of over 99% using the SRC algorithm 
without 
introducing 
an 
additional 
operator 
in 
the 
measurement domain. The adaptation of the SRC method is 
an advantageous approach in gesture recognition studies. 
This paper brings about following advantages in gesture 
recognition. 
 
‚Ä¢ 
Multi-dimensional gestures can be reshaped (multi 
dimensional readings are put into vector form) and 
represented as a one dimensional vector as in the 
study face recognition implemented by Wright et al. 
[11] and have a high recognition accuracy. 
142
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-195-3
MMEDIA 2012 : The Fourth International Conferences on Advances in Multimedia

‚Ä¢ 
No prior clustering algorithm is necessary, however, 
pre-classification algorithms can be used to reduce 
the computation time, and there is no upper and 
lower bound for the number of classes and the 
number of gesture classes. 
‚Ä¢ 
It can be applied in any signal acquisition 
environment. 
‚Ä¢ 
The algorithm achieves high accuracy for rich 
gesture databases.  
‚Ä¢ 
The feature selection is random. 
 
The rest of the paper is organized as follows. Section II 
gives brief description of the previous sensor garment and 
gesture recognition and CS and SRC based signal 
classification studies. Section III presents the contemplated 
gesture sets for wearable sensor t-shirt and the application of 
SRC for gesture recognition by sensor garments. The paper 
ends with conclusion section.  
II. 
PREVIOUS STUDIES 
The sensor t-shirt (Fig. 1) consists of a new class of strain 
sensors network developed at the university of Pisa in Italy 
[7] which satisfies the user requirements such as wearability, 
comfort and long term monitoring. The first study on 
mapping from sensor readings to position and posture 
domain are conducted by Tognetelli et al in the study [7] 
who developed and used the sensor garment equipping an 
elastomeric fabric with piezzo-resistive graphite stripes by 
smearing them on the garment.  
 
 
Figure 1.  Sensor Shirts and Data Acquisation System Used in 
Experiments (b-c [20]) 
 Tognetelli et al [7] define posture a geometrical model 
of body kinematics. According to the definition, when the 
sensor t-shirt is worn by a user and a posture is performed, 
the sensor network produces electrical signals strictly related 
to the posture. The non-linear signal behaviour of the 
network is modelled by the linear combination of 
exponential functions. The construct (a mapping function F) 
between the sensor space and kinematic configuration 
readings, and corresponding measurements by using a 
goniometer are stored in a database, and sensor readings are 
mapped using multi-variate piece-wise interpolation and 
function inversions. The proposed method in [7] is 
considered to be time-consuming by the authors as a high 
number of matrix inversions are necessary.    
There are numerous gesture recognition methods 
available in the literature. Some of these methods require 
feature extraction and clusterization algorithms peculiar to 
gestures that are designed for only their gesture domain and 
cannot be generalized unlike our gesture recognition 
algorithm which gives highly accurate results for different 
measurement and signal domains. On the other hand, 
stochastic Hidden Markov Models, Dynamic Time Warping 
and Neural Network based classification methods are 
common and the accuracy rates vary depending on the 
application. Although we tested our SRC based gesture 
recognition method for different measurement domains ‚Äì 
with a touchpad, an IR camera and piezo-resistive signal 
measurements, we only focus on gesture recognition 
performed by using the sensor jacket in this study. Therefore, 
we only review the research studies using the sensor jacket, 
CS, and SRC based classification in gesture recognition.   
CS and SR methods were first used in the study [12] by 
Akl and Valee for gesture recognition with a complementary 
algorithm Affinitiy Propagation (AP) proposed by Frey and 
Dueck [13] which clusters the data by message passing 
between the points. In their study, the gestural data which 
consists of accelerometer signals in x, y and z coordinates 
acquired by a Wiimote are clustered using the AP algorithm 
into gesture classes using the Dynamic Time Warping 
(DTW) similarity measure. Then, the gesture to be 
recognized 
is 
compared 
with 
candidate 
exemplars 
determined by AP. Final classification is carried out 
converting the classification problem to SR type by 
introducing a pre-processor. The CS solution is applied to the 
finalist exemplars hence recovering the gesture class with a 
high recognition rate attained. 
We tested the proposed algorithm by [12 and 19] for 
three different rich gesture sets. The critical issue is the pre-
classification algorithm which will be detailed after outlining 
the principles of CS and SRC.  
 Compressed Sensing (CS) and Sparse Representation 
(SR) of signals is a new research field which allows signals 
to be recovered with a few number of samples -much below 
the well-known Nyquist sampling rate from random/non-
adaptive measurements- as long as the signal is sufficiently 
sparse in measurement domain [13-17]. 
Mathematically, given a sufficiently k-sparse signal  
 ‚àà    whose members consists of a few nonzero k-
elements and zeros in a measurement domain with an 
orthonormal basis  (such as Fourier, Direct Cosine 
Transformation or wavelet bases), the whole content of x can 
be recovered by sampling via a random matrix  ‚àà  	  
which satisfies the Restricted Isometry Property (RIP) by 
preserving the lengths of k-sparse elements with the 
condition that m<<n. The resulting equation  
   is 
then solved by the linear programming method ‚Ñì1 
minimization.    
The SRC algorithm uses a dictionary matrix consisting of 
training samples. In the algorithm, first, training samples of k 
classes and the test image are converted to a column vector 
and projected on a lower dimensional space using a 
generated random measurement matrix. Then training 
vectors are stacked into a matrix to construct the dictionary. 
The resulting equation is solved to recover the sparse signal x 
by ‚Ñì1 minimization methods after the columns of the 
143
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-195-3
MMEDIA 2012 : The Fourth International Conferences on Advances in Multimedia

dictionary and test vector are normalized.  The SRC 
algorithm assumes the test image vector lie in the linear span 
of training samples (1) associated with the same class of 
object where the signal x[0, 0, 0, 0, Œ±1, Œ±2,‚Ä¶ Œ±n, 0, 0, 0, 0].  
 
 
  , ,+, , . . . , ,   
(1111) 
The pseudo code for the algorithm is as follows: 
 
‚Ä¢ 
Construct the dictionary matrix A=[œë,, œë,, ..  œë,] 
‚àà R !"#  for k classes by reducing the dimension 
using a random matrix having RIP and converting 
the samples,  and test image vector to one 
dimensional vectors œë and y 
‚Ä¢ 
Normalize the columns vector of reduced A% and the 
reduced test image vector y', 
‚Ä¢ 
Solve 
the 
‚Ñì1 
minimization 
problem 
x( 
argmin"‚Äñx‚Äñ subject to A%x = y' 
‚Ä¢ 
Compute the residuals ri(y) =  ‚Äñy' / A%Œ¥i  1x ÃÇ3‚Äñ 
where Œ¥i is a selection operator for x ÃÇ corresponding 
the ith class span in A 
‚Ä¢ 
Identify y by finding the minimum of ri(y)  
In the study by Akl and Valee [12], 3 axis gesture traces 
are 
divided 
into 
the 
acceleration 
components 
of 
corresponding axes Rx, Ry and Rz and the 

4	  4	  5	   
(2222) 
where 
4	 is the randomly sampled x component of the 
gesture to be recognized and 4	  is the classes of the 
remaining gesture traces after narrowing the AP results.  
They convert the recognition problem to CS and SR 
recognition problem as shown below. 
6	  789:14	
;3; 
 
(3333) 
<	  6	4	
œØ                     
(4444) 
Where Qx is the orthonormal basis for 4	 and 4	
œØis the 
pseudo-inverse of 4	thus the gesture recognition problem 
has a new form of 
:	  <	
4	  6	  5	
>   
(5555) 
Equation (5) is solved for all axis components to identify 
the gesture class by computing (6) and taking the minimum 
of (?@1A3.  
(?@  (	

  (B
  (C
   
(6666) 
The algorithm gives higher accuracy rates when the AP is 
applied with this method. The CS based classification with 
the introduction of the pre-processor operator only gives 
efficient results for a few gesture classes. If the AP is 
eliminated with our gesture sets.  
III. 
THE SENSOR JACKET SYSTEM AND SRC FOR 
GESTURE RECOGNITION 
The sensor t-shirt has 52 individual piezzo resistive 
sensor strips which are located from wrist to shoulders on the 
right and left side of the t-shirt. The data is acquired by the  
National Instrument Data Acquisition Unit (Fig. 1.).  
 There are three gesture classes to be recognized by 
wearing the sensor t-shirt in the first gesture set. These are; 
moving the arm from relaxed to front at shoulder level, from 
relaxed position to side at shoulder level and from side to 
front keeping the arm straight moving horizontally at 
shoulder level. However we further expands our gesture 
recognition study by designing a second gesture set to verify 
and repeat the study. The second gesture set includes 5 
gesture classes (Table 1.). 
TABLE I.  
TABLE 1. SECOND GESTURE SET 
 
Right arm up: Right arm is moved from 
rest to shoulder level straight, hand points 
ahead 
 
Right arm up at side: Right arm is moved 
from rest to shoulder level towards right 
straigthly  
 
Forearm is moved upper from the rest. 
 
Right hand is put on head from the relaxed 
position 
 
Right hand is put on heart level from the 
rest 
 
Each sensor reading (Fig. 2.) is sparse in Discrete Cosine 
Transform (DCT) domain. Before using sensor readings we 
apply a light Gaussian smoother to the readings to eliminate 
jitter on the data .  
144
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-195-3
MMEDIA 2012 : The Fourth International Conferences on Advances in Multimedia

 
 
Figure 2.  Sensor Data at 50 Hz (Readings from 52 Sensor Threads and a 
Local View) 
 All sensor readings are normalized, giving a zero mean 
and a variance of one.  All inactive sensor signals are 
eliminated defining an absolute total variation threshold that 
is the ratio of any value in a thread signal to the absolute 
value of the difference between maximum and minimum 
values. If  this ratio exceeds 10%,  it is assumed  to be there 
is a considerable variation in thread readings which 
contributes to the identification of  the activity and gestures 
(Fig 2).    
The remaining sensor readings are concatenated in a 
vector for an individual gesture. A gesture dictionary is 
constituted from three gesture classes by stacking the gesture 
traces as columns of the dictionary. The rest of the solution is 
to design a measurement matrix and apply ‚Ñì1 minimization. 
 CS theory states that if the signal is sparse in any 
domain, signals can be recovered with an overwhelming 
probability by random measurement matrices having The 
Restricted Isometry Property (RIP) condition. Random 
Gaussian or Achlioptas‚Äô matrix [18] can be used for both 
dimensionality reduction and measurements, since the values 
having RIP properties preserve distances in the embedding 
space. We use Achlioptas‚Äô matrix since 2/3rds of the matrix is 
sparse, making it easier to construct than a Gaussian matrix 
thus saving computation time.  
Achlioptas‚Äô matrix is defined as 
 
D‚àö3 G
1  HA9: I8JKLKAMA9
 1/6
0     HA9: I8JKLKAMA9
   2/3
/1  HA9: I8JKLKAMA9
  1/6
 
(7777) 
 
The pseudo code for the gesture recognition algorithm 
are as follows. 
‚Ä¢ 
Normalize the data, apply a Gaussian smoother and 
reshape all the gestures and the test gesture, and take 
DCT of each 
‚Ä¢ 
Find the longest length of gestures (lhmax) and make 
the other gestures of the same length by zero 
padding, and stack the training gestures into training 
matrix PQ  ‚àà RST	 	  
 
PQ 
U
U
U
U
V  
W
W
‚Ä¶
WX
W
W
‚Ä¶
WX
‚ãÆ
‚ãÆ
‚ãÆ
 
W
W
‚Ä¶
WXX
0
     0
    0
   0
Z
Z
Z
Z
[
 
 
(8888) 
 
‚Ä¢ 
Take m measurement from both the test gesture 
vector and the training matrix with the designed 
random measurement matrix Umxn to form the 
reduced equations 
'  P\Q, where x=[0, 0, 0, 0, Œ±1, 
Œ±2,‚Ä¶ Œ±n, 0, 0, 0, 0] consists of a few nonzero 
coefficients corresponding to gesture class. 
‚Ä¢ 
Solve 
the 
‚Ñì1 
minimization 
problem 
( 
L8]^A_	‚Äñ‚Äñ subject to P\Q  
' 
‚Ä¢ 
Compute the residuals ri(y) =  ‚Äñ
' / P\Q`A  1 ÃÇ3‚Äñ 
where `A is a selection operator for  ÃÇ corresponding 
the ith class span in P\Q 
‚Ä¢ 
Identify y by finding the minimum of ri(y)  
 
There are 10 gesture traces collected for each gesture 
class using sensor jacket for our gesture recognition study. 
We construct gesture dictionary by randomly choosing 6 
gestures from the database, the remaining 4 gestures from 
each class are used for testing purpose. The proposed 
algorithm gives 100% recognition rate for the sensor jacket 
gesture recognition.  This paper gives only a brief 
presentation of the recognition algorithm for the initial 
studies of gesture recognition with a sensing garment. 
However, we used the same method for other two gesture 
databases. 
The first database consists of 23 gestures (Fig. 3.) which 
are 2D gestures captured by the IR camera of a Wiimote. 15 
gestures from each gesture class, 10 for dictionary and 5 for 
testing are captured from 3 subjects. In total, we have 1035 
gesture traces from 3 subjects stored in xml format. These 
gesture files are then converted to .mat files which are then 
used as input for the SCR gesture recognition algorithm. 
 
145
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-195-3
MMEDIA 2012 : The Fourth International Conferences on Advances in Multimedia

 
Figure 3.  Mixed Gesture Set for Wiimote Gesture Recognition 
Our system gives 100% user-dependent recognition 
accuracy for each person with a full dictionary matrix which 
consists of 10 gestures for each gesture class including 230 
columns in total. To be able to provide a user independent 
gesture recognition system, the dictionary is built by 
arbitrarily chosen gestures from each subject with the same 
number of gestures from each class. Then, we used the 
remaining gestures for testing purposes.  The system 
misclassified only 2 gestures out of 300 test samples, 
corresponding to 99.33% recognition accuracy for 20 
gestures. 3 gestures were removed from the database, since 
one gesture class (star shown in Fig 3) was not collected 
from one of the subjects, and 2 gesture classes which are 
check mark and left arrow are performed in very different 
manner.  
 
Figure 4.  $1 Gesture Set [19] 
 
 
We tested our system also with the gesture sets of the $1 
gesture recognition study [19]. The set consists of 16 
different gestures collected from 11 subjects (Fig. 4.). 
Each gesture is repeated 10 times in a 3 speed profile 
(fast, slow and medium speed) by each subject. The gesture 
dictionary is built by choosing two random gestures. The 
random gestures belong to any speed profile from the gesture 
folder of each of 5 subjects, so that every gesture class 
consists of 10 gestures. The gestures tested are chosen from 
the remaining subjects‚Äô folder randomly. The SRC gesture 
recognition algorithm misclassified only 2 gestures out of 80 
test gestures with 97.5% accuracy. When the two 
misclassified gestures are analysed (Fig. 5.)  
It is seen that the algorithm confuses the circle and 
rectangle gesture since both of them is unclosed and even 
may be confused by human brain.    
 
 
Figure 5.  Confused Gestures in $1 Gesture Set 
IV. 
CONCLUSION 
In this paper, we presented a robust gesture and posture 
recognition algorithm based on an emerging research field 
CS and SR,  in signal processing for the wearable sensing 
garment which consists of a sensor network having piezo-
resistive properties. The gesture recognition algorithm we 
presented is highly accurate regardless of the signal 
acquisition method used, and gives excellent results even for 
high dimensional signals and large gesture dictionaries. Our 
findings state that gestures can be recognized with over 99% 
accuracy rate using the SRC algorithm.  
Gesture and posture recognition studies in which sensing 
garments are used have been studied in literature both 
theoretically 
and 
experimentally 
[6-7, 
20]. 
Various 
algorithms were proposed in those specific applications for 
gesture and posture recognition. Our algorithm outperforms 
in the gesture recognition studies realized by using the sensor 
jacket with an accuracy level 100% in mapping the sensor 
readings into gesture domain. 
This study can be extended for detection of postures in 
sensing 
garment 
based 
studies. 
There 
are 
several 
optimization algorithms proposed for the solution of convex 
optimization problems. We utilized GPRS (Gradient 
Projection for Sparse Reconstruction) method proposed by 
Mario et al. (2008) for the ‚Ñì1 linear programming problem, as 
it solves the reconstruction problem in a significantly shorter 
time [21]. 
Solution of the equations for the sensor jacket gesture 
recognition study takes less than 0.1 second with a AMD 
146
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-195-3
MMEDIA 2012 : The Fourth International Conferences on Advances in Multimedia

Turion 2x2.2Hz processor. This time period can be regarded 
sufficient for real time applications. The gesture recognition 
method given in this paper is promising and can provide 
solutions to high dimensional gesture recognition problems. 
Gesture spotting is the second fundamental problem in this 
research field. We focus on the development of a new 
algorithms which make use of recent developments for low-
rank and sparse matrix separation methods for robust posture 
recognition and gesture spotting. 
ACKNOWLEDGMENT 
This project is sponsored by the Australian Research 
council Discovery Grant (DP0988088) titled ‚ÄúA Gesture-
Based Interface for Designing in Virtual Reality‚Äù. 
 
REFERENCES 
[1] F. J. Perales,   "Human Motion Analysis & Synthesis using Computer 
Vision and Graphics Techniques State of Art and Applications" Proc. 
of the 5th World Multi-Conference on Systemics, Cybernetics and 
Informatics (SCI2001), July 2001. doi:10.1.1.90.6176. 
[2] C. Einsmann, M.  Quirk, B. Muzal, B. Venkatramani, B.,  T. Martin 
and M. Jones, "Modeling a Wearable Full-Body Motion Capture 
System". Proc. of 9th IEEE International Syposium on Wearable 
Computers,  Oct. 2005. pp. 144 ‚Äì 151.  doi=10.1.1.74.1235 
[3] J. G. Hagedorn,  S. G. Satterfield, J. T. Kelso, W. Austin, J.E. Terrill 
and A. E. Peskin, "Correction of Location and Orientation Errors in 
Electromagnetic Motion Tracking". in J. MIT Press Teleoperators and 
Virtual Environments, 2007, vol 16-4,  pp. 352 -- 366.    
[4] A. Hornung, S. Sar-Dessai and L. Kobbelt,  "Self-Calibrating Optical 
Motion Tracking for Articulated Bodies". Proc. of Virtual Reality 
(VR 2005),  IEEE Press. March  2005.  pp. 75 ‚Äì 82.  
[5] R. Slyper and J. K. Hodkings, "Action Capture with Accelerometers". 
Proc. of ACM SIGGRAPH/Eurographics Symposium on Computer 
Animation, ACM Press.  July 2008. pp. 193-199. 
[6] A. Tognetti, F.  Lorussi, R.  Bartalesi, S. Quaglini, M. Tesconi,   G. 
Zupone and D. De Rossi. "Wearable Kinesthetic System for 
Capturing and Classifying Upper Limb Gesture in Post-Stroke 
Rehabilitation". J. Neuro Engineering and Rehabilitation. June 2005. 
vol. 2, 1-16.  
[7] F. Lorussi, S. Galatolo and D. E. De Rossi. "Body Segment Position 
Reconstruction and Posture Classification by Smart Textiles". IEEE J. 
of Sensors. Sept. 2009. vol 9, pp. 1014 -- 1024, doi: 
10.1109/JSEN.2009.2024867. 
[8] T. Gulrez and M. Kavakli, M. "Precision Position Tracking in Virtual 
Reality Environments Using Sensor Networks". Proc. of IEEE 
International Symposium on Industrial Electronics (ISIE2007), Nov. 
2007. pp. 1997-2003. doi: 10.1109/ISIE.2007.4374914.  
[9] M. Kavakli. "Gesture Recognition in Virtual Reality". In: Special 
Issue on: Immersive Virtual, Mixed, or Augmented Reality Art of 
The International Journal of Arts and Technology (IJART), 2008, Vol 
1 no 2, pp. 215-229. doi: 10.1504/IJART.2008.021928.   
[10] J. Wright, A. Yang, A. Ganesh, S. Sastry and Y. Ma. "Robust Face 
Recognition via Sparse Representation", IEEE Transactions on 
Pattern Analysis and Machine Intelligence (PAMI). Feb. 2009. vol. 
31. issue 2,  pp. 210‚Äî227. doi: 10.1109/TPAMI.2008.79.  
[11] A. Akl and S. Valaee. "Accelerometer-based Gesture Recognition via 
Dynamic-Time Warping, Affinity Propagation, & Compressive 
Sensing". Proc. of IEEE International Conference on Acoustics 
Speech and Signal Processing (ICASSP). March 2010. pp 2270 ‚Äì 
2273. doi: 10.1109/ICASSP.2010.5495895.  
[12] B.J. Frey and D. Dueck. "Clustering by Passing Messages Between 
Data Points". Science. Feb. 200. Vol. 31, no. 5814, pp. 972--976. doi: 
10.1126/science.1136800. 
[13] E. Cand√®s, J. Romberg and T. Tao. "Robust Uncertainty Principles: 
Exact Signal Reconstruction from Highly Incomplete Frequency 
Information".  Feb. 2006. IEEE Trans. Inform. Theory, vol 52, issue 
2,  pp. 489--509. doi: 10.1109/TIT.2005.862083.    
[14] E. J. Cand√®s and T. Tao. "Near Optimal Signal Recovery from 
Random Projections: Universal Encoding Strategies?". IEEE Trans. 
Inform. Theory. Dec. 2006. vol. 52, issue 12, pp. 5406‚Äì5425. doi: 
10.1109/TIT.2006.885507  
[15] D. Donoho. "Compressed Sensing". IEEE Trans. Inform. Theory. 
Apr. 
2006. 
vol 
52, 
issue 
4, 
pp. 
1289--1306, 
 
doi: 
10.1109/TIT.2006.871582. 
[16] E.J. Cand√®s, and  M.B. Wakin "An Introduction To Compressive 
Sampling". IEEE Signal Processing Magazine, March 2008. vol 25, 
issue 2. pp. 21-30. doi: 10.1109/MSP.2007.914731. 
[17] R. G. Baraniuk, E.J. Cand√®s, E. Nowak and M. Vetterli. 
"Compressive Sensing". Signal Processing Magazine. March  
2008, 
 IEEE 
press, 
vol 
24(2), 
pp. 
12-13. 
 
doi: 
10.1109/MSP.2008.915557. 
[18] A. Dimitris. "Database-friendly Random Projections". Proc. of PODS 
'01 Proceedings of the twentieth ACM SIGMOD-SIGACT-SIGART 
symposium on Principles of database systems.  May 2001. pp. 274-
281.  doi: 10.1145/375551.375608.  
[19] J.O. Wobbrock, A.D. Wilson and Y.  Li. "Gestures without Libraries, 
Toolkits or Training: A $1 Recognizer for User Interface Prototypes". 
Proc. of the ACM Symposium on User Interface Software and 
Technology (UIST '07). ACM Press. Oct. 2007.  pp. 159-168.  doi:  
10.1145/1294211.1294238.  
[20] G. Pioggia, M. Ferro, G. Zupone, L. Chirulli, and D. D. Rossi, 
‚ÄúDevelopment of a sensing seat for human authentication". Proc. of 
3rd IET International Conference on Intelligent Environments. Sep. 
2007.  pp. 441‚Äì446. 
[21] M. Figueiredo, R. D. Nowak, and S. Wright, ‚ÄúGradient projection for 
sparse reconstruction: Application to compressed sensing and other 
inverse problems‚Äù. IEEE J. of Selected Topics in Signal Processing. 
Dec. 
2007. 
 
vol. 
1, 
no. 
4, 
pp. 
586‚Äì597. 
doi: 
10.1109/JSTSP.2007.910281.    
 
147
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-195-3
MMEDIA 2012 : The Fourth International Conferences on Advances in Multimedia

