Missing Categorical Data Imputation
for FCM Clusterings of Mixed Incomplete Data
Takashi Furukawa
Graduate school of Engineering
Hokkai-Gakuen University
Sapporo, Japan
Email: 6512103t@hgu.jp
Shin-ichi Ohnishi
Faculty of Engineering
Hokkai-Gakuen University
Sapporo, Japan
Email: ohnishi@hgu.jp
Takahiro Yamanoi
Faculty of Engineering
Hokkai-Gakuen University
Sapporo, Japan
Email: yamanoi@hgu.jp
Abstract—The Data mining is related to human congnitive
ability, and one of popular method is fuzzy clustering. The focus
of fuzzy c-means (FCM) clustering method is normally used on
numerical data. However, most data existing in databases are
both categorical and numerical. To date, clustering methods have
been developed to analyze only complete data. Although we,
sometimes, encounter data sets that contain one or more missing
feature values (incomplete data) in data intensive classiﬁcation
systems, traditional clustering methods cannot be used for such
data. Thus, we study this theme and discuss clustering methods
that can handle mixed numerical and categorical incomplete
data. In this paper, we propose some algorithms that use
the missing categorical data imputation method and distances
between numerical data that contain missing values. Finally, we
show through a real data experiment that our proposed method
is more effective than without imputation, when missing ratio
becomes higher.
Keywords-clustering; incomplete data; mixed data; FCM.
I.
INTRODUCTION
Clustering is the most popular method for discovering
group and data structures in datasets in data intensive classiﬁ-
cation systems. Fuzzy clustering allows each datum to belong
to some clusters. Thus data are classiﬁed into an optimal
cluster accurately [1]. The k-means algorithm is the most
popular algorithm used in scientiﬁc and industrial applications
because of its simplicity and efﬁciency. Whereas k-means
gives satisfactory results for numeric attributes, it is not appro-
priate for data sets containing categorical attributes because it
is not possible to ﬁnd a mean of categorical value. Although,
traditional clustering methods handle only numerical data, real
world data sets contain mixed (numerical and categorical) data.
Therefore, traditional clustering methods cannot be applied to
mixed data sets. Recently, clustering methods that deal with
mixed data sets have been developed [4][5].
Moreover, when we analyze real world data sets, we
encounter incomplete data. Incomplete data are found for
example through data input errors, inaccurate measures, and
noise. Traditional clustering methods cannot be directly ap-
plied to data sets that contain incomplete data, so we need
to treat such data. A common approach to analyzing data
with missing values is to remove attributes and/or instances
with large fractions of missing values. However, this approach
excludes partial data from analytical consideration and hence
compromises the reliability of results. Therefore, we need
analytical tools that handle incomplete categorical data, a
process that is called imputation. To date, many imputation
methods have been proposed, but most apply only to numerical
variables. Thus, when analyzing categorical data or mixed data
containing missing values, one has to eliminate from con-
sideration data with missing values. Moreover, an imputation
method applicable to fuzzy clustering is rare.
Fuzzy c-means (FCM) clustering is a very popular fuzzy
extension of k-means. However, FCM for mixed data cannot
be applied to data that contains missing data. Therefore, we
use the imputation method for missing categorical data, and
then we apply FCM clustering for mixed data. If we encounter
missing numerical data, we use the partial distance [7] instead
of the Euclidean distance.
In this paper, we describe the development of a fuzzy
clustering algorithm for mixed data with missing numerical
and categorical data. The next section introduces the FCM
algorithm. Section III presents the clustering algorithm for
mixed data. Sections IV and V introduce the missing categor-
ical imputation method, and the notion of distance between
data that contain missing values. Section VI proposes a fuzzy
clustering algorithm that can treat mixed incomplete data.
Finally, Section VI shows through a real data experiment
that our proposed method is more effective than without
imputation, when missing ratio becomes higher.
II.
FUZZY c-MEANS CLUSTERING
The FCM algorithm proposed by Dunn [1] and extended
by Bezdek [2] is one of the most well-known algorithms in
fuzzy clustering analysis. This algorithm uses the squared-
norm to measure similarities between cluster centers and data
points. It can only be effective in clustering spherical clusters.
To cluster more general datasets, a number of algorithms
have been proposed by replacing the squared-norm with other
similarity measures [3]. The notation that we use throughout
is as follows. Let xi = (xij), i = 1, . . . , n, j = 1, . . . , m is a
feature value of the ith data vector, c is the number of clusters.
bc = (bc1, . . . , bcm)T is the cluster center of the cth cluster,
uci is the degree to which xi belongs to the cth cluster. Then,
uci satisﬁes the following constraint
C
∑
c=1
uci = 1, i = 1, . . . , n
(1)
94
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

The FCM algorithm for solving (2) alternates the optimiza-
tions of Lfcm over the variables u and b
Lfcm =
C
∑
c=1
n
∑
i=1
uθ
ci


m
∑
j=1
(xij − bcj)2


(2)
where θ is the fuzziﬁcation parameter (θ > 1). Minimizing the
u values of (2) are less fuzzy for values of θ near 1 and fuzzier
for large values of θ. The choice θ = 2 is widely accepted as
a good choice of fuzziﬁcation parameter.
III.
FUZZY c-MEANS CLUSTERING FOR MIXED
DATABASES
The FCM algorithm has been widely used and adapted.
However, only numerical data can be treated; categorical data
cannot. When we analyze categorical data, we have to imple-
ment a quantiﬁcation of such data. For example, suppose we
obtained n sample data that have m categorical data consisting
of Kj categories.
Then, the jth item data can be expressed as an (n × Kj)
dummy variable matrix Gj = {gijk}, i = 1, . . . , n, k =
1, . . . , Kj
gijk =
{1,
data i contains category k
0,
otherwise
(3)
Honda et al. proposed a method that combined the quantiﬁ-
cation of categorical data and the fuzzy clustering of numerical
data [6]. The variables up to (m − q) are numerical; the rest
is categorical. Calculating
L =
C
∑
c=1
n
∑
i=1
uθ
ci


m−q
∑
j=1
(xij − bcj)2 +
m
∑
j=m−q+1
(gT
ijqj − bcj)2

 (4)
where qj is a categorical score, which can be computed as
follows
qj =
(
GT
j
(
C
∑
c=1
U θ
c
)
Gj
)−1( C
∑
c=1
bcjGT
j U θ
c 1n
)
(5)
To obtain a unique solution, we impose the following con-
straint.
1T
nGjqj = 0
(6)
qT
j GT
j Gjqj = n
(7)
Algorithm: Fuzzy c-means algorithm for mixed databases
1.
Initialize membership uci, c = 1, . . . , C, i = 1, . . . , n
and cluster center bcj, c = 1, . . . , C, then normalize
uci satisfying (1).
2.
Update category score qj, j = m−q+1, . . . , m, using
(5) according to constraint conditions (6) and (7). We
then interpret gT
ijqj as the jth numerical score xij.
3.
Update cluster center bcj using
bcj =
∑n
i=1 uθ
cixij
∑n
i=1 uθ
ci
(8)
4.
Update membership uci using
uci =
( C
∑
l=1
(Dci
Dli
)
1
θ−1 )−1
(9)
where
Dci = ∥xi − bc∥2
(10)
If xi = bc, uci = 1/Ci
5.
Let ϵ judgment value for convergence. Compare
uNEW
ci
to uOLD
ci
using
max
c,i ∥uNEW
ci
− uOLD
ci
∥ < ϵ
(11)
If true then stop, otherwise return to Step 2.
IV.
MISSING CATEGORICAL DATA IMPUTATION METHOD
Recently, missing data imputation has been recognized
and developed as an important task. However, we are not
accustomed to combining the clustering algorithm and the im-
putation method. Most missing data imputations are restricted
to only numerical data. There are a few methods that permit
missing categorical data or mixed data imputation [8][9].
If attributes and/or instances are missing, we do not apply
the clustering algorithm. Instead, we apply the imputation
method to ﬁll the missing values, and then we can apply
the clustering algorithm. In this paper, we use the missing
categorical data imputation method, a“novel rough set model
based on similarity”, as proposed by Sen et al. [7].
DEFINITION 1. (Missing Attribute Set) An incomplete infor-
mation system is denoted S =< U, A, V, f >; with attribute
set A = {ak|k = 1, 2, . . . , m}; V is the domain of the
attribute. V = Vk, Vk is the domain of the attribute ak, which
is the category value. ak(xi) is the value of attribute ak of
object xi, and ”∗” means missing value. The missing attribute
set (MAS) of object xi is deﬁned as follows:
MASi = {k | ak(xi) = ∗, k = 1, 2, . . . , m}
DEFINITION 2. (Similarity between objects) For two objects
xi ∈ U and xj ∈ U, their similarity Pk(xi, xj) of attribute ak
is deﬁned as
Pk(xi, xj) =
{1, ak(xi) = ak(xj) ∧ ak(xi) ̸= ∗ ∧ ak(xj) ̸= ∗
0, ak(xi) ̸= ak(xj) ∨ ak(xi) = ∗ ∨ ak(xj) = ∗
(12)
Then the similarity of the two objects of all attributes is
deﬁned as:
P(xi, xj) =



0, ∃ak ∈ A(ak(xi) ̸= ak(xj) ∧ ak(xi) ̸= ∗
∧ak(xj) ̸= ∗
∑m
k=1 Pk(xi, xj), others
(13)
The similarity matrix is M(i, j) = P(xi, xj).
DEFINITION 3. (Nearest undifferentiated set (NS) of an
object) The NS of object xi ∈ U is deﬁned as a set NSi
of objects that have a maximum similarity:
NSi = {j | (M(i, j) = max
xk∧k̸=i(M(i, k))) ∧ M(i, j) > 0}
Algorithm: Missing Categorical Data Imputation
95
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

1.
Set parameter num = 0 to record the quantity of
imputation data in the current iteration; for all the
xi ∈ U, if xi has missing attribute, compute its miss-
ing attribute set MASi and nearest undifferentiated
set NSi;
2.
For all the objects xi that have missing attributes,
which means MASi ̸= φ, do the perform loop for
all the k ∈ MASi in order:
2.1
if |NSi| = 0,
break(to deal with the next missing attribute object);
2.2
if |NSi| = 1, assume j ∈ NSi and ak(xj) ̸= ∗, then:
ak(xi) = ak(xj);
num + +;
2.3
if |NSi| ≥ 2,
2.3.1
If there exists m, n ∈ NSi satisﬁed
(ak(xm) ̸= ∗)∧(ak(xn) ̸= ∗)∧(ak(xm) ̸= ak(xn)),
set:
ak(xi) = ∗;
2.3.2
Otherwise, if there exists j0 ∈ N and ak(xj0) :
num + +;
3.
if num > 0, return to Step 1, otherwise, go to step
4;
4.
End. Other methods can be used.
V.
DISTANCES BETWEEN DATA THAT CONTAIN MISSING
VALUES
In
some
situations,
the
feature
vectors
in
X
=
{x1, . . . , xn} can have missing feature values. Any data with
some missing feature values are called incomplete data. The
original FCM algorithm and the FCM algorithm for mixed
databases is a useful tool, but it is not directly applicable to
data that contain missing values. Hathaway et al. proposed
four approaches to incomplete data[7]: the whole data strat-
egy (WDS), the partial distance strategy (PDS), the optimal
completion strategy (OCS), and the nearest prototype strategy
(NPS). In WDS, if the proportion of incomplete data is small,
then it may be useful to simply delete all incomplete data and
apply FCM to the remaining complete data. WDS should be
used only if np
nx ≤ 0.75, where np = |XP | and ns = |X| · m.
The cases when missing values ∥XM∥ are sufﬁciently large
that the use of the WDS cannot be justiﬁed entails calculating
partial (squared Euclidean) distances using all available (non-
missing) feature values, and then scaling this quantity by the
reciprocal of the proportion of components used. For this study,
we used the PDS approach for mixed databases containing
incomplete data.
In the PDS approach, the general formula for the partial
distance calculation of Dci is
Dci = m
Ii
m
∑
j=1
(xij − bcj)2Iij
(14)
where
Iij =
{0
(xij ∈ XM)
1
(xij ∈ XP )
for 1 ≤ i ≤ n, 1 ≤ j ≤ m
(15)
Ii =
m
∑
j=1
Iij
(16)
XP = {xij| the value for xij is present in X}
XM = {xij| the value for xij is missing from X}
For example, let m = 3 and n = 4. Denoting missing
values by *,
X =


1
∗
∗
4
∗


Then, XP = {x1 = 1, x4 = 4} , XM = {x2, x3, x5}, and
Dci = ∥xi − bc∥2
2
= ∥(1 ∗ ∗ 4 ∗)T − (5 6 7 8 9)T∥2
2
=
5
(5 − 3)((1 − 5)2 + (4 − 8)2)
(17)
The PDS version of the FCM algorithm, is obtained by
making two modiﬁcations of the FCM algorithm. First, we
calculate Dci in (10) for incomplete data according to (14) –
(16). Second, we replace the calculation of b in (8) with
bcj =
∑n
i=1 uθ
ciIijxcj
∑n
i=1 uθ
ciIij
(18)
VI.
FCM FOR MIXED DATABASES WITH INCOMPLETE
DATA
For clustering analysis, treating missing data becomes
especially important when the fraction of missing values is
large and the data are of mixed type. We combine the FCM
algorithm for mixed databases with the imputation method
and the PDS approach to construct a FCM algorithm for
mixed databases containing missing values. Here, we assume
incomplete mixed data xij, i = 1, . . . , n, j = 1, . . . , m, the
values up to m − q correspond to numerical data and the
rest is categorical. The dummy valuable matrix Gj = {gijk},
k = 1, . . . , Kj, is described in equation (3). Applying the FCM
algorithm to mixed databases that contain incomplete data is
considered as follows:
Algorithm: FCM for mixed databases containing incom-
plete data
1.
If there are missing categorical data, use the impu-
tation algorithm described in Section IV, and sepa-
rate the complete categorical data xij(i = 1, . . . , n,
j = m − q + 1, . . . , m)
2.
Initialize membership uci and cluster center bcj, then
normalize uci satisfying ∑n
i=1 uci = 1, i = 1, . . . , n.
3.
Update the category score
qj =
(
GT
j
(
C
∑
c=1
U θ
c
)
Gj
)−1( C
∑
c=1
bcjGT
j U θ
c 1n
)
(19)
according to the following constraint conditions:
1T
nGjqj = 0
(20)
96
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

qT
j GT
j Gjqj = n.
(21)
We interpret gT
ijqj to be the jth numerical score xij.
4.
Update cluster center bcj using
bcj =
∑n
i=1 uθ
ciIijxcj
∑n
i=1 uθ
ciIij
(22)
5.
Update membership uci using
uci =
( C
∑
l=1
(Dci
Dli
)
1
θ−1 )−1
(23)
where Dci is calculated form
Dci = m
Ii
m
∑
j=1
(xij − bcj)2Iij
(24)
6.
Let ϵ be a set value to judge convergence. Then
compare uNEW
ci
to uOLD
ci
using
max
c,i ∥uNEW
ci
− uOLD
ci
∥ < ϵ
(25)
If true, then stop, otherwise return to Step 3.
VII.
EXPERIMENTAL RESULTS
In this section, we show the performance of our algorithm
for mixed incomplete data.
We use credit approval datasets from UCI Machine Learn-
ing Repository which have 683 samples, 15 attributes(6 is
numerical and the rest categorical), and 53 missing values.
Table I lists the type of attribute(”N” is numerical and ”C” is
categorical) and the number of missing values. This database
has its own real classiﬁcation result, i.e., each sample has been
classiﬁed into 2 groups ”+” or ”−”.
Fig. 1 the result for this incomplete mixed data using the
proposed fuzzy clustering method; The number of samples
with membership value over 10 intervals between 0 and 1 are
found. 77% of the ”+” group samples have high membership
in cluster1 and almost all of ”−” group samples are strongly
classiﬁed in cluster 2. The fuzziﬁcation parameter θ is 1.2. The
result shows that our proposed method is applicable for these
real data.
Next, we compared following four methods; (I) Using
Imputation method for categorical missing values, PDS for
non-imputation missing values and numerical missing values
(Imp + PDS). (II) Using imputation method for categorical
missing values, WDS for non-imputation missing values and
PDS for numerical missing values (Imp + PDS + WDS). (III)
Using PDS for all missing values (PDS). (IV) Using WDS for
all missing values (WDS).
Fig. ?? shows the results of these 4 methods. This graph’s
positive area indicate numbers of ”+” group samples that have
membership value to cluster1, and area of negative indicate ”-”
group samples data to cluster2. Results of (II) and (IV) have
enough high membership samples (from 0.9 to 1.0).
Finally, we change missing ratio (from 0.7% to 0.9% and
1.2%) and apply four methods. Results are shown in Fig. 3
to 6. (II)Imp+PDS+WDS and (III)PDS cannot classify enough
when missing ratio is high (1.2%) in Fig. 4 and 5. Further in
TABLE I.
ATTRIBUTES AND MISSING VALUES
Attribute
type
Category
Missing
A1
C
2
12
A2
N
-
12
A3
N
-
0
A4
C
4
6
A5
C
3
6
A6
C
14
6
A7
C
9
6
A8
N
-
0
A9
C
2
0
A10
C
2
0
A11
N
-
0
A12
C
2
0
A13
C
3
0
A14
N
-
13
A15
N
-
0
Fig. 1.
Fuzzy Clustering Result(Real data)
Fig. 6, (IV)WDS have a lot of samples that cannot be used in
any missing ratio (especially in high missing ratio), because
this method except all sample data which contain missing
values(describe value of 0 in each graph). From these point
of view, (I) Imp+PDS can be better method for these dataset
as shown in Fig. 3.
Fig. 2.
Comparing four methods
97
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

Fig. 3.
Missing Result of PDS (I)
Fig. 4.
Missing result of WDS (II)
Fig. 5.
Missing result of Imp + PDS (III)
Fig. 6.
Missing result of Imp + WDS + PDS (IV)
VIII.
CONCLUSION
In this paper, we discussed a FCM clustering algorithm that
handles mixed data containing missing values. In our study,
we applied the imputation method to missing categorical data
before clustering, followed by the FCM clustering algorithm.
When we encountered numerical missing data, we used the
PDS (and WDS) distance for numerical missing data. A real
data experiment shows that our proposed method is more
effective than without imputation, when missing ratio becomes
higher. To obtain better performance during the clustering
analysis for mixed data containing missing values, we plan
to apply our algorithm to another datasets, too.
REFERENCES
[1]
J. C. Dunn, A Fuzzy Relative of the ISODATA Process and Its Use in
Detecting Compact Well-Separated Clusters, Journal of Cybernetics 3:
32-57, 1973.
[2]
J. C. Bezdek, Pattern Recognition with Fuzzy Objective Function
Algorithms, Plenum Press, 1981
[3]
W. Sen, F. Xiaodong, H. Yushan, and W. Qiang, Missing Categorical
Data Imputation Approach Based on Similarity, IEEE International
conference on Systems, Man, and Cybernetics, 2012.
[4]
Y. Naija, K. Blibech, S. Chakhar, and R. Robbana, Extension of Parti-
tional Clustering Methods for Handling Mixed Data, IEEE International
Conference on Data Mining Workshop, 2008.
[5]
K. L. Wu and M. S. Yang, Alternative c-means clustering algorithms,
Pattern Recognition vol. 35, pp. 2267-2278, 2002.
[6]
K. Honda and H. Ichihashi, Fuzzy c-means clustering of mixed
databases including numerical and nominal variables, Cybernetics and
Intelligent Systems, 2004 IEEE Conference on, vol. 1, 2004
[7]
R. J. Hathaway and J. C. Bezdek, Fuzzy c-means Clustering of
Incomplete Data, IEEE Transactions on Systems, Man and Cybernetics,
Part B, Vol.31, No. 5, pp.735-744, 2001
[8]
K. Bache and M. Lichman, UCI Machine Learning Repository
[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,
School of Information and Computer Science [retrieved: Feb. 2014]
98
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

